<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Haskell 基本语法（三）递归]]></title>
    <url>%2F2021%2F06%2F29%2Fbasic-haskell-recursion%2F</url>
    <content type="text"><![CDATA[递归是一种定义函数的方式，在该方式下，函数的定义中调用了该函数本身。有点像俄罗斯套娃。 数学中的定义很多时候都会用到递归，比如 fibonacci 数列： F(0) = 1 F(1) = 1 F(n) = F(n - 1) + F(n - 2) 于是有 F(3) = F(2) + F(1) = (F(1) + F(0)) + F(1) = 2。 递归函数的定义中，并不只是包含调用自身的代码，常常还需要非递归形式的定义，如上面的 F(0) = 1 和 F(1) = 1。这样的代码称作边缘条件（edge condition）。边缘条件对于递归函数的终止至关重要。假如上面的 F(0) 和 F(1) 未定义，则任何一个输入都会导致函数无限调用自身，永远不会终止。 递归是 Haskell 中很重要的概念。不同于命令式的语言，在 Haskell 中需要定义计算本身是什么，而不是定义怎样一步步得出结果。 求最大值1234567maximum' :: (Ord a) =&gt; [a] -&gt; amaximum' [] = error "maximum of empty list"maximum' [x] = xmaximum' (x:xs) | x &gt; maxTail = x | otherwise = maxTail where maxTail = maximum' xs 使用 max 函数（返回两个输入值中较大的那个）编写更短的形式：1234maximum' :: (Ord a) =&gt; [a] -&gt; amaximum' [] = error "maximum of empty list"maximum' [x] = xmaximum' (x:xs) = max x (maximum' xs) 当输入为 [2, 5, 1] 时，计算过程如下：maximum&#39; [2, 5, 1] -&gt; max 2 (maximum&#39; [5, 1]) -&gt; max 2 (max 5 (maximum&#39; [1])) -&gt; max 2 (max 5 1) -&gt; max 2 5 -&gt; 5。 生成由固定数量的同一元素构成的列表1234replicate' :: (Num i, Ord i) =&gt; i -&gt; a -&gt; [a]replicate' n x | n &lt;= 0 = [] | otherwise = x:replicate' (n-1) x 如 replicate&#39; 3 5 -&gt; 5:(replicate&#39; 2 5) -&gt; 5:(5:(replicate&#39; 1 5)) -&gt; 5:(5:(5:(replicate&#39; 0 5))) -&gt; 5:(5:(5:[])) -&gt; [5, 5, 5]。 取出列表中的前几个元素12345take' :: (Num i, Ord i) =&gt; i -&gt; [a] -&gt; [a] take' n _ | n &lt;= 0 = []take' _ [] = []take' n (x:xs) = x : take' (n-1) xs 其中 take&#39; n _ 和 take&#39; _ [] 分别作为两种不同情况下的终止条件。第一个模式 take&#39; n _ 表示当 n 小于等于 0 时，不管输入的是什么样的列表都返回空列表 []。可以作为如 take&#39; 2 [1, 2, 3] 的终止条件。即前两个元素被取出并拼接成 [1, 2] 后 n 等于 0，满足第一个模式，递归终止。第二个模式 take _ [] 表示当输入的列表是空列表时，不管 n 是多少都返回空列表。可以作为如 take&#39; 3 [1, 2] 的终止条件。即前两个元素被取出并拼接成 [1, 2] 后，n 为 1，但列表成为空列表，满足第二个模式，递归终止。第三个模式 take&#39; n (x:xs) 则用来定义从输入的列表头部逐个取出 n 个元素并拼接成新列表的递归逻辑。 reverse 的自定义实现123reverse' :: [a] -&gt; [a]reverse' [] = []reverse' (x:xs) = reverse' xs ++ [x] zip 的自定义实现1234zip' :: [a] -&gt; [b] -&gt; [(a,b)]zip' _ [] = []zip' [] _ = []zip' (x:xs) (y:ys) = (x,y):zip' xs ys elem 的自定义实现（判断某个元素是否属于某个列表）12345elem' :: (Eq a) =&gt; a -&gt; [a] -&gt; Boolelem' a [] = Falseelem' a (x:xs) | a == x = True | otherwise = a `elem'` xs 快速排序123456quicksort :: (Ord a) =&gt; [a] -&gt; [a]quicksort [] = []quicksort (x:xs) = let smallerSorted = quicksort [a | a &lt;- xs, a &lt;= x] biggerSorted = quicksort [a | a &lt;- xs, a &gt; x] in smallerSorted ++ [x] ++ biggerSorted 递归思维递归函数的定义通常遵循如下模式： 定义边缘条件（edge conditon）用于在特定条件下终止递归的执行 取出部分元素执行特定操作，再调用递归函数本身处理剩余的元素 某个列表中所有元素之和等于该列表的第一个元素加上剩余的所有元素之和；某个列表的长度等于尾部（去除头部第一个元素）所有元素的长度加 1。 通常情况下，edge condition 就是令递归函数无实际意义的条件。对于列表来说，最常见的 edge condition 就是空列表。 参考资料Learn You a Haskell for Great Good!]]></content>
      <categories>
        <category>Program</category>
      </categories>
      <tags>
        <tag>Haskell</tag>
        <tag>Program</tag>
        <tag>Functional</tag>
        <tag>Recursion</tag>
        <tag>Function</tag>
        <tag>Computation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Haskell 基本语法（二）模式匹配]]></title>
    <url>%2F2021%2F06%2F25%2Fbasic-haskell-pattern-match%2F</url>
    <content type="text"><![CDATA[式匹配包含一系列特定的模式，用来判断数据是否符合规则，且能够通过这些模式把符合要求的数据解构出来。Haskell 中的模式匹配可以应用到任意的数据类型上（数字、字符、列表、元组等等）。 函数中的模式匹配可以在函数体的定义中，用不同的代码行分别指定不同的模式：123456789101112Prelude&gt; :&#123;Prelude| lucky :: (Integral a) =&gt; a -&gt; StringPrelude| lucky 7 = "LUCKY NUMBER SEVEN!"Prelude| lucky x = "Sorry, you're out of luck!"Prelude| :&#125;Prelude&gt;Prelude&gt; lucky 1"Sorry, you're out of luck!"Prelude&gt; lucky 10"Sorry, you're out of luck!"Prelude&gt; lucky 7"LUCKY NUMBER SEVEN!" PS：上述代码是在 Haskell 的交互式解释器（REPL) ghci 中定义和执行函数的效果。像 lucky 这种包含多行代码的函数，在 ghci 解释器中直接定义时，需要把整个函数体用 :{ 和 :} 括起来（否则解释器会报错）。实际的 lucky 函数代码应为：123lucky :: (Integral a) =&gt; a -&gt; String lucky 7 = "LUCKY NUMBER SEVEN!" lucky x = "Sorry, you're out of luck, pal!" 即 :{ 和 :} 从代码的角度讲是多余的，只是 ghci 解释器的缘故，导致必须加上这两个分隔符。若在文件中编写代码，则应该使用第二种形式。 代码的第一行 lucky :: (Integral a) =&gt; a -&gt; String 是函数的类型签名，也可以省略，解释器会自行推导。lucky 7 和 lucky x 两行代码则指定了具体的两个模式：当函数输入为数字 7 时匹配第一个模式，任何其他的数字输入则匹配第二个模式并将该输入值绑定给变量 x。 一个包含更多个模式的函数：1234567sayMe :: (Integral a) =&gt; a -&gt; String sayMe 1 = "One!" sayMe 2 = "Two!" sayMe 3 = "Three!" sayMe 4 = "Four!" sayMe 5 = "Five!" sayMe x = "Not between 1 and 5" 需要注意的是，最后一行代码 sayMe x 必须作为最后一个模式。函数体中的模式会按照自顶而下的顺序检查是否匹配，若当前的模式已完成匹配，则忽略后面的检查；若当前模式不匹配，则继续向下逐个进行检查。若 sayMe x 作为顶部的第一个模式（它实际上会匹配所有合法值），则任何输入值都会在第一步就完成匹配，进而忽略后面的 sayMe 1、sayMe 2 等模式，不再进行判断。即输入任何数字都会先匹配 x 并输出 Not between 1 and 5。 使用模式匹配和递归实现阶乘函数123factorial :: (Integral a) =&gt; a -&gt; a factorial 0 = 1 factorial n = n * factorial (n - 1) 比如当输入为 3 时，factorial 函数会匹配第二个模式，结果为 3 * (factorial 2)。继续迭代，进一步计算结果中的 factorial 2，得到 3 * (2 * (factorial 1))、3 * (2 * (1 * (factorial 0)))。而 factorial 0 会匹配第一个模式得到结果 1，迭代终止，再和前面的数字相乘后得到最终结果。 假如将 factorial n = n * factorial (n - 1) 作为第一个模式，则 factorial n 会匹配包含数字 0 在内的所有数字，另一个模式 factorial 0 = 1 就永远不会触发。从而导致迭代没有终止条件，一直进行下去。因此，在模式匹配中，更精确更有指向性的模式总是放在相对通用和宽泛的模式前面。 在使用模式匹配时，应该总是包含一个 catch-all 模式，这样就不会出现所有模式都不匹配的情况。若程序的输入与所有模式都不匹配，程序会崩溃掉。12345678910111213Prelude&gt; :&#123;Prelude| charName :: Char -&gt; StringPrelude| charName 'a' = "Albert"Prelude| charName 'b' = "Broseph"Prelude| charName 'c' = "Cecil"Prelude| :&#125;Prelude&gt;Prelude&gt; charName 'a'"Albert"Prelude&gt; charName 'b'"Broseph"Prelude&gt; charName 'h'*** Exception: &lt;interactive&gt;:(3,1)-(5,22): Non-exhaustive patterns in function charName 元组中的模式匹配在不使用模式匹配的情况下，实现一个计算两个向量之和的函数：12addVectors :: (Num a) =&gt; (a, a) -&gt; (a, a) -&gt; (a, a)addVectors a b = (fst a + fst b, snd a + snd b) 通过模式匹配实现上述功能：1234567Prelude&gt; :&#123;Prelude| addVectors :: (Num a) =&gt; (a, a) -&gt; (a, a) -&gt; (a, a)Prelude| addVectors (x1, y1) (x2, y2) = (x1 + x2, y1 + y2)Prelude| :&#125;Prelude&gt;Prelude&gt; addVectors (1, 2) (3, 4)(4,6) fst 和 snd 函数可以分别用来获取元组中的第一个和第二个元素（但是只针对包含两个元素的元组）。对于有 3 个元素的元组，实际上可以借助模式匹配自己实现：12345678first :: (a, b, c) -&gt; afirst (x, _, _) = x second :: (a, b, c) -&gt; bsecond (_, y, _) = y third :: (a, b, c) -&gt; cthird (_, _, z) = z 可以在列表推导中使用模式匹配：123Prelude&gt; let xs = [(1,3), (4,3), (2,4), (5,3), (5,6), (3,1)]Prelude&gt; [a+b | (a,b) &lt;- xs][4,7,6,8,11,4] 甚至列表本身也可以用于模式匹配。如模式 x:xs 会将列表的第一个元素绑定给变量 x，把其余元素绑定给 xs。此模式的应用非常普遍，尤其是在递归函数中。如果想提取列表的前 3 个元素并将它们绑定给指定变量，可以使用 x:y:z:zs 形式的模式。 利用对列表的模式匹配实现自定义的 head 函数（获取列表中的第一个元素）：12345678910Prelude&gt; :&#123;Prelude| head' :: [a] -&gt; aPrelude| head' [] = error "Can't call head on an empty list!"Prelude| head' (x:_) = xPrelude| :&#125;Prelude&gt;Prelude&gt; head' [4, 5, 6]4Prelude&gt; head' "Hello"'H' 借助递归和模式匹配实现自定义的 length 函数（获取列表的长度）：123length' :: (Num b) =&gt; [a] -&gt; blength' [] = 0length' (_:xs) = 1 + length' xs 对于任何一个合法的输入如 &quot;ham&quot;，length&#39; 函数的计算过程如下：length&#39; &quot;ham&quot; =&gt; 1 + length&#39; &quot;am&quot; =&gt; 1 + (1 + length&#39; &quot;m&quot;) =&gt; 1 + (1 + (1 + length&#39; [])) =&gt; 1 + (1 + (1 + 0)) 实现自定义的 sum 函数（求列表中各元素之和）：123sum' :: (Num a) =&gt; [a] -&gt; asum' [] = 0sum' (x:xs) = x + sum' xs 守卫（guards）守卫一般用来测试某个（些）值的特定属性是否为真，很像 if 语句。守卫和模式整合得非常好。 以下是一个求 BMI（体重指数）的函数定义：123456bmiTell :: (RealFloat a) =&gt; a -&gt; StringbmiTell bmi | bmi &lt;= 18.5 = "You're underweight, you emo, you!" | bmi &lt;= 25.0 = "You're supposedly normal. Pffft, I bet you're ugly!" | bmi &lt;= 30.0 = "You're fat! Lose some weight, fatty!" | otherwise = "You're a whale, congratulations!" 管道符（|）后面的布尔表达式即为守卫的定义。若该表达式计算结果为 True，则对应的代码被执行。若该表达式计算结果为 False，则继续测试下一个守卫。 通常情况下，最后一个守卫是 otherwise。它其实是 otherwise = True 的简写形式，会捕获所有剩余的情况。 守卫可以配合有多个参数的函数使用：123456bmiTell :: (RealFloat a) =&gt; a -&gt; a -&gt; StringbmiTell weight height | weight / height ^ 2 &lt;= 18.5 = "You're underweight, you emo, you!" | weight / height ^ 2 &lt;= 25.0 = "You're supposedly normal. Pffft, I bet you're ugly!" | weight / height ^ 2 &lt;= 30.0 = "You're fat! Lose some weight, fatty!" | otherwise = "You're a whale, congratulations!" 12Prelude&gt; bmiTell 65 1.75"You're supposedly normal. Pffft, I bet you're ugly!" 通过守卫自定义 max 函数：1234max' :: (Ord a) =&gt; a -&gt; a -&gt; amax' a b | a &gt; b = a | otherwise = b where可以通过 where 关键字优化上面的 bmiTell 函数：1234567bmiTell :: (RealFloat a) =&gt; a -&gt; a -&gt; StringbmiTell weight height | bmi &lt;= 18.5 = "You're underweight, you emo, you!" | bmi &lt;= 25.0 = "You're supposedly normal. Pffft, I bet you're ugly!" | bmi &lt;= 30.0 = "You're fat! Lose some weight, fatty!" | otherwise = "You're a whale, congratulations!" where bmi = weight / height ^ 2 变量 bmi 在这里只计算了一次，不同于之前的 weight / height ^ 2 有可能会被重复计算 3 次。 更进一步，bmiTell 函数还可以改为如下形式：12345678910bmiTell :: (RealFloat a) =&gt; a -&gt; a -&gt; StringbmiTell weight height | bmi &lt;= skinny = "You're underweight, you emo, you!" | bmi &lt;= normal = "You're supposedly normal. Pffft, I bet you're ugly!" | bmi &lt;= fat = "You're fat! Lose some weight, fatty!" | otherwise = "You're a whale, congratulations!" where bmi = weight / height ^ 2 skinny = 18.5 normal = 25.0 fat = 30.0 where 语句中也可以定义函数，比如通过由多个包含身高体重的元组组成的列表，计算一系列 BMI 值：123calcBmis :: (RealFloat a) =&gt; [(a, a)] -&gt; [a]calcBmis xs = [bmi w h | (w, h) &lt;- xs] where bmi weight height = weight / height ^ 2 参考资料Learn You a Haskell for Great Good!]]></content>
      <categories>
        <category>Program</category>
      </categories>
      <tags>
        <tag>Haskell</tag>
        <tag>Functional</tag>
        <tag>Recursion</tag>
        <tag>GHC</tag>
        <tag>Pattern</tag>
        <tag>Match</tag>
        <tag>Deconstruction</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[The Rust programming language 读书笔记——模式匹配]]></title>
    <url>%2F2021%2F06%2F23%2Fthe-rust-programming-language-reading-notes-pattern-match%2F</url>
    <content type="text"><![CDATA[模式是 Rust 中一种用来匹配类型结构的特殊语法，将其与 match 表达式或其他工具配合使用可以更好地控制程序流程。模式被用来与某个特定的值进行匹配，若匹配成功，则可以继续使用这个值的某些部分；若匹配失败，模式对应的代码就被简单地略过。 模式的应用场景match 分支模式可以被应用在 match 表达式的分支中。match 表达式由 match 关键字、待匹配的值以及至少一个匹配分支组成。匹配分支则由某个模式及模式匹配成功后应当执行的表达式组成。12345match 值 &#123; 模式 =&gt; 表达式, 模式 =&gt; 表达式, 模式 =&gt; 表达式,&#125; match 表达式必须穷尽匹配值的所有可能性。为了确保代码满足要求，可以在最后的分支处使用全匹配模式。例如变量名可以被用来覆盖所有剩余的可能性。还有一个特殊的 _ 模式可以被用来匹配所有可能的值，且不将它们绑定到任何一个变量上。即忽略所有未被指定的值。12345678910fn main() &#123; let some_value = 3; match some_value &#123; 1 =&gt; println!("one"), 3 =&gt; println!("three"), 5 =&gt; println!("five"), 7 =&gt; println!("seven"), _ =&gt; (), &#125;&#125; if let 表达式12345678910111213141516fn main() &#123; let favorite_color: Option&lt;&amp;str&gt; = None; let age: Result&lt;u8, _&gt; = "34".parse(); if let Some(color) = favorite_color &#123; println!("Using your favorite color &#123;&#125; as the background", color); &#125; else if let Ok(age) = age &#123; if age &gt; 30 &#123; println!("Using purple as the background color"); &#125; else &#123; println!("Using orange as the background color"); &#125; &#125; else &#123; println!("Using blue as the background color"); &#125;&#125; 上述代码通过执行一系列的条件检查来确定使用的背景颜色。其中的变量已经被赋予了硬编码值，但现实中应当通过用户输入来获取这些值。 和 match 分支类似，if let 分支能够以同样的方式对变量进行覆盖。if let Ok(age) = age 这句代码中引入了新的变量 age 来存储 Ok 变体中的值，并覆盖了右侧的同名变量。 while let 循环while let 会反复执行同一个模式匹配直到出现失败的情形。1234567891011fn main() &#123; let mut stack = Vec::new(); stack.push(1); stack.push(2); stack.push(3); while let Some(top) = stack.pop() &#123; println!("&#123;&#125;", top); &#125;&#125; 上面的代码会依次打印 3、2、1。其中的 pop 方法会尝试取出动态数组的最后一个元素并将它包裹在 Some(value) 中返回。若动态数组为空，则 pop 返回 None。while 循环会在 pop 返回 Some 时执行循环体中的代码，pop 返回 None 时结束循环。 for 循环for 语句中紧随关键字 for 之后的值就是一个模式。比如 for x in y 中的 x 就是一个模式。 在 for 循环中使用模式来解构元组：1234567fn main() &#123; let v = vec!['a', 'b', 'c']; for (index, value) in v.iter().enumerate() &#123; println!("&#123;&#125; is at index &#123;&#125;", value, index); &#125;&#125; 上述代码使用 enumerate 方法作为迭代器的适配器，会在每次迭代过程中生成一个包含值本身及其索引的元组。如首次调用 enumerate 会产生元组 (0, &#39;a&#39;)。当这个值与模式 (index, value) 进行匹配时，index 就会被赋值为 0，value 就会被赋值为 ‘a’。 let 语句最基本的 let 赋值语句中也同样用到了模式。更正式的 let 语句的定义如下：let PATTERN = EXPRESSION; 在类似于 let x = 5; 这样的语句中，单独的变量名成为最朴素的模式。其中 x 作为模式表达的含义是，将此处匹配到的所有内容绑定至变量 x，因为 x 就是整个模式本身。 用 let 模式匹配来解构元组：let (x, y, z) = (1, 2, 3); 如果模式中元素的数量与元组中元素的数量不同，则整个类型会匹配失败，导致编译错误。 函数的参数函数的参数同样也是模式。12345678fn print_coordinates(&amp;(x, y): &amp;(i32, i32)) &#123; println!("Current location: (&#123;&#125;, &#123;&#125;)", x, y);&#125;fn main() &#123; let point = (3, 5); print_coordinates(&amp;point);&#125; 模式 &amp;(x, y) 能够和值 &amp;(3, 5) 匹配，因此 x 的值为 3，y 的值为 5。 可失败性模式可以被分为不可失败（irrefutable）和可失败（refutable）两种类型。不可失败的模式能够匹配任何传入的值。如语句 let x = 5; 中的 x，因为 x 能够匹配右侧表达式所有可能的返回值。可失败模式则可能因为某些特定的值而匹配失败。如表达式 if let Some(x) = a_value 中的 Some(x)。若 a_value 变量的值是 None 而不是 Some，则左边的 Some(x) 模式就会出现不匹配的情况。 函数参数、let 语句及 for 循环只接收不可失败模式。因为这些场合下，程序无法在值不匹配时执行任何有意义的行为。if let 和 while let 表达式则只接收可失败模式。因为它们在被设计时就将匹配失败的情形考虑在内了，条件表达式的功能就是根据条件的成功与否执行不同的操作。 模式语法匹配字面量12345678910fn main() &#123; let x = 1; match x &#123; 1 =&gt; println!("one"), 2 =&gt; println!("two"), 3 =&gt; println!("three"), _ =&gt; println!("anything"), &#125;&#125; 匹配命名变量命名变量是一种可以匹配任何值的不可失败模式。需要注意的是，当我们在 match 表达式中使用命名变量时，由于 match 开启了一个新的作用域，所以被定义在 match 表达式内作为模式一部分的变量会覆盖掉 match 结构外的同名变量。1234567891011121314fn main() &#123; let x = Some(5); let y = 10; match x &#123; Some(50) =&gt; println!("Got 50"), Some(y) =&gt; println!("Matched, y = &#123;:?&#125;", y), _ =&gt; println!("Default case, x = &#123;:?&#125;", x), &#125; // =&gt; Matched, y = 5 println!("at the end: x = &#123;:?&#125;, y = &#123;:?&#125;", x, y); // =&gt; at the end: x = Some(5), y = 10&#125; 在上述代码中，第二个匹配分支的模式引入了新的变量 y，它会匹配 Some 变体中携带的任何值。因为处在 match 表达式创建的新作用域中，这里的 y 是一个新的变量，而不是程序起始处声明的那个存储了 10 的 y。新的 y 绑定能够匹配 Some 中的任意值，即匹配 x 变量中 Some 内部的值 5。 match 表达式创建的作用域会随着当前表达式的结束而结束，其内部的 y 也无法幸免。因此代码最后的 println! 会输出 at the end: x = Some(5), y = 10。 多重模式可以在 match 表达式的分支匹配中使用 | 来表示或的意思，从而一次性地匹配多个模式。123456789fn main() &#123; let x = 1; match x &#123; 1 | 2 =&gt; println!("one or two"), 3 =&gt; println!("three"), _ =&gt; println!("anything"), &#125;&#125; 使用 ..= 来匹配区间12345678fn main() &#123; let x = 5; match x &#123; 1..=5 =&gt; println!("one through five"), _ =&gt; println!("something else"), &#125;&#125; 使用解构来分解值可以使用模式来分解结构体、枚举、元组或引用，从而使用这些值中的不同部分。 解构结构体123456789101112struct Point &#123; x: i32, y: i32,&#125;fn main() &#123; let p = Point &#123; x: 0, y: 7 &#125;; let Point &#123; x: a, y: b &#125; = p; assert_eq!(0, a); assert_eq!(7, b);&#125; 上述代码创建了 a 和 b 两个变量，分别匹配了 p 结构体中字段 x 和 y 的值。采用与字段名相同的变量名在实践中非常常见，为了避免写出类似于 let Point { x: x, y: y } = p 这样冗余的代码，Rust 允许采用如下形式的代码解构结构体：123456789101112struct Point &#123; x: i32, y: i32,&#125;fn main() &#123; let p = Point &#123; x: 0, y: 7 &#125;; let Point &#123; x, y &#125; = p; assert_eq!(0, x); assert_eq!(7, y);&#125; 除了为所有字段创建变量，还可以在结构体模式中使用字面量来进行解构。这一技术使我们可以在某些特定字段符合要求的前提下再对其他字段进行解构。1234567891011121314struct Point &#123; x: i32, y: i32,&#125;fn main() &#123; let p = Point &#123; x: 0, y: 7 &#125;; match p &#123; Point &#123; x, y: 0 &#125; =&gt; println!("On the x axis at &#123;&#125;", x), Point &#123; x: 0, y &#125; =&gt; println!("On the y axis at &#123;&#125;", y), Point &#123; x, y &#125; =&gt; println!("On neither axis: (&#123;&#125;, &#123;&#125;)", x, y), &#125;&#125; 通过在第一个分支中要求 y 字段匹配字面量 0，从而匹配到所有位于 x 轴上的点，同时创建了一个可以在随后代码块中使用的 x 变量。类似的第二个分支匹配 y 轴上的点，第三个分支匹配所有剩余的点。 甚至可以按照某种更为复杂的方式来将模式混合、匹配或嵌套在一起。let ((feet, inches), Point {x, y}) = ((3, 10), Point { x: 3, y: -10 }); 忽略模式中的值使用 _ 忽略整个值可以使用下划线 _ 作为通配符来匹配任意可能的值而不绑定值本身。虽然 _ 模式最常被用在 match 表达式的最后一个分支中，实际上我们可以把它用于包括函数参数在内的一切模式中。1234567fn foo(_: i32, y: i32) &#123; println!("This code only uses the y parameter: &#123;&#125;", y);&#125;fn main() &#123; foo(3, 4);&#125; 上述代码会忽略传给第一个参数的值 3。忽略函数参数在某些情况下会变得有用。比如正在实现一个 trait，而这个 trait 的方法包含了你不需要的某些参数。此时就可以借助忽略模式避免编译器产生未使用变量的警告。 使用 .. 忽略值的剩余部分12345678910111213struct Point &#123; x: i32, y: i32, z: i32,&#125;fn main() &#123; let origin = Point &#123; x: 0, y: 0, z: 0 &#125;; match origin &#123; Point &#123; x, .. &#125; =&gt; println!("x is &#123;&#125;", x), &#125;&#125; .. 语法会自动展开并填充任意多个所需的值。123456789fn main() &#123; let numbers = (2, 4, 8, 16, 32); match numbers &#123; (first, .., last) =&gt; &#123; println!("Some numbers: &#123;&#125;, &#123;&#125;", first, last); &#125; &#125;&#125; 上述代码使用 first 和 last 分别匹配了元组中的第一个值和最后一个值，而它们之间的 .. 模式则会匹配并忽略中间的值。 使用匹配守卫添加额外条件匹配守卫（match guard）是附加在 match 分支模式后的 if 条件语句，分支中的模式只有在该条件被同时满足时才能匹配成功。匹配守卫的条件可以使用模式中创建的变量。123456789fn main() &#123; let num = Some(4); match num &#123; Some(x) if x &lt; 5 =&gt; println!("less than five: &#123;&#125;", x), Some(x) =&gt; println!("&#123;&#125;", x), None =&gt; (), &#125;&#125; 上述代码中，num 能够与第一个分支中的模式匹配成功，随后的匹配守卫则会检查模式中创建的变量 x 是否小于 5。由于 num 同样满足这一条件，最终执行了第一个分支中的代码。假设 num 的值是 Some(10)，则第一个匹配分支中的匹配守卫无法成立，Rust 会进入第二个分支继续比较最终匹配成功。 我们无法通过模式表达类似于 if x &lt; 5 这样的条件，匹配守卫增强了语句中表达相关逻辑的能力。 参考资料The Rust Programming Language]]></content>
      <categories>
        <category>Rust</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Functional</tag>
        <tag>Advanced</tag>
        <tag>Pattern</tag>
        <tag>Match</tag>
        <tag>Rust</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[The Rust programming language 读书笔记——泛型与 trait（特征）]]></title>
    <url>%2F2021%2F06%2F20%2Fthe-rust-programming-language-reading-notes-generics-and-trait%2F</url>
    <content type="text"><![CDATA[所有的编程语言都会致力于高效地处理重复概念，Rust 中的泛型（generics）就是这样一种工具。泛型是具体类型或其他属性的抽象替代。比如 Option&lt;T&gt;、Vec&lt;T&gt;、Hash&lt;K, V&gt; 等。 将代码提取为函数以减少重复工作下面的代码可以用来在数字列表中找到最大值：1234567891011fn main() &#123; let number_list = vec![34, 50, 25, 100, 65]; let mut largest = number_list[0]; for number in number_list &#123; if number &gt; largest &#123; largest = number; &#125; &#125; println!("The largest number is &#123;&#125;", largest);&#125; 为了消除重复代码，可以通过定义函数来创建抽象，令该函数可以接收任意整数列表作为参数并进行求值。12345678910111213141516fn largest(list: &amp;[i32]) -&gt; i32 &#123; let mut largest = list[0]; for &amp;item in list.iter() &#123; if item &gt; largest &#123; largest = item; &#125; &#125; largest&#125;fn main() &#123; let number_list = vec![34, 50, 25, 100, 65]; let result = largest(&amp;number_list); println!("The largest number is &#123;&#125;", result);&#125; 假设我们拥有两个不同的函数：一个用于在 i32 切片中搜索最大值；另一个用于在 char 切片中搜索最大值。代码可能是下面这个样子：12345678910111213141516171819202122232425262728293031fn largest_i32(list: &amp;[i32]) -&gt; i32 &#123; let mut largest = list[0]; for &amp;item in list.iter() &#123; if item &gt; largest &#123; largest = item; &#125; &#125; largest&#125;fn largest_char(list: &amp;[char]) -&gt; char &#123; let mut largest = list[0]; for &amp;item in list.iter() &#123; if item &gt; largest &#123; largest = item; &#125; &#125; largest&#125;fn main() &#123; let number_list = vec![34, 50, 25, 100, 65]; let result = largest_i32(&amp;number_list); println!("The largest number is &#123;&#125;", result); let char_list = vec!['y', 'm', 'a', 'q']; let result = largest_char(&amp;char_list); println!("The largest char is &#123;&#125;", result);&#125; 泛型数据类型在函数定义中使用当使用泛型来定义一个函数时，我们需要将泛型放置在函数签名中用于指定参数和返回值类型的地方。以这种方式编写的代码更加灵活，可以在不引入重复代码的同时向函数调用者提供更多的功能。 上面代码中的 largest_i32 和 largest_char 是两个只在名称和签名上有所区别的函数。largest_i32 作用于 i32 类型的切片，而 largest_char 作用于 char 类型的切片。这两个函数拥有完全相同的代码，因此可以通过在一个函数中使用泛型来消除重复代码。 在函数签名中使用泛型合并不同的 largest 函数：1234567891011121314151617181920fn largest&lt;T: PartialOrd + Copy&gt;(list: &amp;[T]) -&gt; T &#123; let mut largest = list[0]; for &amp;item in list.iter() &#123; if item &gt; largest &#123; largest = item; &#125; &#125; largest&#125;fn main() &#123; let number_list = vec![34, 50, 25, 100, 65]; let result = largest(&amp;number_list); println!("The largest number is &#123;&#125;", result); let char_list = vec!['y', 'm', 'a', 'q']; let result = largest(&amp;char_list); println!("The largest char is &#123;&#125;", result);&#125; 其中 largest&lt;T: PartialOrd + Copy&gt; 部分的 PartialOrd 和 Copy 是为类型 T 指定的两个 trait 约束（后面会提到）。 在结构体定义中使用同样地，也可以使用 &lt;&gt; 语法来定义在一个或多个字段中使用泛型的结构体。123456789struct Point&lt;T&gt; &#123; x: T, y: T,&#125;fn main() &#123; let integer = Point &#123; x: 5, y: 1 &#125;; let float = Point &#123; x: 1.0, y: 4.0 &#125;;&#125; 如上面的代码，在结构名后的一对尖括号中声明泛型参数后，就可以在结构体定义中用于指定具体数据类型的位置使用泛型了。 在定义 Point&lt;T&gt; 结构体时仅使用了一个泛型参数，表明该结构体对某个类型 T 是通用的。但无论 T 具体的类型是什么，字段 x 和 y 都同时属于这个类型。即 x 和 y 只能是同一类型。 为了使结构体 Point 中的 x 和 y 能够被实例化为不同的类型，可以使用多个泛型参数。12345678910struct Point&lt;T, U&gt; &#123; x: T, y: U,&#125;fn main() &#123; let both_integer = Point &#123; x: 5, y: 1 &#125;; let both_float = Point &#123; x: 1.0, y: 4.0 &#125;; let integer_and_float = Point &#123; x: 5, y: 4.0 &#125;;&#125; 在方法定义中使用方法也可以在自己的定义中使用泛型：123456789101112131415struct Point&lt;T&gt; &#123; x: T, y: T,&#125;impl&lt;T&gt; Point&lt;T&gt; &#123; fn x(&amp;self) -&gt; &amp;T &#123; &amp;self.x &#125;&#125;fn main() &#123; let p = Point &#123; x: 5, y: 10 &#125;; println!("p.x = &#123;&#125;", p.x());&#125; 上面的代码为结构体 Point&lt;T&gt; 实现了名为 x 的方法，返回一个指向 x 字段中 T 类型值的引用。 紧跟着 impl 关键字声明 T 是必须的。通过在 impl 之后将 T 声明为泛型，Rust 能够识别出 Point&lt;T&gt; 中尖括号内的类型是泛型而不是具体的类型。 实际上，可以单独为 Point&lt;f32&gt; 实例而不是所有的 Point&lt;T&gt; 泛型实例来实现特定的方法。当在 Point&lt;32&gt; 声明中使用了明确的类型 f32，也意味着无需在 impl 之后附带任何类型声明了。12345impl Point&lt;f32&gt; &#123; fn distance_from_origin(&amp;self) -&gt; f32 &#123; (self.x.powi(2) + self.y.powi(2)).sqrt() &#125;&#125; 上面的代码意味着，类型 Point&lt;f32&gt; 将会拥有一个名为 distance_from_origin 的方法，而其他的 Point&lt;T&gt; 实例则没有该方法的定义。 结构体定义中的泛型参数并不总是与方法签名中使用的类型参数一致。12345678910111213141516171819202122struct Point&lt;T, U&gt; &#123; x: T, y: U,&#125;impl&lt;T, U&gt; Point&lt;T, U&gt; &#123; fn mixup&lt;V, W&gt;(self, other: Point&lt;V, W&gt;) -&gt; Point&lt;T, W&gt; &#123; Point &#123; x: self.x, y: other.y, &#125; &#125;&#125;fn main() &#123; let p1 = Point &#123; x: 5, y: 10.4 &#125;; let p2 = Point &#123; x: "Hello", y: 'c' &#125;; let p3 = p1.mixup(p2); println!("p3.x = &#123;&#125;, p3.y = &#123;&#125;", p3.x, p3.y); // =&gt; p3.x = 5, p3.y = c&#125; trait：定义共享行为trait 用来向 Rust 编译器描述某些特定类型拥有的且能够被其他类型共享的功能，使我们可以以一种抽象的方式来定义共享行为。 trait 与其他语言中的接口（interface）功能类似，但也不尽相同。类型的行为由该类型本身可供调用的方法组成。当我们可以在不同的类型上调用相同的方法时，就称这些类型共享了相同的行为。trait 提供了一种将特定方法组合起来的途径，定义了为达成某种目的所必须的方法（行为）集合。 定义 trait假如我们拥有多个结构体（struct），分别持有不同类型、不同数量的文本字段。其中 NewsArticle 结构体存放新闻故事，Tweet 结构体存放推文。我们还想要方便地获取存储在 NewsArticle 和 Tweet 实例中的数据摘要。因此需要为每个结构体类型都实现摘要行为，从而可以在这些实例上统一地调用 summarize 方法来请求摘要内容。 可以定义如下形式的 Summary trait：123trait Summary &#123; fn summarize(&amp;self) -&gt; String;&#125; 在大括号中声明了用于定义类型行为的方法签名，即 fn summarize(&amp;self) -&gt; String;。方法签名后省略了大括号及方法的具体实现。任何想要实现这个 trait 的类型都需要为上述方法提供自定义行为。编译器会确保每一个实现了 Summary trait 的类型都定义了与这个签名完全一致的 summarize 方法。一个 trait 可以包含多个方法，每个方法签名占据单独一行并以分号结尾。 为类型实现 trait 完整代码：1234567891011121314151617181920212223242526272829303132333435363738394041trait Summary &#123; fn summarize(&amp;self) -&gt; String;&#125;struct NewsArticle &#123; headline: String, location: String, author: String, content: String,&#125;impl Summary for NewsArticle &#123; fn summarize(&amp;self) -&gt; String &#123; format!("&#123;&#125;, by &#123;&#125; (&#123;&#125;)", self.headline, self.author, self.location) &#125;&#125;struct Tweet &#123; username: String, content: String, reply: bool, retweet: bool,&#125;impl Summary for Tweet &#123; fn summarize(&amp;self) -&gt; String &#123; format!("&#123;&#125;: &#123;&#125;", self.username, self.content) &#125;&#125;fn main() &#123; let tweet = Tweet &#123; username: String::from("horse_ebooks"), content: String::from("of course, as you probably already know, people"), reply: false, retweet: false, &#125;; println!("1 new tweet: &#123;&#125;", tweet.summarize()); // =&gt; 1 new tweet: horse_ebooks: of course, as you probably already know, people&#125; 其中 impl Summary for NewsArticle 和 impl Summary for Tweet 部分负责为 NewsArticle 和 Tweet 两个结构体类型定义 Summary trait 中指定的 summarize 方法，并为该方法实现具体的行为。 默认实现某些时候，为 trait 中的某些或所有方法都提供默认行为非常有用，使我们无需为每一个类型的 trait 实现都提供自定义行为。当我们为某个特定类型实现 trait 时，可以选择保留或重载每个方法的默认行为。 如为 Summary trait 中的 summarize 方法指定一个默认的字符串返回值：12345trait Summary &#123; fn summarize(&amp;self) -&gt; String &#123; String::from("(Read More...)") &#125;&#125; 假如需要在 NewsArticle 的实例中使用上述默认实现，而不是自定义实现，可以指定一个空的 impl 代码块：impl Summary for NewsArticle {} 此时虽然没有直接为 NewsArticle 定义 summarize 方法，依然可以在 NewsArticle 实例上调用 summarize 方法。1234567891011121314fn main() &#123; let article = NewsArticle &#123; headline: String::from("Penguins win the Stanley Cup Championship!"), location: String::from("Pittsburgh, PA, USA"), author: String::from("Iceburgh"), content: String::from( "The Pittsburgh Penguins once again are the best hockey team in the NHL.", ), &#125;; println!("New article available! &#123;&#125;", article.summarize()); // =&gt; New article available! (Read More...)&#125; 可以在默认实现中调用同一 trait 中的其他方法，哪怕这些被调用的方法没有默认实现。例如，可以为 Summary trait 定义一个需要被实现的方法 summarize_author（即 trait 中没有该方法的默认实现，需要在后续的类型中实现），再通过调用 summarize_author 为 summarize 方法提供一个默认实现：1234567trait Summary &#123; fn summarize_author(&amp;self) -&gt; String; fn summarize(&amp;self) -&gt; String &#123; format!("(Read more from &#123;&#125;...)", self.summarize_author()) &#125;&#125; 为了使用这个版本的 Summary，只需要在后续类型实现这一 trait 时定义 summarize_author 方法：12345impl Summary for Tweet &#123; fn summarize_author(&amp;self) -&gt; String &#123; format!("@&#123;&#125;", self.username) &#125;&#125; 定义了 summarize_author 之后，就可以在 Tweet 实例上调用 summarize 了。summarize 的默认实现会进一步调用我们提供的 summarize_author 的定义。1234567891011fn main() &#123; let tweet = Tweet &#123; username: String::from("horse_ebooks"), content: String::from("of course, as you probably already know, people"), reply: false, retweet: false, &#125;; println!("1 new tweet: &#123;&#125;", tweet.summarize()); // =&gt; 1 new tweet: (Read more from @horse_ebooks...)&#125; trait 作为参数前面的代码中为 NewsArticle 和 Tweet 类型实现了 Summary trait，我们还可以定义一个 notify 函数来调用这些类型的 summarize 方法。语法如下：123fn notify(item: impl Summary) &#123; println!("Breaking news! &#123;&#125;", item.summarize());&#125; 上述代码没有为 item 参数指定具体的类型，而是使用了 impl 关键字及对应的 trait 名称。这意味着 item 参数可以接收任何实现了指定 trait 的类型。在 notify 函数体内，则可以调用来自 Summary trait 的任何方法。尝试使用其他类型（如 String 或 i32）来调用 notify 函数则无法通过编译，因为这些类型没有实现 Summary trait。 上述代码其实只是 trait 约束的一种语法糖，完整形式如下：12fn notify&lt;T: Summary&gt;(item: T) &#123; println!("Breaking news! &#123;&#125;", item.summarize()); 通过 + 语法来指定多个 trait 约束如果 notify 函数需要在调用 summarize 方法的同时显示格式化后的 item，则此处的 item 就必须实现两个不同的 trait：Summary 和 Display。fn notify(item: impl Summary + Display) { 这一语法在泛型的 trait 约束中同样有效：fn notify&lt;T: Summary + Display&gt;(item: T) { where 从句简化 trait 约束因为每个泛型都拥有自己的 trait 约束，定义多个类型参数的函数可能会有大量的 trait 约束信息需要被填写在函数名与参数列表之间。Rust 提供了一种替代语法。 如 fn some_function&lt;T: Display + Clone, U: Clone + Debug&gt;(t: T, u: U) -&gt; i32 { 可以改写成如下形式：1234fn some_function&lt;T, U&gt;(t: T, u: U) -&gt; i32 where T: Display + Clone, U: Clone + Debug&#123; 返回实现了 trait 的类型同样可以在返回值中使用 impl Trait 语法，用于返回某种实现了特定 trait 的类型。12345678fn returns_summarizable() -&gt; impl Summary &#123; Tweet &#123; username: String::from("horse_ebooks"), content: String::from("of course, as you probably already know, people"), reply: false, retweet: false, &#125;&#125; 之前在介绍泛型时编写的 largest 函数就通过 trait 约束来限定泛型参数的具体类型。在 largest 函数中，我们想要使用大于号运算符来比较两个 T 类型的值。这一运算符被定义为标准库 std::cmp::PartialOrd 的一个默认方法，因此需要在 T 的 trait 约束中指定 PartialOrd，才能够使 largest 函数用于任何可比较类型的切片上。 我们在编写 largest 函数的非泛型版本时，只尝试过搜索 i32 和 char 类型的最大值。这两种都是拥有确定大小并存储在栈上的类型，实现了 Copy trait。但当我们尝试将 largest 函数泛型化时，list 参数中的类型有可能是没有实现 Copy trait 的。为了确保这个函数只会被那些实现了 Copy trait 的类型所调用，还需要把 Copy 加入到 T 的 trait 约束中。 所以最终的 largest 函数采用如下声明：fn largest&lt;T: PartialOrd + Copy&gt;(list: &amp;[T]) -&gt; T { 使用 trait 约束有条件地实现方法通过在带有泛型参数的 impl 代码块中使用 trait 约束，我们可以单独为实现了指定 trait 的类型编写方法。123456789101112131415161718192021222324252627use std::fmt::Display;struct Pair&lt;T&gt; &#123; x: T, y: T,&#125;impl&lt;T&gt; Pair&lt;T&gt; &#123; fn new(x: T, y: T) -&gt; Self &#123; Self &#123; x, y &#125; &#125;&#125;impl&lt;T: Display + PartialOrd&gt; Pair&lt;T&gt; &#123; fn cmp_display(&amp;self) &#123; if self.x &gt;= self.y &#123; println!("The largest member is x = &#123;&#125;", self.x); &#125; else &#123; println!("The largest member is y = &#123;&#125;", self.y); &#125; &#125;&#125;fn main() &#123; let pair = Pair::new(3, 4); pair.cmp_display()&#125; 上面的代码中，所有的 Pair&lt;T&gt; 类型都会实现 new 方法，但只有在内部类型 T 实现了 PartialOrd（用于比较）和 Display（用于打印）这两个 trait 的前提下，才会实现 cmd_display 方法。 总结借助于 trait 和 trait 约束，我们可以在使用泛型参数消除重复代码的同时，向编译器指明自己希望泛型拥有的功能。而编译器则可以利用这些 trait 约束信息来确保代码中使用的具体类型提供了正确的行为。在动态语言中，尝试调用类型没有实现的方法会导致在运行时出现错误。Rust 将这些错误出现的时机转移到了编译期，我们无需编写那些用于在运行时检查类型的代码，这一机制在保留泛型灵活性的同时提升了代码性能。 参考资料The Rust Programming Language]]></content>
      <categories>
        <category>Rust</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Type</tag>
        <tag>OOP</tag>
        <tag>Rust</tag>
        <tag>Generics</tag>
        <tag>Interface</tag>
        <tag>Trait</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[The Rust programming language 读书笔记——通用集合类型]]></title>
    <url>%2F2021%2F06%2F14%2Fthe-rust-programming-language-reading-notes-collections%2F</url>
    <content type="text"><![CDATA[Rust 标准库包含了一系列被称为集合的数据结构。与内置的数组和元组不同，集合将自己持有的数据存储在堆上。这使得数据的大小不需要在编译时确定，且可以随着程序的运行按需扩大或缩小数据占用的空间。 Rust 中有 3 种最常用的集合类型： 动态数组（vector） 字符串（string） 哈希映射（hash map） 使用动态数组存储多个值动态数组（Vec&lt;T&gt;）支持在单个数据结构中存储多个相同类型的值，这些值会彼此相邻地排布在内存中。 可以调用函数 Vec::new 来创建一个空的动态数组：let v: Vec&lt;i32&gt; = Vec::new(); 上述代码会创建一个用来存储 i32 数据地的空的动态数组。由于并未在这个动态数组中插入任何值，因此需要显式地添加类型标记（Vec&lt;i32&gt;）。 用初始值去创建动态数组的场景也十分常见，因此 Rust 特意提供了一个用于简化代码的 vec! 宏。let v = vec![1, 2, 3] 更新动态数组：123456let mut v = Vec::new();v.push(5);v.push(6);v.push(7);v.push(8); 销毁动态数组时也会销毁其中的元素123456&#123; let v = vec![1, 2, 3, 4]; // 执行与 v 相关的操作&#125; // &lt;- v 在这里离开作用域并随之被销毁 可以使用索引和 get 两种方法读取动态数组中的元素。12345678910fn main() &#123; let v = vec![1, 2, 3, 4]; let third: &amp;i32 = &amp;v[2]; println!("The third element is &#123;&#125;", third); match v.get(2) &#123; Some(third) =&gt; println!("The third number is &#123;&#125;", third), None =&gt; println!("There is no third element"), &#125;&#125; 需要注意的是： 动态数组使用数字进行索引，索引值从 0 开始 使用 &amp; 与 [] 会直接返回元素的引用 接收索引作为参数的 get 方法会返回一个 Option&lt;T&gt; 类型 当尝试使用不存在的索引值去访问动态数组时，上述两种引用方法会导致程序触发不同的响应方式。比如对于某个持有 5 个元素的动态数组，尝试访问其索引为 100 的元素。 [] 方法会因为索引指向了不存在的元素而触发 panic，假如希望在尝试越界访问元素时令程序直接崩溃，此方法就很适用。get 方法会在检测到索引越界时直接返回 None，而不会导致程序崩溃。当偶尔越界访问动态数组的元素是一种正常行为时，可以使用此方法。此外，代码应该合乎逻辑地处理 Some(&amp;element) 与 None 两种不同的情形。 在存在指向动态数组元素的引用时，尝试向动态数组中添加元素会导致编译器报错。比如下面的代码：123456fn main() &#123; let mut v = vec![1, 2, 3, 4, 5]; let first = &amp;v[0]; v.push(6); print!("The first element is &#123;&#125;", first);&#125; 对第一个元素的引用需要关心动态数组结尾处的变化，这与动态数组的机制有关。动态数组中的元素是连续地存储在堆中的，插入新的元素也许会没有足够多的空间将所有元素依次相邻地放下。这就需要分配新的内存空间，再将旧的元素移动到新的空间上，旧的空间被释放。也就是说，动态数组末尾插入数据有可能导致上面代码中第一个元素的引用指向了被释放的内存。 遍历动态数组123456fn main() &#123; let v = vec![100, 32, 57]; for i in &amp;v &#123; print!("&#123;&#125;", i); &#125;&#125; 也可以遍历可变的动态数组，获得元素的可变引用，并修改其中的值。1234567fn main() &#123; let mut v = vec![100, 32, 57]; for i in &amp;mut v &#123; *i += 50; print!("&#123;&#125;", i) &#125;&#125; 为了使 += 运算符修改可变引用的值，需要使用解引用运算符 * 来获取 i 绑定的值。 使用字符串存储 UTF-8 文本Rust 在语言核心部分只有一种字符串类型，即字符串切片 str，通常以借用的形式（&amp;str）出现。字符串切片是一些指向存储在别处的 UTF-8 编码的字符串的引用。 String 类型被定义在 Rust 标准库中，没有内置在语言的核心部分。它也采用了 UTF-8 编码。 创建字符串许多对于 Vec&lt;T&gt; 的操作同样可用于 String，比如可以从 new 函数创建一个新的空字符串：let mut s = String::new(); 可以对那些实现了 Display trait 的类型调用 to_string 方法，创建有初始数据的字符串：let s = &quot;initial contents&quot;.to_string(); 也可以使用 String::from 函数基于字符串字面量生成 String：let s = String::from(&quot;initial contents&quot;); 字符串是基于 UTF-8 编码的，因此可以将任何合法的数据编码进字符串：let hello = String::from(&quot;你好&quot;); 更新字符串可以使用 push_str 方法来向 String 中添加一段字符串切片。12let mut s = String::from("foo");s.push_str("bar"); push 方法接收单个字符作为参数，并将它添加到 String 中。12let mut s = String::from("lo");s.push('l'); 使用 + 运算符将两个 String 合并到一个新的 String 中：123456fn main() &#123; let s1 = String::from("Hello, "); let s2 = String::from("world!"); let s3 = s1 + &amp;s2; // 这里的 s1 已经被移动且再也不能被使用 println!("&#123;&#125;", s3);&#125; 需要注意的是，上面的加法操作中只对变量 s2 采用了引用，而 s1 由于所有权的移动在加法操作之后不再有效。这里的 + 运算符会调用一个 add 方法，其签名类似于：fn add(self, s: &amp;str) -&gt; String { 由于函数签名中的 self 并没有使用 &amp; 标记，因此 add 函数会取得 self 的所有权，导致 s1 被移动至 add 函数调用中，在调用后失效。这种实现要比单纯的复制更加高效。 对于复杂一些的比如多个字符串的合并，可以使用 format! 宏：12345let s1 = String::from("tic");let s2 = String::from("tac");let s3 = String::from("toe");let s = format!("&#123;&#125;-&#123;&#125;-&#123;&#125;", s1, s2, s3); format! 宏与 println! 宏的工作原理完全相同，只不过 format! 会将结果包含在一个 String 中返回。这使得用 format! 的代码更加易读，且不会夺取任何参数的所有权。 字符串索引Rust 中的字符串不支持索引。比如下面的代码会导致编译器报错：12let s1 = String::from("hello");let h = s1[0]; String 实际上是一个基于 Vec&lt;u8&gt; 的封装类型。let len = String::from(&quot;Hola&quot;).len(); 中，变量 len 的值为 4，意味着动态数组所存储的字符串 Hola 占用了 4 个字节。而 let len = String::from(&quot;你好&quot;).len(); 中，Rust 返回的结果却并不是 2，而是 6。这就是使用 UTF-8 编码来存储“你好”所需要的字节数。因此对于字符串中字节的索引并不总是能对应到一个有效的 Unicode 标量值。 还有一个原因，索引操作的复杂度往往会被预期为常数时间 O(1)，但在 String 中，Rust 必须要从头遍历至索引位置来确定究竟有多少合法字符存在，这无法保障常数时间的性能。 字符串切片字符串切片是指向 String 对象中某个连续部分的引用：123let s = String::from("hello world");let hello = &amp;s[0..5];let world = &amp;s[6..11]; 向函数传入字符串切片并不会导致切片指向的原始 String 因为所有权的移动而失效。 字符串字面量就是切片。let s = &quot;Hello, world!&quot;;变量 s 的类型其实是 &amp;str，是一个指向二进制程序特定位置的切片。正是由于 &amp;str 是一个不可变引用，字符串字面量才是不可变的。 尝试通过索引引用字符串通常是一个坏主意，因为该操作应当返回的类型是不明确的：究竟应该是字节、字符、字形簇还是切片呢？Rust 要求程序员做出更加明确的标记，在索引的 [] 中填写范围来指定所需的字节内容，即明确其类型为字符串切片。123456fn main() &#123; let hello = String::from("你好"); let s = &amp;hello[0..3]; println!("&#123;&#125;", s); // =&gt; 你&#125; 在上面的代码中，s 将会是一个包含了字符串前 3 个字节的 &amp;str，即 你。若尝试在代码中使用 &amp;hello[0..2]，则程序运行时会发生 panic：thread &#39;main&#39; panicked at &#39;byte index 2 is not a char boundary; it is inside &#39;你&#39; (bytes 0..3) of `你好`&#39; 切记要小心谨慎地使用范围语法创建字符串切片。 假如确实需要对每一个 Unicode 标量值都进行处理，最好的办法是使用 chars 方法：12345678fn main() &#123; let hello = String::from("你好"); for c in hello.chars() &#123; println!("&#123;&#125;", c); // =&gt; 你 // =&gt; 好 &#125;&#125; 在映射中存储键值对哈希映射 HashMap&lt;K, V&gt; 存储了从 K 类型键关联到 V 类型值之间的映射关系。 创建哈希映射123456use std::collections::HashMap;let mut scores = HashMap::new();scores.insert(String::from("Blue"), 10);scores.insert(String::from("Yellow"), 50); 和动态数组一样，哈希映射也将其数据存储在堆上。它同样也是同质的，即所有键必须拥有相同的类型，所有的值也必须拥有相同的类型。 另一种构建哈希映射的方法：123456use std::collections::HashMap;let teams = vec![String::from("Blue"), String::from("Yellow")];let initial_scores = vec![10, 50];let scores: HashMap&lt;_, _&gt; = teams.iter().zip(initial_scores.iter()).collect(); 哈希映射与所有权对于那些实现了 Copy trait 的类型如 i32，它们的值会被简单地复制到哈希映射中。而对于 String 这种持有所有权的值，其所有权会转移给哈希映射：12345678use std::collections::HashMap;let field_name = String::from("Favorite color");let field_value = String::from("Blue");let mut map = HashMap::new();map.insert(field_name, field_value);// filed_name 和 field_value 从这一刻开始失效，若尝试使用它们则会导致编译错误！ 在调用 insert 方法后，field_name 和 field_value 变量会被移动到哈希映射中，之后就无法再使用这两个变量了。 访问哈希映射中的值123456789use std::collections::HashMap;let mut scores = HashMap::new();scores.insert(String::from("Blue"), 10);scores.insert(String::from("Yellow"), 50);let team_name = String::from("Blue");let score = scores.get(&amp;team_name); get 返回的是一个 Option&lt;&amp;V&gt; 类型。因此上面代码中的 score 将会是与蓝队相关联的值，即 Some(&amp;10)。若哈希映射中没有指定键所对应的值，get 方法就会返回 None。 可以使用 for 循环遍历哈希映射：12345678910use std::collections::HashMap;let mut scores = HashMap::new();scores.insert(String::from("Blue"), 10);scores.insert(String::from("Yellow"), 50);for (key, value) in &amp;scores &#123; println!("&#123;&#125;: &#123;&#125;", key, value);&#125; 更新哈希映射替换旧值12345678use std::collections::HashMap;let mut scores = HashMap::new();scores.insert(String::from("Blue"), 10);scores.insert(String::from("Blue"), 25);println!("&#123;:?&#125;", scores); 原来的值 10 会被新值 25 替换掉。 只在某个键没有对应值时才插入数据即若某个键对应的值存在，保持原状；若该值不存在，将参数作为新值插入。 1234567891011fn main() &#123; use std::collections::HashMap; let mut scores = HashMap::new(); scores.insert(String::from("Blue"), 10); scores.entry(String::from("Yellow")).or_insert(50); scores.entry(String::from("Blue")).or_insert(50); println!("&#123;:?&#125;", scores); // =&gt; &#123;"Blue": 10, "Yellow": 50&#125;&#125; 基于旧值更新值1234567891011121314fn main() &#123; use std::collections::HashMap; let text = "hello world wonderful world"; let mut map = HashMap::new(); for word in text.split_whitespace() &#123; let count = map.entry(word).or_insert(0); *count += 1; &#125; println!("&#123;:?&#125;", map); // =&gt; &#123;"hello": 1, "world": 2, "wonderful": 1&#125;&#125; 参考资料The Rust Programming Language]]></content>
      <categories>
        <category>Rust</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>DataStructure</tag>
        <tag>List</tag>
        <tag>Rust</tag>
        <tag>String</tag>
        <tag>Collection</tag>
        <tag>Vector</tag>
        <tag>HashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[The Rust programming language 读书笔记——结构体（Struct）]]></title>
    <url>%2F2021%2F06%2F09%2Fthe-rust-programming-language-reading-notes-struct%2F</url>
    <content type="text"><![CDATA[结构（Struct）是一种自定义数据类型。允许我们命名多个相关的值并将它们组成一个有机的结合体。 定义与实例化关键字 struct 被用来定义并命名结构体，一个良好的结构体名称需反映出自身数据组合的意义。123456struct User &#123; username: String, email: String, sign_in_count: u64, active: bool,&#125; 结构体就像是类型的通用模板，将具体的数据填入模板时就创建了新的实例。123456let user1 = User &#123; email: String::from("someone@example.com"), username: String::from("someone@example.com"), active: true, sign_in_count: 1,&#125;; 在创建了结构体实例后，可以通过点号来访问实例中的特定字段。假如这个实例是可变的，还可以通过点号来修改字段的值。12345678let mut user1 = User &#123; email: String::from("someone@example.com"), username: String::from("someusername123"), active: true, sign_in_count: 1,&#125;;user1.email = String::from("anotheremail@example.com"); 需要注意的是，一旦结构体实例定义为可变，那么实例中的所有字段都将是可变的。 可以在函数体的最后一个表达式中构建结构体实例，来隐式的将这个实例作为结果返回。12345678fn build_user(email: String, username: String) -&gt; User &#123; User &#123; email: email, username: username, active: true, sign_in_count: 1, &#125;&#125; 在变量名与字段名相同时，可以使用简化版的字段初始化方法重构上面的 build_user 函数。12345678fn build_user(email: String, username: String) -&gt; User &#123; User &#123; email, username, active: true, sign_in_count: 1, &#125;&#125; 在许多情况下，新创建的实例中，除了需要修改的小部分字段以外，其余字段的值与旧实例完全相同。可以使用结构体更新语法快速实现此类新实例的创建。 使用结构体更新语法来为一个 User 实例设置新的 email 和 username 字段的值，并从 user1 实例中获取剩余字段的值：12345let user2 = User &#123; email: String::from("another@example.com"), username: String::from("anotherusername567"), ..user1&#125;; .. 表示剩下的那些还未被显式赋值的字段都与给定实例拥有相同的值。 元组结构体可以使用一种类似元组的方式定义结构体，这种结构体也被称作元组结构体。元组结构体同样拥有表明自身含义的名称，但无需在声明时对其字段进行命名，只标注类型即可。12345struct Color(i32, i32, i32);struct Point(i32, i32, i32);let black = Color(0, 0, 0);let origin = Point(0, 0, 0); 这里的 black 和 origin 是不同的类型，因为它们两个分别是不同元组结构体的实例。每一个结构体都拥有自己的类型。 示例程序使用 cargo 命令创建一个名为 rectangles 的项目：cargo new rectangles这个程序会接收以像素为单位的宽度和高度作为输入，并计算出对应的长方形面积。 编辑项目中的 src/main.rs 源代码文件：12345678910fn main() &#123; let width1 = 30; let height1 = 50; print!("The area of the rectangle is &#123;&#125;", area(width1, height1));&#125;fn area(width: u32, height: u32) -&gt; u32 &#123; width * height&#125; 运行 cargo run 命令查看输出：1234$ cargo run Finished dev [unoptimized + debuginfo] target(s) in 2.53s Running `target/debug/rectangle`The area of the rectangle is 1500 area 函数用来计算长方形的面积，接收宽和高两个参数。这两个参数是相互关联的，但程序中没有任何地方可以体现这一点。将宽和高放在一起能够使代码更加易懂和易于维护。 使用元组关联长方形的宽和高12345678fn main() &#123; let rect1 = (30, 50); print!("The area of the rectangle is &#123;&#125;", area(rect1));&#125;fn area(dimensions: (u32, u32)) -&gt; u32 &#123; dimensions.0 * dimensions.1&#125; 在上面的代码中，元组使输入的参数结构化了，现在只需要传递一个参数就可以调用函数 area。但元组不会给出自身元素的名称，只能通过索引访问。这使得程序变得难以阅读。比如当需要将该长方形绘制到屏幕上时，混淆宽度和高度就容易出现问题。 使用结构体增加有意义的描述信息12345678910111213141516struct Rectangle &#123; width: u32, height: u32,&#125;fn main() &#123; let rect1 = Rectangle &#123; width: 30, height: 50, &#125;; print!("The area of the rectangle is &#123;&#125;", area(&amp;rect1));&#125;fn area(rectangle: &amp;Rectangle) -&gt; u32 &#123; rectangle.width * rectangle.height&#125; Rectangle 结构体表明了宽度和高度是相互关联的两个值，并为这些值提供了描述性的名字。因此代码看起来会更加清晰。 方法方法与函数十分相似，它们都使用 fn 关键字及一个名称进行声明；它们都可以拥有参数和返回值；它们都包含了一段在调用时执行的代码。但方法总是被定义在某个结构体（或者枚举类型、trait 对象）的上下文中，且它们的第一个参数都是 self，用于指代调用该方法的结构体实例。 将 area 函数定义为 Rectangle 结构体中的方法：123456789101112131415161718struct Rectangle &#123; width: u32, height: u32,&#125;impl Rectangle &#123; fn area(&amp;self) -&gt; u32 &#123; self.width * self.height &#125;&#125;fn main() &#123; let rect1 = Rectangle &#123; width: 30, height: 50, &#125;; print!("The area of the rectangle is &#123;&#125;", rect1.area());&#125; 由于方法的声明被放置在 impl Rectangle 块中，因此 Rust 能够将 self 的类型推导为 Rectangle，我们才可以在 area 的签名中使用 &amp;self 来替代 &amp;Rectangle。使用方法替代函数不仅能够避免在每个方法的签名中重复编写 self 的类型，还有助于程序员组织代码的结构。可以将某个类型的实例需要的功能放置在同一个 impl 块中，避免用户在代码库中盲目地搜索它们。 添加 can_hold 方法检测当前的 Rectangle 实例能否完整地包含传入的另一个 Rectangle 实例：12345678910111213141516171819202122232425262728293031struct Rectangle &#123; width: u32, height: u32,&#125;impl Rectangle &#123; fn area(&amp;self) -&gt; u32 &#123; self.width * self.height &#125; fn can_hold(&amp;self, other: &amp;Rectangle) -&gt; bool &#123; self.width &gt; other.width &amp;&amp; self.height &gt; other.height &#125;&#125;fn main() &#123; let rect1 = Rectangle &#123; width: 30, height: 50, &#125;; let rect2 = Rectangle &#123; width: 10, height: 40, &#125;; let rect3 = Rectangle &#123; width: 60, height: 45, &#125;; print!("Can rect1 hold rect2? &#123;&#125;", rect1.can_hold(&amp;rect2)); print!("Can rect1 hold rect3? &#123;&#125;", rect1.can_hold(&amp;rect3));&#125; 关联函数除了方法，impl 块还允许我们定义不用接收 self 作为参数的函数。这类函数与结构体（而不是实例）相互关联，因此也被称为关联函数。它们不会作用于某个具体的结构体实例。之前用到的 String::from 就是关联函数的一种。 关联函数常被用作构造器来返回一个结构体的新实例。例如可以编写一个 square 关联函数，只接收一个参数，该参数同时用作宽度与高度来构造正方形实例。 12345impl Rectangle &#123; fn square(size: u32) -&gt; Rectangle &#123; Rectangle &#123; width: size, height: size &#125; &#125;&#125; 这样就可以使用 let sq = Rectangle::square(3); 类似的语法来创建正方形实例。 总结结构体可以让我们基于特定领域的规则创建有意义的自定义类型。通过使用结构体，可以将相互关联的数据组合起来，并为每条数据赋予有含义的名称，从而使代码更加清晰。方法可以让我们为结构体实例指定特殊的行为，而关联函数则可以将那些不需要实例的特定功能放置到结构体的命名空间中。 参考资料The Rust Programming Language]]></content>
      <categories>
        <category>Rust</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Function</tag>
        <tag>Type</tag>
        <tag>Development</tag>
        <tag>Class</tag>
        <tag>OOP</tag>
        <tag>Rust</tag>
        <tag>Struct</tag>
        <tag>Method</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vim 配置光标形状和颜色（Windows Terminal、xterm）]]></title>
    <url>%2F2021%2F06%2F08%2Fchange-vim-cursor-shape-and-color-in-xterm-or-windows-terminal%2F</url>
    <content type="text"><![CDATA[Windows Terminal 里的 Vim 设置了浅的配色，刚好光标默认是白色的竖线，不容易看出来。很有点费眼睛。 想把光标改成其他颜色的方块样式。因为不是 gvim，guicursor 之类的配置不起作用。上网查了些资料，测试如下配置可以正常生效（貌似这个 Terminal 是属于 xterm 那一类）：123456789101112131415" Set cursor shape and colorif &amp;term =~ "xterm" " INSERT mode let &amp;t_SI = "\&lt;Esc&gt;[6 q" . "\&lt;Esc&gt;]12;blue\x7" " REPLACE mode let &amp;t_SR = "\&lt;Esc&gt;[3 q" . "\&lt;Esc&gt;]12;black\x7" " NORMAL mode let &amp;t_EI = "\&lt;Esc&gt;[2 q" . "\&lt;Esc&gt;]12;green\x7"endif" 1 -&gt; blinking block 闪烁的方块" 2 -&gt; solid block 不闪烁的方块" 3 -&gt; blinking underscore 闪烁的下划线" 4 -&gt; solid underscore 不闪烁的下划线" 5 -&gt; blinking vertical bar 闪烁的竖线" 6 -&gt; solid vertical bar 不闪烁的竖线 其中各配置项的含义如下： &amp;t_SI 表示插入模式 &amp;t_SR 表示替换模式 &amp;t_EI 表示 Normal 模式 . 号左边的 &quot;\&lt;Esc&gt;[6 q&quot; 用来配置光标的形状。其中 6 的取值可以是 1 - 6，分别指代不同的光标样式（参考前面的注释） . 号右边的 &quot;\&lt;Esc&gt;]12;blue\x7&quot; 用来配置光标颜色，其中的 blue 可以替换为其他颜色名词 设置光标颜色时也可以使用 RGB 颜色，格式为 rgb:RR/GG/BB。比如纯白色的光标即为 &quot;\&lt;Esc&gt;]12;rgb:FF/FF/FF\x7&quot;。 若只想设置光标形状，直接去掉 . 号以及右边的颜色配置部分即可。如 let &amp;t_SR = &quot;\&lt;Esc&gt;[3 q&quot;。同理，只想修改颜色时也可以将 . 号左边的形状配置部分删掉。. 号在这里的作用其实是字符串拼接，方便区分形状配置部分和颜色配置部分而已。去掉 . 号直接将两部分配置写在一个字符串里也是可以的。即 let &amp;t_SR = &quot;\&lt;Esc&gt;[3 q&quot; . &quot;\&lt;Esc&gt;]12;black\x7&quot; 等同于 let &amp;t_SR = &quot;\&lt;Esc&gt;[3 q\&lt;Esc&gt;]12;black\x7&quot; Normal 模式（绿色方块）： 插入模式（蓝色竖线）： 替换模式（黑色下划线）： 参考资料Cursor color in xterm; change accordingly to the syntax in vim]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Configuration</tag>
        <tag>Tools</tag>
        <tag>Tricks</tag>
        <tag>Vim</tag>
        <tag>Xterm</tag>
        <tag>Terminal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[The Rust programming language 读书笔记——所有权与 Move 机制]]></title>
    <url>%2F2021%2F06%2F07%2Fthe-rust-programming-language-reading-notes-ownership-and-move%2F</url>
    <content type="text"><![CDATA[所有权概念是 Rust 语言的核心功能 Rust 没有垃圾回收（GC）机制 Rust 通过所有权和相关工具保障内存安全 所有语言都需要管理自己在运行时使用的计算机内存空间。使用垃圾回收机制的语言（Java、Python）会在运行时定期检查并回收没有被继续使用的内存；另外一些语言（C、C++）则需要程序员手动地分配和释放内存。 Rust 采用第三种方式：它使用包含特定规则的所有权系统来管理内存。这套规则允许编译器在编译过程中执行检查工作，不会产生任何的运行时开销。 栈与堆栈和堆都是代码在运行时可以使用的内存空间。所有存储在栈中的数据必须拥有一个已知且固定的大小。在编译期无法确定大小的数据只能存放在堆中。 堆空间的管理较为松散。当希望将数据放入堆中时，可以请求特定大小的空间，操作系统会根据请求在堆中找到一块足够大的可用空间，并把指向这块空间地址的指针返回给我们。这个过程称为分配。 由于指针（内存地址）的大小是固定的且可以在编译期确定，因此可以将指针存放在栈中。通过指针指向的地址访问指针所指向的具体数据。 由于多了指针跳转的环节，访问堆上的数据要慢于访问栈上的数据。许多系统编程语言都需要程序员去记录代码中分配的堆空间，最小化堆上的冗余，并及时清理无用数据以避免耗尽内存空间。所有权的概念就是为了将上述问题交给 Rust 处理，减轻程序员的这部分心智负担。 所有权规则 Rust 中的每一个值都有一个对应的变量作为它的拥有者 在同一时间内，值有且只有一个拥有者 当所有者离开自己的作用域时，它拥有的值就会被释放掉 变量作用域作用域是一个对象在程序中有效的范围。 如：1234&#123; // 变量 s 还未声明，因此在这里不可用 let s = "hello"; // 从这里开始变量 s 变得可用 // 执行与 s 相关的操作&#125; // 作用域到这里结束，变量 s 不再可用 变量在进入作用域后变得有效 变量会保持自己的有效性直到离开自己的作用域 字符串字面量（如 let s = &quot;hello&quot;）属于被硬编码进程序的字符串值。很方便，但并不适用于所有场景。一是因为字符串字面量是不可变的，二是因为并不是所有字符串的值都能在编写代码时确定。比如需要获取用户的输入并保存。 Rust 提供了第二种字符串类型 String。String 会在堆上分配存储空间，因此能够处理未知大小的文本。12345let mut s = String::from("hello");s.push_str(", world!"); // push_str() 函数向 String 空间的尾部添加了一段字符串字面量println!("&#123;&#125;", s); // 这里会输出完整的 hello, world! 对于字符串字面量而言，由于在编译时就知道其内容，这部分硬编码的文本被直接嵌入到了可执行文件中。这也是访问字符串字面量异常高效的原因。对于 String 类型而言，为了支持一种可变的、可增长的类型，需要在堆上分配一块在编译时未知大小的内存来存放数据。当使用完 String 时，则需要通过某种方式来将这些内存归还给操作系统。 对于拥有 GC 机制的语言，GC 会替代程序员记录并清理那些不再使用的内存。而对于没有 GC 的语言，识别不再使用的内存并调用代码显式释放的工作就需要程序员来完成。假如忘记释放内存，就会造成内存泄漏；假如过早地释放内存，就会产生一个非法变量；假如重复释放同一块内存，就会产生无法预知的后果。 Rust 提供了另外一套解决方案：内存会在拥有它的变量离开作用域后自动地进行释放。1234&#123; // 变量 s 还未声明，因此在这里不可用 let s = String::from("hello"); // 从这里开始变量 s 变得可用 // 执行与 s 相关的操作&#125; // 作用域到这里结束，变量 s 失效 Rust 会在作用域结束的地方（即 } 处）自动回收分配给变量 s 的内存。 内存与分配对于整数类型的数据：12let x = 5;let y = x; 上述代码将整数值 5 绑定给变量 x，再创建一个 x 值的拷贝，绑定给变量 y。由于整数是已知固定大小的简单值，两个值 5 会同时被推入栈中。 对于 String 类型的数据：12let s1 = String::from("hello");let s2 = s1; 类似的代码，运行方式却并不一致。 String 的内存布局如下图： 对于绑定给变量 s1 的 String 来说，该字符串的文本内容（hello）保存在了堆上，同时在栈中保存着一个指向字符串内容的指针、一个长度和一个容量信息。 当将 s1 赋值给 s2 时，便复制了一次 String 的数据。这意味着我们复制了它存储在栈上的指针、长度和容量字段，而指针指向的堆上的数据并没有被复制。 变量 s1 和 s2 的内存布局如下图： 前面提到过，当一个变量离开当前的作用域时，Rust 会自动将变量使用的堆内存释放和回收。但若是有两个指针指向了同一个地址，就会导致如 s2 和 s1 离开自己的作用域时，Rust 会尝试重复释放相同的内存，进而有可能导致正在使用的数据发生损坏。为了确保内存安全，同时也避免复制分配的内存，Rust 在上述场景下会简单的将 s1 废弃。因此也就不需要在 s1 离开作用域后清理任何东西。这一行为即为 Move。 试图在 s2 创建完毕后访问 s1（如下所示）会导致编译错误。12345fn main() &#123; let s1 = String::from("hello"); let s2 = s1; // 变量 s1 在这里被废弃 print!("&#123;&#125;, world", s1); // 错误&#125; Rust 会报出 borrow of moved value: s1 错误。 Rust 永远不会自动创建数据的深度拷贝。 对于栈上数据的复制，比如：1234let x = 5;let y = x;println!("x = &#123;&#125;, y = &#123;&#125;", x, y); 上面的代码是完全合法的。因为整型的数据可以在编译时确定自己的大小，能够将数据完整地存储在栈中。对于这些类型而言，深度拷贝与浅度拷贝没有任何区别。 所有权与函数将值传递给函数在语义上类似于对变量进行赋值。将变量传递给函数将会触发移动或复制。 123456789101112131415161718fn main() &#123; let s = String::from("hello"); //变量 s 进入作用域 takes_ownership(s); // s 的值被移动进了函数 // 变量 s 从这里开始不再有效 let x = 5; // 变量 x 进入作用域 makes_copy(x); // 变量 x 被传递进了函数 // 但 i32 类型不受 Move 机制影响，因此这里 x 依旧可用&#125;fn takes_ownership(some_string: String) &#123; // some_string 进入作用域 print!("&#123;&#125;", some_string);&#125; // some_string 离开作用域，占用的内存被释放fn makes_copy(some_integer: i32) &#123; print!("&#123;&#125;", some_integer);&#125; // some_integer 离开作用域，没有特别的事情发生 在上述代码中，尝试在调用 takes_ownership 后使用变量 s 会导致编译错误。 函数在返回值的过程中也会发生所有权的转移。123456789101112131415fn main() &#123; let s1 = gives_ownership(); // gives_ownership 将它的返回值移动至变量 s1 中 let s2 = String::from("hello"); // 变量 s2 进入作用域 let s3 = takes_and_gives_back(s2); // s2 被移动进函数 takes_and_gives_back，而这个函数的返回值又被移动到了变量 s3 上&#125; // s3 和 s1 在这里离开作用域并被销毁，而 s2 已经移动了，因此不会发生任何事情fn gives_ownership() -&gt; String &#123; let some_string = String::from("hello"); // some_string 进入作用域 some_string // some_string 作为返回值移动至调用方&#125;// takes_and_gives_back 将取得一个 String 的所有权并将它作为结果返回fn takes_and_gives_back(a_string: String) -&gt; String &#123; a_string // a_string 作为返回值移动至调用方&#125; 变量的所有权转移总是遵循相同的模式：将一个值赋值给另一个变量时就会转移所有权。当一个持有堆数据的变量离开作用域时，它的数据就会被清理回收，除非这些数据的所有权被移动到了另一个变量上。 引用与借用参考如下示例代码：12345678910fn main() &#123; let s1 = String::from("hello"); let (s2, len) = calculate_length(s1); print!("The length of '&#123;&#125;' is &#123;&#125;", s2, len);&#125;fn calculate_length(s: String) -&gt; (String, usize) &#123; let length = s.len(); (s, length)&#125; 由于调用 caculate_length 会导致 String 移动到函数体内部，我们又需要在调用后继续使用该 String，因此不得不通过元组将 String 作为元素继续返回。 这种写法未免过于笨拙。在下面的代码中，新的 calculate_length 函数使用了 String 的引用作为参数而不会直接转移值的所有权。 123456789fn main() &#123; let s1 = String::from("hello"); let len = calculate_length(&amp;s1); print!("The length of '&#123;&#125;' is &#123;&#125;", s1, len);&#125;fn calculate_length(s: &amp;String) -&gt; usize &#123; s.len()&#125; 在新的代码中，调用 calculate_length 函数时使用了 &amp;s1 作为参数，且在该函数的定义中使用 &amp;String 替代了 String。&amp; 代表引用，允许在不获取所有权的情况下使用值。 &amp;s1 语法允许在不转移所有权的前提下创建一个指向 s1 值的引用。由于引用不持有值的所有权，当引用离开当前作用域时，它指向的值也不会被丢弃。当一个函数使用引用而不是值本身作为参数时，我们就不需要为了归还所有权而特意去返回值。毕竟引用根本没有取得所有权。 这种通过引用传递参数给函数的方法也称作借用。 可变引用与变量类似，引用默认是不可变的。Rust 不允许修改引用指向的值（除非声明为 mut）。 123456789fn main() &#123; let mut s = String::from("hello"); change(&amp;mut s); print!("&#123;&#125;", s)&#125;fn change(some_string: &amp;mut String) &#123; some_string.push_str(", world");&#125; 对于特定作用域中的特定数据，一次只能声明一个可变引用。比如：123456fn main() &#123; let mut s = String::from("hello"); let r1 = &amp;mut s; let r2 = &amp;mut s; println!("&#123;&#125;", r1)&#125; 就会出现 cannot borrow s as mutable more than once at a time 编译错误。这个规则使得引用的可变性只能以一种受到严格限制的方式使用。但另一方面，遵循这条限制性规则可以在编译时避免数据竞争。即不允许两个或两个以上的指针同时访问（且至少有一个指针会写入数据）同一空间。数据竞争会导致未定义的行为，往往难以在运行时进行跟踪，也就使得出现的 bug 更加难以被诊断和修复。 不能在拥有不可变引用的同时创建可变引用。编译时会报出 cannot borrow s as immutable because it is also borrowed as mutable 错误。1234567fn main() &#123; let mut s = String::from("hello"); let r1 = &amp;s; // 没问题 let r2 = &amp;s; // 没问题 let r3 = &amp;mut s; // 错误 println!("&#123;&#125;", r2)&#125; 不能在拥有不可变引用的同时创建可变引用，但可以同时存在多个不可变引用。因为对数据的只读操作不会影响到其他读取数据的用户。 Rust 编译器可以为用户提早（编译时而不是运行时）暴露那些潜在的 bug，并且明确指出出现问题的地方。用户就不再需要去追踪调试为何数据会在运行时发生了非预期的变化。 参考资料The Rust Programming Language]]></content>
      <categories>
        <category>Rust</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Reference</tag>
        <tag>Rust</tag>
        <tag>Ownership</tag>
        <tag>Move</tag>
        <tag>Pointer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[The Rust programming language 读书笔记——通用编程概念]]></title>
    <url>%2F2021%2F06%2F04%2Fthe-rust-programming-language-reading-notes-common-concepts%2F</url>
    <content type="text"><![CDATA[一、变量Rust 中的变量默认是不可变的。 可以通过如下代码测试变量的不可变性： 使用 cargo new variables 命令创建新的 Rust 项目 进入新创建的 variables 目录，编辑 src/main.rs 源代码文件 123456fn main() &#123; let x = 10; println!("The value is &#123;&#125;", x); x = 20; println!("The value is &#123;&#125;", x);&#125; 运行 cargo run 命令编译并执行 Rust 程序，出现如下报错：1error[E0384]: cannot assign twice to immutable variable `x` 即 Rust 编译器不允许程序代码对不可变变量进行二次赋值。 可以通过 let mut 关键字声明可变变量。123456fn main() &#123; let mut x = 10; println!("The value is &#123;&#125;", x); x = 20; println!("The value is &#123;&#125;", x);&#125; 12345$ cargo run Finished dev [unoptimized + debuginfo] target(s) in 0.29s Running `target/debug/variables`The value is 10The value is 20 PS：在使用重型数据结构时，适当地使用可变性去修改一个实例，可能比重新返回一个新分配的实例更有效率；而数据结构更为轻量时，采用偏函数式的风格创建新变量来进行赋值，可能会使代码更易于理解。 常量 使用 const 而不是 let 关键字声明常量 声明常量时必须显式地标注值的类型 常量可以被声明在任何作用域中。在一个值需要被不同部分的代码共同引用时很有用处 无法将一个函数的返回值或其他需要在运行时计算的值绑定到常量上 const PI: f32 = 3.1415; ShadowShadow 的意思是，一个新声明的变量可以覆盖掉旧的同名变量。 123456fn main() &#123; let x = 5; let x = x + 1; let x = x * 2; println!("The value is &#123;&#125;", x);&#125; 123 Finished dev [unoptimized + debuginfo] target(s) in 0.00s Running `target/debug/variables`The value is 12 Shadow 机制允许在复用变量名称的同时改变变量的类型。比如下面的代码就是合法的：12let spaces = " ";let sapces = spaces.len(); 通过复用 spaces 这个名字，就不需要再声明诸如 spaces_str 和 spaces_num 之类的变量。 但如果使用 mut 关键字来模拟上述效果就会报错。12let mut spaces = " ";spaces = spaces.len(); 因为编译器拒绝修改变量的类型，即便该变量是可变的。Shadow 的机制在于使用 let 关键字重新声明了变量。 二、数据类型Rust 是一门静态类型语言，在编译过程中需要知道所有变量的具体类型。 大部分情况下，编译器可以自动推导出变量类型。但比如需要将 String 类型转换为数值类型时，就必须显式地添加类型标注：let guess: u32 = &quot;42&quot;.parse().expect(&quot;Not a number&quot;); 标量（Scalar）类型标量类型是单个值类型的统称。Rust 内置 4 种基础的标量类型：整数、浮点数、布尔值和字符。 整数类型 长度 有符号 无符号 8 bit i8 u8 16 bit i16 u16 32 bit i32 u32 64 bit i64 u64 有无符号代表了一个整数类型是否包含负数。即有符号的整数总是需要一个 bit 表示当前数值是否为正。对于一个 n bit 的有符号整数，其取值范围是 - 2 ^ (n - 1) 到 2 ^ (n - 1) - 1；长度为 n bit 的无符号整数，其取值范围则是 0 到 2 ^ n - 1。 浮点数类型包含 f32 和 f64 两种类型。Rust 默认会将未标注类型的浮点数推导为 f64。整数会推导为 i32。 字符类型Rust 中，char 类型使用单引号指定，字符串类型使用双引号指定。 char 类型占用 4 个字节，是一个 Unicode 标量值。let smile = &#39;😀&#39;; 复合类型复合类型可以将多个不同类型的值组合成一个类型。Rust 内置两种复合类型，元组和数组。 元组 元组每个位置上的值都有一个类型 元组拥有固定的长度。无法在声明结束后增加或减少其中的元素。 123fn main() &#123; let tup: (i32, f64, u8) = (500, 6.4, 1);&#125; 为了从元组中获取单个值，可以使用模式匹配来解构（拆包）元组。12345fn main() &#123; let tup = (500, 6.4, 1); let (x, y, z) = tup; print!("The value of y is: &#123;&#125;", y);&#125; 还可以通过索引使用点号访问元组中的元素。123456fn main() &#123; let x: (i32, f64, u8) = (500, 6.4, 1); let five_hundred = x.0; let six_point_four = x.1; let one = x.2;&#125; 数组 数组中的所有元素都必须是相同的类型 数组拥有固定的长度，一旦声明就无法更改大小 12345678910111213141516fn main() &#123; let months = [ "January", "February", "March", "April", "May", "June", "July", "August", "September", "October", "November", "December", ];&#125; 数组的类型标注：let a: [i32; 5] = [1, 2, 3, 4, 5]; 初始化含有相同元素的数组：let a = [3; 5];等价于 let a = [3, 3, 3, 3, 3]; 数组由一整块分配在栈上的内存组成，可以通过索引访问数组中的元素。123456fn main() &#123; let a = [1, 2, 3, 4, 5]; let first = a[0]; let second = a[1];&#125; 三、函数必须显式地声明每个参数（如果有）的数据类型。12345678fn main() &#123; another_function(5, 6);&#125;fn another_function(x: i32, y: i32) &#123; print!("The value of x is: &#123;&#125;", x); print!("The value of y is: &#123;&#125;", y);&#125; Rust 是一门基于表达式的语言。它将语句（statement）与表达式（expression）区分为两个不同的概念。 如使用 let 关键字创建变量并绑定值时的指令就是一条语句：let y = 6;语句不会返回值。 在 C 或 Ruby 语言里，赋值语句会返回所赋的值。因此可以使用 x = y =6 这样的语句，但 Rust 不支持这样的语法。 表达式会计算出某个值作为结果返回。如 5 + 6 就是表达式（返回 11），let y = 6 中的数字 6 也是表达式（返回 6 本身）。表达式本身可以作为语句的一部分。用来创建新作用域的大括号也是表达式。 123456789fn main() &#123; let x = 5; let y = &#123; let x = 3; x + 1 &#125;; println!("The value of y is: &#123;&#125;", y);&#125; 在上述代码中，let y = 后面大括号部分的内容就是一个表达式，它会将计算出的结果 4 作为返回值。该返回值接着通过赋值语句绑定给变量 y。结尾处的 x + 1 并没有添加分号。若加上分号，则这段代码就变成了语句而不会返回任何值。 函数可以向调用它的代码返回值。但需要在箭头后面声明值的类型。可以使用 return 关键字指定一个值提前从函数中返回，但大多数函数都隐式地返回了最后的表达式。12345678fn main() &#123; let x = plus_one(5); print!("The value of x is: &#123;&#125;", x);&#125;fn plus_one(x: i32) -&gt; i32 &#123; x + 1&#125; 上述代码会输出 6。但如果在 plus_one 函数末尾的 x + 1 处加上分号，该表达式就会变成语句（不返回任何值），最终在编译时报出 mismatched types 错误。原因是 plus_one 的声明中指定返回值类型为 i32，但由于语句不返回任何值，Rust 默认返回了一个空元组（()），导致实际的返回值类型与函数定义产生了冲突。 四、控制流if 表达式if 表达式必须产生一个 bool 类型的值，否则会触发编译错误。123456fn main() &#123; let number = 3; if number &#123; print!("number was three"); &#125;&#125; 在上面的代码中，if 表达式的计算结果为 3，而 Rust 期望获得一个 bool 值，因此编译时会爆出 mismatched types 错误。Rust 不会自动尝试将非布尔值转换为布尔类型。 if 是一个表达式。可以在 let 语句右侧使用 if 表达式来完成赋值。123456789fn main() &#123; let condition = true; let number = if condition &#123; 5 &#125; else &#123; 6 &#125;; print!("The value of number is &#123;&#125;", number);&#125; 整个 if 表达式的值取决于具体哪一个代码块得到了执行。因此，所有 if 分支可能返回的值都必须是同一种类型的。否则会触发编译错误。123456789fn main() &#123; let condition = true; let number = if condition &#123; 5 &#125; else &#123; "six" // 错误，类型不匹配 &#125;; print!("The value of number is &#123;&#125;", number);&#125; 循环Rust 提供了 3 种循环：loop、while、for。 从 loop 循环中返回值123456789101112fn main() &#123; let mut counter = 0; let result = loop &#123; counter += 1; if counter == 10 &#123; break counter * 2; &#125; &#125;; print!("The result is &#123;&#125;", result);&#125; break 关键字中断循环并返回 counter * 2。 while 循环1234567891011fn main() &#123; let mut number = 3; while number != 0 &#123; println!("&#123;&#125;!", number); number = number - 1; &#125; println!("LIFTOFF!!!");&#125; for 循环遍历集合中的元素1234567fn main() &#123; let a = [10, 20, 30, 40, 50]; for element in a.iter() &#123; println!("the value is: &#123;&#125;", element); &#125;&#125; for 循环重构前面使用 while 循环的代码123456fn main() &#123; for number in (1..4).rev() &#123; println!("&#123;&#125;!", number); &#125; println!("LIFTOFF!!!");&#125; 参考资料The Rust Programming Language]]></content>
      <categories>
        <category>Rust</category>
      </categories>
      <tags>
        <tag>Function</tag>
        <tag>Development</tag>
        <tag>Programming</tag>
        <tag>Basic</tag>
        <tag>Rust</tag>
        <tag>Variable</tag>
        <tag>Loop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vim 8.1 懒人配置手册（包含 C/C++、Python、Rust 自动补全，基于 coc.nvim）]]></title>
    <url>%2F2021%2F05%2F30%2Fvim-configuration-with-coc-support-rust-c-python-complete%2F</url>
    <content type="text"><![CDATA[先说点废话。 最近装了 WSL2，想着作为 Win10 内置的 Linux 系统，应该比一般的虚拟机要来得平滑一些。毕竟虚拟机还要装 Virtualbox，每次开机还要多点几下，还要等它启动。怕麻烦。。。 可能习惯问题，喜欢在 Linux 下配置开发环境（学习写代码）。总感觉 Windows 上略显磨叽了一些。也许我道行不够。碰到需要编译的东西，一套工具装起来过于繁琐，直接 sudo apt install gcc 不香吗。 可惜 WSL 没有桌面支持，装不上 Vscode。对于工具的选择，我的原则是简单够用就好，Vscode 即是目前我的最爱（非重度编码）。开箱即用，功能满足基本需求。无非代码高亮、自动补全、查看定义、语法检查、代码格式化，再加个跳转。 于是决定在 Windows 系统上安装 Vscode，借助 Remote WSL 插件“远程”编码。可惜有 BUG，一直不能正常工作。Github 上提了 issue，没人理。无奈转向 Vim。 一开始用的补全插件是 YouCompleteMe，还要编译。虽然敲个命令就能自动执行，但光 Rust 支持就在本地给我搞了将近 1G 的文件，不太能忍。网上查了下，貌似已经很老的机制了。于是转向较新一点的 coc.nvim。据说支持各种 LSP（这个缩写。。。），也不懂，能用就行。 废话结束。 一、效果截图 二、NERDTree 文件浏览器vim 用的自带的 8.1 版本，有内置的插件管理。一般的插件安装流程是直接将插件源代码 clone 到 ~/.vim/pack/vendor/start 路径下（没有就创建），再在 vim 中运行 :helptags ~/.vim/pack/vendor/start/someplugin/doc 命令生成帮助文档（这一步可选）。 vim 会自动检测已经下载的插件。vendor 路径下可以有 start 和 opt 两个目录，start 路径下的插件会在 vim 启动时自动加载，opt 路径下的插件则需要通过 :packadd 命令手动加载。 vendor 也可以是其他名称，同位置下也可以有多个相同结构的目录，方便对不同类型的插件分别进行管理。省事起见，这里所有的插件都放在 ~/.vim/pack/vendor/start 下面。 NERDTree 文件浏览器插件安装：12cd ~/.vim/pack/vendor/startgit clone https://github.com/scrooloose/nerdtree 在 ~/.vimrc 文件中添加配置：12345678" 进入 vim 时自动开启 NERDTreeautocmd VimEnter * NERDTree | wincmd p" 若关闭某个 buff 后 NERDTree 是仅剩的最后一个 buff，则自动关闭 NERDTreeautocmd BufEnter * if tabpagenr('$') == 1 &amp;&amp; winnr('$') == 1 &amp;&amp; exists('b:NERDTree') &amp;&amp; b:NERDTree.isTabTree() | quit | endif" 使用 Ctrl+n 快捷键打开或关闭 NERDTreennoremap &lt;C-n&gt; :NERDTreeToggle&lt;CR&gt; 更多配置选项参考 VimAwesome 三、vim-airline 与配色安装 vim-airline 状态栏美化插件：git clone https://github.com/vim-airline/vim-airline 关于配色，萝卜青菜各有所爱。懒得去一个一个试。准备了两套，vim-one 深色和 gruvbox 浅色。 vim-one 插件安装：git clone https://github.com/rakr/vim-one 添加配置：12345" 深色背景set bg=dark" 启用 one 配色colorscheme one 效果截图： 安装 gruvbox 插件：git clone https://github.com/morhetz/gruvbox 修改配置文件（注释掉 colorscheme one）：123set bg=light" colorscheme oneautocmd vimenter * ++nested colorscheme gruvbox 效果截图： 更复杂的配置可自行在 VimAwesome 搜索对应的插件，或者进入相应的 Github 主页查看。 四、coco.nvim 代码补全与语法检查安装 nodejs &gt;= 10.12，官网上写的是通过 curl -sL install-node.now.sh/lts | bash 命令安装。我个人建议使用 nvm 安装最新的 lts 版本。此处不赘述。 安装 coc.nvim 插件：git clone https://github.com/neoclide/coc.nvim.git 为了得到某种编程语言的补全功能，还需要安装对应语言的 coc 扩展以及代码补全后端（LSP）。比如 C/C++ 对应的 coc 扩展为 coc-clangd，LSP 为 clangd。两个都需要。 安装 coc 扩展的方法非常简单，进入 vim 后运行 :CocInstall extension_name 命令即可。比如使用 :CocInstall coc-clangd 命令安装 coc-clangd 扩展。coc 扩展我遇到的都比较小，安装非常迅速，也会单独开一个窗口显示进度信息。 coc 扩展安装完成后，打开对应的源代码文件，比如 vim test.c，vim 就会自动在本地环境中寻找对应的 LSP（C/C++ 语言是 clangd）。 若 clangd 此时并未安装，vim 就会提示你运行某个命令（在 vim 内部）自动安装该依赖。这里有个坑。不知道是不是网络的问题，我复制运行了 vim 提供的命令，一直显示下载中，几个小时不见下载完成。。。 好在可以手动安装 clangd，退出 vim 直接运行 sudo apt install clangd 即可。此时 coc.nvim 对于 C/C++ 的补全支持即安装配置完成。 Rust 和 Python 语言支持对于 Rust 语言，需要先安装 coc-rust-analyzer 扩展：:CocInstall coc-rust-analyzer这一步简单迅速。 安装 rust-src：rustup component add rust-src 接着还必须安装针对 Rust 的 LSP（rust-analyzer）。鉴于安装 clangd 时出现的曲折，我决定手动安装 rust-analyzer。诡异的事情发生了。手动安装的可执行程序不被 coc 识别。无奈下尝试 vim 中的自动安装居然成功了。。。 方法是用 vim 新建任意一个 rust 源文件（vim test.rs），vim 会自动弹出提示，找不到 rust-analyzer，是否自动安装，选择 Yes 即可。这里的安装过程居然异乎寻常的快。安装完成后可能不会立即生效，会尝试创建索引。多打开几个文件试试。 至于 Python，安装 coc-pyright：:CocInstall coc-pyright 印象中并没有做其他操作，对于 Python 的支持就自动生效了，也许是安装扩展的时候自动安装了对应的 LSP。 对于其他语言的支持，可参考 Using coc extensions。 coc.nvim 示例配置（从官方 Github 上 copy 的，主要是一些快捷键的映射，可根据需求删减。没细看）：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165" Set internal encoding of vim, not needed on neovim, since coc.nvim using some" unicode characters in the file autoload/float.vimset encoding=utf-8" TextEdit might fail if hidden is not set.set hidden" Some servers have issues with backup files, see #649.set nobackupset nowritebackup" Give more space for displaying messages.set cmdheight=2" Having longer updatetime (default is 4000 ms = 4 s) leads to noticeable" delays and poor user experience.set updatetime=300" Don't pass messages to |ins-completion-menu|.set shortmess+=c" Always show the signcolumn, otherwise it would shift the text each time" diagnostics appear/become resolved.if has("nvim-0.5.0") || has("patch-8.1.1564") " Recently vim can merge signcolumn and number column into one set signcolumn=numberelse set signcolumn=yesendif" Use tab for trigger completion with characters ahead and navigate." NOTE: Use command ':verbose imap &lt;tab&gt;' to make sure tab is not mapped by" other plugin before putting this into your config.inoremap &lt;silent&gt;&lt;expr&gt; &lt;TAB&gt; \ pumvisible() ? "\&lt;C-n&gt;" : \ &lt;SID&gt;check_back_space() ? "\&lt;TAB&gt;" : \ coc#refresh()inoremap &lt;expr&gt;&lt;S-TAB&gt; pumvisible() ? "\&lt;C-p&gt;" : "\&lt;C-h&gt;"function! s:check_back_space() abort let col = col('.') - 1 return !col || getline('.')[col - 1] =~# '\s'endfunction" Use &lt;c-space&gt; to trigger completion.if has('nvim') inoremap &lt;silent&gt;&lt;expr&gt; &lt;c-space&gt; coc#refresh()else inoremap &lt;silent&gt;&lt;expr&gt; &lt;c-@&gt; coc#refresh()endif" Make &lt;CR&gt; auto-select the first completion item and notify coc.nvim to" format on enter, &lt;cr&gt; could be remapped by other vim plugininoremap &lt;silent&gt;&lt;expr&gt; &lt;cr&gt; pumvisible() ? coc#_select_confirm() \: "\&lt;C-g&gt;u\&lt;CR&gt;\&lt;c-r&gt;=coc#on_enter()\&lt;CR&gt;"" Use `[g` and `]g` to navigate diagnostics" Use `:CocDiagnostics` to get all diagnostics of current buffer in location list.nmap &lt;silent&gt; [g &lt;Plug&gt;(coc-diagnostic-prev)nmap &lt;silent&gt; ]g &lt;Plug&gt;(coc-diagnostic-next)" GoTo code navigation.nmap &lt;silent&gt; gd &lt;Plug&gt;(coc-definition)nmap &lt;silent&gt; gy &lt;Plug&gt;(coc-type-definition)nmap &lt;silent&gt; gi &lt;Plug&gt;(coc-implementation)nmap &lt;silent&gt; gr &lt;Plug&gt;(coc-references)" Use K to show documentation in preview window.nnoremap &lt;silent&gt; K :call &lt;SID&gt;show_documentation()&lt;CR&gt;function! s:show_documentation() if (index(['vim','help'], &amp;filetype) &gt;= 0) execute 'h '.expand('&lt;cword&gt;') elseif (coc#rpc#ready()) call CocActionAsync('doHover') else execute '!' . &amp;keywordprg . " " . expand('&lt;cword&gt;') endifendfunction" Highlight the symbol and its references when holding the cursor.autocmd CursorHold * silent call CocActionAsync('highlight')" Symbol renaming.nmap &lt;leader&gt;rn &lt;Plug&gt;(coc-rename)" Formatting selected code.xmap &lt;leader&gt;f &lt;Plug&gt;(coc-format-selected)nmap &lt;leader&gt;f &lt;Plug&gt;(coc-format-selected)augroup mygroup autocmd! " Setup formatexpr specified filetype(s). autocmd FileType typescript,json setl formatexpr=CocAction('formatSelected') " Update signature help on jump placeholder. autocmd User CocJumpPlaceholder call CocActionAsync('showSignatureHelp')augroup end" Applying codeAction to the selected region." Example: `&lt;leader&gt;aap` for current paragraphxmap &lt;leader&gt;a &lt;Plug&gt;(coc-codeaction-selected)nmap &lt;leader&gt;a &lt;Plug&gt;(coc-codeaction-selected)" Remap keys for applying codeAction to the current buffer.nmap &lt;leader&gt;ac &lt;Plug&gt;(coc-codeaction)" Apply AutoFix to problem on the current line.nmap &lt;leader&gt;qf &lt;Plug&gt;(coc-fix-current)" Map function and class text objects" NOTE: Requires 'textDocument.documentSymbol' support from the language server.xmap if &lt;Plug&gt;(coc-funcobj-i)omap if &lt;Plug&gt;(coc-funcobj-i)xmap af &lt;Plug&gt;(coc-funcobj-a)omap af &lt;Plug&gt;(coc-funcobj-a)xmap ic &lt;Plug&gt;(coc-classobj-i)omap ic &lt;Plug&gt;(coc-classobj-i)xmap ac &lt;Plug&gt;(coc-classobj-a)omap ac &lt;Plug&gt;(coc-classobj-a)" Remap &lt;C-f&gt; and &lt;C-b&gt; for scroll float windows/popups.if has('nvim-0.4.0') || has('patch-8.2.0750') nnoremap &lt;silent&gt;&lt;nowait&gt;&lt;expr&gt; &lt;C-f&gt; coc#float#has_scroll() ? coc#float#scroll(1) : "\&lt;C-f&gt;" nnoremap &lt;silent&gt;&lt;nowait&gt;&lt;expr&gt; &lt;C-b&gt; coc#float#has_scroll() ? coc#float#scroll(0) : "\&lt;C-b&gt;" inoremap &lt;silent&gt;&lt;nowait&gt;&lt;expr&gt; &lt;C-f&gt; coc#float#has_scroll() ? "\&lt;c-r&gt;=coc#float#scroll(1)\&lt;cr&gt;" : "\&lt;Right&gt;" inoremap &lt;silent&gt;&lt;nowait&gt;&lt;expr&gt; &lt;C-b&gt; coc#float#has_scroll() ? "\&lt;c-r&gt;=coc#float#scroll(0)\&lt;cr&gt;" : "\&lt;Left&gt;" vnoremap &lt;silent&gt;&lt;nowait&gt;&lt;expr&gt; &lt;C-f&gt; coc#float#has_scroll() ? coc#float#scroll(1) : "\&lt;C-f&gt;" vnoremap &lt;silent&gt;&lt;nowait&gt;&lt;expr&gt; &lt;C-b&gt; coc#float#has_scroll() ? coc#float#scroll(0) : "\&lt;C-b&gt;"endif" Use CTRL-S for selections ranges." Requires 'textDocument/selectionRange' support of language server.nmap &lt;silent&gt; &lt;C-s&gt; &lt;Plug&gt;(coc-range-select)xmap &lt;silent&gt; &lt;C-s&gt; &lt;Plug&gt;(coc-range-select)" Add `:Format` command to format current buffer.command! -nargs=0 Format :call CocAction('format')" Add `:Fold` command to fold current buffer.command! -nargs=? Fold :call CocAction('fold', &lt;f-args&gt;)" Add `:OR` command for organize imports of the current buffer.command! -nargs=0 OR :call CocAction('runCommand', 'editor.action.organizeImport')" Add (Neo)Vim's native statusline support." NOTE: Please see `:h coc-status` for integrations with external plugins that" provide custom statusline: lightline.vim, vim-airline.set statusline^=%&#123;coc#status()&#125;%&#123;get(b:,'coc_current_function','')&#125;" Mappings for CoCList" Show all diagnostics.nnoremap &lt;silent&gt;&lt;nowait&gt; &lt;space&gt;a :&lt;C-u&gt;CocList diagnostics&lt;cr&gt;" Manage extensions.nnoremap &lt;silent&gt;&lt;nowait&gt; &lt;space&gt;e :&lt;C-u&gt;CocList extensions&lt;cr&gt;" Show commands.nnoremap &lt;silent&gt;&lt;nowait&gt; &lt;space&gt;c :&lt;C-u&gt;CocList commands&lt;cr&gt;" Find symbol of current document.nnoremap &lt;silent&gt;&lt;nowait&gt; &lt;space&gt;o :&lt;C-u&gt;CocList outline&lt;cr&gt;" Search workspace symbols.nnoremap &lt;silent&gt;&lt;nowait&gt; &lt;space&gt;s :&lt;C-u&gt;CocList -I symbols&lt;cr&gt;" Do default action for next item.nnoremap &lt;silent&gt;&lt;nowait&gt; &lt;space&gt;j :&lt;C-u&gt;CocNext&lt;CR&gt;" Do default action for previous item.nnoremap &lt;silent&gt;&lt;nowait&gt; &lt;space&gt;k :&lt;C-u&gt;CocPrev&lt;CR&gt;" Resume latest coc list.nnoremap &lt;silent&gt;&lt;nowait&gt; &lt;space&gt;p :&lt;C-u&gt;CocListResume&lt;CR&gt; 五、彩蛋smile在 vim 中运行 :smile 效果： 123456789101112131415161718192021222324252627:smile oooo$$$$$$$$$$$$oooo oo$$$$$$$$$$$$$$$$$$$$$$$$o oo$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$o o$ $$ o$ o $ oo o$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$o $$ $$ $$o$ oo $ $ &quot;$ o$$$$$$$$$ $$$$$$$$$$$$$ $$$$$$$$$o $$$o$$o$ &quot;$$$$$$o$ o$$$$$$$$$ $$$$$$$$$$$ $$$$$$$$$$o $$$$$$$$ $$$$$$$ $$$$$$$$$$$ $$$$$$$$$$$ $$$$$$$$$$$$$$$$$$$$$$$ $$$$$$$$$$$$$$$$$$$$$$$ $$$$$$$$$$$$$ $$$$$$$$$$$$$$ &quot;&quot;&quot;$$$ &quot;$$$&quot;&quot;&quot;&quot;$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$ &quot;$$$ $$$ o$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$ &quot;$$$o o$$&quot; $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$ $$$o $$$ $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$&quot; &quot;$$$$$$ooooo$$$$o o$$$oooo$$$$$ $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$ o$$$$$$$$$$$$$$$$$ $$$$$$$$&quot;$$$$ $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$ $$$$&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; &quot;&quot;&quot;&quot; $$$$ &quot;$$$$$$$$$$$$$$$$$$$$$$$$$$$$&quot; o$$$ &quot;$$$o &quot;&quot;&quot;$$$$$$$$$$$$$$$$$$&quot;$$&quot; $$$ $$$o &quot;$$&quot;&quot;$$$$$$&quot;&quot;&quot;&quot; o$$$ $$$$o o$$$&quot; &quot;$$$$o o$$$$$$o&quot;$$$$o o$$$$ &quot;$$$$$oo &quot;&quot;$$$$o$$$$$o o$$$$&quot;&quot; &quot;&quot;$$$$$oooo &quot;$$$o$$$$$$$$$&quot;&quot;&quot; &quot;&quot;$$$$$$$oo $$$$$$$$$$ &quot;&quot;&quot;&quot;$$$$$$$$$$$ $$$$$$$$$$$$ $$$$$$$$$$&quot; &quot;$$$&quot;&quot;&quot;&quot; Kill Sheep 小游戏针对 vim 8.2 版本，可在 Windows 系统中安装 gvim 8.2。 进入 C:\Users\xxx\vimfiles\pack\vendor\start 路径下（没有就创建），clone 源代码：git clone https://github.com/vim/killersheep.git 打开 gvim，最大化，运行 :KillKillKill 命令即可进入游戏。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Configuration</tag>
        <tag>Tools</tag>
        <tag>Vim</tag>
        <tag>Editor</tag>
        <tag>Rust</tag>
        <tag>IDE</tag>
        <tag>Completer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows Terminal 美化（wsl2、zsh、天气、数字时钟、ASCII Logo、彩色动画）]]></title>
    <url>%2F2021%2F05%2F26%2Fwindows-terminal-beautify-wsl2-weather-digital-clock-splash-animation%2F</url>
    <content type="text"><![CDATA[上次用 WSL（Windows Subsystem for Linux）要追溯到好几年前了。当时 WSL 刚出来不久，抱着尝鲜的态度试着装了，想着万一能用，就不用装虚拟机了。 结果遇到了 BUG，就再也没用过。最近才听说 WSL2 已经有了，类似虚拟机的机制，好用很多。再次装来试试，目前还没遇到啥问题。记录下初始的美化步骤。 一、效果截图天气、日历、数字时钟、Linux 发行版的 logo、系统信息 123456789101112131415161718192021222324252627282930Weather report: Hangzhou May 2021 Su Mo Tu We Th Fr Sa ┌────────────────────────────┐ _`/&quot;&quot;.-. Rain shower, mist 1 │ ┏━┓┏━┓ ┏━┓┏━┓ ┏━┓┏┳┓ │ ,\_( ). 21 °C 2 3 4 5 6 7 8 │ ┃┃┃┣━┓╹┃┃┃┣━┓ ┣━┛┃┃┃ │ /(___(__) ↓ 15 km/h 9 10 11 12 13 14 15 │ ┗━┛┗━┛╹┗━┛┗━┛ ╹ ╹ ╹ │ ‘ ‘ ‘ ‘ 3 km 16 17 18 19 20 21 22 └────────────────────────────┘ ‘ ‘ ‘ ‘ 0.8 mm 23 24 25 26 27 28 29 30 31 _-`````-, ,- &apos;- . starky@xxxxxx .&apos; .- - | | - -. `. ---------------- /.&apos; / `. \ OS: Ubuntu 20.04.2 LTS on Windows 10 x86_64:/ : _... ..._ `` : Kernel: 5.4.72-microsoft-standard-WSL2:: : /._ .`:&apos;_.._\. || : Uptime: 38 mins:: `._ ./ ,` : \ . _.&apos;&apos; . Packages: 736 (dpkg)`:. / | -. \-. \_ / Shell: zsh 5.8 \:._ _/ .&apos; .@) \@) ` `\ ,.&apos; Terminal: /dev/pts/0 _/,--&apos; .- .\,-.`--`. CPU: Intel i7-10850H (12) @ 2.712GHz ,&apos;/&apos;&apos; (( \ ` ) Memory: 118MiB / 12466MiB (0%) /&apos;/&apos; \ `-&apos; ( CPU Usage: 1% &apos;/&apos;&apos; `._,-----&apos; Disk (/): 3.3G / 251G (2%) &apos;&apos;/&apos; .,---&apos; Battery1: 100% [Full] &apos;&apos;/&apos; ;: Local IP: xx.xx.xx.xx &apos;&apos;/&apos;&apos; &apos;&apos;/ Public IP: xx.xx.xx.xx &apos;&apos;/&apos;&apos;/&apos;&apos; &apos;/&apos;/&apos; `;GNU 启动动画 动图（加载慢） 二、安装 WSL2 和 Windows Terminal参考微软官方文档 Windows Subsystem for Linux Installation Guide for Windows 10 很详细，不用再看其他文章了。 三、oh-my-zsh进入 wsl，安装 zsh：sudo apt updatesudo apt install zsh -y 安装 oh-my-zsh：sh -c &quot;$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&quot; 安装 Powerline9k 主题：git clone https://github.com/bhilburn/powerlevel9k.git ~/.oh-my-zsh/custom/themes/powerlevel9k 启用 Powerline9k 主题：编辑 ~/.zshrc 配置文件，修改 ZSH_THEME 项的内容为 ZSH_THEME=&quot;powerlevel9k/powerlevel9k&quot; 安装字体：访问 nerd-fonts 的 Github release 页，下载某种字体的压缩包（如 JetBrainsMono.zip），解压后在 Windows 系统上安装字体文件（有些时候可能需要使用管理员权限安装） 修改 Windows Terminal 的默认字体： 四、oh-my-zh 插件安装 zsh-autosuggestions：git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions 安装 zsh-syntax-highlighting：git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting 启用插件（包含默认插件）：修改 ~/.zshrc 配置文件的 plugins 项，内容如下（可按需添加或删减）123456789101112131415plugins=( cargo command-not-found docker git golang npm nvm rust sudo systemd web-search zsh-autosuggestions zsh-syntax-highlighting) 插件安装完成后，如上图中的情况，直接按键盘上的右方向键即可自动补全命令。 五、neofetch 获取 Linux 发行版 ASCII logo 和系统信息安装 neofetch：sudo apt install neofetch 效果如下：123456789101112131415161718192021222324$ neofetch --ascii_distro raspbian `.::///+:/-. --///+//-:`` starky@xxxxxx `+oooooooooooo: `+oooooooooooo: ---------------- /oooo++//ooooo: ooooo+//+ooooo. OS: Ubuntu 20.04.2 LTS on Windows 10 x86_64 `+ooooooo:-:oo- +o+::/ooooooo: Kernel: 5.4.72-microsoft-standard-WSL2 `:oooooooo+`` `.oooooooo+- Uptime: 11 mins `:++ooo/. :+ooo+/.` Packages: 736 (dpkg) ...` `.----.` ``.. Shell: zsh 5.8 .::::-``:::::::::.`-:::-` Terminal: /dev/pts/0 -:::-` .:::::::-` `-:::- CPU: Intel i7-10850H (12) @ 2.712GHz `::. `.--.` `` `.---.``.::` Memory: 107MiB / 12466MiB (0%) .::::::::` -::::::::` ` CPU Usage: 0% .::` .:::::::::- `::::::::::``::. Disk (/): 3.3G / 251G (2%)-:::` ::::::::::. ::::::::::.`:::- Battery1: 100% [Full]:::: -::::::::. `-:::::::: :::: Local IP: xx.xx.xx.xx-::- .-:::-.``....``.-::-. -::- Public IP: xx.xx.xx.xx .. `` .::::::::. `..`.. -:::-` -::::::::::` .:::::` :::::::` -::::::::::` :::::::. .::::::: -::::::::. :::::::: `-:::::` ..--.` ::::::. `...` `...--..` `...` .:::::::::: `.-::::-` neofetch 默认会输出当前系统的 logo，这里写个脚本（random_distro.sh）随机获取某个 Linux 发行版的 logo。12345678# random_distro.shdistro_list=('Alpine' 'Anarchy' 'Android' 'Antergos' 'antiX' 'AOSC' 'ArcoLinux' 'ArchBox' 'ARCHlabs' 'ArchStrike' 'XFerience' 'ArchMerge' 'Arch' 'Artix' 'Arya' 'Bedrock' 'BlackArch' 'BLAG' 'BlankOn' 'BlueLight' 'bonsai' 'BSD' 'BunsenLabs' 'Calculate' 'Carbs' 'CentOS' 'Chakra' 'Chapeau' 'Chrom' 'Cleanjaro' 'ClearOS' 'Clear_Linux' 'Clover' 'Condres' 'Container_Linux' 'CRUX' 'Debian' 'Deepin' 'DesaOS' 'Devuan' 'DracOS' 'DragonFly' 'Drauger' 'Elementary' 'EndeavourOS' 'Endless' 'Exherbo' 'Fedora' 'Feren' 'FreeBSD' 'FreeMiNT' 'Frugalware' 'Funtoo' 'GalliumOS' 'Gentoo' 'Pentoo' 'GNU' 'GoboLinux' 'Grombyang' 'Guix' 'Haiku' 'Huayra' 'Hyperbola' 'janus' 'Kali' 'KaOS' 'KDE_neon' 'Kogaion' 'Korora' 'KSLinux' 'Kubuntu' 'LEDE' 'LFS' 'Linux_Lite' 'LMDE' 'Lubuntu' 'Lunar' 'macos' 'Mageia' 'Mandriva' 'Manjaro' 'Maui' 'Mer' 'Minix' 'LinuxMint' 'MX_Linux' 'Namib' 'Neptune' 'NetBSD' 'Netrunner' 'NixOS' 'Nurunner' 'NuTyX' 'OBRevenge' 'OpenBSD' 'OpenIndiana' 'OpenMandriva' 'OpenWrt' 'osmc' 'Oracle' 'Parabola' 'Pardus' 'Parrot' 'Parsix' 'TrueOS' 'PCLinuxOS' 'Peppermint' 'popos' 'Porteus' 'PostMarketOS' 'Puppy' 'PureOS' 'Qubes' 'Radix' 'Raspbian' 'Reborn_OS' 'Redstar' 'Redcore' 'Redhat' 'Refracted_Devuan' 'Rosa' 'sabotage' 'Sabayon' 'Sailfish' 'SalentOS' 'Scientific' 'Septor' 'SharkLinux' 'Siduction' 'SliTaz' 'SmartOS' 'Solus' 'Source_Mage' 'Sparky' 'Star' 'SteamOS' 'SunOS' 'openSUSE_Leap' 'openSUSE' 'SwagArch' 'Tails' 'Trisquel' 'Ubuntu-Budgie' 'Ubuntu-GNOME' 'Ubuntu-MATE' 'Ubuntu-Studio' 'Void' 'Obarun' 'windows10' 'Windows7' 'Xubuntu')length=$&#123;#distro_list[@]&#125;distro=$&#123;distro_list[$RANDOM % $length]&#125;neofetch --ascii_distro $distro 运行 bash random_distro.sh 即可获取随机的 Linux 发行版 logo。 为了使该脚本可以在 Terminal 启动时自动运行，可以添加如下一条命令到 ~/.zshrc 配置文件末尾：bash /path/to/random_distro.sh 六、Shell 脚本显示天气和数字时钟weather-clock.sh 脚本从网上找的，没做改动（参考文章 Terminal splash screen with Weather, Calendar, Time &amp; Sysinfo?）。代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136#!/bin/bash# NAME: now# PATH: $HOME/bin# DESC: Display current weather, calendar and time# CALL: Called from terminal or ~/.bashrc# DATE: Apr 6, 2017. Modified: May 24, 2019.# UPDT: 2019-05-24 If Weather unavailable nicely formatted error message.# NOTE: To display all available toilet fonts use this one-liner:# for i in $&#123;TOILET_FONT_PATH:=/usr/share/figlet&#125;/*.&#123;t,f&#125;lf; do j=$&#123;i##*/&#125;; toilet -d "$&#123;i%/*&#125;" -f "$j" "$&#123;j%.*&#125;"; done# Setup for 92 character wide terminalDateColumn=34 # Default is 27 for 80 character line, 34 for 92 character lineTimeColumn=61 # Default is 49 for " " " " 61 " " " "# Replace Edmonton with your city name, GPS, etc. See: curl wttr.in/:helpcurl wttr.in/Hangzhou?0 --silent --max-time 3 &gt; /tmp/now-weather# Timeout #. Increase for slow connection---^readarray aWeather &lt; /tmp/now-weatherrm -f /tmp/now-weather# Was valid weather report found or an error message?if [[ "$&#123;aWeather[0]&#125;" == "Weather report:"* ]] ; then WeatherSuccess=true echo "$&#123;aWeather[@]&#125;"else WeatherSuccess=false echo "+============================+" echo "| Weather unavailable now!!! |" echo "| Check reason with command: |" echo "| |" echo "| curl wttr.in/Edmonton?0 |" # Replace Edmonton with your city echo "| --silent --max-time 3 |" echo "+============================+" echo " "fiecho " " # Pad blank lines for calendar &amp; time to fit#--------- DATE -------------------------------------------------------------# calendar current month with today highlighted.# colors 00=bright white, 31=red, 32=green, 33=yellow, 34=blue, 35=purple,# 36=cyan, 37=whitetput sc # Save cursor position.# Move up 9 linesi=0while [ $((++i)) -lt 10 ]; do tput cuu1; doneif [[ "$WeatherSuccess" == true ]] ; then # Depending on length of your city name and country name you will: # 1. Comment out next three lines of code. Uncomment fourth code line. # 2. Change subtraction value and set number of print spaces to match # subtraction value. Then place comment on fourth code line. Column=$((DateColumn - 10)) tput cuf $Column # Move x column number # Blank out ", country" with x spaces printf " "else tput cuf $DateColumn # Position to column 27 for date displayfi# -h needed to turn off formating: https://askubuntu.com/questions/1013954/bash-substring-stringoffsetlength-error/1013960#1013960cal &gt; /tmp/terminal1# -h not supported in Ubuntu 18.04. Use second answer: https://askubuntu.com/a/1028566/307523tr -cd '\11\12\15\40\60-\136\140-\176' &lt; /tmp/terminal1 &gt; /tmp/terminalCalLineCnt=1Today=$(date +"%e")printf "\033[32m" # color green -- see list above.while IFS= read -r Cal; do printf "%s" "$Cal" if [[ $CalLineCnt -gt 2 ]] ; then # See if today is on current line &amp; invert background tput cub 22 for (( j=0 ; j &lt;= 18 ; j += 3 )) ; do Test=$&#123;Cal:$j:2&#125; # Current day on calendar line if [[ "$Test" == "$Today" ]] ; then printf "\033[7m" # Reverse: [ 7 m printf "%s" "$Today" printf "\033[0m" # Normal: [ 0 m printf "\033[32m" # color green -- see list above. tput cuf 1 else tput cuf 3 fi done fi tput cud1 # Down one line tput cuf $DateColumn # Move 27 columns right CalLineCnt=$((++CalLineCnt))done &lt; /tmp/terminalprintf "\033[00m" # color -- bright white (default)echo ""tput rc # Restore saved cursor position.#-------- TIME --------------------------------------------------------------tput sc # Save cursor position.# Move up 8 linesi=0while [ $((++i)) -lt 9 ]; do tput cuu1; donetput cuf $TimeColumn # Move 49 columns right# Do we have the toilet package?if hash toilet 2&gt;/dev/null; then echo " $(date +"%I:%M %P") " | \ toilet -f future --filter border &gt; /tmp/terminal# Do we have the figlet package?elif hash figlet 2&gt;/dev/null; then# echo $(date +"%I:%M %P") | figlet &gt; /tmp/terminal date +"%I:%M %P" | figlet &gt; /tmp/terminal# else use standard fontelse# echo $(date +"%I:%M %P") &gt; /tmp/terminal date +"%I:%M %P" &gt; /tmp/terminalfiwhile IFS= read -r Time; do printf "\033[01;36m" # color cyan printf "%s" "$Time" tput cud1 # Up one line tput cuf $TimeColumn # Move 49 columns rightdone &lt; /tmp/terminaltput rc # Restore saved cursor position.exit 0 运行效果：123456789$ bash weather-clock.shWeather report: Hangzhou May 2021 Su Mo Tu We Th Fr Sa ┌────────────────────────────┐ _`/&quot;&quot;.-. Rain shower, mist 1 │ ┏━┓┏━┓ ┏━┓┏━┓ ┏━┓┏┳┓ │ ,\_( ). 21 °C 2 3 4 5 6 7 8 │ ┃┃┃┣━┓╹┃┃┃┗━┫ ┣━┛┃┃┃ │ /(___(__) ↓ 15 km/h 9 10 11 12 13 14 15 │ ┗━┛┗━┛╹┗━┛┗━┛ ╹ ╹ ╹ │ ‘ ‘ ‘ ‘ 3 km 16 17 18 19 20 21 22 └────────────────────────────┘ ‘ ‘ ‘ ‘ 0.8 mm 23 24 25 26 27 28 29 30 31 其中获取天气的关键代码为 curl wttr.in/Hangzhou?0 --silent --max-time 3，可自行改为自己所在的城市。 同样，为了使 Terminal 在启动时能自动运行该脚本，在 ~/.zshrc 配置文件的末尾（random-distro.sh 上面一行）添加如下内容：bash /path/to/weather-clock.sh PS：数字时钟的正常显示需要依赖 toilet 软件。安装 toilet：sudo apt install toilet 七、pipe.sh 生成 Terminal 启动动画获取 pipe.sh 程序：git clone https://github.com/pipeseroni/pipes.sh.git 提取项目中的 pipes.sh/pipes.sh 源文件到任意路径下。为了使 Terminal 在启动时能自动运行该脚本，在 ~/.zshrc 配置文件的末尾（weather-clock.sh 上面一行）添加如下内容：bash /path/to/pipes.sh -p 5 运行效果： 按下空格键可终止动画。 GIF 版本：]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Shell</tag>
        <tag>Terminal</tag>
        <tag>Zsh</tag>
        <tag>Beautify</tag>
        <tag>Neofetch</tag>
        <tag>Ascii Art</tag>
        <tag>Weather</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Miniconda 和 poetry 搭建 Python 开发环境（支持多版本、依赖管理）]]></title>
    <url>%2F2021%2F05%2F19%2Fbuild-python-development-environment-with-miniconda-and-poetry%2F</url>
    <content type="text"><![CDATA[基于自己的日常习惯测试整理，通过 Windows 系统演示（Linux 系统操作步骤大同小异）。Miniconda 用来提供 conda 命令管理多个 Python 版本（如 Python 3.8、Python 3.9）；poetry 则用来创建基于项目的虚拟环境，维护对应的包依赖关系。 一、效果演示conda 命令查看安装的 Python 版本：123456C:\Users\Administrator&gt;conda env list# conda environments:#base * C:\Users\xniu\Miniconda3python2.7.18 C:\Users\xniu\Miniconda3\envs\python2.7.18python3.9.4 C:\Users\xniu\Miniconda3\envs\python3.9.4 poetry 查看某个项目的包依赖关系：12345678910111213141516(python3.9.4) C:\Users\Administrator\projects\auto-test&gt;poetry showcertifi 2020.12.5 Python package for providing Mozilla&apos;s CA Bundle.chardet 4.0.0 Universal encoding detector for Python 2 and 3idna 2.10 Internationalized Domain Names in Applications (IDNA)requests 2.25.1 Python HTTP for Humans.selenium 3.141.0 Python bindings for Seleniumurllib3 1.26.4 HTTP library with thread-safe connection pooling, file post, and more.(python3.9.4) C:\Users\Administrator\projects\auto-test&gt;poetry show -trequests 2.25.1 Python HTTP for Humans.|-- certifi &gt;=2017.4.17|-- chardet &gt;=3.0.2,&lt;5|-- idna &gt;=2.5,&lt;3`-- urllib3 &gt;=1.21.1,&lt;1.27selenium 3.141.0 Python bindings for Selenium`-- urllib3 * 二、安装 MinicondaMiniconda 软件提供了 conda 命令，可以用来创建基于不同 Python 版本的虚拟环境。 访问 Miniconda 官网，下载对应系统版本的安装包并安装。 安装完成后，添加 conda 命令的路径（安装目录下的 Scripts 目录）到 PATH 环境变量。其路径一般为 C:\Users\xxx\Miniconda3\Scripts\。 添加完成后，打开一个新的命令提示符，运行 conda 命令看是否有反应。 创建基于不同 Python 版本的虚拟环境conda create -n python3.9.4 python=3.9.4上述命令会创建一个新的 Python 虚拟环境，并安装 Python 3.9.4。 其中 -n 选项用于指定该虚拟环境的名称，方便后续通过 conda activate xxx 启用该虚拟环境；python=3.9.4 命令用于安装指定版本的 Python 程序。 虚拟环境创建成功后，即可使用 conda activate python3.9.4 命令启用该虚拟环境。此后在该命令提示符环境下任何 python 命令都会自动使用 Python3.9.4 执行。 conda env list 命令可以查看现有的 Python 虚拟环境。 PS：更多 conda 命令可参考 Command reference。 三、安装 poetrypoetry 的安装可参考 poetry 官方文档。对于 Windows 系统可直接打开一个 PowerShell 窗口，运行以下命令：(Invoke-WebRequest -Uri https://raw.githubusercontent.com/python-poetry/poetry/master/get-poetry.py -UseBasicParsing).Content | python - 安装成功后，poetry 命令会自动添加到 PATH 环境变量中。 创建基于项目的虚拟环境打开一个新的命令提示符，使用 conda activate python3.9.4 命令激活某个 Python 版本。 进入到项目路径下，运行 poetry init 命令初始化配置。1234567891011121314151617181920212223242526272829303132(python3.9.4) C:\Users\Administrator\projects\python\test-poetry&gt;poetry initThis command will guide you through creating your pyproject.toml config.Package name [test-poetry]:Version [0.1.0]:Description []:Author [None, n to skip]: nLicense []:Compatible Python versions [^3.9]:Would you like to define your main dependencies interactively? (yes/no) [yes] noWould you like to define your development dependencies interactively? (yes/no) [yes] noGenerated file[tool.poetry]name = &quot;test-poetry&quot;version = &quot;0.1.0&quot;description = &quot;&quot;authors = [&quot;Your Name &lt;you@example.com&gt;&quot;][tool.poetry.dependencies]python = &quot;^3.9&quot;[tool.poetry.dev-dependencies][build-system]requires = [&quot;poetry-core&gt;=1.0.0&quot;]build-backend = &quot;poetry.core.masonry.api&quot;Do you confirm generation? (yes/no) [yes] yes 上述操作会在项目目录下自动创建 pyproject.toml 配置文件，内容如下：1234567891011121314[tool.poetry]name = "test-poetry"version = "0.1.0"description = ""authors = ["Your Name &lt;you@example.com&gt;"][tool.poetry.dependencies]python = "^3.9"[tool.poetry.dev-dependencies][build-system]requires = ["poetry-core&gt;=1.0.0"]build-backend = "poetry.core.masonry.api" 使用 poetry shell 命令自动创建基于当前项目的虚拟环境并激活该环境：12345(python3.9.4) C:\Users\Administrator\projects\python\test-poetry&gt;poetry shellCreating virtualenv test-poetry-thSlgjIV-py3.9 in C:\Users\Administrator\AppData\Local\pypoetry\Cache\virtualenvsSpawning shell within C:\Users\Administrator\AppData\Local\pypoetry\Cache\virtualenvs\test-poetry-thSlgjIV-py3.9Microsoft Windows [Version 10.0.18363.1316](c) 2019 Microsoft Corporation. All rights reserved. 运行 code . 命令使用 VSCode 软件打开本项目，此时即可在 IDE 中切换到新创建的基于本项目的虚拟环境（VSCode 已经安装了 Python 插件）。 安装依赖包poetry add xxx 命令可以用来在当前环境中安装某个依赖包：123456789101112131415(python3.9.4) C:\Users\Administrator\projects\python\test-poetry&gt;poetry add requestsUsing version ^2.25.1 for requestsUpdating dependenciesResolving dependencies...Writing lock filePackage operations: 5 installs, 0 updates, 0 removals • Installing certifi (2020.12.5) • Installing chardet (4.0.0) • Installing idna (2.10) • Installing urllib3 (1.26.4) • Installing requests (2.25.1) poetry add xxx -D 命令可以用来安装针对开发环境的某个依赖包（用 poetry remove 命令卸载此类包时也需要指定 -D 选项）：12345678910111213(python3.9.4) C:\Users\Administrator\projects\python\test-poetry&gt;poetry add autopep8 -DUsing version ^1.5.7 for autopep8Updating dependenciesResolving dependencies...Writing lock filePackage operations: 3 installs, 0 updates, 0 removals • Installing pycodestyle (2.7.0) • Installing toml (0.10.2) • Installing autopep8 (1.5.7) 同时，安装的依赖包信息也会自动添加到 pyproject.toml 配置文件中：12345678910111213141516[tool.poetry]name = "test-poetry"version = "0.1.0"description = ""authors = ["Your Name &lt;you@example.com&gt;"][tool.poetry.dependencies]python = "^3.9"requests = "^2.25.1"[tool.poetry.dev-dependencies]autopep8 = "^1.5.7"[build-system]requires = ["poetry-core&gt;=1.0.0"]build-backend = "poetry.core.masonry.api" 后续配置新的环境时，pyproject.toml 可以发挥类似 requirements.txt 文件的作用。即借助此文件中的配置，可以直接使用 peotry install 命令自动安装文件中包含的依赖项。 维护环境依赖使用 poetry show 命令查看当前安装的依赖包列表：123456789(python3.9.4) C:\Users\Administrator\projects\python\test-poetry&gt;poetry showautopep8 1.5.7 A tool that automatically formats Python code to conform to the PEP 8 style guidecertifi 2020.12.5 Python package for providing Mozilla&apos;s CA Bundle.chardet 4.0.0 Universal encoding detector for Python 2 and 3idna 2.10 Internationalized Domain Names in Applications (IDNA)pycodestyle 2.7.0 Python style guide checkerrequests 2.25.1 Python HTTP for Humans.toml 0.10.2 Python Library for Tom&apos;s Obvious, Minimal Languageurllib3 1.26.4 HTTP library with thread-safe connection pooling, file post, and more. 使用 poetry show -t 命令查看当前环境中各包之间的依赖关系：123456789(python3.9.4) C:\Users\Administrator\projects\python\test-poetry&gt;poetry show -tautopep8 1.5.7 A tool that automatically formats Python code to conform to the PEP 8 style guide|-- pycodestyle &gt;=2.7.0`-- toml *requests 2.25.1 Python HTTP for Humans.|-- certifi &gt;=2017.4.17|-- chardet &gt;=3.0.2,&lt;5|-- idna &gt;=2.5,&lt;3`-- urllib3 &gt;=1.21.1,&lt;1.27 若此时使用 poetry remove autopep8 -D 命令移除 autopep8，则之前自动安装的 pycodestyle、toml 依赖项也会被移除。1234567891011(python3.9.4) C:\Users\Administrator\projects\python\test-poetry&gt;poetry remove autopep8 -DUpdating dependenciesResolving dependencies...Writing lock filePackage operations: 0 installs, 0 updates, 3 removals • Removing autopep8 (1.5.7) • Removing pycodestyle (2.7.0) • Removing toml (0.10.2) PS：更多 poetry 命令和用法可参考官方文档：Poetry Commands]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Python</tag>
        <tag>Development</tag>
        <tag>Poetry</tag>
        <tag>Miniconda</tag>
        <tag>Conda</tag>
        <tag>Package</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django（drf）配合 Vue Element 实现文件上传下载功能]]></title>
    <url>%2F2021%2F03%2F13%2Fdjango-drf-and-vue-element-file-upload-and-download%2F</url>
    <content type="text"><![CDATA[后台代码Models编辑 models.py 代码，通过 FileField 字段记录文件信息：123456789from django.db import modelsclass FilesModel(models.Model): file = models.FileField(upload_to='uploads/') class Meta: db_table = 'files_storage' ordering = ['-id'] Serializer这里使用 Django REST framework 实现后端 REST API，需要创建序列化器 serializers.py，内容如下：123456789from rest_framework import serializers# files 是 app 的名字from files import modelsclass FilesSerializer(serializers.ModelSerializer): class Meta: model = models.FilesModel fields = '__all__' Views编辑 views.py 代码，内容如下：1234567from rest_framework.viewsets import ModelViewSetfrom files import models, serializersclass FileViewSet(ModelViewSet): queryset = models.FilesModel.objects.all() serializer_class = serializers.FilesSerializer Urls在 files 路径下新建 urls.py 文件，填写路由配置：12345678910from django.urls import include, pathfrom rest_framework import routersfrom files import viewsrouter = routers.DefaultRouter()router.register(r'files', views.FileViewSet)urlpatterns = [ path('', include(router.urls))] 在项目总配置路径下（settings.py 所在的路径）编辑根路由配置文件 urls.py：1234567from django.contrib import adminfrom django.urls import path, includeurlpatterns = [ path('admin/', admin.site.urls), path('storage/', include('files.urls'))] 测试后端 API运行后台服务 python manage.py runserver 0.0.0.0:8000，访问 http://xx.xx.xx.xx:8000/storage/files/，界面如下： 测试上传文件，效果如下： 前端代码（手动上传）借助 Element UI 的 upload 组件，Vue 代码（index.vue）如下：123456789101112131415161718192021222324252627282930&lt;template&gt; &lt;div&gt; &lt;el-upload ref=&quot;upload&quot; drag action=&quot;http://xx.xx.xx.xx:8000/storage/files/&quot; :auto-upload=&quot;false&quot; :on-success=&quot;onSuccess&quot; &gt; &lt;i class=&quot;el-icon-upload&quot; /&gt; &lt;div class=&quot;el-upload__text&quot;&gt;将文件拖到此处，或&lt;em&gt;点击上传&lt;/em&gt;&lt;/div&gt; &lt;/el-upload&gt; &lt;el-button style=&quot;margin-left: 10px;&quot; size=&quot;small&quot; type=&quot;success&quot; @click=&quot;submitUpload&quot;&gt;上传到服务器&lt;/el-button&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; name: &apos;UploadDemo&apos;, methods: &#123; submitUpload() &#123; this.$refs.upload.submit() &#125;, onSuccess() &#123; this.$message.success(&apos;上传成功&apos;) &#125; &#125;&#125;&lt;/script&gt; 其中 el-upload 组件的 action 属性用于指定后台 API 的 URI；:auto-upload 属性用于设置是否自动上传（这里设置为 false，手动触发上传动作）；:on-success 属性用于指定上传成功后触发的方法。 submitUpload() 中的 this.$refs.upload.submit() 方法触发文件上传动作。 界面如下： 测试文件上传： 后台数据如下：12345678910[ &#123; "file": "http://172.20.23.34:8000/storage/files/uploads/template.html", "id": 18 &#125;, &#123; "file": "http://172.20.23.34:8000/storage/files/uploads/20171215091830_55126_hSnPtZR.png", "id": 17 &#125;] 文件上传的同时添加其他数据修改数据库模型编辑后端 models.py 文件，添加其他字段：12345678910from django.db import modelsclass FilesModel(models.Model): name = models.CharField(max_length=20, default='') file = models.FileField(upload_to='uploads/') class Meta: db_table = 'files_storage' ordering = ['-id'] 数据库迁移后，重启后台 Web 服务。 后台数据如下：123456789101112[ &#123; "file": "http://172.20.23.34:8000/storage/files/uploads/template.html", "id": 18, "name": "" &#125;, &#123; "file": "http://172.20.23.34:8000/storage/files/uploads/20171215091830_55126_hSnPtZR.png", "id": 17, "name": "" &#125;] 修改前端代码添加其他数据的输入界面，同时将附加数据绑定到 el-upload 组件中：123456789101112131415161718192021222324252627282930313233343536373839404142&lt;template&gt; &lt;div&gt; &lt;el-label&gt;名称&lt;/el-label&gt; &lt;el-input v-model=&quot;fileData.name&quot; style=&quot;width: 20%&quot; /&gt; &lt;el-upload ref=&quot;upload&quot; drag class=&quot;upload-demo&quot; action=&quot;http://xx.xx.xx.xx:8000/storage/files/&quot; :data=&quot;fileData&quot; :auto-upload=&quot;false&quot; :on-success=&quot;onSuccess&quot; style=&quot;padding: 30px&quot; &gt; &lt;i class=&quot;el-icon-upload&quot; /&gt; &lt;div class=&quot;el-upload__text&quot;&gt;将文件拖到此处，或&lt;em&gt;点击上传&lt;/em&gt;&lt;/div&gt; &lt;/el-upload&gt; &lt;el-button style=&quot;margin-left: 10px;&quot; size=&quot;small&quot; type=&quot;success&quot; @click=&quot;submitUpload&quot;&gt;上传到服务器&lt;/el-button&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; name: &apos;UploadDemo&apos;, data() &#123; return &#123; fileData: &#123; name: &apos;&apos; &#125; &#125; &#125;, methods: &#123; submitUpload() &#123; this.$refs.upload.submit() &#125;, onSuccess() &#123; this.$message.success(&apos;上传成功&apos;) &#125; &#125;&#125;&lt;/script&gt; 其中 el-upload 组件的 :data 属性用于指定文件上传时附加的数据（类型为 JavaScript 对象）。 文件上传测试： 上传完成，后台数据如下：1234567891011121314151617[ &#123; "file": "http://172.20.23.34:8000/storage/files/uploads/AnyDesk.exe", "id": 19, "name": "测试文件" &#125;, &#123; "file": "http://172.20.23.34:8000/storage/files/uploads/template.html", "id": 18, "name": "" &#125;, &#123; "file": "http://172.20.23.34:8000/storage/files/uploads/20171215091830_55126_hSnPtZR.png", "id": 17, "name": "" &#125;] 文件下载修改后台视图代码（views.py），添加文件下载的 API 响应逻辑： 123456789101112131415from rest_framework.viewsets import ModelViewSetfrom files import models, serializersfrom rest_framework.decorators import actionfrom django.http import FileResponseclass FileViewSet(ModelViewSet): queryset = models.FilesModel.objects.all() serializer_class = serializers.FilesSerializer @action(methods=['get', 'post'], detail=True) def download(self, request, pk=None, *args, **kwargs): file_obj = self.get_object() response = FileResponse(open(file_obj.file.path, 'rb')) return response 此时访问 http://xx.xx.xx.xx:8000/storage/files/[id]/download/ 链接，即可直接下载上传到服务器上的文件。 1234$ curl -o anydesk.exe 172.20.23.34:8000/storage/files/19/download/ % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 3584k 100 3584k 0 0 102M 0 --:--:-- --:--:-- --:--:-- 102M 参考资料Element UI 官方文档Django 官方文档]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Web</tag>
        <tag>Django</tag>
        <tag>Vue</tag>
        <tag>drf</tag>
        <tag>Element</tag>
        <tag>File</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基本算法问题的 Python 解法——图（Graph）问题]]></title>
    <url>%2F2021%2F02%2F20%2Fclassic-compute-problems-with-python-graph-problems%2F</url>
    <content type="text"><![CDATA[图（Graph）是一种用来对某些现实问题进行建模的抽象的数学结构，这些问题从逻辑上可以被划分成一系列相互连接的节点。其中的节点称为顶点（vertex），顶点之间的连接称为边（edge）。比如地铁线路就可以看作由图表示成的运输网络。每一个顶点都代表一个地铁站，而顶点之间的边则表示两个地铁站之间的路径。如果想知道某个站点到另一个站点的最短路径，图算法就能发挥作用。实际上，图算法可以被应用到任何类型的网络问题中。 map as graph 123456789101112131415# edge.pyfrom __future__ import annotationsfrom dataclasses import dataclass@dataclassclass Edge: u: int # the "from" vertex v: int # the "to" vertex def reversed(self) -&gt; Edge: return Edge(self.v, self.u) def __str__(self) -&gt; str: return f"&#123;self.u&#125; -&gt; &#123;self.v&#125;" 上面代码中的 Edge 类表示两个顶点之间的连接（即“边”），每个顶点都由整数索引表示。其中 u 用来表示第一个顶点，v 表示第二个顶点。这里只关注非方向性的 graph，edge 是双向的。而在有向图（digraph）中，edge 可以是单向的。reversed() 方法用来返回当前 edge 的逆向形式。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172# graph.pyfrom typing import TypeVar, Generic, List, Optionalfrom edge import EdgeV = TypeVar('V') # type of the vertices in the graphclass Graph(Generic[V]): def __init__(self, vertices: List[V] = []) -&gt; None: self._vertices: List[V] = vertices self._edges: List[List[Edge]] = [[] for _ in vertices] @property def vertex_count(self) -&gt; int: return len(self._vertices) # Number of vertices @property def edge_count(self) -&gt; int: return sum(map(len, self._edges)) # Number of edges # Add a vertex to the graph and return its index def add_vertex(self, vertex: V) -&gt; int: self._vertices.append(vertex) self._edges.append([]) # Add empty list for containing edges return self.vertex_count - 1 # Return index of added vertex # This is an undirected graph, # so we always add edges in both directions def add_edge(self, edge: Edge) -&gt; None: self._edges[edge.u].append(edge) self._edges[edge.v].append(edge.reversed()) # Add an edge using vertex indices (convenience method) def add_edge_by_indices(self, u: int, v: int) -&gt; None: edge: Edge = Edge(u, v) self.add_edge(edge) # Add an edge by looking up vertex indices (convenience method) def add_edge_by_vertices(self, first: V, second: V) -&gt; None: u: int = self._vertices.index(first) v: int = self._vertices.index(second) self.add_edge_by_indices(u, v) # Find the vertex at a specific index def vertex_at(self, index: int) -&gt; V: return self._vertices[index] # Find the index of a vertex in the graph def index_of(self, vertex: V) -&gt; int: return self._vertices.index(vertex) # Find the vertices that a vertex at some index is connected to def neighbors_for_index(self, index: int) -&gt; List[V]: return list(map(self.vertex_at, [e.v for e in self._edges[index]])) # Look up a vertice's index and find its neighbors (convenience method) def neighbors_for_vertex(self, vertex: V) -&gt; List[V]: return self.neighbors_for_index(self.index_of(vertex)) # Return all of the edges associated with a vertex at some index def edges_for_index(self, index: int) -&gt; List[Edge]: return self._edges[index] # Look up the index of a vertex and return its edges (convenience method) def edges_for_vertex(self, vertex: V) -&gt; List[Edge]: return self.edges_for_index(self.index_of(vertex)) # Make it easy to pretty-print a Graph def __str__(self) -&gt; str: desc: str = "" for i in range(self.vertex_count): desc += f"&#123;self.vertex_at(i)&#125; -&gt; &#123;self.neighbors_for_index(i)&#125;\n" return desc Graph 类聚焦于 graph 的核心角色，即将顶点用边连接起来。_vertices 列表是 Graph 类的核心，每个顶点都会被存储在该列表中。但是之后在实际引用时会使用顶点在列表中的索引。顶点本身有可能会是非常复杂的数据类型，但其索引一定会是 int 类型，相对而言更加方便使用。graph 数据类型可以使用 adjacency lists 方式实现，每个顶点都拥有一个列表，里面包含了这个顶点连接的其他顶点。这里使用了由 edge 组成的列表再组成的列表（_edges），每个顶点都拥有一个由 edge 组成的列表，这些 edge 表示该顶点与其他顶点的连接关系。 Graph 类中实现的方法的简单介绍： vertex_count 属性：获取 graph 中顶点的数量 edge_count 属性：获取 graph 中边的数量 add_vertex 方法：添加一个新的孤立的顶点并返回其索引 add_edge 方法：添加一条边（双向，参数是 Edge 对象） add_edge_by_indices 方法：通过顶点索引添加新的边（参数是边的两个顶点的索引 u、v） add_edge_by_vertices 方法：通过顶点添加新的边（参数是边的两个顶点（Vertex）对象） vertex_at 方法：通过特定的索引查询顶点 index_of 方法：根据顶点返回其索引 neighbors_for_index 方法：根据某个顶点的索引获取其临近的顶点（参数为顶点索引） neighbors_for_vertex 方法：根据某个顶点获取其临近的顶点（参数为顶点对象） edges_for_index 方法：根据某个顶点的索引获取与其连接的边（参数为顶点索引） edges_for_vertex 方法：根据某个顶点获取与其连接的边（参数为顶点对象） __str__ 方法：友好的方式输出整个 graph 补充测试代码：1234567891011121314151617181920212223242526272829303132# graph.py continuedif __name__ == "__main__": # test basic Graph construction city_graph: Graph[str] = Graph(["Seattle", "San Francisco", "Los Angeles", "Riverside", "Phoenix", "Chicago", "Boston", "New York", "Atlanta", "Miami", "Dallas", "Houston", "Detroit", "Philadelphia", "Washington"]) city_graph.add_edge_by_vertices("Seattle", "Chicago") city_graph.add_edge_by_vertices("Seattle", "San Francisco") city_graph.add_edge_by_vertices("San Francisco", "Riverside") city_graph.add_edge_by_vertices("San Francisco", "Los Angeles") city_graph.add_edge_by_vertices("Los Angeles", "Riverside") city_graph.add_edge_by_vertices("Los Angeles", "Phoenix") city_graph.add_edge_by_vertices("Riverside", "Phoenix") city_graph.add_edge_by_vertices("Riverside", "Chicago") city_graph.add_edge_by_vertices("Phoenix", "Dallas") city_graph.add_edge_by_vertices("Phoenix", "Houston") city_graph.add_edge_by_vertices("Dallas", "Chicago") city_graph.add_edge_by_vertices("Dallas", "Atlanta") city_graph.add_edge_by_vertices("Dallas", "Houston") city_graph.add_edge_by_vertices("Houston", "Atlanta") city_graph.add_edge_by_vertices("Houston", "Miami") city_graph.add_edge_by_vertices("Atlanta", "Chicago") city_graph.add_edge_by_vertices("Atlanta", "Washington") city_graph.add_edge_by_vertices("Atlanta", "Miami") city_graph.add_edge_by_vertices("Miami", "Washington") city_graph.add_edge_by_vertices("Chicago", "Detroit") city_graph.add_edge_by_vertices("Detroit", "Boston") city_graph.add_edge_by_vertices("Detroit", "Washington") city_graph.add_edge_by_vertices("Detroit", "New York") city_graph.add_edge_by_vertices("Boston", "New York") city_graph.add_edge_by_vertices("New York", "Philadelphia") city_graph.add_edge_by_vertices("Philadelphia", "Washington") print(city_graph) 运行结果：123456789101112131415Seattle -&gt; ['Chicago', 'San Francisco']San Francisco -&gt; ['Seattle', 'Riverside', 'Los Angeles']Los Angeles -&gt; ['San Francisco', 'Riverside', 'Phoenix']Riverside -&gt; ['San Francisco', 'Los Angeles', 'Phoenix', 'Chicago']Phoenix -&gt; ['Los Angeles', 'Riverside', 'Dallas', 'Houston']Chicago -&gt; ['Seattle', 'Riverside', 'Dallas', 'Atlanta', 'Detroit']Boston -&gt; ['Detroit', 'New York']New York -&gt; ['Detroit', 'Boston', 'Philadelphia']Atlanta -&gt; ['Dallas', 'Houston', 'Chicago', 'Washington', 'Miami']Miami -&gt; ['Houston', 'Atlanta', 'Washington']Dallas -&gt; ['Phoenix', 'Chicago', 'Atlanta', 'Houston']Houston -&gt; ['Phoenix', 'Dallas', 'Atlanta', 'Miami']Detroit -&gt; ['Chicago', 'Boston', 'Washington', 'New York']Philadelphia -&gt; ['New York', 'Washington']Washington -&gt; ['Atlanta', 'Miami', 'Detroit', 'Philadelphia'] 寻找最短路径在 graph 理论中，任意两个顶点之间的所有连线（边）称为路径。即从一个顶点到达另一个顶点需要走过的所有路径。在一个未加权的 graph 中（即不考虑边的长度），寻找最短的路径意味着从起始顶点到目标顶点之间经过的边最少。可以使用宽度优先搜索（breadth-first search, BFS）算法查找两个顶点之间的最短路径。（BFS 算法的具体实现可参考 基本算法问题的 Python 解法（递归与搜索）中的迷宫问题）。 BFS 部分代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162# generic_search.pyfrom __future__ import annotationsfrom typing import TypeVar, Generic, List, Callable, Deque, Set, OptionalT = TypeVar('T')class Node(Generic[T]): def __init__(self, state: T, parent: Optional[Node]) -&gt; None: self.state: T = state self.parent: Optional[Node] = parentclass Queue(Generic[T]): def __init__(self) -&gt; None: self._container: Deque[T] = Deque() @property def empty(self) -&gt; bool: return not self._container # not is true for empty container def push(self, item: T) -&gt; None: self._container.append(item) def pop(self) -&gt; T: return self._container.popleft() # FIFO def __repr__(self) -&gt; str: return repr(self._container)def bfs(initial: T, goal_test: Callable[[T], bool], successors: Callable[[T], List[T]]) -&gt; Optional[Node[T]]: # frontier is where we've yet to go frontier: Queue[Node[T]] = Queue() frontier.push(Node(initial, None)) # explored is where we've been explored: Set[T] = &#123;initial&#125; # keep going while there is more to explore while not frontier.empty: current_node: Node[T] = frontier.pop() current_state: T = current_node.state # if we found the goal, we're done if goal_test(current_state): return current_node # check where we can go next and haven't explored for child in successors(current_state): if child in explored: # skip children we already explored continue explored.add(child) frontier.push(Node(child, current_node)) return None # went through everything and never found goaldef node_to_path(node: Node[T]) -&gt; List[T]: path: List[T] = [node.state] # work backwards from end to front while node.parent is not None: node = node.parent path.append(node.state) path.reverse() return path 继续补充 graph.py 代码如下：123456789101112# graph.py continuedif __name__ == "__main__":# ... from generic_search import bfs, Node, node_to_path bfs_result: Optional[Node[V]] = bfs("Boston", lambda x: x == "Miami", city_graph.neighbors_for_vertex) if bfs_result is None: print("No solution found using breadth-first search!") else: path: List[V] = node_to_path(bfs_result) print("Path from Boston to Miami:") print(path) bfs() 函数接受三个参数：初始状态、用于检测当前状态是否符合目标状态的 Callable（可调用对象）、用于寻找达成目标状态的路径的 Callable。若需要寻找 Boston 到 Miami 的最短路径（不考虑加权的情况），则初始状态为顶点 “Boston”，用于状态检测的 Callable 则判断当前顶点是否为 “Miami”。 运行效果：12Path from Boston to Miami:['Boston', 'Detroit', 'Washington', 'Miami'] 加权图之前的计算中，最短路径只考虑经过的站点最少，而未将站点之间的路程计算在内。若需要将路程包含进去，则可以为 edge 加上权重来表示该 edge 对应的距离。 为了实现加权的 graph，需要实现 Edge 的子类 WeightedEdge 以及 Graph 的子类 WeightedGraph。每一个 WeightedEdge 对象都有一个关联的 float 类型的属性用来表示权重。123456789101112131415161718# weighted_edge.pyfrom __future__ import annotationsfrom dataclasses import dataclassfrom edge import Edge@dataclassclass WeightedEdge(Edge): weight: float def reversed(self) -&gt; WeightedEdge: return WeightedEdge(self.v, self.u, self.weight) # so that we can order edges by weight to find the minimum weight edge def __lt__(self, other: WeightedEdge) -&gt; bool: return self.weight &lt; other.weight def __str__(self) -&gt; str: return f"&#123;self.u&#125; &#123;self.weight&#125;&gt; &#123;self.v&#125;" WeightedEdge 子类添加了一个 weight 属性，通过 __lt__() 方法实现了 &lt; 操作符，令 WeightedEdge 对象成为可比较的，使得返回 weight 最小的 edge 成为可能。 1234567891011121314151617181920212223242526272829303132# weighted_graph.pyfrom typing import TypeVar, Generic, List, Tuplefrom graph import Graphfrom weighted_edge import WeightedEdgeV = TypeVar('V') # type of the vertices in the graphclass WeightedGraph(Generic[V], Graph[V]): def __init__(self, vertices: List[V] = []) -&gt; None: self._vertices: List[V] = vertices self._edges: List[List[WeightedEdge]] = [[] for _ in vertices] def add_edge_by_indices(self, u: int, v: int, weight: float) -&gt; None: edge: WeightedEdge = WeightedEdge(u, v, weight) self.add_edge(edge) # call superclass version def add_edge_by_vertices(self, first: V, second: V, weight: float) -&gt; None: u: int = self._vertices.index(first) v: int = self._vertices.index(second) self.add_edge_by_indices(u, v, weight) def neighbors_for_index_with_weights(self, index: int) -&gt; List[Tuple[V, float]]: distance_tuples: List[Tuple[V, float]] = [] for edge in self.edges_for_index(index): distance_tuples.append((self.vertex_at(edge.v), edge.weight)) return distance_tuples def __str__(self) -&gt; str: desc: str = "" for i in range(self.vertex_count): desc += f"&#123;self.vertex_at(i)&#125; -&gt; &#123;self.neighbors_for_index_with_weights(i)&#125;\n" return desc WeightedGraph 类继承自 Graph，在原来的基础上对某些需要适应 weight 属性的方法做了对应的修改。 补充 weighted_graph.py 代码，测试运行效果：123456789101112131415161718192021222324252627282930313233343536# weighted_graph.py continuedif __name__ == "__main__": city_graph2: WeightedGraph[str] = WeightedGraph(["Seattle", "San Francisco", "Los Angeles", "Riverside", "Phoenix", "Chicago", "Boston", "New York", "Atlanta", "Miami", "Dallas", "Houston", "Detroit", "Philadelphia", "Washington"]) city_graph2.add_edge_by_vertices("Seattle", "Chicago", 1737) city_graph2.add_edge_by_vertices("Seattle", "San Francisco", 678) city_graph2.add_edge_by_vertices("San Francisco", "Riverside", 386) city_graph2.add_edge_by_vertices("San Francisco", "Los Angeles", 348) city_graph2.add_edge_by_vertices("Los Angeles", "Riverside", 50) city_graph2.add_edge_by_vertices("Los Angeles", "Phoenix", 357) city_graph2.add_edge_by_vertices("Riverside", "Phoenix", 307) city_graph2.add_edge_by_vertices("Riverside", "Chicago", 1704) city_graph2.add_edge_by_vertices("Phoenix", "Dallas", 887) city_graph2.add_edge_by_vertices("Phoenix", "Houston", 1015) city_graph2.add_edge_by_vertices("Dallas", "Chicago", 805) city_graph2.add_edge_by_vertices("Dallas", "Atlanta", 721) city_graph2.add_edge_by_vertices("Dallas", "Houston", 225) city_graph2.add_edge_by_vertices("Houston", "Atlanta", 702) city_graph2.add_edge_by_vertices("Houston", "Miami", 968) city_graph2.add_edge_by_vertices("Atlanta", "Chicago", 588) city_graph2.add_edge_by_vertices("Atlanta", "Washington", 543) city_graph2.add_edge_by_vertices("Atlanta", "Miami", 604) city_graph2.add_edge_by_vertices("Miami", "Washington", 923) city_graph2.add_edge_by_vertices("Chicago", "Detroit", 238) city_graph2.add_edge_by_vertices("Detroit", "Boston", 613) city_graph2.add_edge_by_vertices("Detroit", "Washington", 396) city_graph2.add_edge_by_vertices("Detroit", "New York", 482) city_graph2.add_edge_by_vertices("Boston", "New York", 190) city_graph2.add_edge_by_vertices("New York", "Philadelphia", 81) city_graph2.add_edge_by_vertices("Philadelphia", "Washington", 123) print(city_graph2) 运行效果：123456789101112131415Seattle -&gt; [('Chicago', 1737), ('San Francisco', 678)]San Francisco -&gt; [('Seattle', 678), ('Riverside', 386), ('Los Angeles', 348)]Los Angeles -&gt; [('San Francisco', 348), ('Riverside', 50), ('Phoenix', 357)]Riverside -&gt; [('San Francisco', 386), ('Los Angeles', 50), ('Phoenix', 307), ('Chicago', 1704)]Phoenix -&gt; [('Los Angeles', 357), ('Riverside', 307), ('Dallas', 887), ('Houston', 1015)]Chicago -&gt; [('Seattle', 1737), ('Riverside', 1704), ('Dallas', 805), ('Atlanta', 588), ('Detroit', 238)]Boston -&gt; [('Detroit', 613), ('New York', 190)]New York -&gt; [('Detroit', 482), ('Boston', 190), ('Philadelphia', 81)]Atlanta -&gt; [('Dallas', 721), ('Houston', 702), ('Chicago', 588), ('Washington', 543), ('Miami', 604)]Miami -&gt; [('Houston', 968), ('Atlanta', 604), ('Washington', 923)]Dallas -&gt; [('Phoenix', 887), ('Chicago', 805), ('Atlanta', 721), ('Houston', 225)]Houston -&gt; [('Phoenix', 1015), ('Dallas', 225), ('Atlanta', 702), ('Miami', 968)]Detroit -&gt; [('Chicago', 238), ('Boston', 613), ('Washington', 396), ('New York', 482)]Philadelphia -&gt; [('New York', 81), ('Washington', 123)]Washington -&gt; [('Atlanta', 543), ('Miami', 923), ('Detroit', 396), ('Philadelphia', 123)] 在加权图中搜索最短路径寻找某个起点城市到另一个城市的所有路线中花费最小的一条，属于单源头最短路径（single-source shortest path）问题，即从加权图中的某个顶点到任意的另外一个顶点的最短路径。 Dijkstra 算法 可以用来解决单源头最短路径问题。该算法从某个起始顶点开始，可以找出加权图中所有其他顶点到起始顶点的最短路径。从某个顶点开始按照远近关系依次遍历完所有顶点并记录其总的花费（从起始顶点到当前顶点），若重复出现的顶点花费更小，则令其替换已有的记录。 具体步骤如下： 将起始顶点加入到优先级队列中 从优先级队列中弹出一个顶点（一开始就是起始顶点）作为当前顶点 查看与当前顶点临近的所有顶点，若某一个之前没有被记录到，或某个顶点按照当前路径的花费低于已有的最小记录，则记录其到起始顶点的距离（作为新的最小记录）及生成该距离的最后一条边（记录路径），并将该顶点 push 到优先级队列中（令其作为之后的“当前”顶点） 重复前面两步直到优先级队列为空 返回所有顶点到起始顶点的最小距离及路径 12345678910111213141516171819202122# priority_queue.pyfrom typing import TypeVar, Generic, Listfrom heapq import heappush, heappopT = TypeVar('T')class PriorityQueue(Generic[T]): def __init__(self) -&gt; None: self._container: List[T] = [] @property def empty(self) -&gt; bool: return not self._container def push(self, item: T) -&gt; None: heappush(self._container, item) def pop(self) -&gt; T: return heappop(self._container) def __repr__(self) -&gt; str: return repr(self._container) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118# dijkstra.pyfrom __future__ import annotationsfrom typing import TypeVar, List, Optional, Tuple, Dictfrom dataclasses import dataclassfrom mst import WeightedPath, print_weighted_pathfrom weighted_graph import WeightedGraphfrom weighted_edge import WeightedEdgefrom priority_queue import PriorityQueueV = TypeVar('V') # type of the vertices in the graph@dataclassclass DijkstraNode: vertex: int distance: float def __lt__(self, other: DijkstraNode) -&gt; bool: return self.distance &lt; other.distance def __eq__(self, other: DijkstraNode) -&gt; bool: return self.distance == other.distancedef dijkstra(wg: WeightedGraph[V], root: V) -&gt; Tuple[List[Optional[float]], Dict[int, WeightedEdge]]: first: int = wg.index_of(root) # distances are unknown at first distances: List[Optional[float]] = [None] * wg.vertex_count distances[first] = 0 # the root is 0 away from the root path_dict: Dict[int, WeightedEdge] = &#123;&#125; # how we got to each vertex pq: PriorityQueue[DijkstraNode] = PriorityQueue() pq.push(DijkstraNode(first, 0)) while not pq.empty: u: int = pq.pop().vertex # explore the next closest vertex dist_u: float = distances[u] # should already have seen it # look at every edge/vertex from current vertex for we in wg.edges_for_index(u): # the old distance from starting vertex to this vertex dist_v: float = distances[we.v] # no old distance or found shorter path if dist_v is None or dist_v &gt; we.weight + dist_u: # update distance to this vertex distances[we.v] = we.weight + dist_u # update the edge on the shortest path to this vertex path_dict[we.v] = we # explore this vertex soon pq.push(DijkstraNode(we.v, we.weight + dist_u)) return distances, path_dict# Helper function to get easier access to dijkstra resultsdef distance_array_to_vertex_dict(wg: WeightedGraph[V], distances: List[Optional[float]]) -&gt; Dict[V, Optional[float]]: distance_dict: Dict[V, Optional[float]] = &#123;&#125; for i in range(len(distances)): distance_dict[wg.vertex_at(i)] = distances[i] return distance_dict# Takes a dictionary of edges to reach each node and returns a list of# edges that goes from `start` ot `end`def path_dict_to_path(start: int, end: int, path_dict: Dict[int, WeightedEdge]) -&gt; WeightedPath: if len(path_dict) == 0: return [] edge_path: WeightedPath = [] e: WeightedEdge = path_dict[end] edge_path.append(e) while e.u != start: e = path_dict[e.u] edge_path.append(e) return list(reversed(edge_path))if __name__ == "__main__": city_graph2: WeightedGraph[str] = WeightedGraph(["Seattle", "San Francisco", "Los Angeles", "Riverside", "Phoenix", "Chicago", "Boston", "New York", "Atlanta", "Miami", "Dallas", "Houston", "Detroit", "Philadelphia", "Washington"]) city_graph2.add_edge_by_vertices("Seattle", "Chicago", 1737) city_graph2.add_edge_by_vertices("Seattle", "San Francisco", 678) city_graph2.add_edge_by_vertices("San Francisco", "Riverside", 386) city_graph2.add_edge_by_vertices("San Francisco", "Los Angeles", 348) city_graph2.add_edge_by_vertices("Los Angeles", "Riverside", 50) city_graph2.add_edge_by_vertices("Los Angeles", "Phoenix", 357) city_graph2.add_edge_by_vertices("Riverside", "Phoenix", 307) city_graph2.add_edge_by_vertices("Riverside", "Chicago", 1704) city_graph2.add_edge_by_vertices("Phoenix", "Dallas", 887) city_graph2.add_edge_by_vertices("Phoenix", "Houston", 1015) city_graph2.add_edge_by_vertices("Dallas", "Chicago", 805) city_graph2.add_edge_by_vertices("Dallas", "Atlanta", 721) city_graph2.add_edge_by_vertices("Dallas", "Houston", 225) city_graph2.add_edge_by_vertices("Houston", "Atlanta", 702) city_graph2.add_edge_by_vertices("Houston", "Miami", 968) city_graph2.add_edge_by_vertices("Atlanta", "Chicago", 588) city_graph2.add_edge_by_vertices("Atlanta", "Washington", 543) city_graph2.add_edge_by_vertices("Atlanta", "Miami", 604) city_graph2.add_edge_by_vertices("Miami", "Washington", 923) city_graph2.add_edge_by_vertices("Chicago", "Detroit", 238) city_graph2.add_edge_by_vertices("Detroit", "Boston", 613) city_graph2.add_edge_by_vertices("Detroit", "Washington", 396) city_graph2.add_edge_by_vertices("Detroit", "New York", 482) city_graph2.add_edge_by_vertices("Boston", "New York", 190) city_graph2.add_edge_by_vertices("New York", "Philadelphia", 81) city_graph2.add_edge_by_vertices("Philadelphia", "Washington", 123) distances, path_dict = dijkstra(city_graph2, "Los Angeles") name_distance: Dict[str, Optional[int]] = distance_array_to_vertex_dict(city_graph2, distances) print("Distances from Los Angeles:") for key, value in name_distance.items(): print(f"&#123;key&#125; : &#123;value&#125;") print("") print("Shortest path from Los Angelges to Boston:") path: WeightedPath = path_dict_to_path(city_graph2.index_of("Los Angeles"), city_graph2.index_of("Boston"), path_dict) print_weighted_path(city_graph2, path) 运行结果：1234567891011121314151617181920212223Distances from Los Angeles:Seattle : 1026San Francisco : 348Los Angeles : 0Riverside : 50Phoenix : 357Chicago : 1754Boston : 2605New York : 2474Atlanta : 1965Miami : 2340Dallas : 1244Houston : 1372Detroit : 1992Philadelphia : 2511Washington : 2388Shortest path from Los Angelges to Boston:Los Angeles 50&gt; RiversideRiverside 1704&gt; ChicagoChicago 238&gt; DetroitDetroit 613&gt; BostonTotal Weight: 2605 参考资料Classic Computer Science Problems in Pythondavecom/ClassicComputerScienceProblemsInPython]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Advanced</tag>
        <tag>Python</tag>
        <tag>DataStructure</tag>
        <tag>Algorithm</tag>
        <tag>Graph</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 设计模式——反模式]]></title>
    <url>%2F2021%2F02%2F03%2Fpython-design-patterns-anti-pattern%2F</url>
    <content type="text"><![CDATA[软件设计模式提供了一套规则或标准，能够帮助开发人员在设计层面进行决策。不良的设计主要表现在四个方面： 不动性：开发的应用程序非常难以重用 刚性：任何小的更改需求都会导致软件的太多部分必须进行相应的改动，牵一发而动全身 脆弱性：应用程序的任何更改都会导致现有系统变得非常容易崩溃 粘滞性：由于架构层面的修改非常困难，修改必须由开发人员在代码层面或环境本身中进行 软件开发反模式在软件开发过程中，往往会偏离最初的代码结构，原因一般有： 开发人员的想法会随着开发过程的推进而发生变化 用例通常会随着客户的反馈而进行更改 最初设计的数据结构可能会随功能或可伸缩性等方面的考虑而发生变化 基于上述原因，软件通常需要进行重构。 意大利面条式代码 典型成因包括： 对面向对象编程和分析的无知 没有考虑产品的架构或设计 快餐式思维 问题： 结构的重用性会降到最低 维护工作量过高 进行修改时，扩展性和灵活性会降低 金锤 金锤的意思是一把锤子搞定所有的钉子（解决所有问题）。软件开发人员或团队通常会有一种倾向，一头扎进一个成熟的解决方案，而不管其是否满足适用性。 典型成因： 来自不了解具体问题的高层的建议 某解决方案在过去多次验证有效，但当前项目有不同的背景和要求 公司已被这种技术“绑架”，或员工们因为顺手对这种技术情有独钟 金锤的影响： 痴迷于一个解决方案，并把它应用于所有软件项目 不是通过功能，而是通过开发中使用的技术来描述产品 没有满足需求，造成与用户的预期不符 熔岩流 熔岩流与软件应用中的死代码或一段用不到的代码有关，人们害怕一旦对其进行修改就会破坏其他东西。随着时间的流逝，这段代码会一直留在软件中并固化其位置，就像熔岩变成硬岩一样。 熔岩流的成因： 在产品中有大量的试错代码 由一个人单独编写的代码，未经审查的情况下移交给了其他开发团队 软件架构或设计的初始思想是通过代码库实现的，但没有人能理解 熔岩流的症状： 开发的测试工作具有很低的代码覆盖率 代码中含有莫名其妙的注释 过时的接口，或开发人员需要围绕既有代码展开工作 复制粘贴式编程 原因： 新手开发者不习惯编写代码或不知道如何开发 快速修复 bug 或急就章式的开发 代码重复，无法满足跨模块标准化以及代码结构化的要求 缺乏长远打算或深谋远虑 后果： 多个软件应用存在同种类型的问题 维护成本更高，bug 的生命周期也会变得更长 较少的模块化代码库，相同的代码会散落于多处 继承问题 软件架构反模式重新发明轮子 原因： 缺乏中央文档或存储库来讲解架构级问题和存放已实现的解决方案 社区或公司内的技术领袖之间缺乏沟通 组织中遵循的流程是从头开始构建的 后果： 解决一个标准问题的方案太多，其中有许多考虑得并不周全 会耗费工程团队更多的时间和资源，导致预算超标，完成时间延后 封闭的系统架构、重复劳动和糟糕的风险管理 供应商套牢 原因： 熟悉供应商公司的权威人士以及技术采购的可能折扣 基于营销和销售业务人员而不是技术评估选择的技术 在当前项目中使用经过验证的技术，即使它不适合当前项目的需要 技术人员已经接受过相关技术的培训 后果： 公司产品的发布周期和维护周期直接取决于供应商的发布时间 该产品是围绕该技术而不是根据客户的要求开放的 产品上市时间不可靠，不能满足客户的期望 委员会设计 原因： 根据组织的流程，产品的架构或设计是由众多的利益相关者批准的 没有指定单独的联系人或负责设计的架构师 由营销或技术专家确定设计优先级，而不是客户反馈 症状： 开发人员和架构师之间的观点冲突，即使在设计完成后依旧如此 过于复杂的设计，很难记录 规格或设计的任何改动都需要经过多次审查，导致实现延迟]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Advanced</tag>
        <tag>Python</tag>
        <tag>Development</tag>
        <tag>Pattern</tag>
        <tag>OOP</tag>
        <tag>Design</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基本算法问题的 Python 解法——约束满足问题（CSP）]]></title>
    <url>%2F2021%2F02%2F03%2Fclassic-compute-problems-with-python-constraint-satisfaction-problems%2F</url>
    <content type="text"><![CDATA[由计算工具解决的很大一部分问题都可以归类为约束满足问题（CSPs, constraint-satisfaction problems）。CSP 一般包含三个基本概念：变量（variables）、域（domains）和约束条件（constraints）。 比如需要在星期五为 Joe、Mary、Sue 三个人安排一场会议，要求 Sue 必须和另外的至少一个人同时在场。针对此问题： Joe、Mary、Sue 三个人即为变量（variables） 每个人（变量）各自空闲的时间点即为对应的域（domains）。比如变量 Mary 在下午 2 点和 3 点的时候有空，这两个时间点即为变量 Mary 对应的域 约束条件（constraints）有两点：Sue 必须在场；除 Sue 以外至少还需要另一人到场 构建 CSP 框架约束条件通过 Constraint 类实现。该类中包含被约束的变量以及测试其是否满足约束的 satisfied() 方法。确定是否满足约束条件是针对某个特定的 CSP 的核心逻辑，该 satisfied() 方法必须为抽象方法，由子类覆盖后发挥实际作用，以满足不同问题的不同约束条件。123456789101112131415# csp.pyfrom typing import Generic, TypeVar, Dict, List, Optionalfrom abc import ABC, abstractmethodV = TypeVar('V') # variable typeD = TypeVar('D') # domain typeclass Constraint(Generic[V, D], ABC): def __init__(self, variables: List[V]) -&gt; None: self.variables = variables @abstractmethod def satisfied(self, assignment: Dict[V, D]) -&gt; bool: pass 约束满足框架的核心部分代码是 CSP 类，该类集中处理变量、域和约束条件。CSP 的类型使用 Generic，目的是使其足够灵活，能够处理各种类型的 variables 和 domains。其中 variables 是 list 类型，domains 是由 variable 和对应的 list （所有可能的值）关联成的 dict 类型，constraints 则是由 variable 和对应的 list（约束条件列表）关联成的 dict 类型。 __init__() 初始化方法会创建 constraints 字典，将 variables 中的值作为键，每个键关联一个空列表。add_constraint() 方法遍历 variables 中的值（同时也是 constraints 中的键），将对应的 constraint 添加到 constraints 字典的该 variable 键关联的列表中。从而完成对 variables、domains、constraints 三类数据的初始化。1234567891011121314151617# csp.pyclass CSP(Generic[V, D]): def __init__(self, variables: List[V], domains: Dict[V, List[D]]) -&gt; None: self.variables = variables self.domains = domains self.constraints: Dict[V, List[Constraint[V, D]]] = &#123;&#125; for variable in self.variables: self.constraints[variable] = [] if variable not in self.domains: raise LookupError("Every variable should have a domain assigned to it") def add_constraint(self, constraint: Constraint[V, D]) -&gt; None: for variable in constraint.variables: if variable not in self.variables: raise LookupError("Variable in constraint not in CSP") else: self.constraints[variable].append(constraint) consistent() 方法用于检查给定的 variable 对应的每一个约束条件是否一一符合当前预设的方案。这个临时的方案用 assignment 表示。即先有某个 variable，然后为其选择对应的 domain 中的任意一个值作为临时的 assignment，再检查该 assignment 是否符合对应的 variable 关联的所有约束条件。123456# csp.pydef consistent(self, variable: V, assignment: Dict[V, D]) -&gt; bool: for constraint in self.constraints[variable]: if not constraint.satisfied(assignment): return False return True 约束满足框架还需要一个简单的 backtracking 搜索用于查找问题的解决方案。Backtracking 意味着一旦在搜索路径的某个节点上终止，则返回到上一个已知的搜索节点，选择另一条搜索路径。有点类似于深度优先搜索（DFS, depth-first search）。12345678910111213141516def backtracking_search(self, assignment: Dict[V, D] = &#123;&#125;) -&gt; Optional[Dict[V, D]]: # assignment is complete if every variable is assigned if len(assignment) == len(self.variables): return assignment # get all variables in the CSP but not in the assignment unassigned: List[V] = [v for v in self.variables if v not in assignment] first: V = unassigned[0] for value in self.domains[first]: local_assignment = assignment.copy() local_assignment[first] = value if self.consistent(first, local_assignment): result: Optional[Dict[V, D]] = self.backtracking_search(local_assignment) if result is not None: return result return None 逐条分析以上代码：12if len(assignment) == len(self.variables): return assignment 上面的 backtracking 搜索采用了递归的形式，此 if 语句则提供了一种递归的终止条件。即当所有 variable 都被赋予了合法的值时，意味着其中一种搭配方案已被找到，则停止进一步的搜索，返回该搭配方案。 12unassigned: List[V] = [v for v in self.variables if v not in assignment]first: V = unassigned[0] 取出 variables 中第一个还未被赋值（未做选择）的 variable，作为下一步中进行赋值（做决定）和约束条件测试的对象。 1234if self.consistent(first, local_assignment): result: Optional[Dict[V, D]] = self.backtracking_search(local_assignment) if result is not None: return result 为前面未赋值的某个 variable “做决定”。将对应的 domain 中所有存在的值依次赋值给该 variable，形成一个新的方案（local_assignment）。若该方案符合所有的约束条件（通过 consistent() 方法检测），则借助递归进行下一轮对另一个 variable 的赋值，直到触发终止条件（所有 variable 都被赋值）。 return None 若针对某个特定的 variable，已经检查完 domain 中包含的所有可能的值，仍没有找到符合要求的方案，则返回 None 表示没有解决。这会导致 backtracking 搜索结束本轮 for 循环，返回到递归的上一层中的 for 循环，尝试为上一步中已赋值的 variable 做出不同的决定，并继续递归（或回溯）下去。 地图上色问题假如有一张澳大利亚地图，需要按州进行上色。要求所有相邻的州不能有相同的颜色。 借助前面构建的约束符合框架，实现代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# map_coloring.pyfrom csp import Constraint, CSPfrom typing import Dict, List, Optionalclass MapColoringConstraint(Constraint[str, str]): def __init__(self, place1: str, place2: str) -&gt; None: super().__init__([place1, place2]) self.place1 = place1 self.place2 = place2 def satisfied(self, assignment: Dict[str, str]) -&gt; bool: # if either place is not in the assignment, then it is not # yet possible for their colors to be conflicting if self.place1 not in assignment or self.place2 not in assignment: return True # check the color assigned to place1 is not the same as the # color assigned to place2 return assignment[self.place1] != assignment[self.place2]if __name__ == "__main__": variables: List[str] = ["Western Australia", "Northern Territory", "South Australia", "Queensland", "New South Wales", "Victoria", "Tasmania"] domains: Dict[str, List[str]] = &#123;&#125; for variable in variables: domains[variable] = ["red", "green", "blue"] csp: CSP[str, str] = CSP(variables, domains) csp.add_constraint(MapColoringConstraint("Western Australia", "Northern Territory")) csp.add_constraint(MapColoringConstraint("Western Australia", "South Australia")) csp.add_constraint(MapColoringConstraint("South Australia", "Northern Territory")) csp.add_constraint(MapColoringConstraint("Queensland", "Northern Territory")) csp.add_constraint(MapColoringConstraint("Queensland", "South Australia")) csp.add_constraint(MapColoringConstraint("Queensland", "New South Wales")) csp.add_constraint(MapColoringConstraint("New South Wales", "South Australia")) csp.add_constraint(MapColoringConstraint("Victoria", "South Australia")) csp.add_constraint(MapColoringConstraint("Victoria", "New South Wales")) csp.add_constraint(MapColoringConstraint("Victoria", "Tasmania")) solution: Optional[Dict[str, str]] = csp.backtracking_search() if solution is None: print("No solution found") else: print(solution)# =&gt; &#123;'Western Australia': 'red', 'Northern Territory': 'green', 'South# Australia': 'blue', 'Queensland': 'red', 'New South Wales': 'green',# 'Victoria': 'red', 'Tasmania': 'green'&#125; 简单梳理一下程序逻辑： 在上述 CSP 中，地图中的 7 个州即为 variables（为方便，以 a、b、c、d、e、f、g 代替）variables = [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;, &#39;f&#39;, &#39;g&#39;] 每个州都可以涂成红绿蓝三种颜色（假设用 1、2、3 指代）中的任何一种，各 variable 对应的所有颜色即组成对应 variable 的 domain：domains = {&#39;a&#39;: [1, 2, 3], &#39;b&#39;: [1, 2, 3], &#39;c&#39;: [1, 2, 3], &#39;d&#39;: [1, 2, 3], &#39;e&#39;: [1, 2, 3], &#39;f&#39;: [1, 2, 3], &#39;g&#39;: [1, 2, 3]} constraints 的逻辑在 MapColoringConstraints 类中实现，即已经涂色的相邻的两个州色彩须不一致。比如 a 与 b 相邻，则该 constraint 的表示如下：MapColoringConstraint(&#39;a&#39;, &#39;b&#39;)而所有的 constraints 都会关联到对应的以 variable 为键的字典中。即若 a 同时与 b 和 c 相邻，则变量 a 的 constraints 表示为：{&#39;a&#39;: [MapColoringConstraint(&#39;a&#39;, &#39;b&#39;), MapColoringConstraint(&#39;a&#39;, &#39;c&#39;)]} backtrack_search() 方法的执行流程为： 在 variables 中取第一个未被赋值（涂色）的 variable，为其赋予对应 domain 中的某个数值作为临时方案 用该 variable 对应的所有 constraints 测试上述临时方案的可行性。若符合要求，则借助递归开启下一轮循环，继续为另一个未被赋值（涂色）的 variable 赋值 若不符合要求，则继续本轮循环，为本 variable 赋予 domain 中的另一个值 若对应 domain 中的所有值赋予 variable 后都不能符合约束要求，则返回 None。本轮循环结束，回到递归的上一轮继续循环，为上一轮中已赋值的 variable 赋予不同的值，延续递归操作 若所有 variable 都已被赋值，则返回 variable 及其对应的值作为最终的解决方案；若所有循环（递归/回溯）结束，返回结果最终为 None，则表示无法找到合理的解决方案 国际象棋的八王后问题国际象棋的棋盘由 8x8 的方格组成，棋子落于方格上。而棋子王后能够吃掉处于同一行、同一列、同一斜线上的任何一个敌方棋子。八王后问题是指需要将 8 个王后放置到国际象棋棋盘上且彼此之间不会产生冲突（即不会有任意两枚棋子位于同一行、同一列或者同一斜线上）。 其中一种可能的解决方案如下图： 实现代码如下：12345678910111213141516171819202122232425262728293031323334353637from csp import Constraint, CSPfrom typing import Dict, List, Optionalclass QueensConstraint(Constraint[int, int]): def __init__(self, columns: List[int]) -&gt; None: super().__init__(columns) self.columns = columns def satisfied(self, assignment: Dict[int, int]) -&gt; bool: # q1c = queen 1 column, q1r = queen 1 row for q1c, q1r in assignment.items(): # q2c = queen 2 column for q2c in range(q1c + 1, len(self.columns) + 1): if q2c in assignment: q2r = assignment[q2c] if q1r == q2r: # same row? return False if abs(q1r - q2r) == abs(q1c - q2c): # same diagonal? return False return Trueif __name__ == "__main__": columns: List[int] = [1, 2, 3, 4, 5, 6, 7, 8] rows: Dict[int, List[int]] = &#123;&#125; for column in columns: rows[column] = [1, 2, 3, 4, 5, 6, 7, 8] csp: CSP[int, int] = CSP(columns, rows) csp.add_constraint(QueensConstraint(columns)) solution: Optional[Dict[int, int]] = csp.backtracking_search() if solution is None: print("No solution found!") else: print(solution)# =&gt; &#123;1: 1, 2: 5, 3: 8, 4: 6, 5: 3, 6: 7, 7: 2, 8: 4&#125; 简单解释下 satisfied() 方法中的两个 for 循环。assignment 采用类似 {1: 1, 2: 5, 3: 8, 4: 6, 5: 3, 6: 7, 7: 2, 8: 4} 的字典类型（一开始会短一些），上述两个 for 循环的作用在于，先以棋盘上的第一列为标准，若第一列与剩余的几列不存在冲突，则去掉第一列，再比较第二列与剩余的几列是否存在冲突，以此类推。一旦出现任何冲突，则返回 False。 参考资料Classic Computer Science Problems in Pythondavecom/ClassicComputerScienceProblemsInPython]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Advanced</tag>
        <tag>Python</tag>
        <tag>DataStructure</tag>
        <tag>Algorithm</tag>
        <tag>CSP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 设计模式——模板方法模式]]></title>
    <url>%2F2020%2F12%2F29%2Fpython-design-patterns-template-pattern%2F</url>
    <content type="text"><![CDATA[行为模式主要关注对象的响应性，处理对象之间的交互以实现更强大的功能。模板方法模式即为一种行为设计模式。比如可以将制作饮料的步骤定义为模板方法中的算法，子类就能使用模板方法来实现沏茶的步骤。且步骤的改变（即子类的具体实现）并不会影响原始算法的结构。这样模板方法模式中的子类就可以通过覆盖来创建不同的行为。 模板方法模式适用于以下场景： 当多个算法或类实现类似或相同逻辑的时候 在子类中实现算法有助于减少重复代码的时候 子类可以通过覆盖实现多种不同行为的时候 模板方法模式的主要意图： 使用基本操作定义算法的框架 重新定义子类的某些操作，无需修改算法的结构 实现代码重用并避免重复工作 利用通用接口或功能实现 AbstractClass：在抽象方法的帮助下定义算法的操作或步骤。这些步骤将被具体的子类覆盖 template_method()：定义算法的框架。在模板方法中调用抽象方法定义的步骤以形成序列或算法 ConcreteClass：实现需要算法子类关注的特定步骤 12345678910111213141516171819202122232425262728293031323334353637from abc import ABCMeta, abstractmethodclass Compiler(metaclass=ABCMeta): @abstractmethod def collectSource(self): pass @abstractmethod def compileToObject(self): pass @abstractmethod def run(self): pass def compileAndRun(self): self.collectSource() self.compileToObject() self.run()class iOSCompiler(Compiler): def collectSource(self): print("Collecting Swift Source Code") def compileToObject(self): print("Compiling Swift code to LLVM bitcode") def run(self): print("Program runing on runtime environment")iOS = iOSCompiler()iOS.compileAndRun()# =&gt; Collecting Swift Source Code# =&gt; Compiling Swift code to LLVM bitcode# =&gt; Program runing on runtime environment 现实中的模板方法模式123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384from abc import abstractmethod, ABCMetaclass Trip(metaclass=ABCMeta): @abstractmethod def setTransport(self): pass @abstractmethod def day1(self): pass @abstractmethod def day2(self): pass @abstractmethod def day3(self): pass @abstractmethod def returnHome(self): pass def itinerary(self): self.setTransport() self.day1() self.day2() self.day3() self.returnHome()class VeniceTrip(Trip): def setTransport(self): print("Take a boat and find your way in the Grand Canal") def day1(self): print("Visit St Mark's Basilica in St Mark's Square") def day2(self): print("Appreciate Doge's Palace") def day3(self): print("Enjoy the food near the Rialto Bridge") def returnHome(self): print("Get souovenirs for friends and get back")class MaldivesTrip(Trip): def setTransport(self): print("On foot, on any island, Wow!") def day1(self): print("Enjoy the marine life of Banana Reef") def day2(self): print("Go for the water sports and snorkelling") def day3(self): print("Relax on the beach and enjoy the sun") def returnHome(self): print("Don't feel like leaving the beach..")class TravelAgency: def arrange_trip(self): choice = input("What kind of place you'd like to go historical or to a beach? ") if choice == 'historical': self.trip = VeniceTrip() self.trip.itinerary() if choice == 'beach': self.trip = MaldivesTrip() self.trip.itinerary()TravelAgency().arrange_trip()# =&gt; What kind of place you'd like to go historical or to a beach? beach# =&gt; On foot, on any island, Wow!# =&gt; Enjoy the marine life of Banana Reef# =&gt; Go for the water sports and snorkelling# =&gt; Relax on the beach and enjoy the sun# =&gt; Don't feel like leaving the beach.. 抽象类 Trip 是一个接口，定义了不同日子使用的交通方式和参观地点等细节 setTransport 是一个抽象方法，由 ConcreteClass 实现，作用是设置交通方式 day1()、day2()、day3() 抽象方法定义了特定日期所参观的地点 itinerary() 模板方法则用于创建完整的行程 VeniceTrip 类和 MaldivesTrip 类是 Trip 接口的具体实现 模板方法的优点和缺点优点： 没有代码重复 使用继承而不是合成，只有为数不多的几个方法需要重写 灵活性，允许子类决定如何实现算法中的步骤 缺点： 调试和理解模板方法模式中的流程序列时可能会令人困惑 模板框架的维护可能是一个问题，任何层次（底层或高层）的变更都可能对实现造成干扰]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Advanced</tag>
        <tag>Python</tag>
        <tag>Development</tag>
        <tag>Pattern</tag>
        <tag>OOP</tag>
        <tag>Design</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 设计模式——观察者模式]]></title>
    <url>%2F2020%2F12%2F29%2Fpython-design-patterns-observer-pattern%2F</url>
    <content type="text"><![CDATA[行为型模式中的观察者模式创建型模式（比如单例模式）是基于对象的创建机制的，这些模式隔离了对象的创建细节，使得实现这些细节的代码能够与要创建的对象类型相互独立。结构型模式（比如门面模式）用于设计对象和类的结构，使得它们能够相互协作以形成更大的结构。重点是结构的简化以及识别类和对象之间的关系。行为型模式（比如观察者模式）主要关注的是对象的责任，处理对象之间的交互，以实现更复杂的功能。对象之间应该可以彼此交互，且应该是松耦合的。 在观察者设计模式中，对象（主题）维护了一个依赖（观察者）列表，以便主题可以使用观察者定义的任何方法通知所有观察者它所发生的变化。 在分布式应用中，多个服务通常是通过彼此交互来实现更大型的操作的。服务可以执行多种操作，但它们执行的操作会直接或很大程度上取决于其交互的服务对象的状态。比如用户注册的示例，其中用户服务负责响应用户在网站上的各种操作。假设有另一个电子邮件的服务，其作用是监视用户的状态并向用户发送电子邮件。若用户刚刚注册，则用户服务将调用电子邮件服务的方法，向用户发送邮件进行账户验证。若账户经过了验证，但信用度较低，则电子邮件服务将监视用户服务并向用户发送信用度过低的电子邮件警报。 因此，若应用中存在一个许多其他服务所依赖的核心服务，该核心服务就会成为观察者必须观察/监视变化的主题。当主题发生变化时，观察者应该改变自身对象状态，或者采取某些动作。从属服务监视核心服务的状态变化是观察者设计模式的经典情境。 观察者模式的主要目标 定义了对象之间的一对多依赖关系，使得对象中的任何更改都将自动通知给其他依赖对象 封装了主题的核心组件 观察者模式的基本实现 12345678910111213141516171819202122232425262728293031323334class Subject: def __init__(self): self.__observers = [] def register(self, observer): self.__observers.append(observer) def notifyAll(self, *args, **kwargs): for observer in self.__observers: observer.notify(subject, *args, **kwargs)class Observer1: def __init__(self, subject): subject.register(self) def notify(self, subject, *args): print(type(self).__name__, ':: Got', args, 'From', subject)class Observer2: def __init__(self, subject): subject.register(self) def notify(self, subject, *args): print(type(self).__name__, ':: Got', args, 'From', subject)subject = Subject()observer1 = Observer1(subject)observer2 = Observer2(subject)subject.notifyAll('notification')# =&gt; Observer1 :: Got ('notification',) From &lt;__main__.Subject object at 0x7f9a1276fa60&gt;# =&gt; Observer2 :: Got ('notification',) From &lt;__main__.Subject object at 0x7f9a1276fa60&gt; 现实中的观察者模式12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485class NewsPublisher: def __init__(self): self.__subscribers = [] self.__latestNews = None def attach(self, subscriber): self.__subscribers.append(subscriber) def detach(self): return self.__subscribers.pop() def subscribers(self): return [type(x).__name__ for x in self.__subscribers] def notifySubscribers(self): for sub in self.__subscribers: sub.update() def addNews(self, news): self.__latestNews = news def getNews(self): return "Got News: " + self.__latestNewsfrom abc import ABCMeta, abstractmethodclass Subscriber(metaclass=ABCMeta): @abstractmethod def update(self): passclass SMSSubscriber(Subscriber): def __init__(self, publisher): self.publisher = publisher self.publisher.attach(self) def update(self): print(type(self).__name__, self.publisher.getNews())class EmailSubscriber(Subscriber): def __init__(self, publisher): self.publisher = publisher self.publisher.attach(self) def update(self): print(type(self).__name__, self.publisher.getNews())class AnyOtherSubscriber: def __init__(self, publisher): self.publisher = publisher self.publisher.attach(self) def update(self): print(type(self).__name__, self.publisher.getNews())if __name__ == '__main__': news_publisher = NewsPublisher() for Subscriber in [SMSSubscriber, EmailSubscriber, AnyOtherSubscriber]: Subscriber(news_publisher) print("\nSubscribers: ", news_publisher.subscribers()) news_publisher.addNews('Hello World') news_publisher.notifySubscribers() print("\nDetached: ", type(news_publisher.detach()).__name__) print("\nSubscribers: ", news_publisher.subscribers()) news_publisher.addNews('My second news') news_publisher.notifySubscribers()# =&gt; Subscribers: ['SMSSubscriber', 'EmailSubscriber', 'AnyOtherSubscriber']# =&gt; SMSSubscriber Got News: Hello World# =&gt; EmailSubscriber Got News: Hello World# =&gt; AnyOtherSubscriber Got News: Hello World# =&gt; Detached: AnyOtherSubscriber# =&gt; Subscribers: ['SMSSubscriber', 'EmailSubscriber']# =&gt; SMSSubscriber Got News: My second news# =&gt; EmailSubscriber Got News: My second news 松耦合与观察者模式松耦合架构的特性： 降低了一个元素内发生的更改可能对其他元素产生意外影响的风险 使得测试、维护和故障排除工作更加简单 系统可以轻松地分解为可定义的元素 观察者模式提供了一种实现主体和观察者松耦合的对象设计模式： 主题对观察者唯一的了解就是它实现的一个特定的接口 可以随时添加任意的新观察者 添加新观察者时，完全无需修改主题 观察者或主题没有绑定在一起，可以彼此独立使用。观察者可以在任何地方重复使用 主题或观察者中的变化不会相互影响 观察者模式的优缺点优点： 使得彼此交互的对象之间保持松耦合 使得可以在无需对主题或观察者进行任何修改的情况下高效地发送数据到其他对象 可以随时添加/删除观察者 缺点： 观察者接口必须由具体观察者实现，涉及继承，且无法进行组合 若实现不当的话，观察者可能会增加复杂性，导致性能降低 在软件应用中，通知有时是不可靠的，并导致竞争条件不一致]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Advanced</tag>
        <tag>Python</tag>
        <tag>Development</tag>
        <tag>Pattern</tag>
        <tag>OOP</tag>
        <tag>Design</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 设计模式——状态模式]]></title>
    <url>%2F2020%2F12%2F26%2Fpython-design-patterns-state-pattern%2F</url>
    <content type="text"><![CDATA[行为模式关注的是对象的响应性，它们通过对象之间的交互以实现更复杂的功能。状态模式是一种行为设计模式，在该模式中，一个对象可以基于其内部状态封装多个行为。比如根据收音机的基本状态（AM/FM），当调谐到 AM 或 FM 频道时，扫描频道的行为就会相应地发生动态的改变。 123456789101112131415161718192021222324252627282930313233343536373839from abc import abstractmethod, ABCMetaclass State(metaclass=ABCMeta): @abstractmethod def handle(self): passclass ConcreteStateB(State): def handle(self): print("ConcreteStateB")class ConcreteStateA(State): def handle(self): print("ConcreteStateA")class Context(State): def __init__(self): self.state = None def getState(self): return self.state def setState(self, state): self.state = state def handle(self): self.state.handle()context = Context()stateA = ConcreteStateA()stateB = ConcreteStateB()context.setState(stateA)context.handle()# =&gt; ConcreteStateA State：定义 Handle() 抽象方法的接口。需要通过 ConcreteState 类实现 ConcreteState：实现 Handle() 方法，可以根据状态变化定义执行的实际操作 Context：接收客户端请求，维护着对象当前状态的引用，以根据请求调用具体的行为 简单示例1234567891011121314151617181920212223242526272829303132333435363738394041from abc import abstractmethod, ABCMetaclass State(metaclass=ABCMeta): @abstractmethod def doThis(self): passclass StartState(State): def doThis(self): print("TV Switching ON...")class StopState(State): def doThis(self): print("TV Switching OFF...")class TVContext(State): def __init__(self): self.state = None def getState(self): return self.state def setState(self, state): self.state = state def doThis(self): self.state.doThis()context = TVContext()context.getState()start = StartState()stop = StopState()context.setState(stop)context.doThis()# =&gt; TV Switching OFF... 真实用例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960class ComputerState: name = "state" allowed = [] def switch(self, state): if state.name in self.allowed: print("current:", self, " =&gt; switching to", state.name) self.__class__ = state else: print("Current:", self, " =&gt; switching to", state.name, "not possible.") def __str__(self): return self.nameclass Off(ComputerState): name = "off" allowed = ['on']class On(ComputerState): name = "on" allowed = ['off', 'suspend', 'hibernate']class Suspend(ComputerState): name = "suspend" allowed = ['on']class Hibernate(ComputerState): name = "hibernate" allowed = ['on']class Computer: def __init__(self): self.state = Off() def change(self, state): self.state.switch(state)if __name__ == '__main__': comp = Computer() comp.change(On) comp.change(Off) comp.change(On) comp.change(Suspend) comp.change(Hibernate) comp.change(On) comp.change(Hibernate)# =&gt; current: off =&gt; switching to on# =&gt; current: on =&gt; switching to off# =&gt; current: off =&gt; switching to on# =&gt; current: on =&gt; switching to suspend# =&gt; Current: suspend =&gt; switching to hibernate not possible.# =&gt; current: suspend =&gt; switching to on# =&gt; current: on =&gt; switching to Hibernate 状态模式的优点 在状态设计模式中，对象的行为是其状态的函数结果，且行为在运行时依旧状态而改变。这消除了对 if/else 或 switch/case 条件逻辑的依赖 使用状态模式，实现多态行为是很方便的，并且易于添加状态来支持额外的行为 状态模式提高了聚合性，针对状态的行为被聚合到 ConcreteState 类中，放置在代码的同一个地方 状态模式不仅改善了扩展应用程序行为时的灵活性，且提高了代码的可维护性。一个 ConcreteState 类即对应一种行为 状态模式的缺点 类爆炸：由于每个状态都需要在 ConcreteState 中定义，可能导致创建太多功能较为单一的类。既增加了代码量，又使得状态机的结构更加难以审查 随着新行为的引入，Context 类需要进行相应的更新以处理每个行为，使得上下文行为更容易受到每个新行为的影响]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Advanced</tag>
        <tag>Python</tag>
        <tag>Development</tag>
        <tag>OOP</tag>
        <tag>Design</tag>
        <tag>Patterns</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 设计模式——命令模式]]></title>
    <url>%2F2020%2F12%2F26%2Fpython-design-patterns-command-pattern%2F</url>
    <content type="text"><![CDATA[命令模式是一种行为设计模式。可以用来实现比如安装软件时的安装向导功能，通常安装向导会通过多个步骤根据用户的选择了解用户的偏好。安装向导首先启动一个名为 Command 的对象，用于存储在向导的多个步骤中用户指定的选项。当用户在最后一个步骤中点击完成按钮时，Command 对象就会运行 execute() 方法，该方法会考察所有存储的选项并完成相应的安装过程。 命令模式通常包含以下术语： Command 对象了解 Receiver 对象的情况，并能调用其方法 调用者（Invoker）方法的参数值存储在 Command 对象中 调用者知道如何执行命令 客户端（Client）用来创建 Command 对象并设置其接收者 命令模式的主要意图： 将请求封装为对象 可用不同的请求对客户端进行参数化 允许将请求保存在队列中 提供面向对象的回调 命令模式的适用场景： 根据需要执行的操作对对象进行参数化 将操作添加到队列并在不同地点执行请求 创建一个结构根据较小的操作来完成高级操作 代码示例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152from abc import ABCMeta, abstractmethodclass Order(metaclass=ABCMeta): @abstractmethod def execute(self): passclass BuyStockOrder(Order): def __init__(self, stock): self.stock = stock def execute(self): self.stock.buy()class SellStockOrder(Order): def __init__(self, stock): self.stock = stock def execute(self): self.stock.sell()class Agent: def __init__(self): self.__orderQueue = [] def placeOrder(self, order): self.__orderQueue.append(order) order.execute()class StockTrade: def buy(self): print("You will buy stocks") def sell(self): print("You will sell stocks")if __name__ == '__main__': stock = StockTrade() buyStock = BuyStockOrder(stock) sellStock = SellStockOrder(stock) agent = Agent() agent.placeOrder(buyStock) agent.placeOrder(sellStock)# =&gt; You will buy stocks# =&gt; You will sell stocks Order 类 -&gt; Command 对象 BuyStockOrder 和 SellStockOrder 类 -&gt; ConcreteCommand 对象，为交易系统定义适当的操作 StockTrade 类 -&gt; Receiver 对象，定义了多个方法（动作）可以被 ConcreteCommand 调用以买入或卖出股票 Agent 类 -&gt; Invoker 对象，作为客户端和 StockTrade 的中介，执行客户下达的订单 命令模式的优点： 将调用操作的类与知道如何执行该操作的类解耦 借助队列系统，可以创建一系列命令 添加新命令更加容易，无需更改现有代码 可以使用命令模式定义回滚系统 命令模式的缺点： 为了实现目标，需要大量的类和对象进行协作 每个单独的命令都是一个 ConcreteCommand 类，增加了实现和维护的成本]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Advanced</tag>
        <tag>Python</tag>
        <tag>Development</tag>
        <tag>OOP</tag>
        <tag>Design</tag>
        <tag>Patterns</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 设计模式——门面模式]]></title>
    <url>%2F2020%2F12%2F25%2Fpython-design-patterns-facade-pattern%2F</url>
    <content type="text"><![CDATA[门面（facade）指建筑物的表面，尤其是最有吸引力的那一面。当人们从建筑物旁边经过时，可以欣赏其外部面貌，而不必了解其本身结构的复杂性。门面在隐藏内部复杂性的同时，也为客户端提供了一个可以轻松访问的接口。 比如需要到某个商店买东西，但对于该商店的布局并不清楚。可以直接找店主说明需要哪些东西，由店主将这些商品找到并提供给顾客。即店主作为购物的接口，顾客无需了解具体商品的位置。 门面设计模式的特点： 为子系统的一组接口提供一个统一的高级接口，帮助客户端以更简单的方式使用这些子系统 门面并不是封装子系统，而是对底层子系统进行组合。即用单个接口对象表示复杂的子系统 门面 一个接口，知道某个请求应该交由那个子系统处理 通过组合的方式将客户端的请求委派给相应的子系统对象 系统 实现子系统的功能，由一组负责不同任务的类来表示 处理门面对象分配的工作，但并不知道门面也不引用它 客户端 会实例化门面 会向门面提出请求 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990class EventManager: def __init__(self): print("Event Manager:: Let me talk to the folks\n") def arrange(self): self.hotelier = Hotelier() self.hotelier.bookHotel() self.florist = Florist() self.florist.setFlowerRequirements() self.caterer = Caterer() self.caterer.setCuisine() self.musician = Musician() self.musician.setMusicType()class Hotelier: def __init__(self): print("Arranging the Hotel for Marriage? --") def __isAvailable(self): print("Is the Hotel free for the event on given day?") return True def bookHotel(self): if self.__isAvailable(): print("Registered the Booking\n\n")class Florist: def __init__(self): print("Flower Decorations for the Event? --") def setFlowerRequirements(self): print("Carnations, Roses and Lilies would be used for Decorations\n\n")class Caterer: def __init__(self): print("Food Arrangements for the Event --") def setCuisine(self): print("Chinese &amp; Continental Cuisine to be served\n\n")class Musician: def __init__(self): print("Musical Arrangements for the Marriage --") def setMusicType(self): print("Jazz and Classical will be played\n\n")class You: def __init__(self): print("You:: Whoa! Marriage Arrangements??!!!") def asskEventManager(self): print("You:: Let's Contact the Event Manager\n\n") em = EventManager() em.arrange() def __del__(self): print("You:: Thanks to Event Manager, all preparations done!")you = You()you.asskEventManager()# =&gt; You:: Whoa! Marriage Arrangements??!!!# =&gt; You:: Let's Contact the Event Manager# =&gt; Event Manager:: Let me talk to the folks# =&gt; Arranging the Hotel for Marriage? --# =&gt; Is the Hotel free for the event on given day?# =&gt; Registered the Booking# =&gt; Flower Decorations for the Event? --# =&gt; Carnations, Roses and Lilies would be used for Decorations# =&gt; Food Arrangements for the Event --# =&gt; Chinese &amp; Continental Cuisine to be served# =&gt; Musical Arrangements for the Marriage --# =&gt; Jazz and Classical will be played# =&gt; You:: Thanks to Event Manager, all preparations done! 最少知识原则门面能够将客户端与实现具体功能的子系统解耦，其背后的设计原理即最少知识原则。 在设计系统时，对于创建的每个对象，都应该考察与之交互的类的数量，以及交互的方式 避免创建许多彼此紧密耦合的类。若类之间存在大量的依赖关系，系统就会变得难以维护，应坚决避免]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Advanced</tag>
        <tag>Python</tag>
        <tag>Development</tag>
        <tag>OOP</tag>
        <tag>Design</tag>
        <tag>Patterns</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 设计模式——代理模式]]></title>
    <url>%2F2020%2F12%2F25%2Fpython-design-patterns-proxy-pattern%2F</url>
    <content type="text"><![CDATA[代理通常是指一个介于寻求方和提供方之间的中介系统。寻求发是发出请求的一方，而提供方则是根据请求提供资源的一方。在设计模式中，代理通常是封装实际服务对象的装饰器或代理人，可以为其包装的对象提供附加功能同时无需改变对象本身的代码。其主要目的是为其他对象提供一个代理者或占位符，从而控制对实际对象的访问。 代理设计模式的主要工作： 为其他对象提供代理，实现对原始对象的访问控制 可以用作一个中间层或接口，以支持分布式访问 通过增加代理，保护真正的组件不受意外影响 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162# agent.pyfrom abc import ABCMeta, abstractmethodclass Payment(metaclass=ABCMeta): @abstractmethod def do_pay(self): passclass Bank(Payment): def __init__(self): self.card = None self.account = None def __getAccount(self): self.account = self.card return self.account def __hasFunds(self): print("Bank:: Checking if Account ", self.__getAccount(), " has enough funds") return True def setCard(self, card): self.card = card def do_pay(self): if self.__hasFunds(): print("Bank:: Paying the merhant") return True else: print("Bank:: Sorry, not enough funds") return Falseclass DebitCard(Payment): def __init__(self): self.bank = Bank() def do_pay(self): card = input("Proxy:: Punch in Card Number: ") self.bank.setCard(card) return self.bank.do_pay()class You: def __init__(self): print("You:: Let's buy the Denim shirt") self.debitCard = DebitCard() self.isPurchased = None def make_payment(self): self.isPurchased = self.debitCard.do_pay() def __del__(self): if self.isPurchased: print("You:: Denim shirt is Mine :-)") else: print("You:: I should earn more :(")you = You()you.make_payment() 123456$ python agent.pyYou:: Let's buy the Denim shirtProxy:: Punch in Card Number: 12345Bank:: Checking if Account 12345 has enough fundsBank:: Paying the merhantYou:: Denim shirt is Mine :-) 关于类 You（对应 UML 图中的 client）的解释： 该类用于实现客户端的行为 __init__() 会调用代理并将其实例化 make_payment() 方法表示购买动作，会在内部调用代理的付款方法 关于类 Bank（对应 UML 图中的 RealSubject）的解释： 该类实际完成从顾客账户向商家划账的动作（do_pay()） 该类提供了多个方法来处理有关付款的一系列逻辑（__getAccount()、__hasFunds()、do_pay() 等） 通过 setCard() 方法从代理处获取借记卡信息 关于 DebitCard 类（对应 UML 图中的 Proxy）的解释： 该类用于实现代理的行为，充当真实主题（银行）的代理 顾客需要付款时，无需跑去银行提款再回到商家支付，而是调用 DebitCard 的 do_pay() 方法 DebitCard 类在内部控制真实主题（Bank）的创建，并向银行提供借记卡的详细信息 Bank 对象在内部对账户进行检查并完成支付动作 代理模式的优点 可以通过缓存笨重的对象或频繁访问的对象来提高应用程序的性能 可以提供对于真实对象的访问授权 远程代理还便于与远程服务器进行交互，并监视系统 门面模式与代理模式的比较 代理模式 门面模式 为其他对象提供代理或占位符，以控制对原始对象的访问 为类的大型子系统提供了一个简单的接口 代理对象具有与目标对象相同的接口，并保存目标对象的引用 实现了子系统之间通信和依赖性的最小化 充当客户端和被封装的对象之间的中介 提供了单一的简单接口]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Advanced</tag>
        <tag>Python</tag>
        <tag>Development</tag>
        <tag>OOP</tag>
        <tag>Design</tag>
        <tag>Patterns</tag>
        <tag>Proxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 设计模式——工厂模式]]></title>
    <url>%2F2020%2F12%2F22%2Fpython-design-patterns-factory-pattern%2F</url>
    <content type="text"><![CDATA[在面向对象编程中，工厂表示一个负责创建其他类型的对象的类。通常作为工厂的类会实现多个关联的方法，客户端通过某些参数调用这些方法，工厂则负责创建对应类型的对象并返回给客户端。 工厂模式的优点： 松耦合。对象的创建独立于类的实现 客户端无需了解创建对象的类，只需知道需要传递的接口、方法和参数即可。简化了客户端的实现 可以轻松地在工厂中添加其他类来创建其他类型的对象，无需更改客户端代码 工厂可以重用现有的对象 简单工厂模式123456789101112131415161718192021222324252627from abc import ABCMeta, abstractmethodclass Animal(metaclass=ABCMeta): @abstractmethod def do_say(self): passclass Dog(Animal): def do_say(self): print("Bhow Bhow")class Cat(Animal): def do_say(self): print("Meow Meow")class ForestFactory: def make_sound(self, object_type): return eval(object_type)().do_say()if __name__ == '__main__': ff = ForestFactory() animal = input("Which animal should make sound, Dog or Cat\n") ff.make_sound(animal) 12345678$ python make_sound.pyWhich animal should make sound, Dog or CatDogBhow Bhow$ python make_sound.pyWhich animal should make sound, Dog or CatCatMeow Meow 工厂方法模式工厂方法模式的特点： 定义一个接口来创建对象，但工厂本身并不负责创建动作，而是由其子类决定实例化哪些类 工厂方法的创建是通过继承而不是通过实例化来完成的 工厂方法使设计更具有定制性。可以返回相同的实例或子类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162from abc import ABCMeta, abstractmethodclass Section(metaclass=ABCMeta): @abstractmethod def describe(self): passclass PersonalSection(Section): def describe(self): print("Personal Section")class AlbumSection(Section): def describe(self): print("Album Section")class PatentSection(Section): def describe(self): print("Patent Section")class PublicationSection(Section): def describe(self): print("Publication Section")class Profile(metaclass=ABCMeta): def __init__(self): self.sections = [] self.createProfile() @abstractmethod def createProfile(self): pass def getSections(self): return self.sections def addSections(self, section): self.sections.append(section)class linkedin(Profile): def createProfile(self): self.addSections(PersonalSection()) self.addSections(PatentSection()) self.addSections(PublicationSection())class facebook(Profile): def createProfile(self): self.addSections(PersonalSection()) self.addSections(AlbumSection())if __name__ == '__main__': profile_type = input("Which Profile you'd like to create?\n[LinkedIn or FaceBook] ") profile = eval(profile_type.lower())() print("Creating Profile...", type(profile).__name__) print("Profile has sections --", profile.getSections()) 12345$ python profile.pyWhich Profile you'd like to create?[LinkedIn or FaceBook] LinkedInCreating Profile... linkedinProfile has sections -- [&lt;__main__.PersonalSection object at 0x7f3d25e53c70&gt;, &lt;__main__.PatentSection object at 0x7f3d25e53ca0&gt;, &lt;__main__.PublicationSection object at 0x7f3d25e53df0&gt;] Profile 抽象类代表 Creator，提供了 createProfile() 工厂方法，用于创建带有适当板块的个人信息界面。但 Profile 并不清楚某个特定界面应该具有哪些板块，如 Facebook 需要提供个人信息板块和相册区。createProfile() 工厂方法实际是由 Profile 的子类去实现的。 两个 Profile 的子类 linkedin 和 facebook 代表 ConcreteCreator，每个类都实现了 createProfile 方法，该方法在运行时创建多个板块（ConcreteProducts）。 工厂方法模式的优点 强大的灵活性，代码更加通用。实现哪些类取决于接口（Product），而不是 ConcreteProduct 类 松耦合。创建对象的代码与使用对象的代码是分离的。客户端不需要关心传递哪些参数以及需要实例化哪些类 抽象工厂模式抽象工厂模式的主要目的是提供一个接口来创建一系列相关的对象，而无需指定具体的类。因此可以帮助客户端一次使用来自一个产品/系列的多个对象。比如正在开发的应用是平台无关的，则需要对不同平台下的各种依赖项（包括操作系统、文件系统调用等）进行抽象处理，由抽象工厂为各个平台创建所需的服务，客户端就不必直接创建平台对象了。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576from abc import ABCMeta, abstractmethodclass PizzaFactory(metaclass=ABCMeta): @abstractmethod def createVegPizza(self): pass @abstractmethod def createNonVegPizza(self): passclass IndianPizzaFactory(PizzaFactory): def createVegPizza(self): return DeluxVeggiePizza() def createNonVegPizza(self): return ChickenPizza()class USPizzaFactory(PizzaFactory): def createVegPizza(self): return MexicanVegPizza() def createNonVegPizza(self): return HamPizza()class VegPizza(metaclass=ABCMeta): @abstractmethod def prepare(self, VegPizza): passclass NonVegPizza(metaclass=ABCMeta): @abstractmethod def serve(self, VegPizza): passclass DeluxVeggiePizza(VegPizza): def prepare(self): print("Prepare ", type(self).__name__)class ChickenPizza(NonVegPizza): def serve(self, VegPizza): print(type(self).__name__, " is served with Chicken on ", type(VegPizza).__name__)class MexicanVegPizza(VegPizza): def prepare(self): print("Prepare ", type(self).__name__)class HamPizza(NonVegPizza): def serve(self, VegPizza): print(type(self).__name__, " is served with Ham on ", type(VegPizza).__name__)class PizzaStore: def makePizzas(self): for factory in [IndianPizzaFactory(), USPizzaFactory()]: self.factory = factory self.NonVegPizza = self.factory.createNonVegPizza() self.VegPizza = self.factory.createVegPizza() self.VegPizza.prepare() self.NonVegPizza.serve(self.VegPizza)pizza = PizzaStore()pizza.makePizzas()# =&gt; Prepare DeluxVeggiePizza# =&gt; ChickenPizza is served with Chicken on DeluxVeggiePizza# =&gt; Prepare MexicanVegPizza# =&gt; HamPizza is served with Ham on MexicanVegPizza 工厂方法与抽象工厂方法的比较 工厂方法 抽象工厂方法 向客户端开放了一个创建对象的方法 包含一个或多个工厂方法来创建一个系列的相关对象 使用继承和子类决定要创建哪个对象 使用组合将创建对象的任务委托给其他类 工厂方法用于创建一个产品 抽象工厂方法用于创建相关产品的系列]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Advanced</tag>
        <tag>Python</tag>
        <tag>Pattern</tag>
        <tag>Design</tag>
        <tag>Factory</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django models 详解之聚合查询（aggregate）与分组查询（annotate）]]></title>
    <url>%2F2020%2F12%2F22%2Fdjango-models-aggregate-and-annotate%2F</url>
    <content type="text"><![CDATA[一、测试代码及数据models.py 代码 12345678910111213from django.db import modelsclass Author(models.Model): name = models.CharField(max_length=100) age = models.IntegerField()class Book(models.Model): name = models.CharField(max_length=300) price = models.DecimalField(max_digits=10, decimal_places=2) authors = models.ManyToManyField(Author) pubdate = models.DateField() 测试数据 authors：12345678910111213141516171819202122[ &#123; "id": 1, "name": "路人甲", "age": 10 &#125;, &#123; "id": 2, "name": "路人乙", "age": 18 &#125;, &#123; "id": 3, "name": "路人丙", "age": 28 &#125;, &#123; "id": 4, "name": "路人丁", "age": 50 &#125;] books：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980[ &#123; "id": 1, "name": "人之初", "price": "38.80", "pubdate": "2020-12-01", "authors": [ 1 ] &#125;, &#123; "id": 2, "name": "性本善", "price": "28.40", "pubdate": "2020-06-01", "authors": [ 2 ] &#125;, &#123; "id": 3, "name": "性相近", "price": "15.20", "pubdate": "2019-10-01", "authors": [ 3 ] &#125;, &#123; "id": 4, "name": "习相远", "price": "35.20", "pubdate": "2019-07-01", "authors": [ 4 ] &#125;, &#123; "id": 5, "name": "苟不教", "price": "5.20", "pubdate": "2018-07-01", "authors": [ 1, 3, 4 ] &#125;, &#123; "id": 6, "name": "性乃迁", "price": "55.20", "pubdate": "2018-12-01", "authors": [ 2, 3, 4 ] &#125;, &#123; "id": 7, "name": "教之道", "price": "33.20", "pubdate": "2018-12-23", "authors": [ 2, 3 ] &#125;, &#123; "id": 8, "name": "贵以专", "price": "27.20", "pubdate": "2017-12-23", "authors": [ 1, 4 ] &#125;] 二、常用聚合操作获取所有书籍的数量：12&gt;&gt;&gt; Book.objects.count()8 获取由路人甲参与著作的所有书籍的数量：12&gt;&gt;&gt; Book.objects.filter(authors__name__contains='路人甲').count()3 获取所有书籍的平均价格：12&gt;&gt;&gt; Book.objects.all().aggregate(Avg('price'))&#123;'price__avg': Decimal('29.800000')&#125; 获取所有书籍中的最高价格：12&gt;&gt;&gt; Book.objects.all().aggregate(Max('price'))&#123;'price__max': Decimal('55.20')&#125; 涉及到一对多或多对多关系的聚合查询计算每一位作者各自参与写作了多少本书：12345678&gt;&gt;&gt; from django.db.models import Count&gt;&gt;&gt; authors=Author.objects.annotate(num_books=Count('book'))&gt;&gt;&gt; authors&lt;QuerySet [&lt;Author: Author object (1)&gt;, &lt;Author: Author object (2)&gt;, &lt;Author: Author object (3)&gt;, &lt;Author: Author object (4)&gt;]&gt;&gt;&gt;&gt; authors[0].num_books3&gt;&gt;&gt; authors.values_list('name', 'num_books')&lt;QuerySet [('路人甲', 3), ('路人乙', 3), ('路人丙', 4), ('路人丁', 4)]&gt; 即作者包含路人甲的书籍有3本，以此类推。 计算每一位作者各自参与写作的书籍数量，根据书籍出版年份是否在2020年以前分界：12345678910&gt;&gt;&gt; from django.db.models import Q&gt;&gt;&gt; before_2020 = Count('book', filter=Q(book__pubdate__lt='2020-01-01'))&gt;&gt;&gt; after_2020 = Count('book', filter=Q(book__pubdate__gt='2020-01-01'))&gt;&gt;&gt; authors = Author.objects.annotate(before_2020=before_2020).annotate(after_2020=after_2020)&gt;&gt;&gt; authors&lt;QuerySet [&lt;Author: Author object (1)&gt;, &lt;Author: Author object (2)&gt;, &lt;Author: Author object (3)&gt;, &lt;Author: Author object (4)&gt;]&gt;&gt;&gt;&gt; authors[0].before_20202&gt;&gt;&gt; authors.values_list('name', 'before_2020', 'after_2020')&lt;QuerySet [('路人甲', 2, 1), ('路人乙', 2, 1), ('路人丙', 4, 0), ('路人丁', 4, 0)]&gt; 即作者包含路人甲的书籍，2020年以前出版的有2本，2020年以后出版的有1本。以此类推。 获取每一位作者各自参与著作的书籍数量，将输出结果按书籍数量由大到小的顺序排序：12345&gt;&gt;&gt; authors = Author.objects.annotate(num_books=Count('book')).order_by('-num_books')&gt;&gt;&gt; authors&lt;QuerySet [&lt;Author: Author object (3)&gt;, &lt;Author: Author object (4)&gt;, &lt;Author: Author object (1)&gt;, &lt;Author: Author object (2)&gt;]&gt;&gt;&gt;&gt; authors.values_list('name', 'num_books')&lt;QuerySet [('路人丙', 4), ('路人丁', 4), ('路人甲', 3), ('路人乙', 3)]&gt; 三、aggregate在聚合查询中，Django 支持通过 aggregate() 方法从整个 QuerySet 中计算出一个汇总数据。如获取所有书籍的平均价格：123&gt;&gt;&gt; from django.db.models import Avg&gt;&gt;&gt; Book.objects.all().aggregate(Avg('price'))&#123;'price__avg': Decimal('29.800000')&#125; 上述语句中的 all() 可以省略。aggregate() 的参数表示我们想要做聚合计算的那一列数据，其中的 &#39;price&#39; 即表示 Book 模型的 price 字段。 aggregate() 对于 QuerySet 来说是一种终止语句，会返回字典形式的键值对作为计算结果。其中的键会根据聚合的字段自动生成，也可以手动指定：12&gt;&gt;&gt; Book.objects.all().aggregate(average_price=Avg('price'))&#123;'average_price': Decimal('29.800000')&#125; 如果想要同时完成多个聚合查询操作，可以为 aggregate() 添加多个参数：123&gt;&gt; from django.db.models import Avg, Max, Min&gt;&gt;&gt; Book.objects.aggregate(Avg('price'), Max('price'), Min('price'))&#123;'price__avg': Decimal('29.800000'), 'price__max': Decimal('55.20'), 'price__min': Decimal('5.20')&#125; 四、annotate借助 annotate() 方法，Django 可以从 QuerySet 的每一个对象中计算出对应的独立的汇总数据。比如想获得 Book 模型中每一本书的作者的数量：12345678&gt;&gt;&gt; from django.db.models import Count&gt;&gt;&gt; q = Book.objects.annotate(num_authors=Count('authors'))&gt;&gt;&gt; q&lt;QuerySet [&lt;Book: Book object (1)&gt;, &lt;Book: Book object (2)&gt;, &lt;Book: Book object (3)&gt;, &lt;Book: Book object (4)&gt;, &lt;Book: Book object (5)&gt;, &lt;Book: Book object (6)&gt;, &lt;Book: Book object (7)&gt;, &lt;Book: Book object (8)&gt;]&gt;&gt;&gt;&gt; q[0].num_authors1&gt;&gt;&gt; q.values_list('name', 'num_authors')&lt;QuerySet [('人之初', 1), ('性本善', 1), ('性相近', 1), ('习相远', 1), ('苟不教', 3), ('性乃迁', 3), ('教之道', 2), ('贵以专', 2)]&gt; 不同于 aggregate()，annotate() 对于 QuerySet 来说并不是终止语句，annotate() 方法的输出结果仍是 QuerySet 对象。该对象可以继续执行被 QuerySet 支持的任意操作，如 filter()、order_by() 等，甚至另一个 annotate()。 五、join &amp; aggregate某些情况下，你想要聚合的字段并不属于当前正在查询的模型，而是属于关联于当前模型的另一个模型。在对这些字段进行聚合查询时，Django 允许使用与 filter() 中相同的用于指定关联字段的双下划线语法。 比如想要获取每一位作者所著书籍的价格区间：1234&gt;&gt;&gt; from django.db.models import Max, Min&gt;&gt;&gt; authors = Author.objects.annotate(min_price=Min('book__price'), max_price=Max('book__price'))&gt;&gt;&gt; authors.values_list('name', 'min_price', 'max_price')&lt;QuerySet [('路人甲', Decimal('5.20'), Decimal('38.80')), ('路人乙', Decimal('28.40'), Decimal('55.20')), ('路人丙', Decimal('5.20'), Decimal('55.20')), ('路人丁', Decimal('5.20'), Decimal('55.20'))]&gt; 即作者为路人甲的书籍中，最低的价格为 5.20，最高的价格为 38.80。 六、filter() 或 order_by() 应用到 annotate()如查找所有多人合著（作者数量大于 1）的书籍列表：12345&gt;&gt;&gt; books = Book.objects.annotate(num_authors=Count('authors')).filter(num_authors__gt=1)&gt;&gt;&gt; books&lt;QuerySet [&lt;Book: Book object (5)&gt;, &lt;Book: Book object (6)&gt;, &lt;Book: Book object (7)&gt;, &lt;Book: Book object (8)&gt;]&gt;&gt;&gt;&gt; books.values_list('name', 'num_authors')&lt;QuerySet [('苟不教', 3), ('性乃迁', 3), ('教之道', 2), ('贵以专', 2)]&gt; 根据作者数量对全部书籍进行排序：12345&gt;&gt;&gt; books = Book.objects.annotate(num_authors=Count('authors')).order_by('num_authors')&gt;&gt;&gt; books&lt;QuerySet [&lt;Book: Book object (2)&gt;, &lt;Book: Book object (4)&gt;, &lt;Book: Book object (1)&gt;, &lt;Book: Book object (3)&gt;, &lt;Book: Book object (8)&gt;, &lt;Book: Book object (7)&gt;, &lt;Book: Book object (5)&gt;, &lt;Book: Book object (6)&gt;]&gt;&gt;&gt;&gt; books.values_list('name', 'num_authors')&lt;QuerySet [('性本善', 1), ('习相远', 1), ('人之初', 1), ('性相近', 1), ('教之道', 2), ('贵以专', 2), ('苟不教', 3), ('性乃迁', 3)]&gt; 参考资料Django 官方文档 —— Aggregation]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Web</tag>
        <tag>Django</tag>
        <tag>Models</tag>
        <tag>Aggregate</tag>
        <tag>Annotate</tag>
        <tag>Backend</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vue.js 截获 Ctrl+S 组合键以及自动保存（提交）功能的实现]]></title>
    <url>%2F2020%2F12%2F14%2Fvue-js-add-auto-save-and-ctrl-s%2F</url>
    <content type="text"><![CDATA[默认情况下，Chrome 中按下 Ctrl+S 组合键会进入“保存网页”界面，并不会与网页中的具体内容做交互。 最近在做一个前端基于 Vue 的在线文档，希望网页中按下 Ctrl+S 组合件就能触发提交动作，将前端数据的改动存储到后端数据库中。并且不管用户是否操作，每隔特定时间也会自动提交文档的当前内容到后端，实现自动保存的功能。 示例代码如下：12345678910111213141516171819202122232425262728293031323334&lt;template&gt; &lt;button @click=&quot;save(&apos;button&apos;)&quot;&gt;保存&lt;/button&gt;&lt;/template&gt;&lt;script&gt;export default &#123; mounted() &#123; document.addEventListener(&apos;keydown&apos;, this.saveContent) this.timer = setInterval(() =&gt; &#123; this.save(&apos;timer&apos;) &#125;, 10 * 1000) &#125;, beforeDestroy() &#123; document.removeEventListener(&apos;keydown&apos;, this.saveContent) clearInterval(this.timer) &#125;, methods: &#123; save(type) &#123; console.log(`content saved by $&#123;type&#125;`) &#125;, saveContent(e) &#123; var key = window.event.keyCode ? window.event.keyCode : window.event.which if (key === 83 &amp;&amp; e.ctrlKey) &#123; this.save(&apos;hot key&apos;) e.preventDefault() &#125; &#125; &#125;&#125;&lt;/script&gt;]]></content>
      <categories>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Web</tag>
        <tag>Development</tag>
        <tag>Frontend</tag>
        <tag>JavaScript</tag>
        <tag>Vue.js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django REST framework 使用 MongoDB 作为数据库后端]]></title>
    <url>%2F2020%2F11%2F27%2Fpython-django-rest-framework-and-mongodb%2F</url>
    <content type="text"><![CDATA[想写个前后端分离的项目，需要在数据库中存储非常复杂的 JSON 格式（包含多层嵌套）的数据，又不想将 JSON 数据转为文本后以 Text 的格式存到 Mysql 数据库中。 因此想尝试下文档型数据库 MongoDB，其用来存放数据的文档结构，本身就是非常类似 JSON 对象的 BSON（Binary JSON）。 但 Django 的官方版本目前还未支持 NoSQL 数据库（参考 FAQ），MongoDB 官方文档建议借助 Djongo 组件完成到原生 Django ORM 的对接。Djongo 实际上是一个 SQL 到 MongoDB 的翻译器。通过 Django 的 admin 应用可以向 MongoDB 中添加或修改文档，其他 Django 模块如 contrib、auth、session 等也可以在不做任何改动的情况下正常使用。 项目初始化安装需要用到的 Python 模块，初始化项目：1234$ pip install djongo djangorestframework$ django-admin startproject mongo_test$ cd mongo_test$ django-admin startapp blogs 修改项目配置文件（mongo_test/settings.py），添加数据库配置：12345678...DATABASES = &#123; 'default': &#123; 'ENGINE': 'djongo', 'NAME': 'mongo_test', &#125;&#125;... 数据库迁移，创建管理员账户，运行 WEB 服务：123$ python manage.py migrate$ python manage.py createsuperuser$ python manage.py runserver 0.0.0.0:8000 访问 http://127.0.0.1:8000/admin ，进入 Django 管理员后台，各部分功能使用正常： 此时访问 MongoDB 数据库，可以查询到存入的数据：123456789101112131415161718192021222324252627282930313233343536// mongo shell&gt; show dbsadmin 0.000GBapscheduler 0.000GBconfig 0.000GBlocal 0.000GBmongo_test 0.000GB&gt; use mongo_testswitched to db mongo_test&gt; show collections;__schema__auth_groupauth_group_permissionsauth_permissionauth_userauth_user_groupsauth_user_user_permissionsdjango_admin_logdjango_content_typedjango_migrationsdjango_session&gt; db.auth_user.find().pretty()&#123; &quot;_id&quot; : ObjectId(&quot;5fc0a6a4e7b96c382fa9ccd8&quot;), &quot;id&quot; : 1, &quot;password&quot; : &quot;pbkdf2_sha256$180000$XL0v3lLCM1RW$rnw4qzoTUtwgc5EoKfB4yaaVEu1jTid8yuBVl0Y6P5Q=&quot;, &quot;last_login&quot; : ISODate(&quot;2020-11-27T07:11:55.492Z&quot;), &quot;is_superuser&quot; : true, &quot;username&quot; : &quot;admin&quot;, &quot;first_name&quot; : &quot;&quot;, &quot;last_name&quot; : &quot;&quot;, &quot;email&quot; : &quot;&quot;, &quot;is_staff&quot; : true, &quot;is_active&quot; : true, &quot;date_joined&quot; : ISODate(&quot;2020-11-27T07:11:31.955Z&quot;)&#125; Django REST framework在配置文件 mongo_test/settings.py 中的 INSTALLED_APPS 配置项下添加 rest_framework 和 blogs 两个应用：123456789101112...INSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'rest_framework', 'blogs']... 数据库模型（Models）编辑 blogs/models.py 文件，创建数据库模型，内容如下：123456789from djongo import modelsclass Blog(models.Model): title = models.CharField(max_length=50) content = models.TextField() class Meta: db_table = 'mongo_blog' 序列化器（Serializers）创建 blogs/serializers.py 文件，内容如下：12345678from blogs.models import Blogfrom rest_framework.serializers import ModelSerializerclass BlogSerializer(ModelSerializer): class Meta: model = Blog fields = '__all__' 视图（Views）编辑 blogs/views.py 文件，内容如下：12345678from blogs.models import Blogfrom blogs.serializers import BlogSerializerfrom rest_framework.viewsets import ModelViewSetclass BlogViewSet(ModelViewSet): queryset = Blog.objects.all() serializer_class = BlogSerializer 路由（URLs）创建 blogs/urls.py 文件，内容如下：12345678910from django.urls import include, pathfrom rest_framework import routersfrom blogs import viewsrouter = routers.DefaultRouter()router.register(r'blog', views.BlogViewSet)urlpatterns = [ path('', include(router.urls))] 根路由编辑项目路由配置文件 mongo_test/urls.py，内容如下：1234567from django.contrib import adminfrom django.urls import path, includeurlpatterns = [ path('admin/', admin.site.urls), path('', include('blogs.urls')),] 访问 http://127.0.0.1/blog ，利用 POST 方法新增数据以测试 REST API 运行效果： 结果爆出 TypeError 错误（int() argument must be a string, a bytes-like object or a number, not &#39;ObjectId&#39;）： 重新访问 http://127.0.0.1:8000/blog ，发现新增的数据已添加到数据库中，只是 id 项为 null：1234567[ &#123; "id": null, "title": "Blog", "content": "This is a TEST Blog" &#125;] 导致基于 REST API 的 CRUD 操作都是不能正常执行的。 ObjectId实际上按照上述方式存入数据库的数据是以下格式：1234567// mongo shell&gt; db.mongo_blog.findOne()&#123; &quot;_id&quot; : ObjectId(&quot;5fc0ae2ea7795c8c4ddae815&quot;), &quot;title&quot; : &quot;Blog&quot;, &quot;content&quot; : &quot;This is a TEST Blog&quot;&#125; 修改数据库模型（blogs/models.py），令其包含 _id 字段：12345678910from djongo import modelsclass Blog(models.Model): _id = models.ObjectIdField() title = models.CharField(max_length=50) content = models.TextField() class Meta: db_table = 'mongo_blog' 刷新 http://127.0.0.1:8000/blog 页面，此时数据显示正常，也可以通过 POST 方法正常添加数据（_id 项留空，会自动生成）： Retrieve上述实现仍有部分问题，实际上只有新值数据（Create）和获取数据列表（List）能够正常运行。而 CRUD 中的 Retrieve、Update、Delete 都会报出 404 错误。即无法通过 _id 获取对应的数据对象。 比如访问 http://127.0.0.1:8000/blog/5fc0b18e60870125f0ed846d/ ： 原因是 MongoDB 中的 _id 是 OjbectId 类型，与 Django REST framework 用于检索的 _id 类型不一致，导致无法通过 _id 找到对应的对象。需要在中间做一步转换工作（将字符串形式的 _id 转换为 ObjectId 形式）。12345// mongo shell&gt; db.mongo_blog.find(&#123;&quot;_id&quot;: &quot;5fc0b18e60870125f0ed846d&quot;&#125;)&gt;&gt; db.mongo_blog.find(&#123;&quot;_id&quot;: ObjectId(&quot;5fc0b18e60870125f0ed846d&quot;)&#125;)&#123; &quot;_id&quot; : ObjectId(&quot;5fc0b18e60870125f0ed846d&quot;), &quot;title&quot; : &quot;Blog2&quot;, &quot;content&quot; : &quot;This is another Blog&quot; &#125; 查看 ModelViewSet 源代码通过查看 ModelViewSet 的源代码，发现后台对 Retrieve 操作的响应逻辑是由mixinx.RetrieveModelMixin 类实现的，其中获取某个特定对象的函数是 self.get_object()：12345678class RetrieveModelMixin: """ Retrieve a model instance. """ def retrieve(self, request, *args, **kwargs): instance = self.get_object() serializer = self.get_serializer(instance) return Response(serializer.data) 进一步查找，发现 get_object() 函数是在 generics.GenericAPIVie 类中实现的，其代码为：12345678910111213141516171819202122232425262728class GenericAPIView(views.APIView): def get_object(self): &quot;&quot;&quot; Returns the object the view is displaying. You may want to override this if you need to provide non-standard queryset lookups. Eg if objects are referenced using multiple keyword arguments in the url conf. &quot;&quot;&quot; queryset = self.filter_queryset(self.get_queryset()) # Perform the lookup filtering. lookup_url_kwarg = self.lookup_url_kwarg or self.lookup_field assert lookup_url_kwarg in self.kwargs, ( &apos;Expected view %s to be called with a URL keyword argument &apos; &apos;named &quot;%s&quot;. Fix your URL conf, or set the `.lookup_field` &apos; &apos;attribute on the view correctly.&apos; % (self.__class__.__name__, lookup_url_kwarg) ) filter_kwargs = &#123;self.lookup_field: self.kwargs[lookup_url_kwarg]&#125; obj = get_object_or_404(queryset, **filter_kwargs) # May raise a permission denied self.check_object_permissions(self.request, obj) return obj 其中最关键的两句为：12filter_kwargs = &#123;self.lookup_field: self.kwargs[lookup_url_kwarg]&#125;obj = get_object_or_404(queryset, **filter_kwargs) {self.lookup_field: self.kwargs[lookup_url_kwarg]} 决定了最终 MongoDB 会以怎样的方式和条件检索某个对象。 实现自己的 ModelViewSet综上，为了让 CURD 操作中的 URD 能够通过 _id（ObjectId）检索获取特定对象，可以实现自己的 ModelViewSet 类，重写 get_object() 方法。 新建 blogs/mongo_viewset.py 文件，内容如下：1234567891011121314151617181920212223242526272829from bson import ObjectIdfrom django.shortcuts import get_object_or_404from rest_framework.viewsets import ModelViewSetclass MongoModelViewSet(ModelViewSet): def get_object(self): queryset = self.filter_queryset(self.get_queryset()) # Perform the lookup filtering. lookup_url_kwarg = self.lookup_url_kwarg or self.lookup_field assert lookup_url_kwarg in self.kwargs, ( 'Expected view %s to be called with a URL keyword argument ' 'named "%s". Fix your URL conf, or set the `.lookup_field` ' 'attribute on the view correctly.' % (self.__class__.__name__, lookup_url_kwarg) ) if self.lookup_field == '_id': filter_kwargs = &#123;self.lookup_field: ObjectId(self.kwargs[self.lookup_field])&#125; else: filter_kwargs = &#123;self.lookup_field: self.kwargs[self.lookup_url_kwarg]&#125; obj = get_object_or_404(queryset, **filter_kwargs) # May raise a permission denied self.check_object_permissions(self.request, obj) return obj 最主要的改动即：1234if self.lookup_field == &apos;_id&apos;: filter_kwargs = &#123;self.lookup_field: ObjectId(self.kwargs[self.lookup_field])&#125;else: filter_kwargs = &#123;self.lookup_field: self.kwargs[self.lookup_url_kwarg]&#125; 视图代码 blogs/views.py 改为如下版本：123456789from blogs.models import Blogfrom blogs.serializers import BlogSerializerfrom blogs.mongo_viewset import MongoModelViewSetclass BlogViewSet(MongoModelViewSet): queryset = Blog.objects.all() serializer_class = BlogSerializer lookup_field = '_id' 此时访问 http://172.20.23.34:8000/blog/5fc0b18e60870125f0ed846d/ 即可正常显示，即能够通过 _id（ObjectId）获取对应的数据对象。 由此 CRUD 操作全部可以正常支持。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Web</tag>
        <tag>Development</tag>
        <tag>Django</tag>
        <tag>Backend</tag>
        <tag>REST</tag>
        <tag>MongoDB</tag>
        <tag>NoSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 设计模式——单例模式]]></title>
    <url>%2F2020%2F11%2F27%2Fpython-design-patterns-singleton%2F</url>
    <content type="text"><![CDATA[单例模式即确保类有且只有一个特定类型的对象，并提供全局访问点。因此通常用于日志记录、数据库操作、打印机后台处理程序等。这些程序在运行过程中只生成一个实例，避免对同一资源产生相互冲突的请求。 特点： 确保类有且只有一个对象被创建 为唯一对象提供访问点，令其可被全局访问 控制共享资源的并行访问 经典单例模式1234567891011121314151617181920212223class Singleton(object): def __new__(cls, name): if not hasattr(cls, 'instance'): cls.instance = super().__new__(cls) return cls.instance def __init__(self, name): self.name = names1 = Singleton('Singleton1')print(s1)# =&gt; &lt;__main__.Singleton object at 0x7efc1b006220&gt;print(s1.name)# =&gt; Singleton1s2 = Singleton('Singleton2')print(s2)# =&gt; &lt;__main__.Singleton object at 0x7efc1b006220&gt;print(s2.name)# =&gt; Singleton2print(s1.name)# =&gt; Singleton2 在上面的代码中，通过定义 __new__ 方法控制对象的创建。方法 hasattr 则用于检查对象 cls 是否具有 instance 属性（即确认该类是否已经生成了一个对象）。若 instance 属性不存在，则使用 super().__new__() 方法创建新的实例；若 instance 属性存在，则分配已有的实例给变量。因此当 s2 = Singleton(&#39;Singleton2&#39;) 执行时，hasattr 发现对象实例已存在（s1），因此直接将已有的对象分配给 s2。s1 和 s2 实际是同一个对象实例。 Monostate（单态）模式Monostate 模式即类的所有实例对象共享相同的状态。123456789101112131415class Borg: __shared_state = &#123;&#125; def __init__(self): self.__dict__ = self.__shared_stateb = Borg()b1 = Borg()print(b is b1) # =&gt; Falseb.x = 4print(b.x) # =&gt; 4print(b1.x) # =&gt; 4b1.x = 6print(b1.x) # =&gt; 6print(b.x) # =&gt; 6 在上述代码中，通过将类变量 __shared_state 赋值给实例变量 __dict__（__dict__ 变量用于存储实例对象的属性等状态），使得类生成的所有对象实例都共享同一状态。即 b 和 b1 是 Borg 类创建的不同的实例对象，但用于保存实例状态的 b.__dict__ 和 b1.__dict__ 却是相同的（即都是 Borg.__shared_state）。因此 b 的属性 x 若发生改变，同样的变化也会体现到 b1 中。 也可以通过修改 __new__ 方法来实现 Borg 模式：1234567891011121314151617181920class Borg: __shared_state = &#123;&#125; def __new__(cls, name): obj = super().__new__(cls) obj.__dict__ = cls.__shared_state return obj def __init__(self, name): self.name = nameb1 = Borg('Borg1')print(b1.name) # =&gt; Borg1b2 = Borg('Borg2')print(b2.name) # =&gt; Borg2print(b1.name) # =&gt; Borg2b1.name = 'Borg'print(b1.name) # =&gt; Borgprint(b2.name) # =&gt; Borgprint(b1 is b2) # =&gt; False 通过元类实现单例模式1234567891011121314151617181920class MetaSingleton(type): def __init__(self, *args, **kwargs): self.__instance = None def __call__(self, *args, **kwargs): if not self.__instance: self.__instance = super().__call__(*args, **kwargs) return self.__instanceclass Logger(metaclass=MetaSingleton): passlogger1 = Logger()logger2 = Logger()print(logger1, logger2)# =&gt; &lt;__main__.Logger object at 0x7fac8af577c0&gt; &lt;__main__.Logger object at# 0x7fac8af577c0&gt;print(logger1 is logger2) # =&gt; True 单例模式的实际应用DB 操作1234567891011121314151617181920212223242526272829import sqlite3class MetaSingleton(type): def __init__(self, *args, **kwargs): self.__instance = None def __call__(self, *args, **kwargs): if not self.__instance: self.__instance = super().__call__(*args, **kwargs) return self.__instanceclass Database(metaclass=MetaSingleton): connection = None def connect(self): if self.connection is None: self.connection = sqlite3.connect("db.sqlite3") self.cursorobj = self.connection.cursor() return self.cursorobjdb1 = Database().connect()db2 = Database().connect()print(db1, db2)# =&gt; &lt;sqlite3.Cursor object at 0x7f810d6f8260&gt; &lt;sqlite3.Cursor object at# 0x7f810d6f8260&gt;print(db1 is db2)# =&gt; True 监控服务12345678910111213141516171819202122232425262728293031323334353637383940414243class HealthCheck: _instance = None def __new__(cls, *args, **kwargs): if not HealthCheck._instance: HealthCheck._instance = super().__new__(cls, *args, **kwargs) return HealthCheck._instance def __init__(self): self._servers = [] def addServer(self): self._servers.append("Server 1") self._servers.append("Server 2") self._servers.append("Server 3") self._servers.append("Server 4") def changeServer(self): self._servers.pop() self._servers.append("Server 5")hc1 = HealthCheck()hc2 = HealthCheck()hc1.addServer()print("Schedule health check for servers (1) ...")for i in range(4): print("Checking ", hc1._servers[i])hc2.changeServer()print("Schedule health check for servers (2) ...")for i in range(4): print("Checking ", hc2._servers[i])# =&gt; Schedule health check for servers (1) ...# =&gt; Checking Server 1# =&gt; Checking Server 2# =&gt; Checking Server 3# =&gt; Checking Server 4# =&gt; Schedule health check for servers (2) ...# =&gt; Checking Server 1# =&gt; Checking Server 2# =&gt; Checking Server 3# =&gt; Checking Server 5]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Advanced</tag>
        <tag>Python</tag>
        <tag>Development</tag>
        <tag>OOP</tag>
        <tag>DesignPattern</tag>
        <tag>Project</tag>
        <tag>MetaClass</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fluent Python 笔记 —— 装饰器和闭包]]></title>
    <url>%2F2020%2F11%2F19%2Ffluent-python-decorator-and-closure%2F</url>
    <content type="text"><![CDATA[装饰器函数装饰器用于在源码中“标记”函数，以某种方式增强函数的行为。它是一种以另一个函数（被装饰的函数）为参数的可调用对象，可能会处理被装饰的函数并将其返回，或者将其替换为另一个函数。 装饰器严格来说只是语法糖。假如有个名为 decorate 的装饰器：123@decoratedef target(): print('running target()') 上述代码效果等同于如下写法：1234def target(): print('running target()')target = decorate(target) 即原来的 target 函数会被替换为 decorate(target) 返回的函数。12345678910111213&gt;&gt;&gt; def deco(func):... def inner():... print('running inner()')... return inner...&gt;&gt;&gt; @deco... def target():... print('running target()')...&gt;&gt;&gt; target()running inner()&gt;&gt;&gt; target&lt;function deco.&lt;locals&gt;.inner at 0x7ff01bad9a60&gt; 如上述代码，deco 返回 inner 函数对象，使用 deco 装饰 target，调用被装饰的 target 实际会运行 inner。target 对象变为 inner 的引用。 装饰器有如下两大特性： 能把被装饰的函数替换成其他函数 装饰器在加载模块时立即执行 装饰器何时执行装饰器会在被装饰的函数定义之后立即运行，这通常是在 Python 加载模块时。 参考如下 registration.py 模块：123456789101112131415161718192021222324252627registry = []def register(func): print(f'running register(&#123;func&#125;)') registry.append(func) return func@registerdef f1(): print('running f1()')@registerdef f2(): print('running f2()')def f3(): print('running f3()')def main(): print('running main()') print('registry -&gt;', registry) f1() f2() f3()if __name__ == '__main__': main() 运行后输出如下：1234567running register(&lt;function f1 at 0x7fbc852d43a0&gt;)running register(&lt;function f2 at 0x7fbc852d4430&gt;)running main()registry -&gt; [&lt;function f1 at 0x7fbc852d43a0&gt;, &lt;function f2 at 0x7fbc852d4430&gt;]running f1()running f2()running f3() Python 加载模块后，装饰器 register 会在其他函数之前运行，将被装饰的函数（f1 和 f2）的引用添加到 registry 列表中。原本的函数 f1 和 f2，以及未被装饰的 f3，则只在 main 明确调用它们时才执行。 如果导入 registration.py 模块（不作为脚本运行），输出如下：123&gt;&gt;&gt; import registrationrunning register(&lt;function f1 at 0x7f8fbd8c3b80&gt;)running register(&lt;function f2 at 0x7f8fbd8c3c10&gt;) 函数装饰器在导入模块时立即执行，而被装饰的函数只在明确调用时执行。突出了导入时和运行时之间的区别。 变量作用域规则测试如下函数，它读取两个变量的值，一个是局部变量 a，是函数的参数；另一个是未被定义的变量 b：12345678910&gt;&gt;&gt; def f1(a):... print(a)... print(b)...&gt;&gt;&gt; f1(3)3Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "&lt;stdin&gt;", line 3, in f1NameError: name 'b' is not defined 运行时变量 a 的值正常输出，接着报出 name ‘b’ is not defined。 若先给全局变量 b 赋值，再调用 f1 函数，就不会报错：1234&gt;&gt;&gt; b = 6&gt;&gt;&gt; f1(3)36 但如下代码的结果可能会让人意想不到：123456789101112&gt;&gt;&gt; b=6&gt;&gt;&gt; def f2(a):... print(a)... print(b)... b = 9...&gt;&gt;&gt; f2(3)3Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "&lt;stdin&gt;", line 3, in f2UnboundLocalError: local variable 'b' referenced before assignment 代码运行后首先输出了 3（print(a)），但是第二个语句 print(b) 执行报错。按照直觉第二个 print 语句应该输出 6，因为全局变量 b 已经在函数执行之前赋值，局部变量 b 的赋值动作也是在 print 语句后面。 事实上是，Python 在编译函数定义体时，会判断 b 是局部变量，Python 会尝试从本地环境获取 b。调用 f2(3) 时，f2 的定义体尝试获取局部变量 b 的值，发现 b 没有绑定后报错。 如果在函数内部赋值时想让解释器把 b 当成全局变量，需要使用 global 声明：123456789101112131415161718&gt;&gt;&gt; b = 6&gt;&gt;&gt; def f3(a):... global b... print(a)... print(b)... b = 9...&gt;&gt;&gt; f3(3)36&gt;&gt;&gt; b9&gt;&gt;&gt; f3(3)39&gt;&gt;&gt; b = 30&gt;&gt;&gt; b30 闭包闭包指延伸了作用域的函数，其中包含函数定义体中引用、不在定义体中定义的非全局变量。 计算移动平均值（不断增加的系列值的均值）的类：123456789# average_oo.pyclass Averager: def __init__(self): self.series = [] def __call__(self, new_value): self.series.append(new_value) total = sum(self.series) return total/len(self.series) 效果如下：12345678&gt;&gt;&gt; from average_oo import Averager&gt;&gt;&gt; avg = Averager()&gt;&gt;&gt; avg(10)10.0&gt;&gt;&gt; avg(11)10.5&gt;&gt;&gt; avg(12)11.0 以下代码是同样功能的函数式实现：123456789def make_averager(): series = [] def averager(new_value): series.append(new_value) total = sum(series) return total / len(series) return averager 12345678&gt;&gt;&gt; from average import make_averager&gt;&gt;&gt; avg = make_averager()&gt;&gt;&gt; avg(10)10.0&gt;&gt;&gt; avg(11)10.5&gt;&gt;&gt; avg(12)11.0 第一个例子中，Averager 类的实例 avg 存储历史值的位置很明显：通过 self.series 实例属性。第二个例子中，series 是 make_averager 函数的局部变量，但调用 avg(10) 时，make_averager 函数已经返回，它的本地作用域也就不存在了。 在 averager 函数中，series 是自由变量（free variable），指未在本地作用域中绑定的变量。 闭包是一种函数，它会保留定义函数时存在的自由变量的绑定。这样在调用函数时，即便定义作用域不可用了，通过闭包仍能使用那些绑定。 nolocal前面实现 make_averager 函数的方式效率并不高，把所有值存储在历史列表中，在每次调用 averager 时使用 sum 求和。更好的实现方式是，只存储目前的总和以及元素个数，只使用这两个值计算均值。1234567891011# average2.pydef make_averager(): count = 0 total = 0 def averager(new_value): count += 1 total += new_value return total / count return averager 上述代码运行后会报出如下错误：12345678&gt;&gt;&gt; from average2 import make_averager&gt;&gt;&gt; avg = make_averager()&gt;&gt;&gt; avg(10)Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "/home/starky/program/python/algorithm/average2.py", line 6, in averager count += 1UnboundLocalError: local variable 'count' referenced before assignment 原因在于，当 count 是数字或其他任何不可变类型时，count += 1 的作用等同于 count = count + 1。导致在 averager 的定义体中为 count 赋值了，将 count 变成了局部变量。total 变量也是如此。之前的 series 变量没有出现此问题，原因是只调用了 series.append，列表作为可变对象，并不存在重新赋值的情况。 Python 3 中引入了 nolocal 声明，其作用是把变量标记为自由变量。为 nolocal 声明的变量赋予新值后，闭包中保存的绑定也会更新。1234567891011def make_averager(): count = 0 total = 0 def averager(new_value): nonlocal count, total count += 1 total += new_value return total / count return averager 实现一个简单的装饰器1234567891011121314151617181920212223242526import timedef clock(func): def clocked(*args): t0 = time.perf_counter() result = func(*args) elapsed = time.perf_counter() - t0 name = func.__name__ arg_str = ', '.join(repr(arg) for arg in args) print('[%0.8fs] %s(%s) -&gt; %r' % (elapsed, name, arg_str, result)) return result return clocked@clockdef snooze(seconds): time.sleep(seconds)@clockdef factorial(n): return 1 if n &lt; 2 else n * factorial(n - 1)if __name__ == '__main__': print('*' * 40, 'Calling snooze(.123)') snooze(.123) print('*' * 40, 'Calling factorial(6)') print('6! =', factorial(6)) 执行结果如下：12345678910**************************************** Calling snooze(.123)[0.12318703s] snooze(0.123) -&gt; None**************************************** Calling factorial(6)[0.00000168s] factorial(1) -&gt; 1[0.00003647s] factorial(2) -&gt; 2[0.00006038s] factorial(3) -&gt; 6[0.00008216s] factorial(4) -&gt; 24[0.00010411s] factorial(5) -&gt; 120[0.00012920s] factorial(6) -&gt; 7206! = 720 在上述代码中：123@clockdef factorial(n): return 1 if n &lt; 2 else n * factorial(n - 1) 等同于：123def factorial(n): return 1 if n &lt; 2 else n * factorial(n - 1)factorial = clock(factorial) factorial 会作为 func 参数传递给 clock，返回 clocked 函数。Python 解释器在背后会把 clocked 赋值给 factorial。此后，每次调用 factorial(n)，实际执行的都是 clocked(n)。总体步骤如下： 记录初始时间 t0 调用原来的 factorial 函数，保存结果 计算执行的时间 格式化收集到的数据 返回第二步保存的结果 以上即装饰器的典型行为：将被装饰的函数替换为新函数，二者接收同样的参数，（通常）返回被装饰函数本该返回的值，并做些额外的操作。 参数化装饰器参数化的注册装饰器 为了便于启用或禁用 register 的函数注册功能，可以为其提供一个可选的 active 参数，设为 False 时，不注册被装饰的函数。从概念上讲，这个新的 register 函数不是装饰器，而是装饰器工厂函数，用来返回真正的装饰器。123456789101112131415161718192021222324# registration_param.pyregistry = set()def register(active=True): def decorate(func): print('running register(active=%s)-&gt;decorate(%s)' % (active, func)) if active: registry.add(func) else: registry.discard(func) return func return decorate@register(active=False)def f1(): print('running f1()')@register()def f2(): print('running f2()')def f3(): print('running f3()') 运行效果：12345&gt;&gt;&gt; import registration_paramrunning register(active=False)-&gt;decorate(&lt;function f1 at 0x7fa801b1bc10&gt;)running register(active=True)-&gt;decorate(&lt;function f2 at 0x7fa801b1bca0&gt;)&gt;&gt;&gt; registration_param.registry&#123;&lt;function f2 at 0x7fa801b1bca0&gt;&#125; decorate 是装饰器，必须返回一个函数。register 是装饰器工厂函数，返回 decorate。只有 active 参数的值为 True 时才注册 func；若 active 不为真，且 func 在 registry 中，则将 func 移除。@register 工厂函数必须作为函数调用，传入所需参数（或 @register()）。 若不使用 @ 句法，也可以像常规函数那样使用 register：123456789101112131415&gt;&gt;&gt; from registration_param import *running register(active=False)-&gt;decorate(&lt;function f1 at 0x7fc32e6d0b80&gt;)running register(active=True)-&gt;decorate(&lt;function f2 at 0x7fc32e6d0c10&gt;)&gt;&gt;&gt; registry&#123;&lt;function f2 at 0x7fc32e6d0c10&gt;&#125;&gt;&gt;&gt; register()(f3)running register(active=True)-&gt;decorate(&lt;function f3 at 0x7fc32e6d0af0&gt;)&lt;function f3 at 0x7fc32e6d0af0&gt;&gt;&gt;&gt; registry&#123;&lt;function f2 at 0x7fc32e6d0c10&gt;, &lt;function f3 at 0x7fc32e6d0af0&gt;&#125;&gt;&gt;&gt; register(active=False)(f2)running register(active=False)-&gt;decorate(&lt;function f2 at 0x7fc32e6d0c10&gt;)&lt;function f2 at 0x7fc32e6d0c10&gt;&gt;&gt;&gt; registry&#123;&lt;function f3 at 0x7fc32e6d0af0&gt;&#125; 参数化的 clock 装饰器12345678910111213141516171819202122232425262728293031# clock_param.pyimport timeDEFAULT_FMT = '[&#123;elapsed:0.8f&#125;s] &#123;name&#125;(&#123;args&#125;) -&gt; &#123;result&#125;'def clock(fmt=DEFAULT_FMT): def decorate(func): def clocked(*_args): t0 = time.time() _result = func(*_args) elapsed = time.time() - t0 name = func.__name__ args = ', '.join(repr(arg) for arg in _args) result = repr(_result) print(fmt.format(**locals())) return _result return clocked return decorateif __name__ == '__main__': @clock() def snooze(seconds): time.sleep(seconds) for i in range(3): snooze(.123)# =&gt; [0.12320948s] snooze(0.123) -&gt; None# =&gt; [0.12319684s] snooze(0.123) -&gt; None# =&gt; [0.12318802s] snooze(0.123) -&gt; None 1234567891011121314# clock_param2.pyimport timefrom clock_param import clock@clock('&#123;name&#125;(&#123;args&#125;) dt=&#123;elapsed:0.3f&#125;s')def snooze(seconds): time.sleep(seconds)for i in range(3): snooze(.123)# =&gt; snooze(0.123) dt=0.123s# =&gt; snooze(0.123) dt=0.123s# =&gt; snooze(0.123) dt=0.123s 标准库中的装饰器——单分派泛函数假设需要开发一个调试 Web 应用的工具，能够生成 HTML 来显示不同类型的 Python 对象。12345import htmldef htmlize(obj): content = html.escape(repr(obj)) return '&lt;pre&gt;&#123;&#125;&lt;/pre&gt;'.format(content) 上述函数适用于任何 Python 类型。但如果想做进一步扩展，使其能够用不同的方式显示不同的类型： str：把内部换行符替换为 ‘\\n’，使用 进行格式化 int：以十进制和十六进制显示数字 list：输出 HTML 列表，根据各个元素的类型进行格式化 Python 不支持重载方法或函数，因此不能使用不同的签名定义 htmlize 的变体，也无法使用不同的方式处理不同的数据类型。一种常见的做法是将 htmlize 变成一个分派函数，使用一系列 if/elif/elif 调用专门的函数，如 htmlize_str、htmlize_int 等。但这样不便于模块的扩展，且显得笨拙。分派函数 htmlize 会随着时间推移变得很大，与各个专门函数之间的耦合也很紧密。 Python 中的 functools.singledispatch 装饰器可以把整体方案拆分为等多个模块，甚至可以为无法修改的类提供专门函数。使用 @singledispatch 装饰的普通函数会变成泛函数（generic function），根据第一个参数的类型以不同方式执行相同操作的一组函数。 12345678910111213141516171819202122232425# htmlize.pyfrom functools import singledispatchfrom collections import abcimport numbersimport html@singledispatchdef htmlize(obj): content = html.escape(repr(obj)) return '&lt;pre&gt;&#123;&#125;&lt;/pre&gt;'.format(content)@htmlize.register(str)def _(text): content = html.escape(text).replace('\n', '&lt;br&gt;\n') return '&lt;p&gt;&#123;0&#125;&lt;/p&gt;'.format(content)@htmlize.register(numbers.Integral)def _(n): return '&lt;pre&gt;&#123;0&#125; (0x&#123;0:x&#125;)&lt;/pre&gt;'.format(n)@htmlize.register(tuple)@htmlize.register(abc.MutableSequence)def _(seq): inner = '&lt;/li&gt;\n&lt;li&gt;'.join(htmlize(item) for item in seq) return '&lt;ul&gt;\n&lt;li&gt;' + inner + '&lt;/li&gt;\n&lt;/ul&gt;' 123456789101112131415&gt;&gt;&gt; from htmlize import htmlize&gt;&gt;&gt; htmlize(&#123;1, 2, 3&#125;)'&lt;pre&gt;&#123;1, 2, 3&#125;&lt;/pre&gt;'&gt;&gt;&gt; htmlize(abs)'&lt;pre&gt;&amp;lt;built-in function abs&amp;gt;&lt;/pre&gt;'&gt;&gt;&gt; htmlize('Heimlich &amp; Co.\n- a game')'&lt;p&gt;Heimlich &amp;amp; Co.&lt;br&gt;\n- a game&lt;/p&gt;'&gt;&gt;&gt; htmlize(42)'&lt;pre&gt;42 (0x2a)&lt;/pre&gt;'&gt;&gt;&gt; print(htmlize(['alpha', 66, &#123;3, 2, 1&#125;]))&lt;ul&gt;&lt;li&gt;&lt;p&gt;alpha&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;pre&gt;66 (0x42)&lt;/pre&gt;&lt;/li&gt;&lt;li&gt;&lt;pre&gt;&#123;1, 2, 3&#125;&lt;/pre&gt;&lt;/li&gt;&lt;/ul&gt; @singledispatch 标记处理 object 类型的基函数。各个专门函数使用 @&lt;base_function&gt;.register(&lt;type&gt;) 装饰。为每个需要特殊处理的类型注册一个函数，numbers.Integral 是 int 的抽象基类。只要可能，注册的专门函数应该尽量处理抽象基类（如 numbers.Integral 和 abc.MutableSequence），不要处理具体实现（如 int 和 list）。这样代码支持的兼容类型会更广泛（支持抽象基类现有的和未来的具体子类），比如用户可能通过子类化 numbers.Integral 实现固定位数的 int 类型。可以叠放多个 register 装饰器，让同一个函数支持不同类型。 @singledispatch 可以在系统的任何地方和任何模块中注册专门函数，还可以为不是自己编写的或者不能修改的类添加自定义函数。 参考资料Fluent Python]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Function</tag>
        <tag>Advanced</tag>
        <tag>Python</tag>
        <tag>Closure</tag>
        <tag>Decorator</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python Cookbook —— 元编程]]></title>
    <url>%2F2020%2F11%2F19%2Fpython-cookbook-metaprogramming%2F</url>
    <content type="text"><![CDATA[一、函数装饰器1234567891011121314151617181920212223242526import timefrom functools import wrapsdef timethis(func): ''' Decorator that reports the execution time. ''' @wraps(func) def wrapper(*args, **kwargs): start = time.time() result = func(*args, **kwargs) elapsed = time.time() - start print(func.__name__, elapsed) return result return wrapper@timethisdef countdown(n): while n &gt; 0: n -= 1countdown(1000000)# =&gt; countdown 0.29901695251464844 装饰器负责接收某个函数作为参数，然后返回一个新的函数作为输出。下面的代码：123@timethisdef countdown(n): ... 实际上等同于123def countdown(n): ...countdown = timethis(countdown) 装饰器内部通常要定义一个接收任意参数（*args, **kwargs）的函数，即 wrapper()。在 wrapper 函数里，调用原始的作为参数传入的函数（func）并获取其结果，再根据需求添加上执行其他操作的代码（比如计时、日志等）。最后新创建的 wrapper 函数被返回并替换掉被装饰的函数（countdown），从而在不改变被装饰函数自身代码的情况下，为其添加额外的行为。 二、带参数的装饰器12345678910111213141516171819202122232425262728293031323334353637383940from functools import wrapsimport loggingdef logged(level, name=None, message=None): &apos;&apos;&apos; Add logging to a function. level is the logging level, name is the logger name, and message is the log message. &apos;&apos;&apos; logging.basicConfig( level=logging.DEBUG, format=&apos;%(asctime)s - %(name)s - %(levelname)s - %(message)s&apos;) def decorate(func): logname = name if name else func.__module__ log = logging.getLogger(logname) logmsg = message if message else func.__name__ @wraps(func) def wrapper(*args, **kwargs): log.log(level, logmsg) return func(*args, **kwargs) return wrapper return decorate# Example use@logged(logging.WARNING)def spam(): pass@logged(logging.INFO, name=&apos;Example&apos;, message=&apos;This is log message&apos;)def foo(): passspam()foo()# =&gt; 2019-10-24 09:22:25,780 - __main__ - WARNING - spam# =&gt; 2019-10-24 09:22:25,783 - Example - INFO - This is log message 最外层的函数 logged() 用于接收传入装饰器的参数，并使这些参数能够被装饰器中的内部函数（decorate()）访问。内部函数 decorate 则用于实现装饰器的“核心逻辑”，即接收某个函数作为参数，通过定义一个新的内部函数（wrapper）添加某些行为，再将这个新的函数返回作为被装饰函数的替代品。 在类中定义的装饰器1234567891011121314151617181920212223242526272829303132333435363738from functools import wrapsclass A: # Decorator as an instance method def decorator1(self, func): @wraps(func) def wrapper(*args, **kwargs): print('Decorator 1') return func(*args, **kwargs) return wrapper #Decorator as a class method @classmethod def decorator2(cls, func): @wraps(func) def wrapper(*args, **kwargs): print('Decorator 2') return func(*args, **kwargs) return wrapper# As an instance methoda = A()@a.decorator1def spam(): passspam()# =&gt; Decorator 1# As a class method@A.decorator2def grok(): passgrok()# =&gt; Decorator 2 利用装饰器向原函数中添加参数123456789101112131415161718192021222324from functools import wrapsimport inspectdef optional_debug(func): if 'debug' in inspect.getfullargspec(func).args: raise TypeError('debug argument already defined') @wraps(func) def wrapper(*args, debug=False, **kwargs): if debug: print('Calling', func.__name__) return func(*args, **kwargs) return wrapper@optional_debugdef add(x, y): print(x + y)add(2, 3)# =&gt; 5add(2, 3, debug=True)# =&gt; Calling add# =&gt; 5 装饰器修改类的定义1234567891011121314151617181920212223242526def log_getattribute(cls): orig_getattribute = cls.__getattribute__ def new_getattribute(self, name): print('getting: ', name) return orig_getattribute(self, name) cls.__getattribute__ = new_getattribute return cls@log_getattributeclass A: def __init__(self, x): self.x = x def spam(self): passa = A(42)print(a.x)a.spam()# =&gt; getting: x# =&gt; 42# =&gt; getting: spam 类装饰器可以用来重写类的部分定义以修改其行为，作为一种直观的类继承或元类的替代方式。比如上述功能也可以通过类继承来实现：1234567891011121314151617class LoggedGetattribute: def __getattribute__(self, name): print('getting: ', name) return super().__getattribute__(name)class A(LoggedGetattribute): def __init__(self, x): self.x = x def spam(self): passa = A(42)print(a.x)a.spam() 在某些情况下，类装饰器的方案要更为直观一些，并不会向继承层级中引入新的依赖。同时由于不使用 super() 函数，速度也稍快一点。 使用元类控制实例的创建Python 中的类可以像函数那样调用，同时创建实例对象：1234567class Spam: def __init__(self, name): self.name = namea = Spam('Guido')b = Spam('Diana') 如果开发人员想要自定义创建实例的行为，可以通过元类重新实现一遍 __call__() 方法。假设在调用类时不创建任何实例：1234567891011121314 class NoInstance(type): def __call__(self, *args, **kwargs): raise TypeError("Can't instantiate directly")class Spam(metaclass=NoInstance): @staticmethod def grok(x): print('Spam.grok')Spam.grok(42) # Spam.groks = Spam()# TypeError: Can't instantiate directly 元类实现单例模式单例模式即类在创建对象时，单一的类确保只生成唯一的实例对象。1234567891011121314151617# singleton.pyclass Singleton(type): def __init__(self, *args, **kwargs): self.__instance = None super().__init__(*args, **kwargs) def __call__(self, *args, **kwargs): if self.__instance is None: self.__instance = super().__call__(*args, **kwargs) return self.__instance else: return self.__instanceclass Spam(metaclass=Singleton): def __init__(self): print('Creating Spam') 123456789&gt;&gt;&gt; from singleton import *&gt;&gt;&gt; a = Spam()Creating Spam&gt;&gt;&gt; b = Spam()&gt;&gt;&gt; a is bTrue&gt;&gt;&gt; c = Spam()&gt;&gt;&gt; a is cTrue 强制检查类定义中的代码规范可以借助元类监控普通类的定义代码。通常的方式是定义一个继承自 type 的元类并重写其 __new__() 或 __init__() 方法。123456class MyMeta(type): def __new__(cls, clsname, bases, clsdict): # clsname is name of class being defined # bases is tuple of base classes # clsdict is class dictionary return super().__new__(cls, clsname, bases, clsdict) 123456class MyMeta(type): def __init__(self, clsname, bases, clsdict): # clsname is name of class being defined # bases is tuple of base classes # clsdict is class dictionary return super().__init__(clsname, bases, clsdict) 为了使用元类，通常会先定义一个供其他对象继承的基类：12345678class Root(metaclass=MyMeta): passclass A(Root): passclass B(Root): pass 元类的重要特性在于，它允许用户在类定义时检查类的内容。在重写的 __init__() 方法内部，可以方便地检查 class dictionary、base class 或者其他与类定义相关的内容。此外，当元类指定给某个普通类以后，该普通类的所有子类也都会继承元类的定义。 下面是一个用于检查代码规范的元类，确保方法的命名里只包含小写字母：123456789101112131415161718192021class NoMixedCaseMeta(type): def __new__(cls, clsname, bases, clsdict): for name in clsdict: if name.lower() != name: raise TypeError('Bad attribute name: ' + name) return super().__new__(cls, clsname, bases, clsdict)class Root(metaclass=NoMixedCaseMeta): passclass A(Root): def foo_bar(self): passclass B(Root): def fooBar(self): pass# TypeError: Bad attribute name: fooBar 元类的定义中重写 __new__() 还是 __init__() 方法取决于你想以何种方式产出类。__new__() 方法生效于类创建之前，通常用于对类的定义进行改动（通过修改 class dictionary 的内容）；__init__() 方法生效于类创建之后，通常是与已经生成的类对象进行交互。比如 super() 函数只在类实例被创建后才能起作用。 以编程的方式定义类可以通过编程的方式创建类，比如从字符串中产出类的源代码。types.new_class() 函数可以用来初始化新的类对象，只需要向其提供类名、父类（以元组的形式）、关键字参数和一个用来更新 class dictionary 的回调函数。1234567891011121314151617181920212223242526# Methodsdef __init__(self, name, shares, price): self.name = name self.shares = shares self.price = pricedef cost(self): return self.shares * self.pricecls_dict = &#123; '__init__': __init__, 'cost': cost,&#125;# Make a classimport typesStock = types.new_class('Stock', (), &#123;&#125;, lambda ns: ns.update(cls_dict))Stock.__module__ = __name__s = Stock('ACME', 50, 91.1)print(s)# =&gt; &lt;__main__.Stock object at 0x7f0e3b62edc0&gt;print(s.cost())# =&gt; 4555.0 通常形式的类定义代码：12class Spam(Base, debug=True, typecheck=False): ... 转换成对应的 type.new_class() 形式的代码：123Spam = types.new_class('Spam', (Base,), &#123;'debug': True, 'typecheck': False&#125;, lambda ns: ns.update(cls_dict)) 从代码中产出类对象在某些场景下是很有用的，比如 collections.nametupe() 函数：1234&gt;&gt;&gt; import collections&gt;&gt;&gt; Stock = collections.namedtuple('Stock', ['name', 'shares', 'price'])&gt;&gt;&gt; Stock&lt;class '__main__.Stock'&gt; 下面是一个类似 namedtuple 功能的实现代码：1234567891011121314151617181920212223242526272829303132333435import operatorimport typesimport sysdef named_tuple(classname, fieldnames): # Populate a dictionary of field property accessors cls_dict = &#123; name: property(operator.itemgetter(n)) for n, name in enumerate(fieldnames) &#125; # Make a __new__ function and add to the class dict def __new__(cls, *args): if len(args) != len(fieldnames): raise TypeError('Expected &#123;&#125; arguments'.format(len(fieldnames))) return tuple.__new__(cls, args) cls_dict['__new__'] = __new__ # Make the class cls = types.new_class(classname, (tuple,), &#123;&#125;, lambda ns: ns.update(cls_dict)) cls.__module__ = sys._getframe(1).f_globals['__name__'] return clsPoint = named_tuple('Point', ['x', 'y'])print(Point)# =&gt; &lt;class '__main__.Point'&gt;p = Point(4, 5)print(p.x)# =&gt; 4print(p.y)# =&gt; 5p.x = 2# =&gt; AttributeError: can't set attribute 在定义时初始化类成员在类定义时完成初始化或其他设置动作，是元类的经典用法（元类在类定义时触发）。12345678910111213141516171819202122232425262728293031323334import operatorclass StructTupleMeta(type): def __init__(cls, *args, **kwargs): super().__init__(*args, **kwargs) for n, name in enumerate(cls._fields): setattr(cls, name, property(operator.itemgetter(n)))class StructTuple(tuple, metaclass=StructTupleMeta): _fields = [] def __new__(cls, *args): if len(args) != len(cls._fields): raise ValueError('&#123;&#125; arguments required'.format(len(cls._fields))) return super().__new__(cls, args)class Stock(StructTuple): _fields = ['name', 'shares', 'price']class Point(StructTuple): _fields = ['x', 'y']s = Stock('ACME', 50, 91.1)print(s)# =&gt; ('ACME', 50, 91.1)print(s[0])# =&gt; ACMEprint(s.name)# =&gt; ACMEs.shares = 23# =&gt; AttributeError: can't set attribute 在上面的代码中，StructTupleMeta 元类从 _fields 类属性中读取属性名列表并将其转换成属性方法。operator.itemgetter() 函数负责创建访问方法（accessor function），property() 函数负责将它们转换成属性（property）。 StructTuple 类用作供其他类继承的基类。其中的 __new__() 方法负责创建新的实例对象。不同于 __init__()，__new__() 方法会在实例创建之前触发，由于 tuple 是不可变对象，创建之后即无法被修改，因此这里使用 __new__()。 参考资料Python Cookbook, 3rd Edition]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Advanced</tag>
        <tag>Python</tag>
        <tag>Class</tag>
        <tag>OOP</tag>
        <tag>MetaProgramming</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fluent Python 笔记 —— 字典与集合]]></title>
    <url>%2F2020%2F11%2F08%2Ffluent-python-dicts-and-sets%2F</url>
    <content type="text"><![CDATA[一、映射类型标准库里的所有映射类型都是利用 dict 实现的，它们有个共同的限制：其中的键必须是可散列的数据类型。关于可散列的数据类型的定义：若某对象是可散列的，则它的散列值在其整个生命周期中是保持不变的。该对象需要实现 __hash__ 方法和 __qe__ 方法（跟其他键做比较）。如果两个可散列对象是相等的，那么他们的散列值一定相等。 不可变数据类型中的 str、bytes 和数字都是可散列类型。虽然元组本身是不可变序列，但元组中的元素有可能是其他可变类型的引用。只有当一个元组中包含的所有元素都是可散列类型的情况下，该元组才是可散列的。12345678&gt;&gt;&gt; tt = (1, 2, (30, 40))&gt;&gt;&gt; hash(tt)-3907003130834322577&gt;&gt;&gt; tl = (1, 2, [30, 40])&gt;&gt;&gt; hash(tl)Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;TypeError: unhashable type: 'list' 一般用户自定义类型的对象都是可散列的，因此这些对象在比较时都是不相等的。若某个对象实现了 __eq__ 方法，并且在方法中用到了该对象的内部状态，则只有当这些内部状态都是不可变类型的情况下，该对象才是可散列的。 二、字典推导123456789101112&gt;&gt;&gt; DIAL_CODES = [... (86, 'China'),... (91, 'India'),... (1, 'America'),... (55, 'Brazil'),... (7, 'Russia')... ]&gt;&gt;&gt; country_code = &#123;country: code for code, country in DIAL_CODES&#125;&gt;&gt;&gt; country_code&#123;'China': 86, 'India': 91, 'America': 1, 'Brazil': 55, 'Russia': 7&#125;&gt;&gt;&gt; &#123;code: country.upper() for country, code in country_code.items() if code &lt; 66&#125;&#123;1: 'AMERICA', 55: 'BRAZIL', 7: 'RUSSIA'&#125; 三、setdefault 处理找不到的键以下代码的写法：1my_dict.setdefault(key, []).append(new_value) 其效果等同于如下代码：123if key not in my_dict: my_dict[key] = []my_dict[key].append(new_value) 都是获取 my_dict 中 key 键对应的值（如果该 key 不存在，则新增 key 并令其值为 []），然后向 key 对应的值（列表）中添加新元素。只不过后者至少要进行两次键查询（如果键不存在，则执行三次键查询），而使用 setdefault 只需要一次键查询就可以完成整个操作。setdefault 在获取 key 键对应的值时，如果该 key 不存在，则把 key 和空列表直接放进映射并返回空列表，因而不需要执行第二次键值查找。 四、弹性键查询defaultdictcollections.defaultdict 可以做到即便某个键在映射里不存在，也能够在读取这个键的时候得到一个默认值。只需要用户在初始化 defaultdict 对象时，为其指定一个创建默认值的方法。即在实例化 defaultdict 的时候，向构造方法提供一个可调用对象，该对象会在 __getitem__ 碰到找不到的键的时候被调用，让 __getitem__ 返回某种默认值。 如 dd = defaultdict(list)。若键 new-key 在 dd 中不存在，表达式 dd[&#39;new-key&#39;] 会执行以下操作： 调用 list() 创建一个新列表 把新列表作为值，new-key 作为键存放到 dd 中 返回新列表的引用 这个用来生成默认值得可调用对象（list()）存放在名为 default_factory 的实例属性里。若创建 defaultdict 的时候没有指定 default_factory，则查询不存在的键会触发 KeyError。这些特性背后依赖的是 __missing__ 特殊方法，这个特殊方法是所有映射类型都可以选择性地去支持的。 missing所有的映射类型处理找不到的键的时候，都会涉及到 __missing__ 方法。虽然基类 dict 并没有定义这个方法，但如果有一个类继承了 dict，该类提供 __missing__ 方法，则 __getitem__ 找不到键的时候，会自动调用 __missing__ 而不会抛出 KeyError 异常。 __missing__ 方法只会被 __getitem__ 调用（比如在表达式 d[k] 中）。提供 __missing__ 方法对 get 或 __contains__ 方法的使用没有影响。 如需要实现一种自定义的映射类型，在查询的时候将映射里的键都转换成 str。示例代码如下：1234567891011121314class StrKeyDict(dict): def __missing__(self, key): if isinstance(key, str): raise KeyError(key) return self[str(key)] def get(self, key, default=None): try: return self[key] except KeyError: return default def __contains__(self, key): return key in self.keys() or str(key) in self.keys() 运行结果如下：123456789101112131415161718192021222324&gt;&gt;&gt; from strkeydict import StrKeyDict&gt;&gt;&gt; d = StrKeyDict([('2', 'two'), ('4', 'four')])&gt;&gt;&gt; d['2']'two'&gt;&gt;&gt; d[4]'four'&gt;&gt;&gt; d[1]Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "/home/starky/program/python/algorithm/strkeydict.py", line 5, in __missing__ return self[str(key)] File "/home/starky/program/python/algorithm/strkeydict.py", line 4, in __missing__ raise KeyError(key)KeyError: '1'&gt;&gt;&gt; d.get('2')'two'&gt;&gt;&gt; d.get(4)'four'&gt;&gt;&gt; d.get(1, 'N/A')'N/A'&gt;&gt;&gt; 2 in dTrue&gt;&gt;&gt; 1 in dFalse StrKeyDict 继承自 dict，如果找不到的键本身是字符串，抛出 KeyError 异常；如果找不到的键不是字符串，则将其转换成字符串后再进行查找。get 方法把查找工作用 self[key] 的形式委托给 __getitem__，这样在确定查找失败之前，还能通过 __missing__ 在给某个键一个机会。 isinstance(key, str) 在 __missing__ 中是必须的，若 str(k) 不是一个存在的键，代码就会陷入无限递归。因为 __missing__ 最后一行中的 self[str(key)] 会调用 __getitem__，而 str(key) 又不存在，则 __missing__ 又会被调用。 __contains__ 方法也是必须的，因为从 dict 继承到的 __contians__ 方法不会在找不到键时调用 __missing__ 方法。 不可变 Map标准库里所有的映射类型都是可变的。从 Python 3.3 开始，types 模块引入了一个名为 MappingProxyType 的封装类，可以从普通映射创建一个只读的映射视图。12345678910111213141516&gt;&gt;&gt; from types import MappingProxyType&gt;&gt;&gt; d = &#123;1: 'A'&#125;&gt;&gt;&gt; d_proxy = MappingProxyType(d)&gt;&gt;&gt; d_proxymappingproxy(&#123;1: 'A'&#125;)&gt;&gt;&gt; d_proxy[1]'A'&gt;&gt;&gt; d_proxy[2] = 'x'Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;TypeError: 'mappingproxy' object does not support item assignment&gt;&gt;&gt; d[2] = 'B'&gt;&gt;&gt; d_proxymappingproxy(&#123;1: 'A', 2: 'B'&#125;)&gt;&gt;&gt; d_proxy[2]'B' 集合集合的本质是许多唯一对象的聚集，可用于去重：123&gt;&gt;&gt; l = ['spam', 'spam', 'eggs', 'spam']&gt;&gt;&gt; set(l)&#123;'spam', 'eggs'&#125; 除了保证唯一性，集合还实现了很多基础的中缀运算符。比如 a | b 求并集，a &amp; b 求交集，a - b 求差集等。合理使用这些运算符可以省去不必要的循环和逻辑操作，使代码行数更少且更易读。 比如有一个电子邮件地址的集合 haystack，还要维护一个较小的电子邮件集合 needles，然后求出 needles 中有多少地址同时也出现在了 heystack 里。求 needles 的元素在 heystack 中出现的次数，两个变量都是集合类型，则只用一行代码即可实现：1found = len(needles &amp; haystack) 若不使用交集操作的话，则需要通过以下代码实现：123for n in needles: if n in haystack: found += 1 散列表散列表（Hash Map）是一种稀疏数组（即总是有空白元素的数组），散列表中的单元通常叫做表元（bucket）。在 dict 背后的散列表中，每个键值对都占用一个表元，每个表元都包含两个部分，对键的引用和对值的引用。因为所有表元的大小一致，可以通过偏移量来读取某个表元。 Python 会保证大概三分之一的表元是空的，当快要达到这个阈值时，原有的散列表会被复制到一个更大的空间里。把对象存入散列表中之前，需要先计算该元素键的散列值。 内置的 hash() 函数可用于计算所有内置类型对象的散列值。若自定义对象调用 hash()，实际上运行的是自定义的 __hash__ 方法。若两个对象比较时大小相等，则它们的散列值也必须相等。即 1 == 1.0 为真，则 hash(1) == hash(1.0) 也必须为真。 为了让散列值能够作为散列表索引使用，这些散列值必须在索引空间内尽量分散开。意味着在理想状态下，越是相似但不相等的对象，其散列值差别也越大。123456&gt;&gt;&gt; hash(1.0001)230584300921345&gt;&gt;&gt; hash(1.0002)461168601842689&gt;&gt;&gt; hash(1.0003)691752902764033 散列表算法为了获取 my_dict[search_key] 背后的值，Python 首先会调用 hash(search_key) 来计算 search_key 的散列值，将该值最低的几位数字作为偏移量（具体几位作为偏移量，需依据当前散列表的大小），在散列表里查找表元。若查找出的表元为空，则抛出 KeyError 异常。若表元非空，该表元中会有一对 found_key: found_value。Python 会检查 search_key == found_key 是否为真，若为真则返回 found_value。若 search_key 与 found_key 不匹配，这种情况称为散列冲突。算法会在散列值中另外再取几位数字，用特殊方法处理一下，把新得到的数字作为索引继续寻找表元并重复以上步骤。 字典的特性键必须是可散列的可散列对象满足以下三个要求： 支持 hash() 函数，且通过 __hash__() 得到的散列值是不变的 支持通过 __eq__() 方法检测相等性 若 a == b 为真，则 hash(a) == hash(b) 也为真 所有用户自定义对象默认都是可散列的，其散列值有 id() 获取，且都不相等。 字典在内存上开销巨大字典使用了散列表，散列表又必须是稀疏的，从而导致字典在空间的使用上效率低下。若需要存放数量巨大的记录，放在由元组或具名元组构成的列表中会是比较好的选择。用元组取代字典存储记录，一是避免了散列表所耗费的空间，二是无需把记录中字段的名字在每个元素里都存一遍，从而节省空间。在用户自定义类型中，__slots__ 属性可以改变实例属性的存储方式，由 dict 变为 tuple。 字典的键查询很快dict 的实现是典型的空间换时间。字典类型有着巨大的内存开销，但是它提供了无视数据量大小的快速访问。 键的次序取决于添加顺序 集合的特性集合里的元素必须是可散列的 集合很消耗内存 可以很高效地判断元素是否存在于某个集合中 元素的次序取决于被添加到集合里的次序 参考资料Fluent Python]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Python</tag>
        <tag>DataStructure</tag>
        <tag>Dict</tag>
        <tag>Map</tag>
        <tag>Hash</tag>
        <tag>Set</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fluent Python 笔记 —— 使用一等函数实现设计模式]]></title>
    <url>%2F2020%2F11%2F08%2Ffluent-python-first-class-function-and-design-patterns%2F</url>
    <content type="text"><![CDATA[经典的策略模式 “策略模式”：定义一系列算法，把它们一一封装，并且使它们之间可以相互替换。本模式使得算法可以独立于使用它的对象而变化 电商领域有个明显的功能可以使用“策略”模式，即根据客户的属性或订单中的商品计算折扣。假如有如下折扣规则： 有 1000 或以上积分的顾客，每个订单享 5% 折扣 同一订单中，单个商品数量达到 20 个或以上，享 10% 折扣 订单中的不同商品达到 10 个或以上，享 7% 折扣 如上述 UML 图，上下文提供服务，会把一些计算委托给实现不同算法的可互换组件。本例中是订单 Order，会根据不同算法计算促销折扣；策略指实现不同算法的组件共用的接口。本例中是名为 Promotion 的抽象类；具体策略即“策略”的具体子类，FidelityPromo、BulkPromo 和 LargeOrderPromo 是这里实现的三个具体策略。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768from abc import ABC, abstractmethodfrom collections import namedtupleCustomer = namedtuple('Customer', 'name fidelity')class LineItem: def __init__(self, product, quantity, price): self.product = product self.quantity = quantity self.price = price def total(self): return self.price * self.quantityclass Order: # 上下文 def __init__(self, customer, cart, promotion=None): self.customer = customer self.cart = list(cart) self.promotion = promotion def total(self): if not hasattr(self, '__total'): self.__total = sum(item.total() for item in self.cart) return self.__total def due(self): if self.promotion is None: discount = 0 else: discount = self.promotion.discount(self) return self.total() - discount def __repr__(self): fmt = '&lt;Order total: &#123;:.2f&#125; due: &#123;:.2f&#125;&gt;' return fmt.format(self.total(), self.due())class Promotion(ABC): # 策略：抽象基类 @abstractmethod def discount(self, order): """返回折扣金额"""class FidelityPromo(Promotion): """为积分为1000或以上的顾客提供5%折扣""" def discount(self, order): return order.total() * .05 if order.customer.fidelity &gt;= 1000 else 0class BulkItemPromo(Promotion): """单个商品为20个或以上时提供10%折扣""" def discount(self, order): discount = 0 for item in order.cart: if item.quantity &gt;= 20: discount += item.total() * .1 return discountclass LargeOrderPromo(Promotion): """订单中的不同商品达到10个或以上时提供7%折扣""" def discount(self, order): distinct_items = &#123;item.product for item in order.cart&#125; if len(distinct_items) &gt;= 10: return order.total() * .07 return 0 执行效果：1234567891011121314&gt;&gt;&gt; from order import *&gt;&gt;&gt; joe = Customer('John Doe', 0)&gt;&gt;&gt; ann = Customer('Ann Smith', 1100)&gt;&gt;&gt; cart = [LineItem('banana', 4, .5), LineItem('apple', 10, 1.5), LineItem('watermellon', 5, 5.0)]&gt;&gt;&gt; Order(joe, cart, FidelityPromo())&lt;Order total: 42.00 due: 42.00&gt;&gt;&gt;&gt; Order(ann, cart, FidelityPromo())&lt;Order total: 42.00 due: 39.90&gt;&gt;&gt;&gt; banana_cart = [LineItem('banana', 30, .5), LineItem('apple', 10, 1.5)]&gt;&gt;&gt; Order(joe, banana_cart, BulkItemPromo())&lt;Order total: 30.00 due: 28.50&gt;&gt;&gt;&gt; long_order = [LineItem(str(item_code), 1, 1.0) for item_code in range(10)]&gt;&gt;&gt; Order(joe, long_order, LargeOrderPromo())&lt;Order total: 10.00 due: 9.30&gt; 使用函数实现策略模式1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253from collections import namedtupleCustomer = namedtuple('Customer', 'name fidelity')class LineItem: def __init__(self, product, quantity, price): self.product = product self.quantity = quantity self.price = price def total(self): return self.price * self.quantityclass Order: def __init__(self, customer, cart, promotion=None): self.customer = customer self.cart = list(cart) self.promotion = promotion def total(self): if not hasattr(self, '__total'): self.__total = sum(item.total() for item in self.cart) return self.__total def due(self): if self.promotion is None: discount = 0 else: discount = self.promotion(self) return self.total() - discount def __repr__(self): fmt = '&lt;Order total: &#123;:.2f&#125; due: &#123;:.2f&#125;&gt;' return fmt.format(self.total(), self.due())def fidelity_promo(order): return order.total() * .05 if order.customer.fidelity &gt;= 1000 else 0def bulk_item_promo(order): discount = 0 for item in order.cart: if item.quantity &gt;= 20: discount += item.total() * .1 return discountdef large_order_promo(order): distince_items = &#123;item.product for item in order.cart&#125; if len(distince_items) &gt;= 10: return order.total() * .07 return 0 计算折扣只需调用 self.promotion() 函数，无需涉及到抽象类。各个策略都是由函数实现的。为了把折扣策略应用到 Order 实例上，只需把促销函数作为参数传入。 执行效果：1234567891011121314&gt;&gt;&gt; from order_fun import *&gt;&gt;&gt; joe = Customer('John Doe', 0)&gt;&gt;&gt; ann = Customer('Ann Smith', 1100)&gt;&gt;&gt; cart = [LineItem('banana', 4, .5), LineItem('apple', 10, 1.5), LineItem('watermellon', 5, 5.0)]&gt;&gt;&gt; Order(joe, cart, fidelity_promo)&lt;Order total: 42.00 due: 42.00&gt;&gt;&gt;&gt; Order(ann, cart, fidelity_promo)&lt;Order total: 42.00 due: 39.90&gt;&gt;&gt;&gt; banana_cart = [LineItem('banana', 30, .5), LineItem('apple', 10, 1.5)]&gt;&gt;&gt; Order(joe, banana_cart, bulk_item_promo)&lt;Order total: 30.00 due: 28.50&gt;&gt;&gt;&gt; long_order = [LineItem(str(item_code), 1, 1.0) for item_code in range(10)]&gt;&gt;&gt; Order(joe, long_order, large_order_promo)&lt;Order total: 10.00 due: 9.30&gt; 具体策略一般没有内部状态，只是处理上下文中的数据。因此一定要使用普通的函数，而无需编写只有一个方法的类，再去实现另一个类声明的单函数接口。函数比用户自定义类的实例更为轻量，各个策略函数在 Python 编译模块时只会创建一次。即普通的函数是可共享的对象，可以同时在多个上下文中使用。 选择最佳策略在上述代码的基础上，添加 best_promo 函数计算所有折扣，并返回额度最大的。1234promos = [fidelity_promo, bulk_item_promo, large_order_promo]def best_promo(order): return max(promo(order) for promo in promos) 与其他几个 *_promo 函数一样，best_promo 函数的参数是一个 Order 实例。使用生成器表达式把 order 传给 promos 列表中的各个函数，返回折扣额度最大的促销策略。虽然上述代码可用且易于阅读，但若想添加新的促销策略，除了定义新的折扣函数以外，还应注意记得把新定义的函数添加到 promos 列表中。 可以使用内置的 globals() 函数找出模块中的全部策略。globals() 函数会返回一个字典，包含针对当前模块的全局符号表（对函数或方法来说，“当前模块”指的是定义它们的模块，而不是调用它们的模块）。123456promos = [globals()[name] for name in globals() if name.endswith('_promo') and name != 'best_promo']def best_promo(order): return max(promo(order) for promo in promos) 动态收集促销折扣函数更为显式的一种方案是使用简单的装饰器。参考下一章节。 使用装饰器改进策略模式使用注册装饰器可以改进前面的电商促销折扣示例。之前的主要问题是，定义体中有函数名称，但 best_promo 用来判断哪个折扣幅度最大的 promos 列表中也有函数名称。这种重复导致新增折扣函数后可能会忘记把它添加到 promos 列表中，导致 best_promos 忽略新策略且不报错，为系统引入了不易察觉的缺陷。 123456789101112131415161718192021222324252627promos = []def promotion(promo_func): promos.append(promo_func) return promo_func@promotiondef fidelity(order): return order.total() * .05 if order.customer.fidelity &gt;= 1000 else 0@promotiondef bulk_item(order): discount = 0 for item in order.cart: if item.quantity &gt;= 20: discount += item.total() * .1 return discount@promotiondef large_order(order): discount_items = &#123;item.product for item in order.cart&#125; if len(discount_items) &gt;= 10: return order.total() * .07 return 0def best_promo(order): return max(promo(order) for promo in promos) promos 列表起初是空的，promotion 把 promo_func 添加到 promos 列表中，然后原封不动地将其返回。即被 @promotion 装饰的函数都会提前添加到 promos 列表中（装饰器在被装饰的函数定义之后（通常是在导入时）立即运行）。 相比于之前的方案，此方案有以下几个优点： 促销函数无需使用特殊的名称（即不用以 _promo 结尾） @promotion 装饰器突出了被装饰的函数的作用，还便于临时禁用某个促销策略：只需把装饰器注释掉 促销折扣策略可以在其他模块中定义，只要使用 @promotion 装饰即可 参考资料Fluent Python]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Functional</tag>
        <tag>Advanced</tag>
        <tag>Python</tag>
        <tag>DesignPattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fluent Python 笔记 —— 可迭代对象、迭代器和生成器]]></title>
    <url>%2F2020%2F10%2F18%2Ffluent-python-iterator-and-generator%2F</url>
    <content type="text"><![CDATA[迭代是数据处理的基石。扫描内存中放不下的数据集时，通常需要一种惰性获取数据项的方式，即按需一次获取一个数据项。这就是迭代器模式。 在 Python 中，所有序列类型都支持迭代。在语言内部，迭代器用于支持以下操作： for 循环 构建和扩展序列类型 逐行遍历文本文件 列表推导、字典推导和集合推导 元组拆包 调用函数时，使用 * 拆包实参 可迭代对象以下代码实现了一个 Sentence 类，通过索引从文本中提取单词：123456789101112131415161718import reimport reprlibRE_WORD = re.compile('\w+')class Sentence: def __init__(self, text): self.text = text self.words = RE_WORD.findall(text) def __getitem__(self, index): return self.words[index] def __len__(self): return len(self.words) def __repr__(self): return f'Sentence(&#123;reprlib.repr(self.text)&#125;)' 效果如下：12345678910111213141516&gt;&gt;&gt; from sentence import Sentence&gt;&gt;&gt; s = Sentence('"The time has come," the Walrus said,')&gt;&gt;&gt; sSentence('"The time ha... Walrus said,')&gt;&gt;&gt; for word in s:... print(word)...ThetimehascometheWalrussaid&gt;&gt;&gt; list(s)['The', 'time', 'has', 'come', 'the', 'Walrus', 'said'] 上面创建的 Sentence 实例是可迭代的。因此该实例对象可被 for 循环调用、可以用于构建列表等。 迭代的机制Python 解释器需要迭代对象 x 时，会自动执行 iter(x)。其作用如下： 检查对象是否实现了 __iter__ 方法，如已实现则调用 __iter__，返回一个迭代器对象 若对象没有实现 __iter__ 方法，但实现了 __getitem__ 方法，Python 会创建一个迭代器，尝试按顺序（从索引 0 开始）获取元素 若上述尝试失败，抛出 TypeError 异常（X object is not iterable） 所有 Python 序列都实现了 __iter__ 方法，因此都支持迭代操作。 可迭代对象与迭代器的对比可迭代对象指通过 iter 函数调用可以获取迭代器的对象。即对象实现了能够返回迭代器的 __iter__ 方法，该对象就是可迭代的；或者实现了 __getitem__ 方法，且其参数是从 0 开始的索引，则对象也可以迭代。 一个简单的 for 循环背后也是有迭代器的作用的：1234567&gt;&gt;&gt; s = 'ABC'&gt;&gt;&gt; for char in s:... print(char)...ABC 使用 while 循环模拟效果如下：123456789101112&gt;&gt;&gt; s = 'ABC'&gt;&gt;&gt; it = iter(s)&gt;&gt;&gt; while True:... try:... print(next(it))... except StopIteration:... del it... break...ABC 使用可迭代的对象（字符串 s）创建迭代器 it 不断在迭代器 it 上调用 next 函数，获取下一个字符 若已获取到最后一个字符，迭代器抛出 StopIteration 异常 捕获 StopIteration 异常，释放 it 对象，退出循环 Python 语言内部会自动处理 for 循环和其他迭代上下文（如列表推导等）中的 StopIteration 异常。 迭代器（如前面的 it）实现了无参数的 __next__ 方法，返回序列中的下一个元素；若没有元素了，则抛出 StopIteration 异常。Python 中的迭代器还实现了 __iter__ 方法，返回该迭代器本身（即确保迭代器本身也是可迭代对象） 典型的迭代器关于可迭代对象与迭代器之间的区别，可以参考如下代码：1234567891011121314151617181920212223242526272829303132import reimport reprlibRE_WORD = re.compile('\w+')class Sentence: def __init__(self, text): self.text = text self.words = RE_WORD.findall(text) def __repr__(self): return f'Sentence(&#123;reprlib.repr(self.text)&#125;)' def __iter__(self): return SentenceIterator(self.words)class SentenceIterator: def __init__(self, words): self.words = words self.index = 0 def __next__(self): try: word = self.words[self.index] except IndexError: raise StopIteration() self.index += 1 return word def __iter__(self): return self 根据迭代器协议，可迭代对象 Sentence 中的 __iter__ 方法会实例化并返回一个迭代器（SentenceIterator），而 SentenceIterator 作为迭代器实现了 __next__ 和 __iter__ 方法。 构建可迭代对象时出现错误的原因经常是混淆了可迭代对象与迭代器。可迭代对象通过内部的 __iter__ 方法返回一个实例化的迭代器对象；而迭代器要实现 __next__ 方法返回单个元素，此外还需要实现 __iter__ 方法返回迭代器本身。 生成器函数1234567891011121314151617181920212223242526272829303132import reimport reprlibRE_WORD = re.compile('\w+')class Sentence: def __init__(self, text): self.text = text self.words = RE_WORD.findall(text) def __repr__(self): return f'Sentence(&#123;reprlib.repr(self.text)&#125;)' def __iter__(self): return SentenceIterator(self.words)class SentenceIterator: def __init__(self, words): self.words = words self.index = 0 def __next__(self): try: word = self.words[self.index] except IndexError: raise StopIteration() self.index += 1 return word def __iter__(self): return self 实现可迭代对象，相较于之前的代码，符合 Python 习惯的方式是用生成器函数替换手动实现的迭代器 SentenceIterator 类。 只要 Python 函数的定义体中有 yield 关键字，则该函数就是生成器函数。调用生成器函数会返回一个生成器对象。1234567891011121314151617181920212223242526&gt;&gt;&gt; def gen_123():... yield 1... yield 2... yield 3...&gt;&gt;&gt; gen_123&lt;function gen_123 at 0x7f63e57f0f80&gt;&gt;&gt;&gt; gen_123()&lt;generator object gen_123 at 0x7f63e57dc950&gt;&gt;&gt;&gt; for i in gen_123():... print(i)...123&gt;&gt;&gt; g = gen_123()&gt;&gt;&gt; next(g)1&gt;&gt;&gt; next(g)2&gt;&gt;&gt; next(g)3&gt;&gt;&gt; next(g)Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;StopIteration 把生成器对象传递给 next() 函数时，其行为与迭代器一致。 惰性求值re.finditer 是 re.findall 函数的惰性版本，返回的不是结果列表而是一个生成器，按需生成 re.MatchObject 实例。即只在需要时才生成下一个单词。 123456789101112131415import reimport reprlibRE_WORD = re.compile('\w+')class Sentence: def __init__(self, text): self.text = text def __repr__(self): return f'Sentence(&#123;reprlib.repr(self.text)&#125;)' def __iter__(self): for match in RE_WORD.finditer(self.text): yield match.group() finditer 函数返回一个迭代器，包含 self.text 中匹配 RE_WORD 的单词，产出 MatchObject 实例。match.group() 方法从 MatchObject 实例中提取匹配正则表达式的具体文本。 生成器函数已极大地简化了代码，但使用生成器表达式能够把代码变得更为简短。123456789101112131415161718&gt;&gt;&gt; def gen_AB():... print('start')... yield 'A'... print('continue')... yield 'B'... print('end.')...&gt;&gt;&gt; res = (x * 3 for x in gen_AB())&gt;&gt;&gt; res&lt;generator object &lt;genexpr&gt; at 0x7f4619324ad0&gt;&gt;&gt;&gt; for i in res:... print('--&gt;', i)...start--&gt; AAAcontinue--&gt; BBBend. 可以看出，生成器表达式会产出生成器。1234567891011121314import reimport reprlibRE_WORD = re.compile('\w+')class Sentence: def __init__(self, text): self.text = text def __repr__(self): return f'Sentence(&#123;reprlib.repr(self.text)&#125;)' def __iter__(self): return (match.group() for match in RE_WORD.finditer(self.text)) 标准库中的生成器函数用于过滤的生成器函数 模块 函数 说明 itertools compress(it, selector_it) 并行处理两个可迭代对象。若 selector_it 中的元素是真值，产出 it 中对应的元素 itertools dropwhile(predicate, it) 把可迭代对象 it 中的元素传给 predicate，跳过 predicate(item) 为真值的元素，在 predicate(item) 为假时停止，产出剩余（未跳过）的所有元素（不再继续检查） 内置 filter(predicate, it) 把 it 中的各个元素传给 predicate，若 predicate(item) 返回真值，产出对应元素 itertools filterfalse(predicate, it) 与 filter 函数类似，不过 predicate(item) 返回假值时产出对应元素 itertools takewhile(predicate, it) predicate(item) 返回真值时产出对应元素，然后立即停止不再继续检查 itertools islice(it, stop) 或 islice(it, start, stop, step=1) 产出 it 的切片，作用类似于 s[:stop] 或 s[start:stop:step，不过 it 可以是任何可迭代对象，且实现的是惰性操作 12345678910111213141516&gt;&gt;&gt; def vowel(c):... return c.lower() in 'aeiou'...&gt;&gt;&gt; list(filter(vowel, 'Aardvark'))['A', 'a', 'a']&gt;&gt;&gt; import itertools&gt;&gt;&gt; list(itertools.filterfalse(vowel, 'Aardvark'))['r', 'd', 'v', 'r', 'k']&gt;&gt;&gt; list(itertools.dropwhile(vowel, 'Aardvark'))['r', 'd', 'v', 'a', 'r', 'k']&gt;&gt;&gt; list(itertools.compress('Aardvark', (1,0,1,1,0,1)))['A', 'r', 'd', 'a']&gt;&gt;&gt; list(itertools.islice('Aardvark', 4))['A', 'a', 'r', 'd']&gt;&gt;&gt; list(itertools.islice('Aardvark', 1, 7, 2))['a', 'd', 'a'] 用于映射的生成器函数 模块 函数 说明 itertools accumulate(it, [func]) 产出累积的总和。若提供了 func，则把 it 中的前两个元素传给 func，再把计算结果连同下一个元素传给 func，以此类推，产出结果 内置 enumerate(it, start=0) 产出由两个元素构成的元组，结构是 (index, item)。其中 index 从 start 开始计数，item 则从 it 中获取 内置 map(func, it1, [it2, ..., itN]) 把 it 中的各个元素传给 func，产出结果；若传入 N 个可迭代对象，则 func 必须能接受 N 个参数，且并行处理各个可迭代对象 123456789101112131415&gt;&gt;&gt; list(enumerate('albatroz', 1))[(1, 'a'), (2, 'l'), (3, 'b'), (4, 'a'), (5, 't'), (6, 'r'), (7, 'o'), (8, 'z')]&gt;&gt;&gt; import operator&gt;&gt;&gt; list(map(operator.mul, range(11), range(11)))[0, 1, 4, 9, 16, 25, 36, 49, 64, 81, 100]&gt;&gt;&gt; list(map(operator.mul, range(11), [2, 4, 8]))[0, 4, 16]&gt;&gt;&gt; list(map(lambda a, b: (a, b), range(11), [2, 4, 8]))[(0, 2), (1, 4), (2, 8)]&gt;&gt;&gt; import itertools&gt;&gt;&gt; sample = [5, 4, 2, 8, 7, 6, 3, 0, 9, 1]&gt;&gt;&gt; list(itertools.accumulate(sample))[5, 9, 11, 19, 26, 32, 35, 35, 44, 45]&gt;&gt;&gt; list(itertools.accumulate(sample, max))[5, 5, 5, 8, 8, 8, 8, 8, 9, 9] 合并多个可迭代对象的生成器函数 模块 函数 说明 itertools chain(it1, ..., itN) 先产出 it1 中的所有元素，然后产出 it2 中的所有元素，以此类推，无缝连接 itertools chain.from_iterable(it) 产出 it 生成的各个可迭代对象中的元素，一个接一个无缝连接；it 中的元素应该为可迭代对象（即 it 是嵌套了可迭代对象的可迭代对象） itertools product(it1, ..., itN, repeat=1) 计算笛卡尔积。从输入的各个可迭代对象中获取元素，合并成 N 个元素组成的元组，与嵌套的 for 循环效果一样。repeat 指明重复处理多少次输入的可迭代对象 内置 zip(it1, ..., itN) 并行从输入的各个可迭代对象中获取元素，产出由 N 个元素组成的元组。只要其中任何一个可迭代对象到头了，就直接停止 itertools zip_longest(it1, ..., itN, fillvalue=None) 并行从输入的各个可迭代对象中获取元素，产出由 N 个元素组成的元组，等到最长的可迭代对象到头后才停止。空缺的值用 fillvalue 填充 123456789101112131415&gt;&gt;&gt; import itertools&gt;&gt;&gt; list(itertools.chain('ABC', range(2)))['A', 'B', 'C', 0, 1]&gt;&gt;&gt; list(itertools.chain(enumerate('ABC')))[(0, 'A'), (1, 'B'), (2, 'C')]&gt;&gt;&gt; list(itertools.chain.from_iterable(enumerate('ABC')))[0, 'A', 1, 'B', 2, 'C']&gt;&gt;&gt; list(zip('ABC', range(5)))[('A', 0), ('B', 1), ('C', 2)]&gt;&gt;&gt; list(zip('ABC', range(5), [10, 20, 30, 40]))[('A', 0, 10), ('B', 1, 20), ('C', 2, 30)]&gt;&gt;&gt; list(itertools.zip_longest('ABC', range(5)))[('A', 0), ('B', 1), ('C', 2), (None, 3), (None, 4)]&gt;&gt;&gt; list(itertools.zip_longest('ABC', range(5), fillvalue='?'))[('A', 0), ('B', 1), ('C', 2), ('?', 3), ('?', 4)] 123456789&gt;&gt;&gt; list(itertools.product('ABC', range(2)))[('A', 0), ('A', 1), ('B', 0), ('B', 1), ('C', 0), ('C', 1)]&gt;&gt;&gt; suits = 'spades hearts diamonds clubs'.split()&gt;&gt;&gt; list(itertools.product('AK', suits))[('A', 'spades'), ('A', 'hearts'), ('A', 'diamonds'), ('A', 'clubs'), ('K', 'spades'), ('K', 'hearts'), ('K', 'diamonds'), ('K', 'clubs')]&gt;&gt;&gt; list(itertools.product('ABC'))[('A',), ('B',), ('C',)]&gt;&gt;&gt; list(itertools.product('ABC', repeat=2))[('A', 'A'), ('A', 'B'), ('A', 'C'), ('B', 'A'), ('B', 'B'), ('B', 'C'), ('C', 'A'), ('C', 'B'), ('C', 'C')] 把输入的各个元素扩展成多个输出元素的生成器函数|模块|函数|说明||-|-|-||itertools|combinations(it, out_len)|把可迭代对象 it 产出的 out_len 个元素组合在一起产出||itertools|combinations_with_replacement(it, out_len)|把 it 产出的 out_len 个元素组合在一起产出，包含相同元素的组合||itertools|count(start=0, step=1)|从 start 开始不断产出数字，按 step 指定的步幅增加||itertools|cycle(it)|从 it 中产出各个元素，存储各个元素的副本，然后按顺序重复不断地产出各个元素||itertools|permutations(it, out_len=None)|把 out_len 个 it 产出的元素排列在一起，然后产出这些排列；out_len 的默认值等于 len(list(it))||itertools|repeat(item, [times])|重复不断地产出指定的元素，除非提供 times 指定次数| 123456789101112131415161718&gt;&gt;&gt; import itertools&gt;&gt;&gt; ct = itertools.count()&gt;&gt;&gt; next(ct)0&gt;&gt;&gt; next(ct), next(ct), next(ct)(1, 2, 3)&gt;&gt;&gt; list(itertools.islice(itertools.count(1, .3), 3))[1, 1.3, 1.6]&gt;&gt;&gt; cy = itertools.cycle('ABC')&gt;&gt;&gt; next(cy)'A'&gt;&gt;&gt; list(itertools.islice(cy, 7))['B', 'C', 'A', 'B', 'C', 'A', 'B']&gt;&gt;&gt; rp = itertools.repeat(7)&gt;&gt;&gt; next(rp), next(rp)(7, 7)&gt;&gt;&gt; list(itertools.repeat(8, 4))[8, 8, 8, 8] 123456789&gt;&gt;&gt; import itertools&gt;&gt;&gt; list(itertools.combinations('ABC', 2))[('A', 'B'), ('A', 'C'), ('B', 'C')]&gt;&gt;&gt; list(itertools.combinations_with_replacement('ABC', 2))[('A', 'A'), ('A', 'B'), ('A', 'C'), ('B', 'B'), ('B', 'C'), ('C', 'C')]&gt;&gt;&gt; list(itertools.permutations('ABC', 2))[('A', 'B'), ('A', 'C'), ('B', 'A'), ('B', 'C'), ('C', 'A'), ('C', 'B')]&gt;&gt;&gt; list(itertools.product('ABC', repeat=2))[('A', 'A'), ('A', 'B'), ('A', 'C'), ('B', 'A'), ('B', 'B'), ('B', 'C'), ('C', 'A'), ('C', 'B'), ('C', 'C')] 用于重新排列元素的生成器函数|模块|函数|说明||-|-|-||itertools|groupby(it, key=None)|产出由两个元素组成的元素，形式为 (key, group)，其中 key 是分组标准，group 是生成器，用于产出分组里的元素||内置|reversed(seq)|从后向前，倒序产出 seq 中的元素；seq 必须是序列，或者实现了 __reversed__ 特殊方法的对象||itertools|tee(it, n=2)|产出一个有 n 个生成器组成的元组，每个生成器都可以独立地产出输入的可迭代对象中的元素| 1234567891011121314151617181920212223242526&gt;&gt;&gt; import itertools&gt;&gt;&gt; animals = ['duck', 'eagle', 'rat', 'giraffe', 'bear', 'bat', 'dolphin', 'shark', 'lion']&gt;&gt;&gt; animals.sort(key=len)&gt;&gt;&gt; animals['rat', 'bat', 'duck', 'bear', 'lion', 'eagle', 'shark', 'giraffe', 'dolphin']&gt;&gt;&gt; for length, group in itertools.groupby(animals, len):... print(length, '-&gt;', list(group))...3 -&gt; ['rat', 'bat']4 -&gt; ['duck', 'bear', 'lion']5 -&gt; ['eagle', 'shark']7 -&gt; ['giraffe', 'dolphin']&gt;&gt;&gt;&gt;&gt;&gt; g1, g2 = itertools.tee('ABC')&gt;&gt;&gt; next(g1)'A'&gt;&gt;&gt; next(g2)'A'&gt;&gt;&gt; next(g2)'B'&gt;&gt;&gt; list(g1)['B', 'C']&gt;&gt;&gt; list(g2)['C']&gt;&gt;&gt; list(zip(*itertools.tee('ABC')))[('A', 'A'), ('B', 'B'), ('C', 'C')] PS：itertools.groupby 假定输入的可迭代对象已按照分组标准完成排序 读取迭代器，返回单个值的函数 模块 函数 说明 内置 all(it) it 中的所有元素都为真值时返回 True，否则返回 False；all([]) 返回 True 内置 any(it) 只要 it 中有元素为真值就返回 True，否则返回 False；any([]) 返回 False 内置 max(it, [key=], [default=]) 返回 it 中值最大的元素；key 是排序函数，与 sorted 中的一样；若可迭代对象为空，返回 default 内置 min(it, [key=], [default=]) 返回 it 中值最小的元素；key 是排序函数；若可迭代对象为空，返回 default functools reduce(func, it, [initial]) 把前两个元素传给 func，然后把计算结果和第三个元素传给 func，以此类推，返回最后的结果。若提供了 initial，则将其作为第一个元素传入 内置 sum(it, start=0) it 中所有元素的总和，若提供可选的 start，会把它也加上 1234567891011121314&gt;&gt;&gt; all([1, 2, 3])True&gt;&gt;&gt; all([1, 0, 3])False&gt;&gt;&gt; all([])True&gt;&gt;&gt; any([1, 2, 3])True&gt;&gt;&gt; any([1, 0, 3])True&gt;&gt;&gt; any([0, 0.0])False&gt;&gt;&gt; any([])False 123456&gt;&gt;&gt; import functools&gt;&gt;&gt; functools.reduce(lambda a, b: a * b, range(1, 6))120&gt;&gt;&gt; import operator&gt;&gt;&gt; functools.reduce(operator.mul, range(1, 6))120 参考资料Fluent Python]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Functional</tag>
        <tag>Advanced</tag>
        <tag>Python</tag>
        <tag>Generator</tag>
        <tag>Iterator</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 与数据结构 —— 基于数组的序列类型]]></title>
    <url>%2F2020%2F10%2F13%2Fpython-and-data-structure-array-based-list%2F</url>
    <content type="text"><![CDATA[Python 中的序列类型包含内置的 list、tuple、str 等，它们有很多明显的共同点。比如都支持通过索引语法（seq[k]）获取序列中的某个特定元素；底层的结构都是用数组来实现的。 Low-Level Array计算机系统一般都包含有数量庞大的内存空间，为了跟踪具体某段数据实际的存储位置，计算机加入了称为内存地址（memory address）的抽象形式。每个字节的存储空间都会关联一个独特的数字作为其地址。 计算机的内存为 random access memory (RAM)，即任意一个 byte 内存的读取与写入耗费的时间都是 O(1)。 通常来说，编程语言会跟踪每一个标识符及其对应的值的位置（内存地址）。为了方便起见，一组相关联的变量则可以保存在一段连续的内存中，即数组（array）。比如字符串实际上是由独立的字符组成的有序的序列： 数组中的每一个元素都占据同样大小的存储空间，使得任意一个元素的访问和更新都可以通过索引以常量的时间完成。 存储引用的数组假如需要用数组保存如下的一个姓名列表：[Rene, Joseph, Janet, Jonas, Helen, Virginia, ...] 使用数组的话，则需要确保数组中的每一个元素都占据同样的内存大小。但字符串本身具有差异很大的长度。当然可以尝试为数组中的每一个元素都分配足够大的内存空间，保证即使最长的字符串也不会超出，但这样必然会导致内存的浪费。 Python 的方案是在 list 或 tuple 中不保存字符串对象本身而是保存其引用。即列表中只是包含一系列内存地址，每一个地址都指向对应元素实际的存储位置。 即便每一个字符串的大小并不相同，列表中保存的字符串的内存地址却都是固定的（64bit）。 由于 list 和 tuple 中保存的是引用，导致同一个对象有可能成为多个 list 中某个元素的实体。比如对某个 list 执行分片操作后，分片中的元素实际上和母列表中对应的元素指向同样的对象。如 temp = primes[3:6]： 若对分片中的某个元素重新赋值，则直接将该元素替换为新的内存地址（指向新对象）即可，如执行 temp[2] = 15： 一个更显著的例子如 counters = [0] * 8，生成的 counters 列表中的 8 个数字 0 实际上都指向了同一个数字对象。这种方式初看上去很容易出现混乱，但是得益于数字本身是不可变对象，即使为数组中的某个元素重新赋值（比如 counters[2] = 1），也只是将当前位置保存的对数字 0 的引用替换为指向新的数字 1 的引用。而原数字 0 本身不发生任何变化，即数组中指向数字 0 的其他元素不受任何影响。 存储数值的数组前面提到过字符串是一种存储一系列字符（而不是这些字符的地址）的序列，这种更直接的形式称为 compact array。它相对于前面的存储引用的数组有着性能上的优势，且需要更少的内存。 比如存储一个包含一百万个 64-bit 整数的序列，理论上只需要 64 MB 的内存。实际上 Python 里的 list 需要 4 到 5 倍的容量去储存这些值。此外对于计算而言，compact array 将有关联的数据直接保存在一段连续的内存中，容易获得更高的性能。 动态数组在创建 low-level 数组时，其大小必须精确地、显式地声明，从而使系统可以为其分配适当的内存空间。但是这些内存附近的空间有可能提供给其他数据用于储存，因此数组在初始化后其容量一般是固定的，其中保存的元素的数量不能超越这个限制。 Python 的 list 类采用了一种称为 dynamic array 的机制，使其看上去没有长度的限制，其容量可以随着元素的添加不断地增长。list 实例会在底层维护着一个容量比当前 list 更大的数组，这个容量更大的数组使得为 list 添加元素变得方便很多。当元素数量持续增长直到数组中预留的空间也要被用尽时，list 会申请一个容量更大的数组替代之前容量较小的数组，旧的数组则被系统回收。 测试代码：123456789import sysdata = []for count in range(20): data.append(None) length = len(data) size = sys.getsizeof(data) print('Length: &#123;0:3d&#125;; Size in bytes: &#123;1:4d&#125;'.format(length, size)) 输出结果：1234567891011121314151617181920Length: 1; Size in bytes: 88Length: 2; Size in bytes: 88Length: 3; Size in bytes: 88Length: 4; Size in bytes: 88Length: 5; Size in bytes: 120Length: 6; Size in bytes: 120Length: 7; Size in bytes: 120Length: 8; Size in bytes: 120Length: 9; Size in bytes: 184Length: 10; Size in bytes: 184Length: 11; Size in bytes: 184Length: 12; Size in bytes: 184Length: 13; Size in bytes: 184Length: 14; Size in bytes: 184Length: 15; Size in bytes: 184Length: 16; Size in bytes: 184Length: 17; Size in bytes: 256Length: 18; Size in bytes: 256Length: 19; Size in bytes: 256Length: 20; Size in bytes: 256 可以看出随着数组长度的增加，其占据的内存空间不是成比例而是分段地进行扩展的。 动态数组的 Python 实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import ctypesclass DynamicArray: def __init__(self): self._n = 0 self._capacity = 1 self._A = self._make_array(self._capacity) def __len__(self): return self._n def __getitem__(self, k): if not 0 &lt;= k &lt; self._n: raise IndexError('invalid index') return self._A[k] def append(self, obj): if self._n == self._capacity: self._resize(2 * self._capacity) self._A[self._n] = obj self._n += 1 def _resize(self, c): B = self._make_array(c) for k in range(self._n): B[k] = self._A[k] self._A = B self._capacity = c def _make_array(self, c): return (c * ctypes.py_object)() def insert(self, k, value): if self._n == self._capacity: self._resize(2 * self._capacity) for j in range(self._n, k, -1): self._A[j] = self._A[j - 1] self._A[k] = value self._n += 1 def remove(self, value): for k in range(self._n): if self._A[k] == value: for j in range(k, self._n - 1): self._A[j] = self._A[j + 1] self._A[self._n - 1] = None self._n -= 1 return raise ValueError('value not found') Python 中 List 的性能 操作 时间 len(data) O(1) data[j] O(1) data.count(value) O(n) data.index(value) O(k + 1)，k 指从左起 value 第一次出现的位置 value in data O(k + 1)，k 指从左起 value 第一次出现的位置 data1 == data2 O(k + 1)，此处 k 指从左起第一次出现不同元素的位置 data[j:k] O(k - j + 1)，j 和 k 指分片的起止位置 data1 + data2 O(n1 + n2) c * data O(cn) data[j] = val O(1) data.append(value) O(1) data.insert(k, value) O(n - k + 1) data.pop() O(1) data.pop(k) O(n - k) data1 += data2 O(n2) data.reverse() O(n) data.sort() O(nlogn) 参考资料Data Structures and Algorithms in Python]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Advanced</tag>
        <tag>Python</tag>
        <tag>DataStructure</tag>
        <tag>List</tag>
        <tag>Array</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 与数据结构 —— 链表及其应用]]></title>
    <url>%2F2020%2F10%2F13%2Fpython-and-data-structure-linked-list%2F</url>
    <content type="text"><![CDATA[list 的局限Python 的 list 类是经过高度优化的，在需要存储数据时是一个很优秀的选择。但仍有以下几点需要注意的劣势： 动态数组的长度通常会大于实际存储的元素的数量 当存储的元素数量不断增长时，动态数组扩展边界的性能较低 靠近数组中间位置的插入和删除操作性能相对较低 基于数组的序列和链表都能够以特定顺序存储元素，但是各自实现的方式差异很大。数组提供了一种更为“中心化”的表示方式，用一大段连续的内存存储多个元素的引用；而链表则更为“分散化”，将每个元素表示为轻量的节点（Node），每个节点都维护着包含元素本身及一个或多个相邻节点的引用，通过引用将多个节点最终连接成线性顺序的序列。 链表无法高效地通过数字索引读取其中元素的值，但是可以避免前面提到过的基于数组的序列的三点劣势。 单链表单链表是最简单的一种形式，组成线性序列的每个节点都包含元素本身及下一个节点的引用。 第一个和最后一个节点分别称为 head 和 tail。从 head 节点开始，跟随每个节点的 next 引用从首节点一直移动到尾部节点的过程，即为链表遍历。 向链表头部插入新元素的步骤： 创建包含新元素的新的节点对象 将新节点的 next 引用指向当前的 head 节点 将新节点设置为链表的新 head 节点 向链表尾部插入新元素的步骤： 创建一个包含新元素的新的节点 将新节点的 next 引用指向 None 作为新的 tail 节点 将当前 tail 节点的 next 引用改为指向上面的新节点 通过单链表实现 Stack 数据结构12345678910111213141516171819202122232425262728293031323334353637383940# linkstack.pyclass EmptyError(Exception): passclass Node: __slots__ = '_element', '_next' def __init__(self, element, next): self._element = element self._next = nextclass LinkedStack: def __init__(self): self._head = None self._size = 0 def __len__(self): return self._size def is_empty(self): return self._size == 0 def push(self, e): self._head = Node(e, self._head) self._size += 1 def top(self): if self.is_empty(): raise EmptyError('Stack is empty') return self._head._element def pop(self): if self.is_empty(): raise EmptyError('Stack is empty') answer = self._head._element self._head = self._head._next self._size -= 1 return answer 运行效果如下：12345678910111213141516171819&gt;&gt;&gt; from linkstack import LinkedStack&gt;&gt;&gt; s = LinkedStack()&gt;&gt;&gt; s.push(1)&gt;&gt;&gt; s.push(2)&gt;&gt;&gt; s.push(3)&gt;&gt;&gt; len(s)3&gt;&gt;&gt; s.pop()3&gt;&gt;&gt; s.pop()2&gt;&gt;&gt; s.pop()1&gt;&gt;&gt; s.pop()Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "/home/starky/program/python/algorithm/linkstack.py", line 35, in pop raise EmptyError('Stack is empty')linkstack.EmptyError: Stack is empty 性能 操作 时间 S.push(e) O(1) S.pop() O(1) S.top() O(1) len(S) O(1) S.is_empty() O(1) 单链表实现 Queue 数据结构1234567891011121314151617181920212223242526272829303132333435363738394041424344454647class Node: __slots__ = '_element', '_next' def __init__(self, element, next): self._element = element self._next = nextclass EmptyError(Exception): passclass LinkedQueue: def __init__(self): self._head = None self._tail = None self._size = 0 def __len__(self): return self._size def is_empty(self): return self._size == 0 def first(self): if self.is_empty(): raise EmptyError('Queue is empty') return self._head._element def dequeue(self): if self.is_empty(): raise EmptyError('Queue is empty') answer = self._head._element self._head = self._head._next self._size -= 1 if self.is_empty(): self._tail = None return answer def enqueue(self, e): newest = Node(e, None) if self.is_empty(): self._head = newest else: self._tail._next = newest self._tail = newest self._size += 1 运行效果如下：12345678910111213141516171819&gt;&gt;&gt; from linkqueue import LinkedQueue&gt;&gt;&gt; q = LinkedQueue()&gt;&gt;&gt; q.enqueue(1)&gt;&gt;&gt; q.enqueue(2)&gt;&gt;&gt; q.enqueue(3)&gt;&gt;&gt; len(q)3&gt;&gt;&gt; q.dequeue()1&gt;&gt;&gt; q.dequeue()2&gt;&gt;&gt; q.dequeue()3&gt;&gt;&gt; q.dequeue()Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "/home/starky/program/python/algorithm/linkqueue.py", line 32, in dequeue raise EmptyError('Queue is empty')linkqueue.EmptyError: Queue is empty 双链表 图中的 header 和 trailer 节点实际上不保存任何元素，这些“dummy”节点称为 sentinels。目的是保证逻辑的一致性，即任何情况下插入新节点，都能确保其左右两边至少各有一个旧节点。 插入新节点示意图： 代码实现：12345678910111213141516171819202122232425262728293031323334353637383940# doublylinked.pyclass Node: __slots__ = '_element', '_prev', '_next' def __init__(self, element, prev, next): self._element = element self._prev = prev self._next = nextclass DoublyLinkedBase: def __init__(self): self._header = Node(None, None, None) self._trailer = Node(None, None, None) self._header._next = self._trailer self._trailer._prev = self._header self._size = 0 def __len__(self): return self._size def is_empty(self): return self._size == 0 def _insert_between(self, e, predecessor, successor): newest = Node(e, predecessor, successor) predecessor._next = newest successor._prev = newest self._size += 1 return newest def _delete_node(self, node): predecessor = node._prev successor = node._next predecessor._next = successor successor._prev = predecessor self._size -= 1 element = node._element node._prev = node._next = node._element = None return element 双链表实现 Deque 数据结构12345678910111213141516171819202122232425262728293031323334# linkdeque.pyfrom doublylinked import DoublyLinkedBaseclass EmptyError(Exception): passclass LinkedDeque(DoublyLinkedBase): def first(self): if self.is_empty(): raise EmptyError("Deque is empty") return self._header._next._element def last(self): if self.is_empty(): raise Empty("Deque is empty") return self._trailer._prev._element def insert_first(self, e): self._insert_between(e, self._header, self._header._next) def insert_last(self, e): self._insert_between(e, self._trailer._prev, self._trailer) def delete_first(self): if self.is_empty(): raise EmptyError("Deque is empty") return self._delete_node(self._header._next) def delete_last(self): if self.is_empty(): raise EmptyError("Deque is empty") return self._delete_node(self._trailer._prev) 运行效果如下：1234567891011121314&gt;&gt;&gt; from linkdeque import LinkedDeque&gt;&gt;&gt; dq = LinkedDeque()&gt;&gt;&gt; dq.insert_first(2)&gt;&gt;&gt; dq.insert_first(1)&gt;&gt;&gt; dq.insert_last(3)&gt;&gt;&gt; dq.insert_last(4)&gt;&gt;&gt; len(dq)4&gt;&gt;&gt; dq.delete_first()1&gt;&gt;&gt; dq.delete_last()4&gt;&gt;&gt; len(dq)2 Link-Based vs. Array-BasedArray-Based 序列的优势： 提供 O(1) 时间下基于整数索引（index）对元素的访问。而链表访问第 k 个元素则需要 O(k) 时间（从链表头部开始遍历） 在不考虑动态数组边界扩展的情况下，各种操作在基于数组的序列中性能更高（步骤相对较少），虽然整体上和链表一样时间都是 O(1) 与链表结构相比，基于数组的序列需要更少的内存。基于数组或链表的序列实际上保存的都是对象的引用，因此这部分占据的内存空间是一致的。数组在最差的情况下（即刚刚扩展过边界的动态数组）需要为 2n 个对象引用收集内存；而单链表本身就需要为 2n 个对象引用提供空间（每个节点都包含元素本身和下一个节点的引用），双链表则为 3n Link-Based 序列的优势： 链表结构能够支持任意位置下插入和删除操作只耗费 O(1) 时间。而基于数组的序列在尾部插入和删除元素是常数时间，在任意索引为 k 的位置插入或移除元素则需要 O(n - k + 1) 时间。 参考资料Data Structures and Algorithms in Python]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Advanced</tag>
        <tag>Python</tag>
        <tag>DataStructure</tag>
        <tag>List</tag>
        <tag>Array</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fluent Python 笔记 —— 对象引用、可变性及其影响]]></title>
    <url>%2F2020%2F10%2F12%2Ffluent-python-object-reference-and-mutation%2F</url>
    <content type="text"><![CDATA[别名Python 中的变量类似于 Java 中的引用式变量，可以理解为附加在对象上的“标注”。 比如下面代码中的变量 a 和 b 实际上指向同一个列表：12345&gt;&gt;&gt; a = [1, 2, 3]&gt;&gt;&gt; b = a&gt;&gt;&gt; a.append(4)&gt;&gt;&gt; b[1, 2, 3, 4] 对于引用式变量的赋值，“把变量分配给对象”的说法更为合理。即赋值语句的右边先执行，右侧产生的对象在赋值前就已经创建了。 尝试运行以下代码：12345678910111213&gt;&gt;&gt; class Gizmo:... def __init__(self):... print(f'Gizmo id: &#123;id(self)&#125;')...&gt;&gt;&gt; x = Gizmo()Gizmo id: 140497327120880&gt;&gt;&gt; y = Gizmo() * 10Gizmo id: 140497327319840Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;TypeError: unsupported operand type(s) for *: 'Gizmo' and 'int'&gt;&gt;&gt; dir()['Gizmo', '__annotations__', '__builtins__', '__doc__', '__loader__', '__name__', '__package__', '__spec__', 'x'] 输出的 Gizmo id: ... 是创建 Gizmo 实例时的副作用。因此 y = Gizmo() * 10 实际上创建了一个新的 Gizmo 实例，但绝不会创建变量 y。因为赋值语句右侧在求值时抛出了异常。因此在赋值语句中，对象在右边创建或获取，之后左边的变量才会绑定给对象。类似于给对象贴标签，贴的多个标签就是别名。 相等性两个变量指向同一个对象：123456789&gt;&gt;&gt; charles = &#123;'name': 'Charles L. Dodgson', 'born': 1832&#125;&gt;&gt;&gt; lewis = charles&gt;&gt;&gt; lewis is charlesTrue&gt;&gt;&gt; id(charles), id(lewis)(140497326642048, 140497326642048)&gt;&gt;&gt; lewis['balance'] = 950&gt;&gt;&gt; charles&#123;'name': 'Charles L. Dodgson', 'born': 1832, 'balance': 950&#125; lewis 是 charles 的别名，两者指向同一个对象。 alex 绑定具有同样内容的另一个对象：12345&gt;&gt;&gt; alex = &#123;'name': 'Charles L. Dodgson', 'born': 1832, 'balance': 950&#125;&gt;&gt;&gt; alex == charlesTrue&gt;&gt;&gt; alex is charlesFalse 则 alex 指代的对象与赋值给 charles 的对象内容一样，但两者绑定的是不同的对象。 每个变量都有标识、类型和值。对象一旦创建，其标识绝不会变。可以将标识理解为对象在内存中的地址。is 运算符比较两个对象的标识，id() 函数返回对象标识的整数表示。 == 与 is 的选择== 用于比较两个对象的值（对象中保存的数据），而 is 比较对象的标识。通常在比较时关注的是值而不是标识，因此 == 出现的几率比 is 要高。 但在变量和单例值之间比较时，应使用 is。比如用 is 检查变量绑定的值是不是 None：x is None 或 x is not None。原因是 is 运算符比 == 速度更快。因为它不能重载，Python 不用寻找并调用特殊方法，而是直接比较两个整数 ID。而 a == b 是 a.__eq__(b) 的语法糖。多数内置类型使用更有意义的方式覆盖了 __eq__ 方法，因此相等性测试可能涉及大量处理工作。 元组的相对不可变性元组中保存的是对象的引用。即便元组本身不可变，若元素引用的对象是可变的，则该元素依然可变。即元组的不可变性指的是 tuple 数据结构的物理内容（即保存的引用）不可变，与引用指向的对象无关。 12345678910111213&gt;&gt;&gt; t1 = (1, 2, [30, 40])&gt;&gt;&gt; t2 = (1, 2, [30, 40])&gt;&gt;&gt; t1 == t2True&gt;&gt;&gt; id(t1[-1])140497326641856&gt;&gt;&gt; t1[-1].append(99)&gt;&gt;&gt; t1(1, 2, [30, 40, 99])&gt;&gt;&gt; id(t1[-1])140497326641856&gt;&gt;&gt; t1 == t2False 元组的值会随着其中元素引用的可变对象的变化而变化。元组中不可变的是元素的标识。 浅复制与深复制赋值列表（或多数内置的其他可变集合）最简单的方式是使用类型构造方法。12345678&gt;&gt;&gt; l1 = [3, [55, 44], (7, 8, 9)]&gt;&gt;&gt; l2 = list(l1)&gt;&gt;&gt; l2[3, [55, 44], (7, 8, 9)]&gt;&gt;&gt; l2 == l1True&gt;&gt;&gt; l2 is l1False list(l1) 会创建 l1 的副本。副本与源列表相等，但两者实际指向不同的对象。还可以使用同样效果的 l2 = l1[:] 语句。 但是，list 构造方法和 [:] 做的都是浅复制，即只复制最外层的容器，副本中的元素是源容器中元素的引用。若所有元素都是不可变的，则没有任何问题，还可以节省内存；若容器中存在可变的元素，则有可能导致意想不到的问题。12345678910111213141516171819202122&gt;&gt;&gt; l1 = [3, [66, 55, 44], (7, 8, 9)]&gt;&gt;&gt; l2 = list(l1)&gt;&gt;&gt; l1.append(100)&gt;&gt;&gt; l1[3, [66, 55, 44], (7, 8, 9), 100]&gt;&gt;&gt; l2[3, [66, 55, 44], (7, 8, 9)]&gt;&gt;&gt; l1[1].remove(55)&gt;&gt;&gt; l1[3, [66, 44], (7, 8, 9), 100]&gt;&gt;&gt; l2[3, [66, 44], (7, 8, 9)]&gt;&gt;&gt; l2[1] += [33, 22]&gt;&gt;&gt; l1[3, [66, 44, 33, 22], (7, 8, 9), 100]&gt;&gt;&gt; l2[3, [66, 44, 33, 22], (7, 8, 9)]&gt;&gt;&gt; l2[2] += (10, 11)&gt;&gt;&gt; l2[3, [66, 44, 33, 22], (7, 8, 9, 10, 11)]&gt;&gt;&gt; l1[3, [66, 44, 33, 22], (7, 8, 9), 100] l2 是 l1 的浅复制副本，但是二者引用同一个列表 [66, 55, 44] 和同一个元组 (7, 8, 9) 把 100 追加到 l1 中，对 l2 没有任何影响 把内部列表 l1[1] 中的 55 移除，l2 也会出现同样的改动。原因是 l2[1] 与 l1[1] 绑定的是同一个列表 同样的，l2[1] 引用的列表通过 += 运算符就地修改列表，这样的修改也会在 l1[1] 中体现 对元组来说，+= 运算符会创建一个新元组重新绑定给变量 l2[2]，等同于 l2[2] = l2[2] + (10, 11)，因此最终状态下 l1 和 l2 中的元组不再是同一个对象 对自定义对象做深复制和浅复制12345678910111213# bus.pyclass Bus: def __init__(self, passengers=None): if passengers is None: self.passengers = [] else: self.passengers = list(passengers) def pick(self, name): self.passengers.append(name) def drop(self, name): self.passengers.remove(name) 1234567891011121314&gt;&gt;&gt; from bus import Bus&gt;&gt;&gt; import copy&gt;&gt;&gt; bus1 = Bus(['Alice', 'Bill', 'Claire', 'David'])&gt;&gt;&gt; bus2 = copy.copy(bus1)&gt;&gt;&gt; bus3 = copy.deepcopy(bus1)&gt;&gt;&gt; id(bus1), id(bus2), id(bus3)(140247402065344, 140247402153680, 140247380561296)&gt;&gt;&gt; bus1.drop('Bill')&gt;&gt;&gt; bus2.passengers['Alice', 'Claire', 'David']&gt;&gt;&gt; id(bus1.passengers), id(bus2.passengers), id(bus3.passengers)(140247380615936, 140247380615936, 140247401717056)&gt;&gt;&gt; bus3.passengers['Alice', 'Bill', 'Claire', 'David'] 使用 copy 和 deepcopy 创建 3 个不同的 Bus 实例。bus1 中的 Bill 下车后，bus2 中也没有他了。原因是 bus2 是 bus1 的浅复制副本，他们共享同一个列表对象。bus3 是 bus1 的深复制副本，其 passengers 属性指向另一个不同的列表对象。 函数参数作为引用Python 唯一支持的参数传递模式是共享传参，多数面向对象语言都采用这一模式。在该模式中，函数内部的形参是实参的别名。上述方案导致函数可能会修改作为参数传入的可变对象，虽然无法修改那些对象的标识（即不能把一个对象替换为另一个对象）。 如下面这个简单的函数，在参数上调用 +=，分别将数字、列表、元组作为参数传入，效果如下：1234567891011121314151617181920&gt;&gt;&gt; def f(a, b):... a += b... return a...&gt;&gt;&gt; x = 1&gt;&gt;&gt; y = 2&gt;&gt;&gt; f(x, y)3&gt;&gt;&gt; a = [1, 2]&gt;&gt;&gt; b = [3, 4]&gt;&gt;&gt; f(a, b)[1, 2, 3, 4]&gt;&gt;&gt; a, b([1, 2, 3, 4], [3, 4])&gt;&gt;&gt; t = (10, 20)&gt;&gt;&gt; u = (30, 40)&gt;&gt;&gt; f(t, u)(10, 20, 30, 40)&gt;&gt;&gt; t, u((10, 20), (30, 40)) 不可变的数字 x 和元组 t 都没变，而可变对象列表 a 变了。 可变类型作为参数默认值函数的可选参数可以有默认值，但是应尽量避免使用可变对象作为参数的默认值。 123456789class HauntedBus: def __init__(self, passengers=[]): self.passengers = passengers def pick(self, name): self.passengers.append(name) def drop(self, name): self.passengers.remove(name) 123456789101112131415161718&gt;&gt;&gt; from hauntedbus import HauntedBus&gt;&gt;&gt; bus1 = HauntedBus(['Alice', 'Bill'])&gt;&gt;&gt; bus1.passengers['Alice', 'Bill']&gt;&gt;&gt; bus2 = HauntedBus()&gt;&gt;&gt; bus2.pick('Carrie')&gt;&gt;&gt; bus2.passengers['Carrie']&gt;&gt;&gt; bus3 = HauntedBus()&gt;&gt;&gt; bus3.passengers['Carrie']&gt;&gt;&gt; bus3.pick('Dave')&gt;&gt;&gt; bus2.passengers['Carrie', 'Dave']&gt;&gt;&gt; bus2.passengers is bus3.passengersTrue&gt;&gt;&gt; bus1.passengers['Alice', 'Bill'] 上述的代码表明，bus2.passengers 和 bus3.passengers 指向同一个列表，而 bus1.passengers 是不同的列表。即没有指定初始乘客的 HauntedBus 实例会共享同一个乘客列表。这个问题的根源在于，函数参数的默认值是在定义函数时计算的，因此该默认值成为了函数对象的属性。因此 self.passengers 变成了 passengers 参数默认值（可变的列表对象）的别名，导致后续的函数调用都会受到影响。1234&gt;&gt;&gt; HauntedBus.__init__.__defaults__(['Carrie', 'Dave'],)&gt;&gt;&gt; HauntedBus.__init__.__defaults__[0] is bus2.passengersTrue 函数对可变参数的修改如果定义的函数接收可变参数，应谨慎考虑调用方是否期望修改传入的参数。比如函数接收一个字典，且在处理过程中要修改它，则该副作用是否要体现到函数外部？ 如下面的 TwilightBus 实例：123456789101112class TwilightBus: def __init__(self, passengers=None): if passengers is None: self.passengers = [] else: self.passengers = passengers def pick(self, name): self.passengers.append(name) def drop(self, name): self.passengers.remove(name) 1234567&gt;&gt;&gt; from twilightbus import TwilightBus&gt;&gt;&gt; basketball_team = ['Sue', 'Tina', 'Maya', 'Diana', 'Pat']&gt;&gt;&gt; bus = TwilightBus(basketball_team)&gt;&gt;&gt; bus.drop('Tina')&gt;&gt;&gt; bus.drop('Pat')&gt;&gt;&gt; basketball_team['Sue', 'Maya', 'Diana'] basketball_team 中有 5 名学生，使用这队学生实例化 TwilightBus。两个学生从 bus 下车后，这两人就从篮球队（basketball_team）中消失了。 代码中 self.passengers = passengers 赋值语句把 self.passengers 变成 passengers 的别名，而后者是传给 __init__ 方法的实参（即 basketball_team）的别名。导致在 self.passengers 上调用 .remove() 和 .append() 方法实际上会修改传给构造方法的列表（basketball_team）。正确的做事是，校车维护自己的乘客列表。即在 __init__ 中，应该把 passengers 参数值的副本赋值给 self.passengers。12345def __init__(self, passengers=None): if passengers is None: self.passengers = [] else: self.passengers = list(passengers) 小结变量保存的是引用，此种行为对 Python 编程有很多实际影响： 简单的赋值操作不会创建副本 对于 += 或 *= 的增量赋值，若左边变量绑定的是不可变对象，则会创建新对象；若左边是可变对象，则就地修改该可变对象 为现有变量赋予新值，不会直接修改之前绑定的变量值。而是创建新的对象并绑定给变量（重新绑定） 函数参数以别名的形式传递，意味着函数可能会修改通过参数传入的可变对象。除非在本地创建可变对象的副本 使用可变类型作用函数参数的默认值有一定风险。若就地修改了参数，则默认值也会改变，进而影响以后使用默认值的调用 参考资料Fluent Python]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Advanced</tag>
        <tag>Python</tag>
        <tag>Mutation</tag>
        <tag>Reference</tag>
        <tag>Object</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fluent Python 笔记——序列类型及其丰富的操作]]></title>
    <url>%2F2020%2F10%2F12%2Ffluent-python-list-and-its-operation%2F</url>
    <content type="text"><![CDATA[序列的分类Python 标准库用 C 语言实现了丰富的序列类型的数据结构，如： 容器序列（能存放不同类型的数据）：list、tuple、collections.deque 等 扁平序列（只容纳同一类型的数据）：str、bytes、bytearray、memoryview、array.array 12&gt;&gt;&gt; a_list = [1, '2', True, [1, 2, 3], 4.5]&gt;&gt;&gt; a_str = 'helloworld' 容器序列存放的是对象的引用，扁平序列存放的是值。即扁平序列是一段连续的内存空间。123456789&gt;&gt;&gt; a_list = [1, '2', True, [1, 2, 3], 4.5]&gt;&gt;&gt; embedded_list = a_list[3]&gt;&gt;&gt; embedded_list[1, 2, 3]&gt;&gt;&gt; embedded_list.append(4)&gt;&gt;&gt; embedded_list[1, 2, 3, 4]&gt;&gt;&gt; a_list[1, '2', True, [1, 2, 3, 4], 4.5] 序列还可以按照是否可变（能够被修改）进行分类： 可变序列：list、bytearray、array.array、collections.deque、memoryview 不可变序列：tuple、str、bytes 123456789&gt;&gt;&gt; a_list = [1, 2, 3]&gt;&gt;&gt; a_list[0] = 2&gt;&gt;&gt; a_list[2, 2, 3]&gt;&gt;&gt; a_tuple = (1, 2, 3)&gt;&gt;&gt; a_tuple[0] = 2Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;TypeError: 'tuple' object does not support item assignment 列表推导for 循环：1234567&gt;&gt;&gt; symbols = '!@#$%'&gt;&gt;&gt; codes = []&gt;&gt;&gt; for symbol in symbols:... codes.append(ord(symbol))...&gt;&gt;&gt; codes[33, 64, 35, 36, 37] 列表推导：1234&gt;&gt;&gt; symbols = '!@#$%'&gt;&gt;&gt; codes = [ord(symbol) for symbol in symbols]&gt;&gt;&gt; codes[33, 64, 35, 36, 37] 通常的原则是，只用列表推导创建新的列表，并尽量保持简短。 列表推导（包括集合推导、字典推导）、生成器表达式在 Python3 中有自己的局部作用域。123456&gt;&gt;&gt; x = 'ABC'&gt;&gt;&gt; dummy = [ord(x) for x in x]&gt;&gt;&gt; x'ABC'&gt;&gt;&gt; dummy[65, 66, 67] 列表推导与 filter/map 的比较：1234567&gt;&gt;&gt; symbols = '$¢£¥€¤'&gt;&gt;&gt; beyond_ascii = [ord(s) for s in symbols if ord(s) &gt; 127]&gt;&gt;&gt; beyond_ascii[162, 163, 165, 8364, 164]&gt;&gt;&gt; beyond_ascii = list(filter(lambda c: c &gt; 127, map(ord, symbols)))&gt;&gt;&gt; beyond_ascii[162, 163, 165, 8364, 164] 作为记录的元组元组其实是一种数据记录（Record），其中的每个元素都对应记录中一个字段的数据，字段在元组中的位置则可以用来区分其含义。123456789&gt;&gt;&gt; lax_coordinates = (33.9425, -118.408056)&gt;&gt;&gt; city, year, pop, area = ('Tokyo', 2003, 32450, 8014)&gt;&gt;&gt; traveler_ids = [('USA', '31195855'), ('BRA', 'CE342567'), ('ESP', 'XDA205856')]&gt;&gt;&gt; for country, _ in traveler_ids:... print(country)...USABRAESP 元组拆包元组拆包可以应用到任何可迭代对象上，唯一的要求即可迭代对象中的元素数量与接收这些元素的空档数一致（除非用 * 忽略多余的元素）。 元组拆包（平行赋值）：123456&gt;&gt;&gt; lax_coordinates = (33.9425, -118.408056)&gt;&gt;&gt; latitude, longitude = lax_coordinates&gt;&gt;&gt; latitude33.9425&gt;&gt;&gt; longitude-118.408056 不使用中间变量交换两个变量的值：1234567&gt;&gt;&gt; a = 1&gt;&gt;&gt; b = 2&gt;&gt;&gt; a, b = b, a&gt;&gt;&gt; a2&gt;&gt;&gt; b1 使用 * 运算符把一个可迭代对象拆开作为函数的参数：12345&gt;&gt;&gt; divmod(20, 8)(2, 4)&gt;&gt;&gt; t = (20, 8)&gt;&gt;&gt; divmod(*t)(2, 4) 元组拆包可以方便一个函数以元组的方式返回多个值，调用函数的代码就可以轻松地（有选择地）接受这些值。1234&gt;&gt;&gt; import os&gt;&gt;&gt; _, filename = os.path.split('/home/luciano/.ssh/idrsa.pub')&gt;&gt;&gt; filename'idrsa.pub' 用 * 处理多余的元素：123456789101112&gt;&gt;&gt; a, b, *rest = range(5)&gt;&gt;&gt; a, b, rest(0, 1, [2, 3, 4])&gt;&gt;&gt; a, b, *rest = range(3)&gt;&gt;&gt; a, b, rest(0, 1, [2])&gt;&gt;&gt; a, b, *rest = range(2)&gt;&gt;&gt; a, b, rest(0, 1, [])&gt;&gt;&gt; a, *body, c, d = range(5)&gt;&gt;&gt; a, body, c, d(0, [1, 2], 3, 4) 具名元组collections.namedtuple 可以用来创建一个带字段名的元组和一个有名字的类，便于对程序进行调试。其类实例消耗的内存与元组是一样的，跟普通的对象实例相比更小一些（不用 __dict__ 存放实例的属性）。1234567891011&gt;&gt;&gt; from collections import namedtuple&gt;&gt;&gt; City = namedtuple('City', 'name country population coordinates')&gt;&gt;&gt; tokyo = City('Tokyo', 'JP', 36.933, (35.689722, 139.691667))&gt;&gt;&gt; tokyoCity(name='Tokyo', country='JP', population=36.933, coordinates=(35.689722, 139.691667))&gt;&gt;&gt; tokyo.population36.933&gt;&gt;&gt; tokyo.coordinates(35.689722, 139.691667)&gt;&gt;&gt; tokyo[1]'JP' 创建具名元组需要传入两个参数，第一个是类名，第二个是类的各个字段的名称。后者可以是多个字符串组成的可迭代对象或由空格分隔开的字段名组成的字符串。可以通过字段名或位置获取某个字段的信息。 具名元组的 _fields 属性包含由这个类中所有字段名称组成的元组；_asdict() 方法可以把具名元组以 collections.OrderedDict 的形式返回。 切片关于切片和区间忽略最后一个元素在切片和区间操作里不包含最后一个元素是 Python 的风格，同时也符合 C 和其他以 0 为起始下标的语言的习惯。部分原因如下： 当只有最后一个位置信息时，可以快速看出区间里包含多少个元素：range(3) 和 my_list[:3] 都返回 3 个元素 起止位置都可见时，可以快速算出区间的长度（stop - start），如切片 my_list[3:6] 即包含 6 - 3 = 3 个元素 可以利用任意一个下标把序列分割成不重叠的两部分（my_list[:x] 和 my_list[x:]） step可以用 s[a:b:c] 的形式对 s 在 a 和 b 之间以 c 为间隔取值。c 值还可以为负，表示反向取值。1234567&gt;&gt;&gt; s = 'bicycle'&gt;&gt;&gt; s[::3]'bye'&gt;&gt;&gt; s[::-1]'elcycib'&gt;&gt;&gt; s[::-2]'eccb' 对 seq[start:stop:step] 求值时，Python 会调用 seq.__getitem__(slice(start, stop, step))。 对切片赋值如果把切片放在赋值语句左边，或把它作为 del 操作的对象，则可以对切片所属的序列进行拼接、切除或就地修改等操作。123456789101112131415&gt;&gt;&gt; l = list(range(10))&gt;&gt;&gt; l[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]&gt;&gt;&gt; l[2:5] = [20, 30]&gt;&gt;&gt; l[0, 1, 20, 30, 5, 6, 7, 8, 9]&gt;&gt;&gt; del l[5:7]&gt;&gt;&gt; l[0, 1, 20, 30, 5, 8, 9]&gt;&gt;&gt; l[3::2] = [11, 22]&gt;&gt;&gt; l[0, 1, 20, 11, 5, 22, 9]&gt;&gt;&gt; l[2:5] = [100]&gt;&gt;&gt; l[0, 1, 100, 22, 9] 需要注意的是，在对切片进行赋值操作时，赋值语句的右侧必须是个可迭代对象。 对序列使用 + 和 *Python 程序员一般默认序列都会支持 + 和 * 的拼接操作。在拼接过程中，两个被操作的序列不会发生任何改动，Python 会创建一个新的包含拼接结果的序列。12345&gt;&gt;&gt; l = [1, 2, 3]&gt;&gt;&gt; l * 5[1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3]&gt;&gt;&gt; 5 * 'abcd''abcdabcdabcdabcdabcd' 如果 a * n 语句中序列 a 里的元素是对其他可变对象的引用的话，这个式子的结果可能会出乎意料。比如用 my_list = [[]] * 3 来初始化一个有列表组成的列表，实际上得到的列表里包含的三个元素是三个引用，且这三个引用都指向同一列表。123456&gt;&gt;&gt; weird_board = [['-'] * 3] * 3&gt;&gt;&gt; weird_board[['-', '-', '-'], ['-', '-', '-'], ['-', '-', '-']]&gt;&gt;&gt; weird_board[1][2] = 'O'&gt;&gt;&gt; weird_board[['-', '-', 'O'], ['-', '-', 'O'], ['-', '-', 'O']] 其错误的本质等同于如下代码：12345678&gt;&gt;&gt; row = ['-'] * 3&gt;&gt;&gt; board = []&gt;&gt;&gt; for i in range(3):... board.append(row)...&gt;&gt;&gt; board[1][2] = 'O'&gt;&gt;&gt; board[['-', '-', 'O'], ['-', '-', 'O'], ['-', '-', 'O']] 即追加同一个行对象（row）到游戏币（board） 正确的做法代码如下：123456&gt;&gt;&gt; board = [['-'] * 3 for i in range(3)]&gt;&gt;&gt; board[['-', '-', '-'], ['-', '-', '-'], ['-', '-', '-']]&gt;&gt;&gt; board[1][2] = 'O'&gt;&gt;&gt; board[['-', '-', '-'], ['-', '-', 'O'], ['-', '-', '-']] 等同于如下代码：12345678910&gt;&gt;&gt; board = []&gt;&gt;&gt; for i in range(3):... row = ['-'] * 3... board.append(row)...&gt;&gt;&gt; board[['-', '-', '-'], ['-', '-', '-'], ['-', '-', '-']]&gt;&gt;&gt; board[1][2] = 'O'&gt;&gt;&gt; board[['-', '-', '-'], ['-', '-', 'O'], ['-', '-', '-']] 即每次迭代中都新建了一个列表，作为新的一行（row）追加到游戏板子（board） 序列的增量赋值增量赋值运算符 += 和 *= 的行为取决于第一个操作对象。+= 调用的特殊方法是 __iadd__（自增）。如果某个类没有实现该方法，Python 会退一步调用 __add__。 如 a += b 就会调用 a 中实现的 __iadd__ 方法，同时对于可变序列（如 list、bytearray、array.array），该方法的行为类似于 a.extend(b)，在 a 上就地改动。如 a 没有实现 __iadd__，a += b 的效果就类似于 a = a + b，计算 a + b 得到一个新的对象，再把这个对象赋值给 a。 *= 对应的是 __imul__。1234567891011121314&gt;&gt;&gt; l = [1, 2, 3]&gt;&gt;&gt; id(l)2888988078920&gt;&gt;&gt; l *= 2&gt;&gt;&gt; l[1, 2, 3, 1, 2, 3]&gt;&gt;&gt; id(l)2888988078920&gt;&gt;&gt; t = (1, 2, 3)&gt;&gt;&gt; id(t)2888988799688&gt;&gt;&gt; t *= 2&gt;&gt;&gt; id(t)2888988107592 作为可变对象的列表运用增量乘法后，ID 没变；而作为不可变对象的元组运用增量乘法后，新的元组被创建。 因此对于不可变序列做重复拼接操作效率会很低，每次都会有一个新对象。但字符串除外，由于对字符串做 += 等操作太普遍，CPython 专门做了优化。在为字符串初始化内存时，程序会预留额外的可扩展空间。 list.sort 与 sortedlist.sort 方法会就地排序列表，即在原列表的基础上完成排序，不会再另外复制一份。也因此其返回值为 None。内置的 sorted 函数则会新建一个列表作为返回值。它可以接收任何形式的可迭代对象（包含不可变序列和生成器），最后返回的始终是排序好的列表。123456789101112&gt;&gt;&gt; fruits = ['grape', 'raspberry', 'apple', 'banana']&gt;&gt;&gt; sorted(fruits)['apple', 'banana', 'grape', 'raspberry']&gt;&gt;&gt; fruits['grape', 'raspberry', 'apple', 'banana']&gt;&gt;&gt; sorted(fruits, key=len)['grape', 'apple', 'banana', 'raspberry']&gt;&gt;&gt; fruits['grape', 'raspberry', 'apple', 'banana']&gt;&gt;&gt; fruits.sort()&gt;&gt;&gt; fruits['apple', 'banana', 'grape', 'raspberry'] 参考资料Fluent Python]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Advanced</tag>
        <tag>Python</tag>
        <tag>DataStructure</tag>
        <tag>List</tag>
        <tag>Array</tag>
        <tag>Slice</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 中的特殊方法及其应用]]></title>
    <url>%2F2020%2F09%2F19%2Fmagic-methods-in-python%2F</url>
    <content type="text"><![CDATA[Python 中的特殊方法主要是为了被解释器调用的，因此应该尽量使用 len(my_object) 而不是 my_object.__len__() 这种写法。在执行 len(my_object) 时，Python 解释器会自行调用 my_object 中实现的 __len__ 方法。 除非有大量的元编程存在，直接调用特殊方法的频率应远小于实现它们的次数。 模拟数值类型可以通过在自定义对象中实现 __add__ 和 __mul__ 等特殊方法 ，令其支持 +、* 等运算符。如下面的模拟向量的 Vector 类：12345678910111213141516171819202122# vector.pyfrom math import hypotclass Vector: def __init__(self, x=0, y=0): self.x = x self.y = y def __repr__(self): return f'Vector(&#123;self.x&#125;, &#123;self.y&#125;)' def __abs__(self): return hypot(self.x, self.y) def __bool__(self): return bool(self.x or self.y) def __add__(self, other): return Vector(self.x + other.x, self.y + other.y) def __mul__(self, scalar): return Vector(self.x * scalar, self.y * scalar) 运行效果如下：12345678910&gt;&gt;&gt; from vector import Vector&gt;&gt;&gt; v1 = Vector(2, 4)&gt;&gt;&gt; v2 = Vector(2, 1)&gt;&gt;&gt; v1 + v2Vector(4, 5)&gt;&gt;&gt; v = Vector(3, 4)&gt;&gt;&gt; abs(v)5.0&gt;&gt;&gt; v * 3Vector(9, 12) 对象的字符串表示Python 有一个 repr 内置函数，能把一个对象用字符串的形式表示出来。实际上这种字符串表达是通过对象内部的 __repr__ 特殊方法定义的。默认情况下，在控制台里查看某个对象时，输出的字符串一般是 &lt;xxx object at 0x7fc99d6ab2e0&gt; 这种形式。 __repr__ 返回的字符串应该准确、无歧义，并尽可能表示出该对象是如何创建的。比如前面的 Vector 对象，其 __repr__ 中定义的字符串形式类似于 Vector(3, 4)，和对象初始化的语法非常近似。 __repr__ 和 __str__ 的区别在于，__str__ 是在向对象应用 str() 函数（或者用 print 函数打印某个对象）时被调用。其返回的字符串对终端用户更友好。如果只想实现其中一个特殊方法，__repr__ 应该是更优的选择。在对象没有实现 __str__ 方法的情况下，Python 解释器会用 __repr__ 代替。 1234567# myclass.pyclass MyClass: def __repr__(self): return 'MyClass' def __str__(self): return 'This is an instance of MyClass' 123456&gt;&gt;&gt; from myclass import MyClass&gt;&gt;&gt; my = MyClass()&gt;&gt;&gt; myMyClass&gt;&gt;&gt; print(my)This is an instance of MyClass 自定义布尔值Python 里有 bool 类型，但实际上任何对象都可以用在需要 bool 类型的上下文（比如 if 或 while 语句）中。为了判断某个值 x 的真假，Python 会调用 bool(x) 返回 True 或 False。 默认情况下，自定义类的实例总是为真。除非这个类对于 __bool__ 或 __len__ 方法有自己的实现。bool(x) 实际上调用了对象 x 中的 __bool__ 方法。如不存在 __bool__ 方法，则 bool(x) 会尝试调用 x.__len__()，返回 0 则为 False，否则为 True。 12345678910# boolclass.pyclass BoolClass: def __init__(self): self.list = [] def add(self, item): self.list.append(item) def __len__(self): return len(self.list) 1234567891011&gt;&gt;&gt; from boolclass import BoolClass&gt;&gt;&gt; b = BoolClass()&gt;&gt;&gt; len(b)0&gt;&gt;&gt; bool(b)False&gt;&gt;&gt; b.add(1)&gt;&gt;&gt; len(b)1&gt;&gt;&gt; bool(b)True 12345678910111213# boolclass.pyclass BoolClass: def __init__(self): self.list = [] def add(self, item): self.list.append(item) def __len__(self): return len(self.list) def __bool__(self): return bool(sum(self.list)) 123456789101112&gt;&gt;&gt; from boolclass import BoolClass&gt;&gt;&gt; b = BoolClass()&gt;&gt;&gt; b.add(1)&gt;&gt;&gt; len(b)1&gt;&gt;&gt; bool(b)True&gt;&gt;&gt; b.add(-1)&gt;&gt;&gt; len(b)2&gt;&gt;&gt; bool(b)False 参考资料Fluent Python]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Python</tag>
        <tag>OOP</tag>
        <tag>Object</tag>
        <tag>Methods</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解 JavaScript（ECMAScript 6）—— 异步编程]]></title>
    <url>%2F2020%2F09%2F19%2Funderstanding-javascript-ecmascript-6-async-programming%2F</url>
    <content type="text"><![CDATA[JavaScript 作为主要面向 Web 编程而创建的语言，其诞生初期即具有了应对异步的用户交互（如点击鼠标、按下键盘等）的能力。后续的 Node.js 引入了 callbacks 作为除事件模型以外的另一种实现异步编程的方式，而之后的 Promise 又使得 JavaScript 处理异步需求的能力更为强大。 一、异步编程基础Event Model当用户点击鼠标或按下键盘上的某个按键时，一个对应的特殊事件（比如 onclick）触发，该事件关联的一系列响应动作即被添加到工作队列中最终被执行。这是 JavaScript 中最基本的异步编程方式。1234567&lt;button id="my-btn"&gt;Click Me&lt;/button&gt; &lt;script&gt; let button = document.getElementById("my-btn") button.onclick = function(event) &#123; console.log("Clicked") &#125; &lt;/script&gt; callbackcallback 模式与基于事件模型的异步编程类似，异步代码都是在后续的某个特定时间点执行。不同的是，其异步执行的操作（函数）需要作为参数传递。12345678910111213let fs = require("fs")fs.readFile("example.txt", &#123; encoding: "utf8" &#125;, function(err, contents)&#123; if (err) &#123; throw err &#125; console.log(contents)&#125;)console.log("Hi!")// Hi!// This is an example text file 上面的例子使用了经典的 Node.js error-first 回调函数模式。readFile() 函数从硬盘读取某个文件，在文件读取完成之后执行 callback 函数。如果读取文件时发生错误，则传递给回调函数的 err 参数为错误对象；未发生错误则 content 参数中包含了读取的文件内容。 在 callback 模式中，readFile() 会立即开始执行，并且在文件读取的进度开启之后暂停。紧接着 readFile() 后面的 console.log(&quot;Hi!&quot;) 会立即执行并输出 Hi! 到屏幕上（此时 readFile() 处于暂停状态，回调函数中的 console.log(contents) 也并未执行）。文件读取结束后，一个新的任务（即 callback 函数以及传递给它的参数）被添加到任务队列中等待最终被执行。从输出中可以看到，Hi! 要先于 contents 被打印。 callback 模式的问题在于，当有过多的 callback 函数嵌套时，会出现称为 callback hell 的情况：123456789101112131415161718192021method1(function(err, result) &#123; if (err) &#123; throw err; &#125; method2(function(err, result) &#123; if (err) &#123; throw err; &#125; method3(function(err, result) &#123; if (err) &#123; throw err; &#125; method4(function(err, result) &#123; if (err) &#123; throw err; &#125; method5(result); &#125;); &#125;); &#125;);&#125;); 二、Promise除了前面提到的 callback hell 会使代码变得过于繁杂以至于难以理解和调试之外，callback 模式对于处理某些较复杂的逻辑也有一定的局限性。比如希望两个异步操作并行执行，在双方都完成之后提醒用户；或者两个异步任务同时开始但是只获取第一个任务执行完后的结果。在这些情景下，就需要同时追踪多个 callback 函数的状态。promise 则针对以上情况做了相应的提升。 promise 是一种对应异步操作执行结果的“占位符”。12// readFile “保证”会在未来的某个时间点完成let promise = readFile("example.txt") readFile() 并不会立即开始读取文件。相反，它会直接返回一个 promise 对象表示异步的读取操作，方便在后续的代码中通过这个 promise 对象访问读取任务的结果。该 promise 代表的结果是否可用取决于其生命周期所处的阶段。 Promise 生命周期promise 的生命周期起始于 pending (unsettled) 状态，表明对应的异步操作还未完成。比如前面的 let promise = readFile(&quot;example.txt&quot;)，在 readFile() 函数返回后 promise 就立即进入了 pending 状态。而异步操作最终完成时，promise 则进入 settled 状态，具体包含两种情况： Fulfilled：promise 对应的异步操作成功执行完毕 Rejected：promise 对应的异步操作未执行完毕（出现错误或其他情况） 内部属性 [[PromiseState]] 用来标记其生命周期状态（如 pending、fulfilled、rejected），该属性不对 promise 对象外部暴露，因此不可以人为修改 promise 对象的生命周期。但是可以在 promise 的状态改变时通过 then() 方法自动触发一系列动作。 所有的 promise 对象都具有 then() 方法，该方法可以接收两个函数作为参数。第一个参数为当 promise 状态为 fulfilled 时调用的函数，所有与异步操作相关的数据都会被传递给该函数；第二个参数为当 promise 状态为 rejected 时调用的函数。这两个参数都是可选的。123456789101112131415161718192021222324let promise = readFile("example.txt");promise.then(function(contents) &#123; // fulfillment console.log(contents)&#125;, function(err) &#123; // rejection console.error(err.message)&#125;);promise.then(function(contents) &#123; // fulfillment console.log(contents);&#125;);promise.then(null, function(err) &#123; // rejection console.error(err.message);&#125;);promise.catch(function(err) &#123; // rejectionconsole.error(err.message);&#125;); 创建 Promisepromise 可以使用 Promise 构造器创建，该构造器接收一个称为 executor 的函数作为参数，包含了初始化 promise 的代码。executor 接收 resolve()、reject() 两个函数作为参数，resolve() 将在 executor 执行成功后调用，传递 promise 已做好准备的信号；executor 执行失败了则调用 reject()。 一个 Promise 的完整示例：123456789101112131415161718192021222324252627282930let fs = require("fs")function readFile(filename) &#123; return new Promise(function(resolve, reject) &#123; fs.readFile(filename, &#123; encoding: "utf8" &#125;, function(err, contents) &#123; // check for errors if (err) &#123; reject(err) return &#125; // the read succeeded resolve(contents) &#125;) &#125;)&#125;let promise = readFile("example.txt")// listen for both fulfillment and rejectionpromise.then(function(contents) &#123; // fulfillment console.log(contents)&#125;, function(err) &#123; // rejection console.error(err.message)&#125;)console.log("Hi!")// Hi!// This is an example text file Promise 的执行流程参考如下代码：12345678910111213141516171819202122232425262728293031323334console.log("At code start")var delayedPromise = new Promise((resolve, reject) =&gt; &#123; console.log("delayedPromise executor") setTimeout(() =&gt; &#123; console.log("Resolving delayedPromise") resolve("Hello") &#125;, 1000)&#125;)console.log("After creating delayedPromise")delayedPromise.then(contents =&gt; &#123; console.log("delayedPromise resolve handled with", contents)&#125;)const immediatePromise = new Promise((resolve, reject) =&gt; &#123; console.log("immediatePromise executor") resolve("World")&#125;)immediatePromise.then(contents =&gt; &#123; console.log("immediatePromise resolve handled with", contents)&#125;)console.log("At code end")// At code start// delayedPromise executor// After creating delayedPromise// immediatePromise executor// At code end// immediatePromise resolve handled with World// Resolving delayedPromise// delayedPromise resolve handled with Hello 具体的执行逻辑为： 代码开始执行，通过 Promise 构造器创建一个 delayedPromise，其中的 console.log() 和 setTimeout()（也可以是其他异步操作）函数立即执行 delayedPromise 创建之后，其最终的结果和状态（是否成功执行）不能立即知晓，因此处于 pending 状态 调用 delayedPromise 的 then 方法，将一个当 promise 成功 resolve 后才执行的 callback 函数放到执行计划中 继续创建另一个 immediatePromise，该 promise 会在创建的过程中立即 resolve，因此其创建完成后即处于 resolved 状态 调用 immediatePromise 的 then 方法，注册一个当 promise 成功 resolve 后才执行的 callback 函数 从最终的结果中可以看出，即便 immediatePromise 在创建后即处于 resolved 状态，At code end 实际上是先于前面的 immediatePromise.then() 输出的。原因是 promise 被设计成专门针对异步操作，then() 方法中的 callback 会永远在当前事件循环中所有代码执行完后才开始触发。 因此实际的执行顺序为：At code start -&gt; 创建 delayedPromise -&gt; 通过 then() 注册 delayPromise 状态为 resolved 时触发的 callback -&gt; 创建 immediatePromise -&gt; 通过 then() 注册 immediatePromise 状态为 resolved 时触发的 callback -&gt; At code end -&gt; immediatePromise 先 resolved，其关联的 callback 执行 -&gt; delayedPromise resolved，其关联的 callback 执行 三、Chaining Promises截止到前面的介绍，promise 看起来只不过在 callback 的基础上做了一点点有限的提升。实际 promise 支持多种形式的连接，足以完成更加复杂的异步逻辑。 每次对 promise 的 then() 或 catch() 方法的调用，实际上都会创建和返回另一个 promise 对象。第二个 promise 对象只有在第一个 promise fulfilled 或 rejected 后才会被 resolve。123456789101112let p1 = new Promise(function(resolve, reject) &#123; resolve(42)&#125;)p1.then(function(value) &#123; console.log(value)&#125;).then(function() &#123; console.log("Finished")&#125;)// 42// Finished unchained 版本：1234567891011let p1 = new Promise(function(resolve, reject) &#123; resolve(42)&#125;)let p2 = p1.then(function(value) &#123; console.log(value)&#125;)p2.then(function() &#123; console.log("Finished")&#125;) p2.then() 也会返回一个 promise 对象，只不过它没有在代码中使用。 错误捕获Promise chaining 允许用户捕获之前的 promise 中出现的错误。12345678910let p1 = new Promise(function(resolve, reject) &#123; resolve(42)&#125;)p1.then(function(value) &#123; throw new Error("Boom!")&#125;).catch(function(error) &#123; console.log(error.message)&#125;)// Boom! p1 的 fulfillment handler 抛出异常，第二个 promise 的 catch() 方法通过它的 rejection handler 接收到该异常。同样的方式也适用于 rejection handler 抛出异常：123456789101112let p1 = new Promise(function(resolve, reject) &#123; throw new Error("Explosion!")&#125;)p1.catch(function(error) &#123; console.log(error.message) throw new Error("Boom!")&#125;).catch(function(error) &#123; console.log(error.message)&#125;)// Explosion!// Boom! executor 抛出异常触发 p1 的 rejection handler，该 handler 又抛出另一个异常触发第二个 promise 的 rejection handler。 Promise Chain 中的返回值Promise Chain 中另一个很重要的特性即在两个 promise 之间传递数据。之前的代码中，可以通过 executor 中的 resovle() 函数将值传递给该 promise 的 fulfillment handler。此外，还可以通过为 fulfillment handler 指定一个返回值，将该值沿着 promise chain 传递。12345678910111213let p1 = new Promise(function(resolve, reject) &#123; resolve(42)&#125;)p1.then(function(value) &#123; console.log(value) return value + 1&#125;).then(function(value) &#123; console.log(value)&#125;)// 42// 43 同样的操作也可以用在 rejection handler 上：12345678910111213let p1 = new Promise(function(resolve, reject) &#123; reject(42)&#125;)p1.catch(function(value) &#123; console.log(value) return value + 1&#125;).then(function(value) &#123; console.log(value)&#125;)// 42// 43 四、响应多个 Promise之前的代码中都是一次只响应一个 promise，但是有时候需要监控多个 promise 的状态并决定之后的动作。ECMAScript 6 提供了两种方法（Promise.all() 和 Promise.race）应对这些情况。 Promise.all()Promise.all() 方法只接收一个包含所有需要监控的 promise 的可迭代对象（如列表）作为参数，并且只有当这些需要监控的 promise 全部 resolved 时，Promise.all() 返回的 promise 才会 resolved。1234567891011121314151617181920let p1 = new Promise(function(resolve, reject) &#123; resolve(42)&#125;)let p2 = new Promise(function(resolve, reject) &#123; resolve(43)&#125;)let p3 = new Promise(function(resolve, reject) &#123; resolve(44)&#125;)let p4 = Promise.all([p1, p2, p3])p4.then(function(value) &#123; console.log(Array.isArray(value)) // true console.log(value[0]) // 42 console.log(value[1]) // 43 console.log(value[2]) // 44&#125;) Promise.all() 创建了 promise p4。只有当列表中的 promise p1，p2，p3 全部 fulfilled 之后，p4 最终才会 fulfilled。前面 3 个 promise resolve 的数字组成列表传递给 p4 的 fulfillment handler，这些数字与生产它们的 promise 的位置是一一对应的。 如果任意一个传入 Promise.all() 的 promise 状态是 rejected，则 Promise.all() 返回的 promise 也会立即 rejected，不会等待其他 promise 结束。1234567891011121314151617let p1 = new Promise(function(resolve, reject) &#123; resovle(42)&#125;)let p2 = new Promise(function(resolve, reject) &#123; reject(43)&#125;)let p3 = new Promise(function(resolve, reject) &#123; resolve(44)&#125;)let p4 = Promise.all([p1, p2, p3])p4.catch(function(value) &#123; console.log(Array.isArray(value)) // false console.log(value) // 43&#125;) 在上面的代码中，p2 的状态为 rejected，p4 的 rejection handler 会立即调用，不会等待 p1 和 p3 执行完毕（p1 和 p3 最终会执行完毕，只是 p4 不会等它们）。 Promise.race()Promise.race() 同样接收一个包含需要监控的多个 promise 的可迭代对象，返回一个新的 promise。但是不同于 Promise.all() 会等待所有监控中的 promise resolved，Promise.race() 会在列表中任意一个 promise resolve 后立即返回。123456789101112131415161718192021let p1 = new Promise(function(resolve, reject) &#123; setTimeout(resolve, 500, 42)&#125;)let p2 = new Promise(function(resolve, reject) &#123; setTimeout(resolve, 100, 43)&#125;)let p3 = new Promise(function(resolve, reject) &#123; setTimeout(resolve, 200, 44)&#125;)let p4 = Promise.race([p1, p2, p3])p4.then(function(value) &#123; console.log(value)&#125;)// 43 传递给 Promise.race() 的 promise 像是处在一个赛道中，看哪一个先执行完毕。如果第一个运行完的 promise 状态为 fulfilled，则最后返回的 promise 状态为 fulfilled；如果第一个运行完的 promise 状态为 rejected，则最后返回的 promise 状态为 rejected。 参考资料Understanding ECMAScript 6Secrets of the JavaScript Ninja, Second Edition]]></content>
      <categories>
        <category>Program</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Advanced</tag>
        <tag>JavaScript</tag>
        <tag>Async</tag>
        <tag>ECMAScript6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaScript 解密 —— 数组（Array）及其函数式操作]]></title>
    <url>%2F2020%2F08%2F21%2Fsecrets-of-javascript-array%2F</url>
    <content type="text"><![CDATA[一、创建数组1234567891011const ninjas = ["Kuma", "Hattori", "Yagyu"]const samurai = new Array("Oda", "Tomoe")console.log(ninjas.length) // 3console.log(ninjas[ninjas.length-1]) // Yagyuconsole.log(ninjas[4]) // undefinedninjas[4] = "Ishi"console.log(ninjas.length) // 5console.log(ninjas) // [ 'Kuma', 'Hattori', 'Yagyu', &lt;1 empty item&gt;, 'Ishi' ]ninjas.length = 2console.log(ninjas) // [ 'Kuma', 'Hattori' ] 数组可以使用 [] 字面量或 Array() 构造器创建 可以使用索引访问数组中的元素。索引从 0 到 array.length - 1 数组的 length 属性表示数组的大小（即元素的个数）。读取超出索引范围的元素，会得到 undefined 给超出索引范围的元素赋值，会自动扩展数组 将数组的 length 属性改为一个较小的值，会自动删除溢出的元素 二、添加和移除元素 push：向数组尾部添加元素 unshift：向数组头部添加元素 pop：从数组尾部弹出元素 shift：从数组头部弹出元素 123456789101112131415const ninjas = []ninjas.push("Kuma")ninjas.push("Hattori")console.log(ninjas) // [ 'Kuma', 'Hattori' ]ninjas.unshift("Yagyu")console.log(ninjas) // [ 'Yagyu', 'Kuma', 'Hattori' ]const lastNinja = ninjas.pop()console.log(lastNinja) // Hattoriconsole.log(ninjas) // [ 'Yagyu', 'Kuma' ]const firstNinja = ninjas.shift()console.log(firstNinja) // Yagyuconsole.log(ninjas) // [ 'Kuma' ] 从任意位置添加或移除元素delete1234const ninjas = ["Yagyu", "Kuma", "Hattori", "Fuma"]delete ninjas[1]console.log(ninjas) // [ 'Yagyu', &lt;1 empty item&gt;, 'Hattori', 'Fuma' ]console.log(ninjas.length) // 4 用 delete 删除数组中的元素，实际上等于用 undefined 替换掉了删除的元素，导致数组中的对应位置出现一个“洞”（undefined），数组仍保持原来的长度。因此不符合最初的目的。 splice12345678910const ninjas = ["Yagyu", "Kuma", "Hattori", "Fuma"]var removedItems = ninjas.splice(1, 1)console.log(removedItems) // [ 'Kuma' ]console.log(ninjas.length) // 3console.log(ninjas) // [ 'Yagyu', 'Hattori', 'Fuma' ]removedItems = ninjas.splice(1, 2, "Mochizuki", "Yoshi", "Momochi")console.log(removedItems) // [ 'Hattori', 'Fuma' ]console.log(ninjas) // [ 'Yagyu', 'Mochizuki', 'Yoshi', 'Momochi' ]console.log(ninjas.length) // 4 移除元素时，splice 方法接收两个参数：被移除片段的起点的索引和片段的长度，返回移除的元素。 splice 方法还可用于在数组的指定位置插入元素。如上面代码中的 splice(1, 2, &quot;Mochizuki&quot;, &quot;Yoshi&quot;, &quot;Momochi&quot;) 即表示从索引 1 开始移除 2 个元素，并在该位置处添加 &quot;Mochizuki&quot;、&quot;Yoshi&quot;、&quot;Momochi&quot; 三个元素。 三、数组的一般操作遍历数组for1234567const ninjas = ["Yagyu", "Kuma", "Hattori"]for(let i = 0; i &lt; ninjas.length; i++)&#123; console.log(ninjas[i])&#125;// Yagyu// Kuma// Hattori forEach12345678const ninjas = ["Yagyu", "Kuma", "Hattori"]ninjas.forEach(ninja =&gt; &#123; console.log(ninja)&#125;)// Yagyu// Kuma// Hattori MappingforEach12345678910111213const ninjas = [ &#123;name: "Yagyu", weapon: "shuriken"&#125;, &#123;name: "Yoshi", weapon: "katana"&#125;, &#123;name: "Kuma", weapon: "wakizashi"&#125;]const weapons = []ninjas.forEach(ninja =&gt; &#123; weapons.push(ninja.weapon)&#125;)console.log(weapons)// [ 'shuriken', 'katana', 'wakizashi' ] map123456789const ninjas = [ &#123;name: "Yagyu", weapon: "shuriken"&#125;, &#123;name: "Yoshi", weapon: "katana"&#125;, &#123;name: "Kuma", weapon: "wakizashi"&#125;]const weapons = ninjas.map(ninja =&gt; ninja.weapon)console.log(weapons)// [ 'shuriken', 'katana', 'wakizashi' ] map 将其 callback 函数（即 ninja =&gt; ninja.weapon）应用到数组的每一个元素上，并以 callback 函数的返回值 ninja.weapon 为元素创建一个新的数组作为 map 的返回值。 Testingevery1234567891011const ninjas = [ &#123;name: "Yagyu", weapon: "shuriken"&#125;, &#123;name: "Yoshi" &#125;, &#123;name: "Kuma", weapon: "wakizashi"&#125;]const allNinjasAreNamed = ninjas.every(ninja =&gt; "name" in ninja)console.log(allNinjasAreNamed) // trueconst allNinjasAreArmed = ninjas.every(ninja =&gt; "weapon" in ninja)console.log(allNinjasAreArmed) // false every 方法接收一个 callback 函数，将其应用到数组的每一个元素。若所有的 callback 执行后的返回值都为 true，则 every 返回 true；否则 every 返回 false。 some1234567891011const ninjas = [ &#123;name: "Yagyu", weapon: "shuriken"&#125;, &#123;name: "Yoshi" &#125;, &#123;name: "Kuma", weapon: "wakizashi"&#125;]const allNinjasAreNamed = ninjas.every(ninja =&gt; "name" in ninja)console.log(allNinjasAreNamed) // trueconst allNinjasAreArmed = ninjas.some(ninja =&gt; "weapon" in ninja)console.log(allNinjasAreArmed) // true some 方法接收一个 callback 函数，将其应用到数组的每一个元素。若至少有一个数组元素应用 callback 函数后返回 true，则 some 返回 true；否则 some 返回 false。 即 every 可以检查数组的所有元素是否都满足一个特定的条件，该条件由 callback 函数指定。而 some 用于检查是否至少有一个数组元素满足某个特定条件。 Searchingfind1234567891011121314151617const ninjas = [ &#123;name: "Yagyu", weapon: "shuriken"&#125;, &#123;name: "Yoshi" &#125;, &#123;name: "Kuma", weapon: "wakizashi"&#125;]const ninjaWithWakizashi = ninjas.find(ninja =&gt; &#123; return ninja.weapon === "wakizashi"&#125;)console.log(ninjaWithWakizashi)// &#123; name: 'Kuma', weapon: 'wakizashi' &#125;const ninjaWithKatana = ninjas.find(ninja =&gt; &#123; return ninja.weapon === "katana"&#125;)console.log(ninjaWithKatana)// undefined find 方法会以 callback 函数为规则搜索数组中的元素，返回满足条件（callback 返回 true）的第一个元素。若所有元素都不满足，则返回 undefined。 filter123456789101112const ninjas = [ &#123;name: "Yagyu", weapon: "shuriken"&#125;, &#123;name: "Yoshi" &#125;, &#123;name: "Kuma", weapon: "wakizashi"&#125;]const armedNinjas = ninjas.filter(ninja =&gt; "weapon" in ninja)console.log(armedNinjas)// [// &#123; name: 'Yagyu', weapon: 'shuriken' &#125;,// &#123; name: 'Kuma', weapon: 'wakizashi' &#125;// ] filter 方法则用来以 callback 函数为规则搜索多个数组元素，符合条件（callback 返回 true）的多个元素以新数组的形式返回。 Finding index1234567const ninjas = ["Yagyu", "Yoshi", "Kuma", "Yoshi"]console.log(ninjas.indexOf("Yoshi")) // 1console.log(ninjas.lastIndexOf("Yoshi")) // 3const yoshiIndex = ninjas.findIndex(ninja =&gt; ninja === "Yoshi")console.log(yoshiIndex) // 1 Sortingsort 方法的常见形式：array.sort((a, b) =&gt; a - b) 传递给 sort 的 callback 函数（如上面的 (a, b) =&gt; a - b）即为具体的排序规则，可能达到的效果如下： callback 函数的返回值小于 0，则 a 排在 b 前面 callback 函数的返回值等于 0，则 a 与 b 在排序上权重相同 callback 函数的返回值大于 0，则 a 排在 b 后面 1234567891011121314const ninjas = [&#123;name: "Yoshi"&#125;, &#123;name: "Hattori"&#125;, &#123;name: "Kuma"&#125;]ninjas.sort(function(ninja1, ninja2)&#123; if(ninja1.name &lt; ninja2.name) &#123; return -1 &#125; if(ninja1.name &gt; ninja2.name) &#123; return 1 &#125; return 0&#125;)console.log(ninjas)// [ &#123; name: 'Hattori' &#125;, &#123; name: 'Kuma' &#125;, &#123; name: 'Yoshi' &#125; ]ninjas.sort((ninja1, ninja2) =&gt; ninja1.name.length - ninja2.name.length)console.log(ninjas)// [ &#123; name: 'Kuma' &#125;, &#123; name: 'Yoshi' &#125;, &#123; name: 'Hattori' &#125; ] AggregatingforEach12345678const numbers = [1, 2, 3, 4]let sum = 0numbers.forEach(number =&gt; &#123; sum += number&#125;)console.log(sum) // 10 reduce1234const numbers = [1, 2, 3, 4]const sum = numbers.reduce((aggregated, number) =&gt; aggregated + number, 0)console.log(sum) // 10 参考资料Secrets of the JavaScript Ninja, Second Edition]]></content>
      <categories>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>DataStructure</tag>
        <tag>Development</tag>
        <tag>JavaScript</tag>
        <tag>Array</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vue.js 通过 Event Bus 实现 Components 间的事件通信（实例）]]></title>
    <url>%2F2020%2F08%2F19%2Fvue-js-event-bus-for-communication-between-components%2F</url>
    <content type="text"><![CDATA[一、环境配置 vue create productapp --default npm install bootstrap@4.0.0 npm install --save core-js 二、源代码productapp/src/main.js：123456789101112131415import Vue from 'vue'import App from './App.vue'import "../node_modules/bootstrap/dist/css/bootstrap.min.css"Vue.config.productionTip = falsenew Vue(&#123; render: h =&gt; h(App), provide: function () &#123; return &#123; eventBus: new Vue() &#125; &#125;&#125;).$mount('#app') productapp/src/App.vue：123456789101112131415161718192021&lt;template&gt; &lt;div class=&quot;container-fluid&quot;&gt; &lt;div class=&quot;row&quot;&gt; &lt;div class=&quot;col-8 m-3&quot;&gt; &lt;product-display&gt;&lt;/product-display&gt; &lt;/div&gt; &lt;div class=&quot;col m-3&quot;&gt; &lt;product-editor&gt;&lt;/product-editor&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;import ProductDisplay from &quot;./components/ProductDisplay&quot;;import ProductEditor from &quot;./components/ProductEditor&quot;;export default &#123; name: &quot;App&quot;, components: &#123; ProductDisplay, ProductEditor &#125;&#125;;&lt;/script&gt; productapp/src/components/ProductDisplay.vue：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;template&gt; &lt;div&gt; &lt;table class=&quot;table table-sm table-striped table-bordered&quot;&gt; &lt;tr&gt; &lt;th&gt;ID&lt;/th&gt;&lt;th&gt;Name&lt;/th&gt;&lt;th&gt;Price&lt;/th&gt;&lt;th&gt;&lt;/th&gt; &lt;/tr&gt; &lt;tbody&gt; &lt;tr v-for=&quot;p in products&quot; v-bind:key=&quot;p.id&quot;&gt; &lt;td&gt;&#123;&#123; p.id &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; p.name &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; p.price &#125;&#125;&lt;/td&gt; &lt;td&gt; &lt;button class=&quot;btn btn-sm btn-primary&quot; @click=&quot;editProduct(p)&quot;&gt; Edit &lt;/button&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt; import Vue from &quot;vue&quot;; export default &#123; data: function () &#123; return &#123; products: [ &#123; id: 1, name: &quot;Kayak&quot;, price: 275 &#125;, &#123; id: 2, name: &quot;Lifejacket&quot;, price: 48.95 &#125;, &#123; id: 3, name: &quot;Soccer Ball&quot;, price: 19.50 &#125;, &#123; id: 4, name: &quot;Corner Flags&quot;, price: 39.95 &#125;, &#123; id: 5, name: &quot;Stadium&quot;, price: 79500 &#125;] &#125; &#125;, methods: &#123; editProduct(product) &#123; this.eventBus.$emit(&quot;edit&quot;, product); &#125;, processComplete(product) &#123; let index = this.products.findIndex(p =&gt; p.id == product.id); if (index == -1) &#123; return; &#125; else &#123; Vue.set(this.products, index, product); &#125; &#125; &#125;, inject: [&quot;eventBus&quot;], created() &#123; this.eventBus.$on(&quot;complete&quot;, this.processComplete); &#125; &#125;&lt;/script&gt; productapp/src/components/ProductEditor.vue：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;template&gt; &lt;div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label&gt;ID&lt;/label&gt; &lt;input v-model.number=&quot;product.id&quot; class=&quot;form-control&quot; /&gt; &lt;label&gt;Name&lt;/label&gt; &lt;input v-model=&quot;product.name&quot; class=&quot;form-control&quot; /&gt; &lt;label&gt;Price&lt;/label&gt; &lt;input v-model.number=&quot;product.price&quot; class=&quot;form-control&quot; /&gt; &lt;/div&gt; &lt;div class=&quot;text-center&quot;&gt; &lt;button class=&quot;btn btn-primary&quot; @click=&quot;save&quot;&gt;Save&lt;/button&gt; &lt;button class=&quot;btn btn-secondary&quot; @click=&quot;cancel&quot;&gt;Cancel&lt;/button&gt; &lt;/div&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; data: function() &#123; return &#123; product: &#123;&#125; &#125;; &#125;, methods: &#123; startEdit(product) &#123; this.product = &#123; id: product.id, name: product.name, price: product.price &#125;; &#125;, save() &#123; this.eventBus.$emit(&quot;complete&quot;, this.product); console.log(`Edit Complete: $&#123;JSON.stringify(this.product)&#125;`); this.product = &#123;&#125; &#125;, cancel() &#123; this.product = &#123;&#125;; &#125; &#125;, inject: [&quot;eventBus&quot;], created() &#123; this.eventBus.$on(&quot;edit&quot;, this.startEdit); &#125;&#125;;&lt;/script&gt; 三、运行效果 参考资料Pro Vue.js 2]]></content>
      <categories>
        <category>Program</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Web</tag>
        <tag>Development</tag>
        <tag>Vue</tag>
        <tag>Frontend</tag>
        <tag>JavaScript</tag>
        <tag>Components</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django 借助 ldap3 自定义支持 LDAP 域账号的认证后端]]></title>
    <url>%2F2020%2F08%2F19%2Fdjango-add-ldap-authentication-backend-with-ldap3%2F</url>
    <content type="text"><![CDATA[一、项目初始化 pip install django ldap3 django-admin startproject auth_demo cd auth_demo django-admin startapp authldap python manage.py migrate 二、编写自定义认证后端Django 的认证系统支持的自定义插件，本质上是一个实现了 get_user(user_id) 和 authenticate(request, **credentials) 方法的类。其中 get_user 接收 user_id（可以是用户名、ID 等，但必须为 user 对象的主键）返回匹配的用户对象或 None；authenticate 接收 request 参数以及认证信息，根据最终的认证结果返回用户对象（认证通过）或 None（认证不通过）。 auth_demo/authldap/authbackends.py：12345678910111213141516171819202122232425262728293031323334353637# auth_demo/authldap/authbackends.pyfrom django.contrib.auth.backends import BaseBackendfrom django.contrib.auth.models import Userimport ldap3# 替换为实际的域控 IPLDAP_HOST = 'xx.xx.xx.xx'class LdapBackend(BaseBackend): def authenticate(self, request, username=None, password=None): if ldap_auth(username, password): try: user = User.objects.get(username=username) except User.DoesNotExist: user = User(username=username) if username.endswith('admin'): user.is_staff = True user.is_superuser = True user.save() return user return None def get_user(self, user_id): try: return User.objects.get(pk=user_id) except User.DoesNotExist: return None# @example.com 改为自己域环境的域名def ldap_auth(username, password): username = username + '@example.com'\ if '@' not in username else username server = ldap3.Server(LDAP_HOST, port=636, use_ssl=True) conn = ldap3.Connection(server, username, password) return conn.bind() 代码中的 ldap_auth 函数用于执行 LDAP 认证，将 Django 收到的认证信息传递给 LDAP 服务器，通过 Connection 对象的 bind() 方法确认用户名密码是否正确。正确返回 True，不正确则返回 False。 LDAP 认证通过后，再检查 User 数据库表中是否已包含该用户。若该用户存在，则直接返回对应的 User 对象；若该用户不存在（第一次登录），则先在 User 中创建同名的新用户并添加权限等，保存后返回刚创建的 User 对象。 假设所有需要添加 Django 管理员权限的账号名字都以 admin 结尾。。。 配置认证后端Django 认证时使用的插件列表由 settings.py 中的 AUTHENTICATION_BACKENDS 字段指定，默认值为 [&#39;django.contrib.auth.backends.ModelBackend&#39;]。因此为了用上前面创建的自定义认证后端，需在 auth_demo/auth_demo/settings.py 配置文件中添加以下内容：1234AUTHENTICATION_BACKENDS = [ 'auth_ldap.authbackends.LdapBackend', 'django.contrib.auth.backends.ModelBackend' ] 三、测试 运行 python manage.py runserver 0.0.0.0:8000 启动 Web 服务 在域中创建 testaccount 和 testaccount-admin 测试账号 访问 http://xx.xx.xx.xx:8000/admin 进入 Django 后台，用测试账号登录 效果如下： 四、初始化用户组首先梳理下之前代码的逻辑流程： Django 后台获取前端传入的认证信息，并转发给 LDAP 服务器进行认证 认证成功且该用户不在数据库中（首次登录），则创建对应的用户并将其返回；该用户已存在则直接返回 创建用户时，若用户名以 admin 结尾，则额外向其添加 staff 权限和管理员权限 认证失败返回 None 假设在数据库中创建新用户时，需要根据一定的规则对用户的属组进行初始化（比如名称以 admin 结尾的用户自动添加到 admin 组中）。最终的代码如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# auth_demo/authldap/authbackends.pyfrom django.contrib.auth.backends import BaseBackendfrom django.contrib.auth.models import User, Groupimport ldap3# 替换为实际的域控 IPLDAP_HOST = &apos;xx.xx.xx.xx&apos;class LdapBackend(BaseBackend): def authenticate(self, request, username=None, password=None): if ldap_auth(username, password): try: user = User.objects.get(username=username) except User.DoesNotExist: user = User(username=username) user.save() if username.endswith(&apos;admin&apos;): user.is_staff = True user.is_superuser = True add_group(user) user.save() return user return None def get_user(self, user_id): try: return User.objects.get(pk=user_id) except User.DoesNotExist: return None# @example.com 改为自己域环境的域名def ldap_auth(username, password): username = username + &apos;@example.com&apos;\ if &apos;@&apos; not in username else username server = ldap3.Server(LDAP_HOST, port=636, use_ssl=True) conn = ldap3.Connection(server, username, password) return conn.bind()def add_group(user, groupname=&apos;admin&apos;): try: group = Group.objects.get(name=groupname) except Group.DoesNotExist: group = Group(name=groupname) group.save() group.user_set.add(user) group.save() 删除上一步中数据库里新建的 testaccount-admin 账号，重新登录测试。则 LDAP 认证成功后，Django 后台会在数据库中新建 testaccount-admin 账号并将其添加至 admin 用户组中（如 admin 组不存在则新建该用户组）。即在新建账号的同时初始化其属组。 参考资料Customizing authentication in Django]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Python</tag>
        <tag>Web</tag>
        <tag>Development</tag>
        <tag>Django</tag>
        <tag>Authentication</tag>
        <tag>LDAP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django REST framework 模型中 Many-to-many 关系的序列化]]></title>
    <url>%2F2020%2F08%2F19%2Fdjango-rest-framework-many-to-many-relations%2F</url>
    <content type="text"><![CDATA[一、模型12345678910111213141516171819# blogs/models.pyfrom django.db import modelsclass TagModel(models.Model): tag = models.CharField(max_length=20, unique=True) description = models.CharField(max_length=100) class Meta: db_table = 'blog_tags'class PostModel(models.Model): title = models.CharField(max_length=50) update_date = models.DateTimeField(auto_now=True) tags = models.ManyToManyField(TagModel) class Meta: db_table = 'blog_posts' 二、Serializers123456789101112131415# blogs/serializers.pyfrom rest_framework import serializersfrom blogs.models import TagModel, PostModelclass TagSerializer(serializers.ModelSerializer): class Meta: model = TagModel fields = '__all__'class PostSerializer(serializers.ModelSerializer): class Meta: model = PostModel fields = '__all__' 三、视图1234567891011121314# blogs/views.pyfrom rest_framework.viewsets import ModelViewSetfrom blogs.models import TagModel, PostModelfrom blogs.serializers import TagSerializer, PostSerializerclass TagViewSet(ModelViewSet): queryset = TagModel.objects.all() serializer_class = TagSerializerclass PostViewSet(ModelViewSet): queryset = PostModel.objects.all() serializer_class = PostSerializer 四、URLs123456789101112# blogs/urls.pyfrom django.urls import include, pathfrom rest_framework import routersfrom blogs.views import TagViewSet, PostViewSetrouter = routers.DefaultRouter()router.register(r'tags', TagViewSet)router.register(r'posts', PostViewSet)urlpatterns = [ path('', include(router.urls))] 修改项目总体的 URL 配置 urls.py：1234567from django.contrib import adminfrom django.urls import path, includeurlpatterns = [ path('admin/', admin.site.urls), path('blog/', include('blogs.urls'))] 五、效果123456789101112131415161718# GET http://127.0.0.1:8002/blog/tags/[ &#123; &quot;description&quot;: &quot;Technique for python programming&quot;, &quot;id&quot;: 1, &quot;tag&quot;: &quot;Python&quot; &#125;, &#123; &quot;description&quot;: &quot;Shell programming tricks&quot;, &quot;id&quot;: 2, &quot;tag&quot;: &quot;Shell&quot; &#125;, &#123; &quot;description&quot;: &quot;Linux system administration&quot;, &quot;id&quot;: 3, &quot;tag&quot;: &quot;Linux&quot; &#125;] 123456789101112# GET http://127.0.0.1:8002/blog/posts/[ &#123; &quot;id&quot;: 1, &quot;tags&quot;: [ 1, 3 ], &quot;title&quot;: &quot;Python for linux administration&quot;, &quot;update_date&quot;: &quot;2020-08-11T07:01:50.893976Z&quot; &#125;] 六、自定义序列化方式为了在获取 posts 列表时，每条 post 中的 tags 不仅仅显示 id，还显示对应的标签名称。修改代码如下：1234567891011121314151617181920212223# blogs/serializers.pyfrom rest_framework import serializersfrom blogs.models import TagModel, PostModelclass TagSerializer(serializers.ModelSerializer): class Meta: model = TagModel fields = '__all__'class TagsReadOnly(serializers.ModelSerializer): class Meta: model = TagModel fields = ['id', 'tag']class PostSerializer(serializers.ModelSerializer): tags = TagsReadOnly(many=True) class Meta: model = PostModel fields = '__all__' 效果：123456789101112131415161718# GET http://127.0.0.1:8002/blog/posts/[ &#123; &quot;id&quot;: 1, &quot;tags&quot;: [ &#123; &quot;id&quot;: 1, &quot;tag&quot;: &quot;Python&quot; &#125;, &#123; &quot;id&quot;: 3, &quot;tag&quot;: &quot;Linux&quot; &#125; ], &quot;title&quot;: &quot;Python for linux administration&quot;, &quot;update_date&quot;: &quot;2020-08-11T07:01:50.893976Z&quot; &#125;] 但此时若使用 POST 或 PUT 方法新增或更新数据，会报出如下错误（即在新增或修改 post 的同时，会尝试创建关联的 tags，但这些 tags 本就已经存在，从而导致冲突）：123456789&#123; "tags": [ &#123; "tag": [ "tag model with this tag already exists." ] &#125; ]&#125; 测试 POST 和 PUT 动作时使用的 JSON 数据格式如下：123456789&#123; "tags": [ &#123; "id": 1, "tag": "Python" &#125; ], "title": "An interesting post"&#125; 为了使 posts 接口在接收数据时支持列表类型的 tags（类似 &quot;tags&quot;: [1, 2, 3] 这种）且能够成功更新，可以选择覆盖 PostSerializer 的 to_internal_value 和 create 方法：1234567891011121314151617181920212223242526272829303132333435# blogs/serializers.pyfrom rest_framework import serializersfrom blogs.models import TagModel, PostModelclass TagSerializer(serializers.ModelSerializer): class Meta: model = TagModel fields = '__all__'class TagsReadOnly(serializers.ModelSerializer): class Meta: model = TagModel fields = ['id', 'tag']class PostSerializer(serializers.ModelSerializer): tags = TagsReadOnly(many=True) class Meta: model = PostModel fields = '__all__' def to_internal_value(self, data): return data def create(self, validated_data): tags_data = validated_data.pop('tags') post = PostModel.objects.create(**validated_data) tags = [TagModel.objects.get( pk=id) for id in tags_data] post.tags.set(tags) post.save() return post 其中 to_internal_value 方法用于验证前端传入的数据（上述代码中不做任何验证）；create 方法用于新增或更新后台数据。 此时再向 posts 接口 POST 或 PUT 数据时，就可以使用如下格式：1234&#123; "tags": [1, 2, 3], "title": "An interesting post"&#125;]]></content>
      <tags>
        <tag>Python</tag>
        <tag>Web</tag>
        <tag>Development</tag>
        <tag>Django</tag>
        <tag>REST</tag>
        <tag>API</tag>
        <tag>Relations</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解 JavaScript（ECMAScript 6）—— Proxy 与 Reflection API]]></title>
    <url>%2F2020%2F08%2F19%2Funderstanding-javascript-ecmascript6-proxy-and-reflection-api%2F</url>
    <content type="text"><![CDATA[一、创建 Proxy12345678910let target = &#123;&#125;let proxy = new Proxy(target, &#123;&#125;)proxy.name = "proxy"console.log(proxy.name) // proxyconsole.log(target.name) // proxytarget.name = "target"console.log(proxy.name) // targetconsole.log(target.name) // target 在上面的例子中，由 Proxy 构造器创建的 proxy 对象会将自身的所有操作直接转发给 target。当 proxy.name 被赋值为 &quot;proxy&quot; 时，target 对象也会创建 name 属性并获得同样的值。实际上 proxy 对象本身并不创建和存储 name 属性，它只是转发对应的操作给 target。 类似的，proxy.name 与 target.name 的值始终保持一致，因为它们实际上都指向了 target.name。这也意味着给 target.name 赋予一个新的值时，该变化也会反映到 proxy.name 上。 使用 set Trap 验证属性Proxy 允许开发者主动拦截本该转发给 target 对象的底层操作，这些拦截行为通过 trap 实现。每个 trap 都可以覆盖 JavaScript 对象的某些内置行为，即 proxy 允许通过 trap 拦截并修改指向 target 对象的操作。 假设需要创建一个新添加的属性值只能是数字类型的对象，就可以借助 set trap 覆盖默认的赋值行为。代码如下：12345678910111213141516171819202122232425let target = &#123; name: "target"&#125;let proxy = new Proxy(target, &#123; set(trapTarget, key, value, receiver) &#123; if (!trapTarget.hasOwnProperty(key)) &#123; if (isNaN(value)) &#123; throw new TypeError("New property must be a number.") &#125; &#125; return Reflect.set(trapTarget, key, value, receiver) &#125;&#125;)proxy.count = 1console.log(proxy.count) // 1console.log(target.count) // 1proxy.name = "proxy"console.log(proxy.name) // proxyconsole.log(target.name) // proxyproxy.anotherName = "proxy"// TypeError: New property must be a number. set trap 中的四个参数含义如下： trapTarget：接收新属性的对象（即 proxy 指向的 target） key：新属性对应的 key value：新属性对应的 value receiver：通常为 proxy 自身 Reflect.set() 是与 set trap 相对应的原始方法，表示被覆盖前的默认的赋值行为。 使用 get Trap 令程序读取不存在属性时报错JavaScript 在读取不存在的属性时并不会报错，而是返回 undefined。12let target = &#123;&#125;console.log(target.name) // undefined 可以借助 get trap 修改读取对象属性时的默认行为：1234567891011121314let proxy = new Proxy(&#123;&#125;, &#123; get(trapTarget, key, receiver) &#123; if (!(key in receiver)) &#123; throw new TypeError("Property " + key + " doesn't exist.") &#125; return Reflect.get(trapTarget, key, receiver) &#125;&#125;)proxy.name = "proxy"console.log(proxy.name) // proxyconsole.log(proxy.nme)// TypeError: Property nme doesn't exist. 通过 deleteProperty Trap 防止删除属性JavaScript 中使用 delete 操作符删除对象的属性：123456789101112131415let target = &#123; name: "target", value: 42&#125;Object.defineProperty(target, "name", &#123; configurable: false &#125;)console.log("value" in target) // truelet result1 = delete target.valueconsole.log(result1) // trueconsole.log("value" in target) // falselet result2 = delete target.nameconsole.log(result2) // falseconsole.log("name" in target) // true 使用 deleteProxy Trap 防止属性被意外删除：123456789101112131415161718192021222324let target = &#123; name: "target", value: 42&#125;let proxy = new Proxy(target, &#123; deleteProperty(trapTarget, key) &#123; if (key === "value") &#123; return false &#125; else &#123; return Reflect.deleteProperty(trapTarget, key) &#125; &#125;&#125;)console.log("value" in proxy) // truelet result1 = delete proxy.valueconsole.log(result1) // falseconsole.log("value" in proxy) // truelet result2 = delete proxy.nameconsole.log(result2) // trueconsole.log("name" in proxy) // false 二、Proxy 的现实应用logging12345678910111213141516171819202122function makeLoggable(target) &#123; return new Proxy(target, &#123; get: (target, property) =&gt; &#123; console.log("Reading " + property) return target[property] &#125;, set: (target, property, value) =&gt; &#123; console.log("Writing value " + value + " to " + property) target[property] = value &#125; &#125;)&#125;let ninja = &#123; name: "Yoshi" &#125;ninja = makeLoggable(ninja)console.log(ninja.name)ninja.weapon = "sword"// Reading name// Yoshi// Writing value sword to weapon 性能测试123456789101112131415161718192021function isPrime(number) &#123; if (number &lt; 2) &#123; return false &#125; for (let i = 2; i &lt; number; i++) &#123; if (number % i === 0) &#123; return false &#125; &#125; return true&#125;isPrime = new Proxy(isPrime, &#123; apply: (target, thisArg, args) =&gt; &#123; console.time("isPrime") const result = target.apply(thisArg, args) console.timeEnd("isPrime") return result &#125;&#125;)console.log(isPrime(1358765377))// isPrime: 6815.107ms// true 自动添加属性12345678910111213141516171819202122function Folder() &#123; return new Proxy(&#123;&#125;, &#123; get: (target, property) =&gt; &#123; console.log("Reading " + property) if(!(property in target)) &#123; target[property] = new Folder() &#125; return target[property] &#125; &#125;)&#125;const rootFolder = new Folder()rootFolder.ninjasDir.firstNinjaDir.ninjaFile = "yoshi.txt"// Reading ninjasDir// Reading firstNinjaDirconsole.log(rootFolder.ninjasDir.firstNinjaDir.ninjaFile)// Reading ninjasDir// Reading firstNinjaDir// Reading ninjaFile// yoshi.txt 参考资料Understanding ECMAScript 6Secrets of the JavaScript Ninja, Second Edition]]></content>
      <categories>
        <category>Program</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Advanced</tag>
        <tag>JavaScript</tag>
        <tag>Proxy</tag>
        <tag>ECMAScript6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaScript 解密 —— 理解对象]]></title>
    <url>%2F2020%2F08%2F06%2Fsecrets-of-javascript-understanding-objects%2F</url>
    <content type="text"><![CDATA[一、prototypesPrototype 是一个对象，其中定义的属性和功能可以自动被其他对象访问。Prototype 可以发挥类似于传统的 OO 语言中类的作用，事实上 JavaScript 中的 prototype 主要用途就是编写 OO 形式的代码。 在 JavaScript 中，对象表示一系列已命名的属性及其属性值的合集。12345let obj = &#123; prop1: 1, // 属性值为基本类型 prop2: function () &#123;&#125;, // 属性值为函数 prop3: &#123;&#125; // 属性值为另一个对象&#125; 关联到某个对象上的属性可以很容易地被修改或删除。123456789101112let obj = &#123; prop1: 1, // 属性值为基本类型 prop2: function () &#123;&#125;, // 属性值为函数 prop3: &#123;&#125; // 属性值为另一个对象&#125;obj.prop1 = [] // 将 prop1 属性的值改为其他类型delete obj.prop2 // 删除某个属性obj.prop4 = "Hello" // 添加一个新的属性console.log(obj)// &#123; prop1: [], prop3: &#123;&#125;, prop4: 'Hello' &#125; 每个对象都可以拥有一个 prototype 的引用，在对象本身不包含某个属性时，可以由 prototype 对象去寻找该属性。12345678910111213141516171819const yoshi = &#123; skulk: true &#125;const hattori = &#123; sneak: true &#125;const kuma = &#123; creep: true &#125;console.log("skulk" in yoshi) // trueconsole.log("sneak" in yoshi) // falseconsole.log("creep" in yoshi) // false// 通过 setPrototypeOf 方法将 hattori 设置为// yoshi 对象的 prototype，yoshi 此时可以访问 sneak 属性Object.setPrototypeOf(yoshi, hattori)console.log("sneak" in yoshi) // trueconsole.log("creep" in yoshi) // false// 将 kuma 设置为 hattori 对象的 prototype，// yoshi 此时可以访问 creep 属性Object.setPrototypeOf(hattori, kuma)console.log("sneak" in yoshi) // trueconsole.log("creep" in yoshi) // true prototype 与对象构建JavaScript 中，最简单的创建新对象的语法如下：123456const warrior = &#123;&#125;warrior.name = 'Saito'warrior.occupation = 'marksman'console.log(warrior)// &#123; name: 'Saito', occupation: 'marksman' &#125; 对于有面向对象编程背景的人来说，上述方式看上去缺少了很多东西，比如没有一个用来初始化对象的类构造器。此外如果需要同时创建多个相同类型的对象，手动地一个一个为对象关联属性则工作量太大且容易出问题。 和其他常见的 OO 语言类似，JavaScript 也是使用 new 关键字通过构造器初始化对象。只不过该过程中被未出现类的定义，new 关键字实际上调用的是构造器函数。123456789101112131415function Ninja() &#123;&#125;// 每个函数都包含一个内置的 prototype 对象，可以被随意修改Ninja.prototype.swingSword = function () &#123; return true&#125;// 作为函数调用 Ninja()，不会创建任何对象const ninja1 = Ninja()console.log(ninja1) // undefined// 作为构造器调用，一个新的对象被创建且作为构造器函数的上下文（this），// 构造器函数的 prototype 成为新创建对象的 prototypeconst ninja2 = new Ninja()console.log(ninja2) // Ninja &#123;&#125;console.log(ninja2.swingSword()) // true 当某个函数作为构造器函数使用时，构造器函数的 prototype 将成为新创建对象的 prototype。在上面的例子中，用 swingSword 方法扩展了 Ninja.prototype，当 ninja2 对象被创建后，其 prototype 就被设置成 Ninja 的 prototype。因此，当后面我们访问 ninja2 对象的 swingSword 属性时，对于属性值的搜索最终传递给 Ninja 的 prototype 对象。此外，所有通过 Ninja 构造器创建的对象都可以访问 swingSword 方法。 实例属性当函数通过 new 关键字作为构造器调用时，其本身即成为新创建对象的上下文。除了通过 prototype 暴露属性外，还可以使用 this 关键字在构造器函数中初始化对象实例。12345678910111213141516function Ninja() &#123; this.swung = false // instance method this.swingSword = function () &#123; return !this.swung &#125;&#125;// prototype methodNinja.prototype.swingSword = function () &#123; return this.swung&#125;const ninja = new Ninja()console.log(ninja.swingSword()) // true 上面代码的执行结果表明，实例方法会覆盖同名的 prototype 方法。 在构造器函数中，this 关键字指向通过 new 创建的对象。因此构造器中添加的属性会直接在新的 ninja 对象中创建。当我们需要访问 ninja 对象的 swingSword 属性时，本就没有必要再从 prototype 中搜索。ninja 对象本身已经有了通过构造器创建的同名的实例属性。 简单来说，每个对象都包含自己版本的通过构造器创建的属性，同时也都能够访问 prototype 的属性（名字相同时实例属性优先）。 Side effects123456789101112131415161718192021222324252627282930// 定义一个构造器函数，具有 swung 属性function Ninja() &#123; this.swung = true&#125;// 通过 new 调用构造器函数，创建一个 Ninja 的实例const ninja1 = new Ninja()// 在 ninja1 实例创建之后，为 prototype 添加 swingSword 方法Ninja.prototype.swingSword = function() &#123; return this.swung&#125;// 即便 swingSword 方法是后面添加到 prototype 的，ninja1 实例仍能访问console.log(ninja1.swingSword()) // true// 完全覆盖 Ninja 的 prototypeNinja.prototype = &#123; pierce: function() &#123; return true &#125;&#125;// Ninja 的 prototype 被完全替换后，ninja1 实例仍能访问 swingSword 方法console.log(ninja1.swingSword()) // true// 再次新建 ninja2 实例，此时该实例不能访问 swingSword 但可以访问 pierce 方法const ninja2 = new Ninja()console.log(ninja2.pierce()) // trueconsole.log(ninja2.swingSword) // undefined 从上面代码中可以看出，构造器函数的 prototype 可以随意被替换，但之前已经生成的对象实例仍指向旧的 prototype。 Object typing123456789function Ninja() &#123;&#125;const ninja = new Ninja()console.log(typeof ninja) // objectconsole.log(ninja instanceof Ninja) // trueconsole.log(ninja.constructor === Ninja) // trueconst ninja2 = new ninja.constructor()console.log(ninja2 instanceof Ninja) // true instanceof 操作符可以帮助我们确定某个对象实例是否由某个特定的构造器创建。此外，还可以借助能够被所有实例访问的 constructor 属性，因为该属性一定指向原始的构造器函数。又因为 constructor 属性是对原始构造器的引用，它因此也可以用来实例化新的对象。 二、继承通过 prototype 实现继承12345678910function Person() &#123;&#125;Person.prototype.dance = function() &#123;&#125;function Ninja() &#123;&#125;Ninja.prototype = new Person()const ninja = new Ninja()console.log(ninja instanceof Ninja) // trueconsole.log(ninja instanceof Person) // trueconsole.log(typeof ninja.dance) // function 当我们通过 ninja 对象访问 dance 方法时，JavaScript 运行时首先试着检查 ninja 对象本身。ninja 本身并不包含 dance 属性，因此 ninja 对象的 prototype（即 person 对象）继续被搜索。person 对象也不包含 dance 属性，最终 person 对象的 prototype 被搜索检查，dance 方法被找到。这就是 JavaScript 中实现继承的方式。 覆盖 constructor 属性引发的问题在上面的代码中，通过创建一个新的 Person 对象作为 Ninja 构造器的 prototype，令 Ninja 成为 Person 的子类。这种方式会导致原始的 Ninja prototype 被替换，即丢失 constructor 属性。而 constructor 属性对于判断对象的起源非常重要。针对这个问题，可以使用 Object.defineProperty 方法为新的 Ninja.prototype 添加 constructor 属性，将其值设置为 Ninja：1234567891011121314function Person() &#123;&#125;Person.prototype.dance = function() &#123;&#125;function Ninja() &#123;&#125;Ninja.prototype = new Person()Object.defineProperty(Ninja.prototype, "constructor", &#123; enumerable: false, value: Ninja, writable: true&#125;)var ninja = new Ninja()console.log(ninja.constructor === Ninja) // true 三、ES6 中的 classES6 中引入了一个新的 class 关键字，为创建对象、实现继承提供了一种更为优雅的方式，不必再自己通过 prototype 手动实现。12345678910111213class Ninja&#123; constructor(name) &#123; this.name = name &#125; swingSword() &#123; return true &#125;&#125;var ninja = new Ninja("Yoshi")console.log(ninja instanceof Ninja) // trueconsole.log(ninja.name) // Yoshiconsole.log(ninja.swingSword()) // true class 关键字实际上是一种语法糖，上述代码等同于 ES5 中的如下代码：123456789101112function Ninja(name) &#123; this.name = name&#125;Ninja.prototype.swingSword = function() &#123; return true&#125;var ninja = new Ninja('Yoshi')console.log(ninja instanceof Ninja) // trueconsole.log(ninja.name) // Yoshiconsole.log(ninja.swingSword()) // true static methods12345678910111213141516171819class Ninja&#123; constructor(name, level) &#123; this.name = name this.level = level &#125; swingSword() &#123; return true &#125; static compare(ninja1, ninja2) &#123; return ninja1.level - ninja2.level &#125;&#125;var ninja1 = new Ninja("Yoshi", 4)var ninja2 = new Ninja("Hattori", 3)console.log("compare" in ninja1 || "compare" in ninja2) // falseconsole.log(Ninja.compare(ninja1, ninja2) &gt; 0) // trueconsole.log("swingSword" in Ninja) // false compare 这种 static methods 是类级别的代码，在 ES6 之前的代码中，可以这样实现：12function Ninja() &#123;&#125;Ninja.compare = function(ninja1, ninja2) &#123; ... &#125; 继承1234567891011121314151617181920212223242526272829303132class Person &#123; constructor(name) &#123; this.name = name &#125; dance() &#123; return true &#125;&#125;class Ninja extends Person &#123; constructor(name, weapon) &#123; super(name) this.weapon = weapon &#125; wieldWeapon() &#123; return true &#125;&#125;var person = new Person("Bob")console.log(person instanceof Person) // trueconsole.log(person.dance()) // trueconsole.log(person.name) // Bobconsole.log(person instanceof Ninja) // falseconsole.log(person.wieldWeapon) // undefinedvar ninja = new Ninja("Yoshi", "Wakizashi")console.log(ninja instanceof Ninja) // trueconsole.log(ninja.wieldWeapon()) // trueconsole.log(ninja instanceof Person) // trueconsole.log(ninja.name) // Yoshiconsole.log(ninja.dance()) // true 参考资料Secrets of the JavaScript Ninja, Second Edition]]></content>
      <categories>
        <category>Program</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>JavaScript</tag>
        <tag>Class</tag>
        <tag>OOP</tag>
        <tag>Inherit</tag>
        <tag>Object</tag>
        <tag>ECMAScript6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解 JavaScript（ECMAScript 6）—— Sets 与 Maps]]></title>
    <url>%2F2020%2F08%2F05%2Funderstanding-javascript-ecmascript-6-sets-and-maps%2F</url>
    <content type="text"><![CDATA[一、ECMAScript 5 中的 Sets 和 Maps在 ECMAScript 5 中，通常使用对象属性来模拟 set 和 map 数据类型：1234567var set = Object.create(null)set.foo = trueif (set.foo) &#123; // code to execute&#125; 用对象属性作为 set 中的非重复键值，将值设置为 true 表明其存在性。 12345var map = Object.create(null)map.foo = "bar"var value = map.fooconsole.log(value) // bar 不同于 set，map 常常需要获取其中保存的数据，而不仅仅用于检查 key 是否存在。 存在的问题用对象作为 set 和 map 适用于简单的场景，在某些情况下对象属性会显露出一定的局限性。比如所有的对象属性都必须是字符串类型，因此同一个对象中绝不能包含多个（转换成字符串后）一致的键。1234var map = Object.create(null)map[5] = "foo"console.log(map["5"]) // foo 数字类型的键 5 实际上在内部会被转换为字符串 &quot;5&quot;，因此 map[5] 和 map[&quot;5&quot;] 指向的是同一个值。 又比如：123456var map = Object.create(null)var key1 = &#123;&#125;var key2 = &#123;&#125;map[key1] = "foo"console.log(map[key2]) // foo 上面代码中的 map[key1] 和 map[key2] 也是指向同一值的。因为对象 key1 和 key2 转换为字符串后的值同为 &quot;[object Object]&quot;。 二、ECMAScript 6 中的 SetsECMAScript 6 中添加了 Set 类型，即一个包含不重复的有序值的列表。12345678910111213let set = new Set()set.add(5)set.add("5")console.log(set) // Set &#123; 5, '5' &#125;let set2 = new Set()let key1 = &#123;&#125;let key2 = &#123;&#125;set2.add(key1)set2.add(key2)console.log(set2.size) // 2 使用 set 去重：123456789101112let set = new Set()set.add(5)set.add("5")set.add(5)console.log(set) // Set &#123; 5, '5' &#125;let set2 = new Set([1, 2, 3, 4, 5, 5, 5, 5])console.log(set2) // Set &#123; 1, 2, 3, 4, 5 &#125;console.log(set2.has(2)) // trueconsole.log(set2.has(6)) // false forEach：1234567891011let set = new Set([1, 2])set.forEach(function(value, key, ownerSet) &#123; console.log(key + " " + value) console.log(ownerSet === set)&#125;)// 1 1// true// 2 2// true 如果需要在 forEach() 的回调函数中使用 this，可以将 this 作为 forEach() 的第二个参数传递：12345678910111213141516let set = new Set([1, 2])let processor = &#123; output(value) &#123; console.log(value) &#125;, process(dataSet) &#123; dataSet.forEach(function(value) &#123; this.output(value) &#125;, this) &#125;&#125;processor.process(set)// 1// 2 Set 与 Array 的互换：1234567let set = new Set([1, 2, 3, 3, 3, 4, 5])console.log(set)// Set &#123; 1, 2, 3, 4, 5 &#125;let array = [...set]console.log(array)// [ 1, 2, 3, 4, 5 ] 12345678function removeDuplicates(items) &#123; return [...new Set(items)]&#125;let numbers = [1, 2, 3, 3, 3, 4, 5]let noDuplicates = removeDuplicates(numbers)console.log(noDuplicates)// [ 1, 2, 3, 4, 5 ] 三、ECMAScript 6 中的 Maps123456let map = new Map()map.set("title", "Understanding ECMAScript 6")map.set("year", 2016)console.log(map.get("title")) // Understanding ECMAScript 6console.log(map.get("year")) // 2016 可以使用对象作为 Map 中的键，这些键不会转换为另一种形式，且都是唯一的：123456789let map = new Map()let key1 = &#123;&#125;let key2 = &#123;&#125;map.set(key1, 5)map.set(key2, 42)console.log(map.get(key1)) // 5console.log(map.get(key2)) // 42 Map 方法：1234567891011121314151617let map = new Map()map.set("name", "Nicholas")map.set("age", 25)console.log(map.size) // 2console.log(map.has("name")) // trueconsole.log(map.get("name")) // Nicholasmap.delete("name")console.log(map.has("name")) // falseconsole.log(map.get("name")) // undefinedconsole.log(map.size) // 1map.clear()console.log(map.has("age")) // falseconsole.log(map.get("age")) // undefinedconsole.log(map.size) // 0 forEach：12345678910let map = new Map([["name", "Nicholas"], ["age", 25]])map.forEach(function(value, key, ownerMap) &#123; console.log(key + " " + value) console.log(ownerMap === map)&#125;)// name Nicholas// true// age 25// true 参考资料Understanding ECMAScript 6]]></content>
      <categories>
        <category>Program</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Web</tag>
        <tag>Development</tag>
        <tag>JavaScript</tag>
        <tag>EMCAScript6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解 JavaScript（ECMAScript 6）—— 基于 destructuring 的数据访问]]></title>
    <url>%2F2020%2F08%2F05%2Funderstanding-javascript-ecmascript-6-destructuring%2F</url>
    <content type="text"><![CDATA[在 ECMAScript 5 及早期版本中，从对象和数组中获取数据会导致很多冗余代码：12345678910let options = &#123; repeat: true, save: false&#125;let repeat = options.repeat, save = options.saveconsole.log(repeat, save)// true false Object Destrcturing123456789let node = &#123; type: "Identifier", name: "foo"&#125;let &#123; type, name &#125; = nodeconsole.log(type, name)// Identifier foo destructuring 也可以为已经初始化过的变量赋值：1234567891011let node = &#123; type: "Identifier", name: "foo"&#125;let type = "Literal", name = 5;(&#123; type, name &#125; = node)console.log(type, name)// Identifier foo ({ type, name } = node) 外面的小括号是必须的。只有大括号的话，大括号会被看成语句块，而语句块不能位于等号左边。 destructuring 赋值语句可以出现在代码的任何位置：12345678910111213let node = &#123; type: "Identifier", name: "foo"&#125;let type = "Literal", name = 5;function outputInfo(value) &#123; console.log(value === node)&#125;outputInfo(&#123; type, name &#125; = node) // trueconsole.log(type, name) // Identifier foo 默认值123456789let node = &#123; type: "Identifier", name: "foo"&#125;let &#123; type, name, value &#125; = nodeconsole.log(type, name, value)// Identifier foo undefined 123456789let node = &#123; type: "Identifier", name: "foo"&#125;let &#123; type, name, value = true &#125; = nodeconsole.log(type, name, value)// Identifier foo true 嵌套对象的 destructuring12345678910111213141516171819let node = &#123; type: "Identifier", name: "foo", loc: &#123; start: &#123; line: 1, column: 1 &#125;, end: &#123; line: 1, column: 4 &#125; &#125;&#125;let &#123; loc: &#123; start &#125;&#125; = nodeconsole.log(start.line, start.column)// 1 1 Array Destructuring1234567let colors = ["red", "green", "blue"]let [ firstColor, secondColor ] = colorsconsole.log(firstColor, secondColor) // red greenlet [ , , thirdColor ] = colorsconsole.log(thirdColor) // blue ECMAScript 5 中的变量互换：1234567let a = 1, b = 2, tmp;tmp = aa = bb = tmpconsole.log(a, b) // 2 1 ECMAScript 6 中的变量互换：12345let a = 1, b = 2;[ a, b ] = [ b, a ]console.log(a, b) // 2 1 嵌套数组：12345let colors = [ "red", [ "green", "lightgreen" ], "blue" ]let [ firstColor, [ secondColor ] ] = colorsconsole.log(firstColor, secondColor) // red green Rest Items：12345678let colors = [ "red", "green", "blue" ]let [ firstColor, ...restColors ] = colorsconsole.log(firstColor) // "red"console.log(restColors.length) // 2console.log(restColors[0]) // greenconsole.log(restColors[1]) // blue 在 ECMAScript 5 中，可以使用 concat() 方法创建某个数组的克隆：12345var colors = [ "red", "green", "blue" ]var clonedColors = colors.concat()console.log(clonedColors)// [ 'red', 'green', 'blue' ] ECMAScript 6 中则可以使用 rest items 语法创建克隆：12345let colors = [ "red", "green", "blue" ]let [ ...clonedColors ] = colorsconsole.log(clonedColors)// [ 'red', 'green', 'blue' ] 参考资料Understanding ECMAScript 6]]></content>
      <categories>
        <category>Program</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Web</tag>
        <tag>Development</tag>
        <tag>JavaScript</tag>
        <tag>ECMAScript6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解 JavaScript（ECMAScript 6）—— 扩展的对象]]></title>
    <url>%2F2020%2F08%2F05%2Funderstanding-javascript-ecmascript-6-expanded-object%2F</url>
    <content type="text"><![CDATA[一、对象字面量对象字面量（object literal）是 JavaScript 中最常见的模式之一，JSON 即基于它的语法。 在 ECMAScript 5 及更早的版本中，对象字面量即一系列简单的键值对的集合：123456789function createPerson(name, age) &#123; return &#123; name: name, age: age &#125;;&#125;console.log(createPerson('Jack', 16))// &#123; name: 'Jack', age: 16 &#125; 而在 ECMAScript 6 中，则可以通过 property initializer 的简写语法省略上述代码中的部分重复内容：123456789function createPerson(name, age) &#123; return &#123; name, age &#125;&#125;console.log(createPerson('Jack', 16))// &#123; name: 'Jack', age: 16 &#125; 如果一个对象字面量只给出名字而没有值，则 JavaScript 引擎会在周围的作用域中寻找同名的变量，将其值赋值给对象字面量中对应的名字。 方法简化ECMAScript 6 同样简化了将方法关联给某个对象字面量的语法。 ECMAScript 5 及更早版本中为对象添加方法：123456789var person = &#123; name: "Nicholas", sayName: function() &#123; console.log(this.name) &#125;&#125;;person.sayName()// Nicholas ECMAScript 6 则支持更简单的语法：123456789var person = &#123; name: "Nicholas", sayName() &#123; console.log(this.name) &#125;&#125;;person.sayName()// Nicholas Computed Property Names在 ECMAScript 5 和早期版本中，允许在对象实例上使用由中括号（[]）包围的计算属性。相对于由点（.）指示的属性，由中括号包裹的属性可以使用变量或者有可能导致语法错误的字符串作为属性名。1234567891011var person = &#123;&#125;var lastName = "last name"person["first name"] = "Nicholas"person[lastName] = "Zakas"person.age = 16console.log(person["first name"])console.log(person[lastName])// Nicholas// Zakas ECMAScript 6 中计算属性的语法则更加灵活：1234567891011let lastName = "last name"let person = &#123; "first name": "Nicholas", [lastName]: "Zakas"&#125;console.log(person["first name"])console.log(person[lastName])// Nicholas// Zakas 甚至可以在中括号中使用表达式作为计算属性名：1234567891011var suffix = " name"var person = &#123; ["first" + suffix]: "Nicholas", ["last" + suffix]: "Zakas"&#125;console.log(person["first name"])console.log(person["last name"])// Nicholas// Zakas 二、新方法Object.is()在 JavaScript 中比较两个值，可以使用相等操作符（==）或相同操作符（===）。大部分开发者会倾向于使用后者。但 === 操作符并非完全准确，比如 +0 和 -0 会被认为相同，而 NaN === NaN 会返回 false。 ECMAScript 6 中引入了 Object.is() 方法可以解决 === 中存在的不准确的问题。1234567891011121314console.log(+0 == -0) // trueconsole.log(+0 === -0) // trueconsole.log(Object.is(+0, -0)) // falseconsole.log(NaN == NaN) // falseconsole.log(NaN === NaN) // falseconsole.log(Object.is(NaN, NaN)) // trueconsole.log(5 == 5) // trueconsole.log(5 == "5") // trueconsole.log(5 === 5) // trueconsole.log(5 === "5") // falseconsole.log(Object.is(5, 5)) // trueconsole.log(Object.is(5, "5")) // false Object.assign()Mixins 是 JavaScript 中最流行的构建对象的方式之一。通过 mixin，一个对象可以接收另一个对象中定义的属性和方法。其底层原理类似于如下代码：1234567891011121314151617181920function mixin(receiver, supplier) &#123; Object.keys(supplier).forEach(function(key) &#123; receiver[key] = supplier[key] &#125;) return receiver&#125;let person1 = &#123; name: "Jack", age: 16&#125;let person2 = &#123; name: "Rose", gender: "F"&#125;mixin(person1, person2)console.log(person1)// &#123; name: 'Rose', age: 16, gender: 'F' &#125; mixin() 函数遍历 supplier 对象的属性，将它们复制给 receiver（注意是浅复制，即当属性值是对象时，复制的是对象的引用）。这允许 receiver 不通过继承就能获取到新的属性。 鉴于 mixin 模式非常常用，ECMAScript 6 中添加了同样行为的 Object.assign() 方法。1234567891011function EventTarget() &#123; /*...*/ &#125;EventTarget.prototype = &#123; constructor: EventTarget, emit: function() &#123; /*...*/ &#125;, on: function() &#123; /*...*/ &#125;&#125;var myObject = &#123;&#125;Object.assign(myObject, EventTarget.prototype)myObject.emit("somethingChanged") 三、PrototypesPrototypes 是 JavaScript 中继承的基础。 修改对象的 Prototype通常某个对象的 prototype 由构造器或 Object.create() 方法指定。ECMAScript 5 中添加了 Object.getPrototypeOf() 方法可以获取任意对象的 prototype，但 prototype 在对象实例化之后就无法再变更了。 ECMAScript 6 中添加了 Object.setPrototypeOf() 方法可以用来变更任意对象的 prototype。123456789101112131415161718192021let person = &#123; getGreeting() &#123; return "Hello" &#125;&#125;let dog = &#123; getGreeting() &#123; return "Woof" &#125;&#125;// prototype is personlet friend = Object.create(person)console.log(friend.getGreeting()) // "Hello"console.log(Object.getPrototypeOf(friend) === person) // true// set prototype to dogObject.setPrototypeOf(friend, dog)console.log(friend.getGreeting()) // "Woof"console.log(Object.getPrototypeOf(friend) === dog) // true 通过 super 访问 Prototypesuper 是一个指向当前对象的 prototype 的指针，即 Object.getPrototypeOf(this) 的值。12345678910111213141516171819let person = &#123; getGreeting() &#123; return "Hello" &#125;&#125;let friend = &#123; getGreeting() &#123; return super.getGreeting() + ", hi" &#125;&#125;Object.setPrototypeOf(friend, person)// prototype is friendlet relative = Object.create(friend)console.log(person.getGreeting()) // "Hello"console.log(friend.getGreeting()) // "Hello, hi"console.log(relative.getGreeting()) // "Hello, hi" 参考资料Understanding ECMAScript 6]]></content>
      <categories>
        <category>Program</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Web</tag>
        <tag>Development</tag>
        <tag>Frontend</tag>
        <tag>JavaScript</tag>
        <tag>OOP</tag>
        <tag>ECMAScript6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 密码学实践 —— 凯撒密码]]></title>
    <url>%2F2020%2F08%2F05%2Fpython-cryptography-caesar-cipher%2F</url>
    <content type="text"><![CDATA[一、原理凯撒密码 是密码学中的一种简单的替换加密技术。明文中的所有字符都会替换为其按照字母表顺序向左（或向右）偏移一定量后得到的新字母，作为加密后密文。如当偏移量为 3 时，明文中所有的字母 A 将被替换成字母 D，B 替换成 E，以此类推。 若收到密文的同时已知加密时使用的偏移量，就可以快速地通过逆运算获取到最初的明文。 下面两张图展示了当偏移量为 8 时明文字母与密文字母的对应关系（图一即凯撒密码轮盘，外层为明文，内层为密文，可旋转以改变偏移量）以及实际的加密过程（图二）： PS：对一段明文消息连续应用多个不同的偏移量进行凯撒密码规则的加密，并不会增强安全等级。即轮盘的多次旋转，实际上等同于抵消后的一次旋转。多次应用的不同偏移量，最终等同于抵消后的一次偏移量，对于暴力破解来说并不会增加复杂度。如第一次对明文实施偏移 3 位的凯撒加密，再对生成的密文实施偏移 10 位的加密，实际上相当于对最初的明文实施了偏移 13 位的加密。 二、Python 实现凯撒密码源代码：1234567891011121314while True: key = input("Please input a key number (like 13):\n") or 13 mode = input("\nPlease input mode (encrypt or decrypt):\n") or "encrypt" symbols = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz1234567890 !?.' # 根据数字 key 对字母表 symbols 进行偏移操作，形成密文字母表 ciphers ciphers = symbols[int(key):] + symbols[:int(key)] # 根据加密与解密动作，生成明文字母到密文字母（或密文到明文）的对应关系 transtab = str.maketrans(symbols, ciphers) if mode == 'encrypt' else str.maketrans(ciphers, symbols) message = input("\nPlease input plaintext or ciphertext:\n") # 完成明文到密文（或密文到明文）的转换 result = message.translate(transtab) print(f"\nThe result is: &#123;result&#125;\n\n") 运行效果如下：12345678910111213141516171819202122Please input a key number (like 13):13Please input mode (encrypt or decrypt):encryptPlease input plaintext or ciphertext:This is my secret message.The result is: guv6Jv6Jz!J6rp5r7Jzr66ntrMPlease input a key number (like 13):13Please input mode (encrypt or decrypt):decryptPlease input plaintext or ciphertext:guv6Jv6Jz!J6rp5r7Jzr66ntrMThe result is: This is my secret message. 三、Python 对凯撒密码的爆破即在加密用的 key 值未知的情况下，尝试所有可能的 key 值（0 到字母表长度减一）对密文进行解密，输出以查看解密出的明文是否有意义。 源代码：1234567891011symbols = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz1234567890 !?.'ciphertext = input("Please input ciphertext:\n")for key in range(len(symbols)): ciphers = symbols[key:] + symbols[:key] transtab = str.maketrans(ciphers, symbols) plaintext = ciphertext.translate(transtab) print(f'Key #&#123;key&#125;: &#123;plaintext&#125;') 运行效果如下：12345678910111213141516171819Please input ciphertext:guv6Jv6Jz!J6rp5r7Jzr66ntrMKey #0: guv6Jv6Jz!J6rp5r7Jzr66ntrMKey #1: ftu5Iu5Iy I5qo4q6Iyq55msqLKey #2: est4Ht4Hx0H4pn3p5Hxp44lrpKKey #3: drs3Gs3Gw9G3om2o4Gwo33kqoJKey #4: cqr2Fr2Fv8F2nl1n3Fvn22jpnIKey #5: bpq1Eq1Eu7E1mkzm2Eum11iomHKey #6: aopzDpzDt6Dzljyl1DtlzzhnlGKey #7: ZnoyCoyCs5CykixkzCskyygmkFKey #8: YmnxBnxBr4BxjhwjyBrjxxfljEKey #9: XlmwAmwAq3AwigvixAqiwwekiDKey #10: Wklv.lv.p2.vhfuhw.phvvdjhCKey #11: Vjku?ku?o1?ugetgv?oguucigBKey #12: Uijt!jt!nz!tfdsfu!nfttbhfAKey #13: This is my secret message.Key #14: Sghr0hr0lx0rdbqds0ldrrZfd?Key #15: Rfgq9gq9kw9qcapcr9kcqqYec!... 参考资料Cracking Codes with Python]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Security</tag>
        <tag>Program</tag>
        <tag>Python</tag>
        <tag>Cryptography</tag>
        <tag>Cipher</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python Tricks —— 使用 pywinrm 远程控制 Windows 主机]]></title>
    <url>%2F2020%2F07%2F20%2Fpython-tricks-remote-control-windows-machines-with-pywinrm%2F</url>
    <content type="text"><![CDATA[WinRM 即 Windows Remote Management，是微软对于 WS-Management 远程管理协议的实现。 一、受控端配置 WinRM 服务方式一：cmd 命令行（管理员） 启用 WinRM 远程服务：winrm quickconfig 查看 WinRM 服务监听状态：winrm e winrm/config/listener 12345678910C:\Windows\system32&gt;winrm e winrm/config/listenerListener [Source="GPO"] Address = * Transport = HTTP Port = 5985 Hostname Enabled = true URLPrefix = wsman CertificateThumbprint ListeningOn = 127.0.0.1, 169.254.52.7, xx.xx.xx.xx, ::1, fe80::3989:dd91:e6b3:6f41%15, fe80::fd01:a9fd:c410:3407%12 允许使用 Basic 认证方式：winrm set winrm/config/service/auth @{Basic=&quot;true&quot;} 12345678winrm set winrm/config/service/auth @&#123;Basic="true"&#125;Auth Basic = true [Source="GPO"] Kerberos = true Negotiate = true Certificate = false CredSSP = false CbtHardeningLevel = Relaxed 允许 WinRM 使用非加密的连接：winrm set winrm/config/service @{AllowUnencrypted=&quot;true&quot;} 方式二：bat 脚本123call winrm quickconfig -quietcall winrm set winrm/config/service/auth @&#123;Basic="true"&#125;call winrm set winrm/config/service @&#123;AllowUnencrypted="true"&#125; 方式三：组策略定位到计算机配置 -&gt; 策略 -&gt; 管理模板 -&gt; Windows 组件 -&gt; Windows 远程管理(WinRM) -&gt; WinRM 服务。启用允许通过 WinRM 进行远程服务器管理、允许基本身份验证、允许未加密通信。 建议同时启用服务与防火墙策略：计算机配置 -&gt; 策略 -&gt; Windows 设置 -&gt; 安全设置 -&gt; 系统服务 -&gt; Windows Remote Management (WS-Management)，启动模式为自动。 计算机配置 -&gt; 策略 -&gt; Windows 设置 -&gt; 安全设置 -&gt; 高级安全 Windows 防火墙 -&gt; 高级安全 Windows 防火墙 - XXX -&gt; 入站规则，开放 5985（HTTP）和 5986（HTTPS）端口。 二、Python 使用 pywinrm 连接 WinRM 服务安装 pywinrm 库：pip install pywinrm 执行 cmd 命令：12345&gt;&gt;&gt; import winrm&gt;&gt;&gt; session = winrm.Session('xx.xx.xx.xx', auth=('Administrator', 'admin_password'))&gt;&gt;&gt; cmd = session.run_cmd('ipconfig')&gt;&gt;&gt; cmd.std_outb'\r\nWindows IP Configuration\r\n\r\n\r\nEthernet adapter \xd2\xd4\xcc\xab\xcd\xf8:\r\n\r\n Connection-specific DNS Suffix . : example.com\r\n Link-local IPv6 Address . . . . . : fe80::3989:dd91:e6b3:6f41%15\r\n IPv4 Address. . . . . . . . . . . : xx.xx.xx.xx\r\n Subnet Mask . . . . . . . . . . . : 255.255.255.0\r\n Default Gateway . . . . . . . . . : 172.20.23.254\r\n\r\nEthernet adapter \xd2\xd4\xcc\xab\xcd\xf8 2:\r\n\r\n Media State . . . . . . . . . . . : Media disconnected\r\n Connection-specific DNS Suffix . : \r\n' 执行 Powershell 命令：12345&gt;&gt;&gt; import winrm&gt;&gt;&gt; session = winrm.Session('xx.xx.xx.xx', auth=('Administrator', 'admin_password'))&gt;&gt;&gt; ps = session.run_ps('Get-Disk')&gt;&gt;&gt; ps.std_outb'\r\nNumber Friendly Name Serial Number HealthStatus OperationalStatus Total Size Partition \r\n Style \r\n------ ------------- ------------- ------------ ----------------- ---------- ----------\r\n0 ST500DM002... Z3TFS1S3 Healthy Online 465.76 GB MBR \r\n\r\n\r\n']]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Tools</tag>
        <tag>Windows</tag>
        <tag>Program</tag>
        <tag>Python</tag>
        <tag>Remote</tag>
        <tag>WinRM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 密码学实践 —— 理解哈希（Hash）算法]]></title>
    <url>%2F2020%2F07%2F03%2Fpractical-cryptography-in-python-hash-algorithm%2F</url>
    <content type="text"><![CDATA[Hash 是密码学安全性的基石，它引入了单向函数（one-way function）和指纹（fingerprint）的概念。即： 对于任意输入，都可以产生相同的、唯一的输出值 输出值中不包含输入值的任何线索 一、保密性（confidentiality）与完整性（integrity）简单来说，信息的保密性确保除授权人员以外的任何人都无法读取该消息，信息的完整性则确保除授权人员以外的任何人都无法修改该消息。很多时候一段加密的消息无法被他人读取和理解（保密性），并不意味着该密文不会在传播过程中被截取和恶意修改（完整性）。 信息摘要（message digest）或指纹（fingerprint）技术即用于验证信息的完整性。 信息摘要需满足的基本条件为： 相同的文档永远会生成相同的摘要（能够作为身份线索） 生成的摘要“感觉”是随机的，即摘要中不包含原始文档的任何信息（无法被破解） 信息摘要也被称作指纹，即可以代表某份文档“身份”的一小段数据，类似于人类的指纹。每个人都可以通过指纹验证其身份，但该指纹并不包含其身体的所有信息。文档的指纹也是如此，可以很方便快速的通过文档内容计算得出一小段唯一的指纹数据作为其身份证明，但是只有指纹数据就几乎不可能得出原始文档的内容。 对于两份文档，只需要比对其信息摘要（指纹）是否一致，就可以确保其内容是否相同，在传播过程中是否被人恶意修改。同时该指纹信息也不会造成原始文档本内容的泄露。 二、MD5MD5 是一种比较古老的哈希算法，其名字中的 MD 即代表 message digest。它可以从任意大小的文档计算出一个唯一的 16 字节长度的摘要数据。 PS：鉴于 MD5 较悠久的历史和不够长的摘要长度，不推荐在安全性很敏感的场景中使用该算法。1234567891011121314151617&gt;&gt;&gt; from hashlib import md5&gt;&gt;&gt; md5(b'alice').hexdigest()'6384e2b2184bcbf58eccf10ca7a6563c'&gt;&gt;&gt; md5(b'bob').hexdigest()'9f9d51bc70ef21ca5c14f307980a29d8'&gt;&gt;&gt; md5(b'balice').hexdigest()'6760742ebf884c998752b4e082b78224'&gt;&gt;&gt; md5(b'cob').hexdigest()'386685f06beecb9f35db2e22da429ec9'&gt;&gt;&gt; md5(b'a').hexdigest()'0cc175b9c0f1b6a831c399e269772661'&gt;&gt;&gt; md5(b'aa').hexdigest()'4124bc0a9335c27f086f24ba207a4912'&gt;&gt;&gt; md5(b'aa' * 100000).hexdigest()'561b1994f6baacd6e5eaf4baaa12849f'&gt;&gt;&gt; md5(b'alice').hexdigest()'6384e2b2184bcbf58eccf10ca7a6563c' 从输出中可以看出，针对不同的输入内容（即便相似度很高，比如 bob 和 cob），摘要算法生成的输出是发散的，彼此之间没有相似性，像是随机生成的结果。但是对于任意相同的输入，生成的摘要数据则都是确定的、唯一的。 三、哈希算法的规则一般我们提到哈希算法，都会关联到密码学、安全性等场景中，实际上我们很早就接触了一种完全“非密码学”的哈希场景。比如小时候跟老师学习判断一个数是奇数还是偶数。。。从本质上看，哈希函数的目的是将巨大（甚至无穷大）数量的事物映射到一个相对较小的数据集中。比如 MD5，不管输入的文档有多大，最终都会生成一个固定长度（16 字节）的十六进制数字作为指纹。这就意味着 MD5 的输入集合，实际上是大于其输出集合的。即只要输入文档的集合足够大（很大很大），就有可能出现重复的指纹信息。 这和判断数字奇偶是相通的。不管某个数字有多大多奇特，我们永远可以将它“压缩”成奇数或偶数，用 1 bit 的 1 或 0 表示就可以。但是只说明某个未知数字是奇数（或偶数），我们就无法猜出该数字的准确值。 上面的逻辑验证了哈希函数共有的 3 个特性： consistency（一致性）：相同的输入只会生成相同的输出信息 compression（压缩）：可以将体量很大的输入压缩成一个固定大小的输出 lossiness（有损的）：只通过检查输出无法反向计算出输入值 但是对于一个满足密码学安全的哈希函数而言，除以上三点以外还需要具有如下属性： Preimage resistance Second-preimage resistance Collision resistance Preimage Resistance哈希函数的 preimage 是指能够生成同一个特定指纹的所有输入的合集。即对于某个哈希函数 H 与摘要 k，所有能够生成 k 的输入值 x （满足 H(x) = k）共同组成了 H 与 k 的 preimage。 preimage resistance 的意义即为，在仅仅只是知晓某个摘要的前提下，通过有限的计算无法获取其 preimage 中的任何一个元素。即只通过结果无法知晓输入。摘要中不包含原始文档的任何信息（lossiness），无法通过逆向运算的方式由摘要反推出原始输入。只能随机地尝试任意输入，以期碰巧得到同样的摘要信息（暴力破解）。 因此前面提到的奇偶函数就不能作为一个安全的哈希函数使用。假设使用奇偶作为哈希函数（奇数输出 1，偶数输出 0），则对于摘要 1，总可以很轻易的在 preimage（此处是全体奇数）中找到任意多个摘要同为 1 的元素。这意味着原始输入可以轻易被修改而不影响指纹数据，则该指纹作为信息完整性的验证条件就失去了意义。 但是对于较安全的哈希算法如 MD5，由 MD5(x) = ca8a0fb205782051bd49f02eae17c9ee 就无法在有限的计算内找到确定的 x 的值。MD5 生成 16 字节（16 * 8 = 128bit）长度的摘要，其中可以包含 2^128 种不同的数字组合。因此使用暴力破解的话，最多需要尝试 2^128 = 340282366920938463463374607431768211456 次！假设每秒钟可以尝试一百万条输入，仍需要 10^26 年完成所有验证操作！ Second-Preimage Resistance 与 Collision Resistancesecond-primage resistance 是指即便知晓某个原始文档以及由该文档生成的摘要数据，仍很难计算可以出生成同样摘要的另一个不同的文档。即在已知 MD5(alice) = 384e2b2184bcbf58eccf10ca7a6563c 的情况下，仍无法找出除 alice 以外的另一个输入生成同样的摘要。为了寻求可以替换掉 alice 的另一个值，同时不影响摘要认证，达到混淆的目的，最终仍需使用暴力破解的方式。 collision resistance 是指很难找出任意两个生成相同摘要（相同而非特定）的输入值。可以参考“生日问题”，即在一个班级中，存在两个生日为同一天的学生的概率远比存在一个生日为特定日期的学生的概率大得多。 collision resistance 的意义在于，无法故意找出两套符合同一指纹的输入以达到混淆的目的。比如 MD5 算法：12345&gt;&gt;&gt; from hashlib import md5&gt;&gt;&gt; md5('bob').hexdigest()'9f9d51bc70ef21ca5c14f307980a29d8'&gt;&gt;&gt; md5('cob').hexdigest()'386685f06beecb9f35db2e22da429ec9' 对于很相似的输入 bob 和 cob，其指纹信息的差异却非常大，没有任何可供预测的规律。这得益于一种称为 avalanche property 的特性：输入的微小变化总可以在输出中产生巨大的无法预测的差异。 由前面提到的生日问题可知，找出两个生成相同指纹的元素远比找出某个可以生成特定指纹的元素要容易的多。以 MD5 算法的暴力破解为例，后者往往需要做 2^128 次尝试，而前者只需要 2^64 次尝试。现实中 MD5 的 collision resistance 远非想象中那么优异，甚至存在一种非暴力破解的方式 能够在一小时以内攻破 MD5 的 collision resistance。所以尽量不要使用 MD5 这个已经不再维护超过 10 年、安全漏洞存在 20 年的古老算法。 参考资料Practical Cryptography in Python: Learning Correct Cryptography by Example]]></content>
      <categories>
        <category>Program</category>
      </categories>
      <tags>
        <tag>Security</tag>
        <tag>Program</tag>
        <tag>Python</tag>
        <tag>Algorithm</tag>
        <tag>Hash</tag>
        <tag>Cryptography</tag>
        <tag>Digest</tag>
        <tag>MD5</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaScript 解密 —— 函数进阶（闭包与生成器）]]></title>
    <url>%2F2020%2F06%2F04%2Funderstanding-javascript-closure-and-generator%2F</url>
    <content type="text"><![CDATA[一、闭包简单来说，闭包（closure）允许函数访问和操作位于自身外部的变量。借助闭包的特性，函数可以访问任何变量及其他函数，只要这些数据在该函数定义时位于其作用域内部。1234567891011121314151617var outerValue = "samurai"var laterfunction outerFunction() &#123; var innerValue = "ninja" function innerFunction() &#123; console.log(outerValue) console.log(innerValue) &#125; later = innerFunction&#125;outerFunction()later()// samurai// ninja 参考上面的代码，按照通常的理解： 变量 outerValue 定义在全局作用域中，因此其可以从程序的任意位置访问 outerFunction 执行，将 innerFunction 关联给全局变量 later 当 later（innerFunction）执行时，outerFunction 已经执行完毕，其内部的作用域理应失效，无法被 later 访问 innerValue 由于在 outerFunction 内部定义，则 later 访问 innerValue 时其值应该为 undefined 实际上程序输出的 innerValue 的值为 ninja，即 outerFunction 内部定义的 innerValue 可以被 later 访问。这就是闭包所产生的效果。 当我们在 outerFunction 内部声明 innerFunction 时，一个包含当前作用域（“当前”指的是内部函数定义的时刻）中所有变量的闭包同时被创建。最终 innerFunction 执行时，即便其声明时的原始作用域已经消失，innerFunction 还是可以通过闭包访问其原始作用域。闭包像是使用了一个“保护层”将函数定义时的作用域封闭起来，只要该函数的生命周期未结束，“保护层”内的作用域就一直可以被访问。 二、闭包的现实应用模拟私有变量私有变量即从对象外部不可见的变量，可以向用户隐藏对象内部不必要的实现细节。JavaScript 没有对私有变量的原生支持，但是通过闭包可以实现类似的功能。123456789101112131415161718function Ninja() &#123; var feints = 0 this.getFeints = function() &#123; return feints &#125; this.feint = function() &#123; feints++ &#125;&#125;var ninja1 = new Ninja()ninja1.feint()console.log(ninja1.feints) // undefinedconsole.log(ninja1.getFeints()) // 1var ninja2 = new Ninja()console.log(ninja2.getFeints()) // 0 在回调函数中使用闭包12345678910111213141516&lt;button id="box1"&gt;First Button&lt;/button&gt; &lt;script&gt; function animateIt(elementId) &#123; var elem = document.getElementById(elementId) var tick = 100 var timer = setInterval(function() &#123; if (tick &lt; 1000) &#123; elem.style.width = tick + "px" tick += 10 &#125; else &#123; clearInterval(timer) &#125; &#125;, 100) &#125; animateIt("box1") &lt;/script&gt; 在上面的代码中，一个匿名函数作为参数（回调函数）传递给 setInterval，令指定元素的宽度能够随时间增长以形成动画效果。该匿名函数借助闭包能够访问外部定义的 elem、tick、timer 三个参数，控制动画的进度。这三个参数定义在 animateIt 内部通过闭包被回调函数访问，而不是直接在全局作用域中定义。这样可以避免多个 animateIt 函数依次运行时引起冲突。 三、生成器生成器是一种可以生成一系列值的特殊函数，只不过这些值不是同时产生的，需要用户显式地去请求新值（通过 for、next 等）。12345678910111213function* WeaponGenerator() &#123; yield "Katana" yield "Wakizashi" yield "Kusarigama"&#125;for(let weapon of WeaponGenerator()) &#123; console.log(weapon)&#125;// Katana// Wakizashi// Kusarigama 调用生成器并不意味着会逐步执行生成器函数的定义代码，而是会创建一个迭代器（iterator）对象，通过这个迭代器对象与生成器进行交互（如请求新的值）。123456789101112131415161718function* WeaponGenerator() &#123; yield "Katana" yield "Wakizashi"&#125;const weaponsIterator = WeaponGenerator()const result1 = weaponsIterator.next()console.log(typeof result1, result1.value, result1.done)// object Katana falseconst result2 = weaponsIterator.next()console.log(typeof result2, result2.value, result2.done)// object Wakizashi falseconst result3 = weaponsIterator.next()console.log(typeof result3, result3.value, result3.done)// object undefined true 使用 while 遍历生成器：12345678910111213function* WeaponGenerator() &#123; yield "Katana" yield "Wakizashi"&#125;const weaponsIterator = WeaponGenerator()let itemwhile(!(item = weaponsIterator.next()).done) &#123; console.log(item.value)&#125;// Katana// Wakizashi 生成器嵌套：12345678910111213141516171819function* WarriorGenerator() &#123; yield "Sun Tzu" yield* NinjaGenerator() yield "Genghis Khan"&#125;function* NinjaGenerator() &#123; yield "Hattori" yield "Yoshi"&#125;for(let warrior of WarriorGenerator()) &#123; console.log(warrior)&#125;// Sun Tzu// Hattori// Yoshi// Genghis Khan 生成器的应用生成 ID123456789101112131415function* IdGenerator() &#123; let id = 0 while (true) &#123; yield ++id &#125;&#125;const idIterator = IdGenerator()const ninja1 = &#123; id: idIterator.next().value &#125;const ninja2 = &#123; id: idIterator.next().value &#125;const ninja3 = &#123; id: idIterator.next().value &#125;console.log(ninja1.id) // 1console.log(ninja2.id) // 2console.log(ninja3.id) // 3 遍历DOM 使用递归函数：123456789101112131415161718192021&lt;div id="subTree"&gt; &lt;form&gt; &lt;input type="text" /&gt; &lt;/form&gt; &lt;p&gt;Paragraph&lt;/p&gt; &lt;span&gt;Span&lt;/span&gt;&lt;/div&gt; &lt;script&gt; function traverseDOM(element, callback) &#123; callback(element) element = element.firstElementChild while (element) &#123; traverseDOM(element, callback) element = element.nextElementSibling &#125; &#125; const subTree = document.getElementById("subTree") traverseDOM(subTree, function(element) &#123; console.log(element.nodeName) &#125;) &lt;/script&gt; 使用生成器（无需借助 callback）：12345678910111213141516171819202122&lt;div id="subTree"&gt; &lt;form&gt; &lt;input type="text" /&gt; &lt;/form&gt; &lt;p&gt;Paragraph&lt;/p&gt; &lt;span&gt;Span&lt;/span&gt;&lt;/div&gt; &lt;script&gt; function* DomTraversal(element) &#123; yield element element = element.firstElementChild while (element) &#123; yield* DomTraversal(element) element = element.nextElementSibling &#125; &#125; const subTree = document.getElementById("subTree") for(let element of DomTraversal(subTree)) &#123; console.log(element.nodeName) &#125; &lt;/script&gt; 通过 next 方法向生成器发送值生成器不仅可以通过 yield 表达式生成一系列值，还可以接受用户传入数据，形成一种双向的通信。1234567891011function* NinjaGenerator(action) &#123; const imposter = yield ("Hattori " + action) yield ("Yoshi (" + imposter + ") " + action)&#125;const ninjaIterator = NinjaGenerator("skulk")const result1 = ninjaIterator.next()console.log(result1.value) // Hattori skulkconst result2 = ninjaIterator.next("Hanzo")console.log(result2.value) // Yoshi (Hanzo) skulk 具体的执行流程为： 第一个 ninjaIterator.next() 向生成器请求新值，获取到第一个 yield 右侧的值 &quot;Hattori &quot; + action，同时在 yield (&quot;Hattori &quot; + action) 表达式处挂起执行流程 第二个 ninjaIterator.next(&quot;Hanzo&quot;) 继续向生成器请求新值，同时还发送了参数 Hanzo 给生成器，该参数刚好用作前面挂起的 yield (&quot;Hattori &quot; + action) 表达式的结果，使得 imposter 的值成为 Hanzo 最终 ninjaIterator.next(&quot;Hanzo&quot;) 请求获得第二个 yield 右侧 &quot;Yoshi (&quot; + imposter + &quot;) &quot; + action 的值，即 Yoshi (Hanzo) skulk 参考资料Secrets of the JavaScript Ninja, Second Edition]]></content>
      <categories>
        <category>Program</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Functional</tag>
        <tag>Function</tag>
        <tag>Web</tag>
        <tag>Development</tag>
        <tag>JavaScript</tag>
        <tag>ECMAScript6</tag>
        <tag>Nodejs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaScript 解密 —— 函数初步]]></title>
    <url>%2F2020%2F06%2F04%2Funderstanding-javascript-function-as-first-class-object%2F</url>
    <content type="text"><![CDATA[一、First-class objects在理解函数作为一等对象前，先列举下 JavaScript 中对象支持的操作： 可以通过 {} 字面量创建 可以被赋值给变量、数组项，可以作为其他对象的属性 123var ninja = &#123;&#125; // 赋值给变量ninjaArray.push(&#123;&#125;) // 作为数组项ninja.data = &#123;&#125; // 作为其他对象的属性 可以作为函数的参数或返回值 可以拥有支持动态创建与赋值的属性1234567891011function hide(ninja) &#123; ninja.visibility = false&#125;hide(&#123;&#125;) // 对象作为函数参数function returnNewNinja() &#123; return &#123;&#125; // 对象作为函数返回值&#125;var ninja = &#123;&#125;ninja.name = "Hanzo" // 动态创建的属性 函数作为一等对象JavaScript 中的函数拥有作为对象的所有特性，因此可以像对待任何其他对象一样对其进行使用。 通过字面量创建： function ninjaFunction() {} 将函数赋值给变量：var ninjaFunction = function() {} 数组中加入函数作为数据项：ninjaArray.push(function() {}) 函数作为对象的属性：ninja.data = function() {} 函数作为其他函数的参数或返回值 12345678function call(ninjaFunction) &#123; ninjaFunction()&#125;call(function() &#123;&#125;) // 函数作为参数function returnNewNinjaFunction() &#123; return function() &#123;&#125; // 函数作为返回值&#125; 函数可以拥有支持动态创建和赋值的属性 12var ninjaFunction = function () &#123;&#125;ninjaFunction.name = "Hanzo" 函数即对象，只不过拥有一项额外的特性（能够被调用）以完成一些特定的动作。任何可以对对象做出的操作，同样可以应用在函数身上。 Callback functions回调函数即在后续的某个指定的时间节点被其他代码调用（call back）的函数。12345678910111213141516var text = "Domo arigato"function useless(ninjaCallback) &#123; console.log("In useless function") return ninjaCallback()&#125;function getText() &#123; console.log("In getText function") return text&#125;console.log(useless(getText))// In useless function// In getText function// Domo arigato 或者12345678var text = 'Domo arigato'function useless(ninjaCallback) &#123; return ninjaCallback()&#125;console.log(useless(function() &#123; return text &#125;))// Domo arigato 回调函数在数组排序中的使用：1234var values = [0, 3, 2, 5, 7, 4, 8, 1]values.sort(function(value1, value2)&#123; return value1 - value2&#125;) Self-memoizing functionsmemoization 是指构建一个特殊的函数，该函数可以将之前计算过的值缓存在自己内部，之后再做同样的计算时则可以直接读取缓存的值而不必重新计算。12345678910111213141516171819202122function isPrime(value) &#123; if (!isPrime.answers) &#123; isPrime.answers = &#123;&#125; &#125; if (isPrime.answers[value] !== undefined) &#123; return isPrime.answers[value] &#125; var prime = value !== 1 for (var i = 2; i &lt; value; i++) &#123; if (value % i === 0) &#123; prime = false break &#125; &#125; return isPrime.answers[value] = prime&#125;console.log(isPrime(5))console.log(isPrime.answers)// true// &#123; '5': true &#125; 二、函数定义JavaScript 提供以下几种定义函数的方式： 函数声明（表达式）：function myFun() { return 1 } Arrow function：myArg =&gt; myArg * 2 函数构造器：new Function(&#39;a&#39;, &#39;b&#39;, &#39;return a + b&#39;) 生成器函数：function* myGen() { yield 1 } 函数声明是最基础的定义函数的方式，其基本格式如下：1234function myFunctionName(myFirstArg, mySecondArg) &#123; myStatement1 myStatement2&#125; 函数声明代码可以出现在另一个函数内部：123456function ninja() &#123; function hiddenNinja() &#123; return "ninja here" &#125; return hiddenNinja()&#125; 函数表达式作为 JavaScript 中的一等对象，函数可以通过字面量创建，可以赋值给变量和对象属性，可以作为另一个函数的参数或返回值。也因此可以将其作为表达式使用，即成为其他代码语句的一部分（比如放在赋值语句的等号右边、充当参数或返回值等）12345var myFunc = function() &#123;&#125;myFunc(function() &#123; // 作为参数 return function() &#123;&#125; // 作为返回值&#125;) 函数表达式甚至可以放置在通常应该使用函数标识符的地方，在声明的同时立即完成调用，称为 immediate function：1234567myFunctionName(3) // 普通调用(function() &#123;&#125;)(3) // immediate call+function () &#123;&#125; ()-function () &#123;&#125; ()!function () &#123;&#125; ()~function () &#123;&#125; () Arrow function在很多情况下，arrow function 可以看作对普通函数表达式的简化。如之前的排序示例：1234var values = [0, 3, 2, 5, 7, 4, 8, 1]values.sort(function(value1, value2)&#123; return value1 - value2&#125;) 使用 arrow function 则可以改为如下形式：12var values = [0, 3, 2, 5, 7, 4, 8, 1]values.sort((value1, value2) =&gt; value1 - value2) arrow function 最简单的语法形式为 param =&gt; expression，一个基本示例如下：12var greet = name =&gt; "Greetings, " + nameconsole.log(greet('Oishi')) // Greetings, Oishi 更复杂一点的形式如：123456var greet = name =&gt; &#123; var helloString = 'Greetings, ' return helloString + name&#125;console.log(greet('Oishi')) // Greetings, Oishi 参数Rest prarmeters12345678function multiMax(first, ...remainingNumbers)&#123; var sorted = remainingNumbers.sort(function(a, b)&#123; return b - a &#125;) return first * sorted[0]&#125;console.log(multiMax(3, 1, 2, 3)) // 9 Default parameters123456function performAction(ninja, action = "skulking") &#123; return ninja + " " + action&#125;console.log(performAction("Fuma")) // Fuma skulkingconsole.log(performAction("Yagyu", "sneaking")) // Yagyu sneaking 甚至可以这样写：12345function performAction(ninja, action = "skulking", message = ninja + " " + action) &#123; return message&#125;console.log(performAction("Yoshi")) // Yoshi skulking 三、函数调用作为“函数”调用1234567function ninja(name) &#123; console.log(name) &#125;ninja('Hattori') // Hattorivar samurai = function(name) &#123; console.log(name) &#125;samurai('Hattori'); // Hattori(function(name) &#123; console.log(name) &#125;)('Hattori') // Hattori 作为方法调用：123var ninja = &#123;&#125;ninja.skulk = function() &#123;&#125;ninja.skulk() 作为方法调用与作为函数调用的区别：1234567891011121314151617function whatsMyContext() &#123; return this&#125;console.log(whatsMyContext() === global) // truevar getMyThis = whatsMyContextconsole.log(getMyThis() === global) // truevar ninja1 = &#123; getMyThis: whatsMyContext&#125;console.log(ninja1.getMyThis() === ninja1) // truevar ninja2 = &#123; getMyThis: whatsMyContext&#125;console.log(ninja2.getMyThis() === ninja2) // true 作为构造器函数：12function whatsMyContext()&#123; return this &#125;new whatsMyContext() 注意与函数构造器（如 new Function(&#39;a&#39;, &#39;b&#39;, &#39;return a + b&#39;) ）的区别：函数构造器用来从字符串中动态地创建函数，而构造器函数则用来创建对象实例。 构造器函数在调用时一般会执行以下操作： 创建一个空的对象 新创建的对象绑定给 this 参数传递给构造器，成为构造器函数的上下文 新创建的对象作为 new 操作的返回值被返回 1234567891011function Ninja() &#123; this.skulk = function() &#123; return this &#125;&#125;var ninja1 = new Ninja()console.log(ninja1.skulk() === ninja1) // truevar ninja2 = new Ninja()console.log(ninja2.skulk() === ninja2) // true 若构造器函数的定义中本身具有返回值，则分为两种情况： 若构造器的定义中返回了一个非对象值（字符串、数字等），则该返回值被忽略，由构造器创建的 this 对象被返回作为 new 表达式的值 若构造器的定义中返回了一个对象，则该对象作为 new 表达式的值，由构造器创建的 this 对象则被忽略12345678910function Ninja() &#123; this.skulk = function() &#123; return true &#125; return 1&#125;var ninja = new Ninja()console.log(ninja) // Ninja &#123; skulk: [Function] &#125;console.log(ninja.skulk()) // true 123456789101112var puppet = &#123; rules: false&#125;function Emperor() &#123; this.rules = true return puppet&#125;var emperor = new Emperor()console.log(emperor) // &#123; rules: false &#125;console.log(emperor.rules) // false apply 和 call 方法：12345678910111213141516function juggle() &#123; var result = 0 for (var n = 0; n &lt; arguments.length; n++) &#123; result += arguments[n] &#125; this.result = result&#125;var ninja1 = &#123;&#125;var ninja2 = &#123;&#125;juggle.apply(ninja1, [1,2,3,4])juggle.call(ninja2, 5,6,7,8)console.log(ninja1.result) // 10console.log(ninja2.result) // 26 参考资料Secrets of the JavaScript Ninja, Second Edition]]></content>
      <categories>
        <category>Program</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Functional</tag>
        <tag>Function</tag>
        <tag>Web</tag>
        <tag>Development</tag>
        <tag>JavaScript</tag>
        <tag>ECMAScript6</tag>
        <tag>Nodejs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django 借助 Celery 实现计划任务排期及调度系统（django-celery-beat）]]></title>
    <url>%2F2020%2F05%2F08%2Ftask-schedule-system-with-django-celery-beat%2F</url>
    <content type="text"><![CDATA[一、环境搭建配置运行环境：123$ python -m venv env$ source ./env/bin/activate$ pip install django-celery-beat django-celery-results redis 项目初始化：123$ django-admin startproject schedule_task$ cd schedule_task$ django-admin startapp schedules 修改 schedule_task/settings.py 配置文件，将 ALLOWED_HOSTS = [] 改为 ALLOWED_HOSTS = [&#39;*&#39;]运行 web 服务： $ python manage.py runserver 0.0.0.0:8000 二、启用 schedule-celery-beat 和 schedule-celery-results在 schedule_task/settings.py 文件中的 INSTALLED_APPS 配置项下，添加如下三个应用：123456INSTALLED_APPS = [ ... 'schedules', 'django_celery_results', 'django_celery_beat'] 其中 django_celery_results 用于在数据库中存储 Celery 任务执行的结果。django_celery_beat 则用于在数据库中记录预先定义好的任务执行规则（比如每隔一分钟执行一次），以及与这些规则关联的待执行的具体任务。 数据库迁移，创建超级用户：12$ python manage.py migrate$ python manage.py createsuperuser 三、系统后台启动 web 服务，用上一步中创建的超级用户登录后台管理系统：http://127.0.0.1:8000/admin 。界面如下： 界面中 CELERY RESULTS 为 django_celery_results 创建的用于保存任务结果的数据库表。 PERIODIC TASKS 下面则是由 django_celery_beat 创建的用于保存 Celery 任务及其执行规则的几张数据库表，具体含义如下： Clocked：定义在具体某个时间点触发的执行规则 Crontabs：类似于 Linux 系统下 crontab 的语法 Intervals：定义任务重复执行的时间间隔 Periodic tasks：具体某个待执行的任务，需要与其他表（Clocked、Crontabs、Intervals、Solar events）中定义的执行规则相关联 Solar events：根据日升和日落等太阳运行轨迹确定执行规则 如定义一个每隔 10 秒执行一次的规则，步骤如下： 四、创建 Celery 任务Celery 任务需要在源代码中手动创建，具体可参考官方文档 Using Celery With Django，简要步骤如下： schedule_task/schedule_task/celery.py：123456789101112131415# schedule_task/schedule_task/celery.pyfrom __future__ import absolute_import, unicode_literalsimport osfrom celery import Celery# set the default Django settings module for the 'celery' program.os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'schedule_task.settings')app = Celery('schedule_task')# - namespace='CELERY' means all celery-related configuration keys# should have a `CELERY_` prefix.app.config_from_object('django.conf:settings', namespace='CELERY')# Load task modules from all registered Django app configs.app.autodiscover_tasks() schedule_task/schedule_task/__init__.py：12345678# schedule_task/schedule_task/__init__.pyfrom __future__ import absolute_import, unicode_literals# This will make sure the app is always imported when# Django starts so that shared_task will use this app.from .celery import app as celery_app__all__ = ('celery_app',) schedule_tasks/schedules/tasks.py：1234567# schedule_tasks/schedules/tasks.pyfrom __future__ import absolute_import, unicode_literalsfrom celery import shared_task@shared_task(bind=True)def debug_task(self): return f'Hello Celery, the task id is: &#123;self.request.id&#125;' 使用 Redis 作为 Message Broker，Django 默认配置的数据库作为 Result Backend，DatabaseScheduler 作为 Celery 的任务调度器： schedule_task/schedule_task/settings.py：12345# schedule_task/schedule_task/settings.py# ...CELERY_RESULT_BACKEND = 'django-db'CELERY_BROKER_URL = 'redis://127.0.0.1:6379/0'CELERY_BEAT_SCHEDULER = 'django_celery_beat.schedulers:DatabaseScheduler' 此时可进入系统管理后台，将任务 debug_task 关联给每隔 10s 执行的规则： 只需要填写基本信息，选择相关联的任务和 Schedule 即可。此外，还可以根据需求自行定义计划任务的其他参数，如： 生效时间 是否只执行一次 传递给任务的参数 失效时间 五、运行测试为了使系统正常运行，需要同时开启三个服务： web 服务：python manage.py runserver 0.0.0.0:8000 Celery Worker：celery -A schedule_task worker -l info Celery Beat：celery -A schedule_task beat -l info 服务成功运行后，输出信息如下 Celery Beat 持续监测数据库中存储的计划任务信息，将满足触发条件的任务传递给 Celery Worker 执行： 12345678910111213141516171819$ celery -A schedule_task beat -l infocelery beat v4.4.2 (cliffs) is starting.__ - ... __ - _LocalTime -&gt; 2020-05-08 03:44:41Configuration -&gt; . broker -&gt; redis://127.0.0.1:6379/0 . loader -&gt; celery.loaders.app.AppLoader . scheduler -&gt; django_celery_beat.schedulers.DatabaseScheduler . logfile -&gt; [stderr]@%INFO . maxinterval -&gt; 5.00 seconds (5s)[2020-05-08 03:44:41,578: INFO/MainProcess] beat: Starting...[2020-05-08 03:44:41,578: INFO/MainProcess] Writing entries...[2020-05-08 03:44:46,745: INFO/MainProcess] Writing entries...[2020-05-08 03:44:51,594: INFO/MainProcess] Scheduler: Sending due task debug_task (schedules.tasks.debug_task)[2020-05-08 03:45:01,585: INFO/MainProcess] Scheduler: Sending due task debug_task (schedules.tasks.debug_task)[2020-05-08 03:45:11,587: INFO/MainProcess] Scheduler: Sending due task debug_task (schedules.tasks.debug_task)[2020-05-08 03:45:21,588: INFO/MainProcess] Scheduler: Sending due task debug_task (schedules.tasks.debug_task)[2020-05-08 03:45:31,591: INFO/MainProcess] Scheduler: Sending due task debug_task (schedules.tasks.debug_task) Celery Worker 负责执行由 Beat 传过来的任务，输出执行结果并将结果保存至 result backend（即数据库）： 123456789101112131415$ celery -A schedule_task worker -l info[tasks] . schedules.tasks.debug_task[2020-05-08 03:44:05,521: INFO/MainProcess] Connected to redis://127.0.0.1:6379/0[2020-05-08 03:44:05,529: INFO/MainProcess] mingle: searching for neighbors[2020-05-08 03:44:06,546: INFO/MainProcess] mingle: all alone[2020-05-08 03:44:06,558: INFO/MainProcess] celery@mirrors ready.[2020-05-08 03:44:51,607: INFO/MainProcess] Received task: schedules.tasks.debug_task[3d6b77bb-d4b7-4a5d-b05f-3b85e5dafce7][2020-05-08 03:44:51,687: INFO/ForkPoolWorker-1] Task schedules.tasks.debug_task[3d6b77bb-d4b7-4a5d-b05f-3b85e5dafce7] succeeded in 0.07936301361769438s: 'Hello Celery, the task id is: 3d6b77bb-d4b7-4a5d-b05f-3b85e5dafce7'[2020-05-08 03:45:01,588: INFO/MainProcess] Received task: schedules.tasks.debug_task[a097dc02-71c9-4cab-9871-92ed1a7f2f45][2020-05-08 03:45:01,660: INFO/ForkPoolWorker-1] Task schedules.tasks.debug_task[a097dc02-71c9-4cab-9871-92ed1a7f2f45] succeeded in 0.07120843604207039s: 'Hello Celery, the task id is: a097dc02-71c9-4cab-9871-92ed1a7f2f45'[2020-05-08 03:45:11,590: INFO/MainProcess] Received task: schedules.tasks.debug_task[1b0dfc23-d3cc-495a-b306-9d1defe4b119][2020-05-08 03:45:11,659: INFO/ForkPoolWorker-1] Task schedules.tasks.debug_task[1b0dfc23-d3cc-495a-b306-9d1defe4b119] succeeded in 0.0677587790414691s: 'Hello Celery, the task id is: 1b0dfc23-d3cc-495a-b306-9d1defe4b119' 后台管理系统 task results 界面： task results 里默认显示的是 UTC 时间，可以修改 schedule_task/schedule_task/settings.py 配置文件更改时区设置：1TIME_ZONE = 'Asia/Shanghai' PS：实际测试以后，此处的时区设置只会对网页端 task results 表格中显示的时间起作用，实际保存到 task results 数据库表中的时间依旧是 UTC 时间。如需要二次开发，可以调用返回的 datetime 对象的 astimezone 方法进行时区格式转换。 参考资料Celery 4.4.2 documentation: First steps with Djangodjango-celery-beat - Database-backed Periodic Tasksdjango-celery-results - Celery Result Backends for Django]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Python</tag>
        <tag>Web</tag>
        <tag>Development</tag>
        <tag>Django</tag>
        <tag>Celery</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解 JavaScript 编程（ECMAScript 6）（一）]]></title>
    <url>%2F2020%2F05%2F07%2Funderstanding-JavaScript-EMCAScript-6-1%2F</url>
    <content type="text"><![CDATA[一、Block Binding在大多数基于 C 的编程语言中，变量通常会在声明时创建。而对于 JavaScript 语言，变量创建的时间点则取决于具体的声明方式。JavaScript 中经典的使用 var 声明变量的方式容易引起困惑，因此 ECMAScript 6 中引入了块级别的变量绑定（block-level binding）。 var 关键字var 关键字对于变量的声明，会默认该声明位于函数顶部（位于函数外部时为全局作用域），而不去管声明语句实际出现的位置。称为 hoisting 。12345678910111213141516function getValue(condition) &#123; if (condition) &#123; var value = "blue" console.log("condition is true and value is " + value) &#125; else &#123; console.log("condition is false and value is " + value) &#125; console.log("outside if, value is " + value)&#125;getValue(true)// condition is true and value is blue// outside if, value is bluegetValue(false)// condition is false and value is undefined// outside if, value is undefined 习惯上会认为，上述代码中只有 condition 为 True 时变量 value 才会被创建；实际上 value 变量存在于函数的各个部分，只是在 condition 为 False 时未被初始化（undefined）。 上面的代码会被 JavaScript 引擎视作如下形式：12345678910function getValue(condition) &#123; var value; if (condition) &#123; value = "blue"; console.log("condition is true and value is " + value) &#125; else &#123; console.log("condition is false and value is " + value) &#125; console.log("outside if, value is " + value)&#125; 块级声明和 let 语句由块级声明创建的变量无法被该代码块以外的部分访问。 块作用域（Block scopes）一般创建于以下位置： 函数内部 代码块内部（被大括号 {} 包裹的部分） 块作用域符合大部分基于 C 的编程语言的工作方式。 let 关键字会将变量的作用域限制在当前代码块内部。12345678910111213function getValue(condition) &#123; if (condition) &#123; let value = "blue" console.log("condition is true and value is " + value) &#125; else &#123; console.log("condition is false and value is " + value) &#125; console.log("outside if, value is " + value)&#125;getValue(true)// condition is true and value is blue// ReferenceError: value is not defined No Redeclaration如果同一作用域内已有相同名称的变量被声明，则 let 语句会报错。123var count = 30let count = 40// SyntaxError: Identifier 'count' has already been declared 但是在不同作用域中，类似的情况则不会报错：1234var count = 30if (true) &#123; let count = 40&#125; const 关键字用于声明常量，常量的值一旦确定后即不可再变更，因此在声明的同时必须赋值以完成初始化。123const maxItems = 30const name;// SyntaxError: Missing initializer in const declaration 需要注意的是，常量的“不可变”仅针对变量与值的绑定关系，而并不限制值本身的改动。即使用 const 声明某个对象，则对象本身的改动不被禁止。12345678910const person = &#123; name: "Nicholas"&#125;person.name = "Greg"person.name// 'Greg'person = &#123; name: "Grep"&#125;// TypeError: Assignment to constant variable. 循环中的块级绑定var：12345for (var i = 0; i &lt; 10; i++) &#123; // do nothing&#125;console.log(i)// 10 let：12345for (let i = 0; i &lt; 10; i++) &#123; // do nothing&#125;console.log(i)// ReferenceError: i is not defined var 声明语句的特性（loop 变量可以从 loop 外部访问）使得在循环中创建函数的行为会产生问题。123456789101112131415161718192021var funcs = []for (var i = 0; i &lt; 10; i++) &#123; funcs.push(function() &#123; console.log(i) &#125;)&#125;funcs.forEach(function(func) &#123; func()&#125;)// 10// 10// 10// 10// 10// 10// 10// 10// 10// 10 解决的办法是使用如下代码：1234567891011121314151617181920212223var funcs = []for (var i = 0; i &lt; 10; i++) &#123; funcs.push((function(value) &#123; return function() &#123; console.log(value) &#125; &#125;(i)))&#125;funcs.forEach(function(func) &#123; func()&#125;)// 0// 1// 2// 3// 4// 5// 6// 7// 8// 9 有了块级声明以后，上述需求可以被简单地实现（只需要将第一段代码中的 var 关键字改为 let 即可）：123456789101112131415161718192021var funcs = []for (let i = 0; i &lt; 10; i++) &#123; funcs.push(function() &#123; console.log(i) &#125;)&#125;funcs.forEach(function(func) &#123; func()&#125;)// 0// 1// 2// 3// 4// 5// 6// 7// 8// 9 二、函数参数带默认值的函数在 ECMAScript 5 及以前版本的 JavaScript 中，通常使用如下模式创建带默认参数的函数：12345function makeRequest(url, timeout, callback) &#123; timeout = timeout || 2000 callback = callback || function() &#123;&#125; // the rest code&#125; 但上述 || （或）操作符的使用存在一定问题，如传递给 timeout 参数的值为 0 时，timeout || 2000 表达式的值为 2000 而不是 0，导致程序出现意想不到的结果。改进如下：12345function makeRequest(url, timeout, callback) &#123; timeout = (typeof timeout !== "undefined") ? timeout : 2000 callback = (typeof callback !== "undefined") ? callback : function() &#123;&#125; // the rest code&#125; 在 ECMAScript 6 中，为函数的参数提供默认值的方式则非常简单直观：123function makeRequest(url, timeout = 2000, callback = function() &#123;&#125;) &#123; // the rest code&#125; 表达式作为参数默认值：12345678910function getValue() &#123; return 5&#125;function add(first, second = getValue()) &#123; return first + second&#125;console.log(add(1, 1)) // 2console.log(add(1)) // 6 甚至可以使用如下代码：12345678910function getValue(value) &#123; return value + 5&#125;function add(first, second = getValue(first)) &#123; return first + second&#125;console.log(add(1, 1)) // 2console.log(add(1)) // 7 匿名参数ECMAScript 5 中的匿名参数（通过 arguments 对象获取所有参数，包含定义函数时未显式指定的参数）：123456789101112131415161718function pick(object) &#123; let result = Object.create(null) for (let i = 1, len = arguments.length; i &lt; len; i++) &#123; result[arguments[i]] = object[arguments[i]] &#125; return result&#125;let book = &#123; title: "Understanding ECMAScript 6", author: "Nicholas C. Zakas", year: 2016&#125;let bookData = pick(book, "author", "year")console.log(bookData.author) // "Nicholas C. Zakas"console.log(bookData.year) // 2016 注意 for 循环是从 i=1 即第二个参数开始的。 Rest Parameters上述 pick 函数可以利用 ECMAScript 6 支持的 Rest Parameters 特性重写为如下形式：12345678910111213141516171819function pick(object, ...keys) &#123; let result = Object.create(null) for (let i = 0, len = keys.length; i &lt; len; i++) &#123; result[keys[i]] = object[keys[i]] &#125; return result&#125;let book = &#123; title: "Understanding ECMAScript 6", author: "Nicholas C. Zakas", year: 2016&#125;let bookData = pick(book, "author", "year")console.log(bookData.author) // "Nicholas C. Zakas"console.log(bookData.year) // 2016 函数构造器123var add = new Function("first", "second", "return first + second")console.log(add(1, 1)) // 2 ECMAScript 6 使得函数构造器可以支持默认参数和 rest parameters 等特性：12345678var add = new Function("first", "second = first", "return first + second")console.log(add(1, 1)) // 2console.log(add(1)) // 2var pickFirst = new Function("...args", "return args[0]")console.log(pickFirst(1, 2)) // 1 函数的两种调用方式123456789function Person(name) &#123; this.name = name&#125;var person = new Person("Nicholas")var notAPerson = Person("Nicholas")console.log(person) // Person &#123; name: 'Nicholas' &#125;console.log(notAPerson) // undefined JavaScript 有两个针对函数的内部方法：[[Call]] 和 [[Construct]]。 当函数不通过 new 关键字调用时，[[Call]] 方法执行，接着运行函数体中的代码；当函数通过 new 关键字调用时，[[Construct]] 方法执行，创建一个新的对象实例并绑定给 this，之后继续执行函数体中的代码。 ECMAScript 6 中可以使用 new.target 判断当前函数是否由 new 调用：12345678910function Person(name) &#123; if (typeof new.target !== "undefined") &#123; this.name = name &#125; else &#123; throw new Error("You must use new with Person.") &#125;&#125;var person = new Person("Nicholas")var notAPerson = Person("Michael") // error Arrow FunctionArrow Function 是指使用 =&gt; 符号定义的函数。与传统的 JavaScript 函数相比，Arrow Function 主要有以下几个不同点： 没有 this, super, arguments, new.target 的绑定。Arrow Function 中 this, super, arguments, new.target 的值由距离最近的非 Arrow Function 定义 不能被 new 调用。Arrow Function 没有构造方法因此不能作为构造器使用 没有 prototype。Arrow Function 的 prototype 属性不存在（函数本身不能被 new 调用，prototype 没有必要） 函数中的 this 的值不能被修改 基本语法：123456789101112131415161718192021222324252627282930313233343536373839let reflect = value =&gt; value// equivalent to:let reflect = function(value) &#123; return value&#125;let sum = (num1, num2) =&gt; num1 + num2// equivalent to:let sum = function(num1, num2) &#123; return num1 + num2&#125;let getName = () =&gt; "Nicholas"// equivalent to:let getName = function() &#123; return "Nicholas"&#125;let doNothing = () =&gt; &#123;&#125;// equivalent to:let doNothing = function() &#123;&#125;let getTempItem = id =&gt; (&#123; id: id, name: "Temp" &#125;)// equivalent to:let getTempItem = function(id) &#123; return &#123; id: id, name: "Temp" &#125;&#125; 参考资料Understanding ECMAScript 6]]></content>
      <categories>
        <category>Program</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Functional</tag>
        <tag>Advanced</tag>
        <tag>JavaScript</tag>
        <tag>ECMAScript6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高效 Python 代码 —— 属性与 @property 方法]]></title>
    <url>%2F2020%2F04%2F03%2Feffective-python-using-property%2F</url>
    <content type="text"><![CDATA[一、用属性替代 getter 或 setter 方法以下代码中包含手动实现的 getter（get_ohms) 和 setter（set_ohms） 方法：12345678910111213141516171819class OldResistor(object): def __init__(self, ohms): self._ohms = ohms self.voltage = 0 self.current = 0 def get_ohms(self): return self._ohms def set_ohms(self, ohms): self._ohms = ohmsr0 = OldResistor(50e3)print(f'Before: &#123;r0.get_ohms()&#125;')r0.set_ohms(10e3)print(f'After: &#123;r0.get_ohms()&#125;')# =&gt; Before: 50000.0# =&gt; After: 10000.0 这些工具方法有助于定义类的接口，使得开发者可以方便地封装功能、验证用法并限定取值范围。但是在 Python 语言中，应尽量从简单的 public 属性写起：123456789101112class Resistor(object): def __init__(self, ohms): self.ohms = ohms self.voltage = 0 self.current = 0r1 = Resistor(50e3)print(f'Before: &#123;r1.ohms&#125;')r1.ohms = 10e3print(f'After: &#123;r1.ohms&#125;')# =&gt; Before: 50000.0# =&gt; After: 10000.0 访问实例的属性则可以直接使用 instance.property 这样的格式。 如果想在设置属性的同时实现其他特殊的行为，如在对上述 Resistor 类的 voltage 属性赋值时，需要同时修改其 current 属性。可以借助 @property 装饰器和 setter 方法实现此类需求：1234567891011121314151617181920212223from resistor import Resistorclass VoltageResistor(Resistor): def __init__(self, ohms): super().__init__(ohms) self._voltage = 0 @property def voltage(self): return self._voltage @voltage.setter def voltage(self, voltage): self._voltage = voltage self.current = self._voltage / self.ohmsr2 = VoltageResistor(1e3)print(f'Before: &#123;r2.current&#125; amps')r2.voltage = 10print(f'After: &#123;r2.current&#125; amps')Before: 0 ampsAfter: 0.01 amps 此时设置 voltage 属性会执行名为 voltage 的 setter 方法，更新当前对象的 current 属性，使得最终的电流值与电压和电阻相匹配。 @property 的其他使用场景属性的 setter 方法里可以包含类型验证和数值验证的代码：1234567891011121314151617181920from resistor import Resistorclass BoundedResistor(Resistor): def __init__(self, ohms): super().__init__(ohms) @property def ohms(self): return self._ohms @ohms.setter def ohms(self, ohms): if ohms &lt;= 0: raise ValueError('ohms must be &gt; 0') self._ohms = ohmsr3 = BoundedResistor(1e3)r3.ohms = -5# =&gt; ValueError: ohms must be &gt; 0 甚至可以通过 @property 防止继承自父类的属性被修改：1234567891011121314151617181920from resistor import Resistorclass FixedResistance(Resistor): def __init__(self, ohms): super().__init__(ohms) @property def ohms(self): return self._ohms @ohms.setter def ohms(self, ohms): if hasattr(self, '_ohms'): raise AttributeError("Can't set attribute") self._ohms = ohmsr4 = FixedResistance(1e3)r4.ohms = 2e3# =&gt; AttributeError: Can't set attribute 要点 优先使用 public 属性定义类的接口，不手动实现 getter 或 setter 方法 在访问属性的同时需要表现某些特殊的行为（如类型检查、限定取值）等，使用 @property @property 的使用需遵循 rule of least surprise 原则，避免不必要的副作用 缓慢或复杂的工作，应放在普通方法中 二、需要复用的 @property 方法对于如下需求：编写一个 Homework 类，其成绩属性在被赋值时需要确保该值大于 0 且小于 100。借助 @property 方法实现起来非常简单：12345678910111213141516171819class Homework(object): def __init__(self): self._grade = 0 @property def grade(self): return self._grade @grade.setter def grade(self, value): if not (0 &lt;= value &lt;= 100): raise ValueError('Grade must be between 0 and 100') self._grade = valuegalileo = Homework()galileo.grade = 95print(galileo.grade)# =&gt; 95 假设上述验证逻辑需要用在包含多个科目的考试成绩上，每个科目都需要单独计分。则 @property 方法及验证代码就要重复编写多次，同时这种写法也不够通用。 采用 Python 的描述符可以更好地实现上述功能。在下面的代码中，Exam 类将几个 Grade 实例作为自己的类属性，Grade 类则通过 __get__ 和 __set__ 方法实现了描述符协议。1234567891011121314151617181920212223242526272829303132class Grade(object): def __init__(self): self._value = 0 def __get__(self, instance, instance_type): return self._value def __set__(self, instance, value): if not (0 &lt;= value &lt;= 100): raise ValueError('Grade must be between 0 and 100') self._value = valueclass Exam(object): math_grade = Grade() science_grade = Grade()first_exam = Exam()first_exam.math_grade = 82first_exam.science_grade = 99print('Math', first_exam.math_grade)print('Science', first_exam.science_grade)second_exam = Exam()second_exam.science_grade = 75print('Second exam science grade', second_exam.science_grade, ', right')print('First exam science grade', first_exam.science_grade, ', wrong')# =&gt; Math 82# =&gt; Science 99# =&gt; Second exam science grade 75 , right# =&gt; First exam science grade 75 , wrong 在对 exam 实例的属性进行赋值操作时：12exam = Exam()exam.math_grade = 40 Python 会将其转译为如下代码：1Exam.__dict__['math_grade'].__set__(exam, 40) 而获取属性值的代码：1print(exam.math_grade) 也会做如下转译：1print(Exam.__dict__['math_grade'].__get__(exam, Exam)) 但上述实现方法会导致不符合预期的行为。由于所有的 Exam 实例都会共享同一份 Grade 实例，在多个 Exam 实例上分别操作某一个属性就会出现错误结果。123456second_exam = Exam()second_exam.science_grade = 75print(&apos;Second exam science grade&apos;, second_exam.science_grade, &apos;, right&apos;)print(&apos;First exam science grade&apos;, first_exam.science_grade, &apos;, wrong&apos;)# =&gt; Second exam science grade 75 , right# =&gt; First exam science grade 75 , wrong 可以做出如下改动，将每个 Exam 实例所对应的值依次记录到 Grade 中，用字典结构保存每个实例的状态：1234567891011121314151617181920212223242526272829class Grade(object): def __init__(self): self._values = &#123;&#125; def __get__(self, instance, instance_type): if instance is None: return self return self._values.get(instance, 0) def __set__(self, instance, value): if not (0 &lt;= value &lt;= 100): raise ValueError('Grade must be between 0 and 100') self._values[instance] = valueclass Exam(object): math_grade = Grade() writing_grade = Grade() science_grade = Grade()first_exam = Exam()first_exam.math_grade = 82second_exam = Exam()second_exam.math_grade = 75print('First exam math grade', first_exam.math_grade, ', right')print('Second exam math grade', second_exam.math_grade, ', right')# =&gt; First exam math grade 82 , right# =&gt; Second exam math grade 75 , right 还有另外一个问题是，在程序的生命周期内，对于传给 __set__ 的每个 Exam 实例来说，_values 字典都会保存指向该实例的一份引用，导致该实例的引用计数无法降为 0 从而无法被 GC 回收。解决方法是将普通字典替换为 WeakKeyDictionary：12from weakref import WeakKeyDictionaryself._values = WeakKeyDictionary() 参考资料Effective Python]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Advanced</tag>
        <tag>Python</tag>
        <tag>Class</tag>
        <tag>OOP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vue.js 学习笔记（二）事件与表单元素]]></title>
    <url>%2F2020%2F04%2F03%2Fevents-and-form-elements-in-vue-js%2F</url>
    <content type="text"><![CDATA[接上文 Vue.js 学习笔记（一）数据绑定与指示器，环境搭建与配置等基础内容可前往参考 Events用户与 HTML 元素的交互行为都会触发特定的事件。Vue.js 通过 v-on 指示器创建对事件的绑定。1234567891011121314151617&lt;template&gt; &lt;div class=&quot;container-fluid&quot;&gt; &lt;div class=&quot;bg-primary text-white m-2 p-3 text-center&quot;&gt; &lt;h3 v-on:click=&quot;name = &apos;Clicked&apos;&quot;&gt;&#123;&#123; name &#125;&#125;&lt;/h3&gt; &lt;/div&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; data: function () &#123; return &#123; name: &quot;Lifejacket&quot; &#125; &#125;,&#125;&lt;/script&gt; Methods &amp; Events12345678910111213141516171819202122232425&lt;template&gt; &lt;div class=&quot;container-fluid&quot;&gt; &lt;div class=&quot;bg-primary text-white m-2 p-3 text-center&quot;&gt; &lt;h3 v-on:click=&quot;handleEvent(&apos;Soccer Ball&apos;, $event)&quot;&gt;&#123;&#123; name &#125;&#125;&lt;/h3&gt; &lt;/div&gt; &lt;div class=&quot;bg-primary text-white m-2 p-3 text-center&quot;&gt; &lt;h3 v-on:click=&quot;handleEvent(&apos;Stadium&apos;, $event)&quot;&gt;&#123;&#123; name &#125;&#125;&lt;/h3&gt; &lt;/div&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; data: function () &#123; return &#123; name: &quot;Lifejacket&quot; &#125; &#125;, methods: &#123; handleEvent(name, $event) &#123; this.name = `$&#123;name&#125; - $&#123;$event.type&#125;`; &#125; &#125;&#125;&lt;/script&gt; 综合示例12345678910111213141516171819202122232425262728293031323334&lt;template&gt; &lt;div class=&quot;container-fluid&quot;&gt; &lt;h3 class=&quot;bg=primary text-white text-center mt-2 p-2&quot;&gt;&#123;&#123; message &#125;&#125;&lt;/h3&gt; &lt;table class=&quot;table table-sm table-striped table-bordered&quot;&gt; &lt;tr&gt;&lt;th&gt;Index&lt;/th&gt;&lt;th&gt;Name&lt;/th&gt;&lt;th&gt;Actions&lt;/th&gt;&lt;/tr&gt; &lt;tr v-for=&quot;(name, index) in names&quot; v-bind:key=&quot;name&quot;&gt; &lt;td&gt;&#123;&#123; index &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; name &#125;&#125;&lt;/td&gt; &lt;td&gt; &lt;button class=&quot;btn btn-sm bg-primary text-white&quot; v-on:click=&quot;handleClick(name)&quot;&gt; Select &lt;/button&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; data: function () &#123; return &#123; message: &quot;Ready&quot;, names: [&quot;Kayak&quot;, &quot;Lifejacket&quot;, &quot;Soccer Ball&quot;, &quot;Stadium&quot;] &#125; &#125;, methods: &#123; handleClick(name) &#123; this.message = `Select: $&#123;name&#125;`; &#125; &#125;&#125;&lt;/script&gt; Keyboard Events123456789101112131415161718192021222324&lt;template&gt; &lt;div class=&quot;container-fluid&quot;&gt; &lt;div class=&quot;bg-primary p-4 text-white h3&quot;&gt; &#123;&#123; message &#125;&#125; &lt;/div&gt; &lt;input class=&quot;form-control bg-light&quot; placeholder=&quot;Type here...&quot; v-on:keydown.ctrl=&quot;handleKey&quot; /&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; data: function () &#123; return &#123; message: &quot;Ready&quot;, &#125; &#125;, methods: &#123; handleKey($event) &#123; this.message = $event.key; &#125; &#125;&#125;&lt;/script&gt; Form Elementsv-model 是 Vue.js 中用于 HTML 表单元素（input、select、textarea 等）的内置指示器。它能够在表单元素与数据之间创建双向绑定，使得不管数据怎样变更，元素的行为与数据值总可以保持一致性。 Two-Way Binding1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;template&gt; &lt;div class=&quot;container-fluid&quot;&gt; &lt;div class=&quot;bg-info m-2 p-2 text-white&quot;&gt; &lt;div&gt;Data Value: &#123;&#123; dataValue &#125;&#125;&lt;/div&gt; &lt;div&gt;Other Value: &#123;&#123; otherValue || &quot;(Empty)&quot; &#125;&#125;&lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;bg-primary m-2 p-2 text-white&quot;&gt; &lt;div class=&quot;form-check&quot;&gt; &lt;label class=&quot;form-check-label&quot;&gt; &lt;input class=&quot;form-check-input&quot; type=&quot;checkbox&quot; v-model=&quot;dataValue&quot; /&gt; Data Value &lt;/label&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;bg-primary m-2 p-2&quot;&gt; &lt;input type=&quot;text&quot; class=&quot;form-control&quot; v-model=&quot;otherValue&quot; /&gt; &lt;/div&gt; &lt;div class=&quot;text-center m-2&quot;&gt; &lt;button class=&quot;btn btn-secondary&quot; v-on:click=&quot;reset&quot;&gt; Reset &lt;/button&gt; &lt;/div&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; name: &quot;app&quot;, data: function () &#123; return &#123; dataValue: false, otherValue: &quot;&quot; &#125; &#125;, methods: &#123; reset() &#123; this.dataValue = false; this.otherValue = &quot;&quot;; &#125; &#125;&#125;&lt;/script&gt; 在上面的示例中，选中或取消 checkbox，在 input 中输入任意文本内容，与之关联的数据 dataValue 和 otherValue 的值都会同步发生改变。反过来，在控制台中手动修改 dataValue 和 otherValue 的值，checkbox 和 input 元素也会立即产生相应的变更。 Binding Text Fields123456789101112131415161718192021222324252627282930313233343536373839&lt;template&gt; &lt;div class=&quot;container-fluid&quot;&gt; &lt;div class=&quot;bg-info m-2 p-2 text-white&quot;&gt; &lt;div&gt;Name: &#123;&#123; name &#125;&#125;&lt;/div&gt; &lt;div&gt;Password: &#123;&#123; password &#125;&#125;&lt;/div&gt; &lt;div&gt;Details: &#123;&#123; details &#125;&#125;&lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;bg-primary m-2 p-2 text-white&quot;&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label&gt;Name&lt;/label&gt; &lt;input class=&quot;form-control&quot; v-model=&quot;name&quot; /&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label&gt;Password&lt;/label&gt; &lt;input type=&quot;password&quot; class=&quot;form-control&quot; v-model=&quot;password&quot; /&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label&gt;Detials&lt;/label&gt; &lt;textarea class=&quot;form-control&quot; v-model=&quot;details&quot; /&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; name: &quot;app&quot;, data: function () &#123; return &#123; name: &quot;Bob&quot;, password: &quot;secret&quot;, details: &quot;Has admin access&quot; &#125; &#125;&#125;&lt;/script&gt; Radio &amp; Checkbox1234567891011121314151617181920212223242526272829303132333435363738394041&lt;template&gt; &lt;div class=&quot;container-fluid&quot;&gt; &lt;div class=&quot;bg-info m-2 p-2 text-white&quot;&gt; &lt;div&gt;Name: &#123;&#123; name &#125;&#125;&lt;/div&gt; &lt;div&gt;Has Admin Access: &#123;&#123; hasAdminAccess &#125;&#125;&lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;bg-primary m-2 p-2 text-white&quot;&gt; &lt;div class=&quot;form-check&quot;&gt; &lt;input class=&quot;form-check-input&quot; type=&quot;radio&quot; v-model=&quot;name&quot; value=&quot;Bob&quot; /&gt; &lt;label class=&quot;form-check-label&quot;&gt;Bob&lt;/label&gt; &lt;/div&gt; &lt;div class=&quot;form-check&quot;&gt; &lt;input class=&quot;form-check-input&quot; type=&quot;radio&quot; v-model=&quot;name&quot; value=&quot;Alice&quot; /&gt; &lt;label class=&quot;form-check-label&quot;&gt;Alice&lt;/label&gt; &lt;/div&gt; &lt;div class=&quot;form-check&quot;&gt; &lt;input class=&quot;form-check-input&quot; type=&quot;checkbox&quot; v-model=&quot;hasAdminAccess&quot; /&gt; &lt;label class=&quot;form-check-label&quot;&gt;Has Admin Access?&lt;/label&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; name: &quot;app&quot;, data: function () &#123; return &#123; name: &quot;Bob&quot;, hasAdminAccess: true &#125; &#125;&#125;&lt;/script&gt; 注意每个 radio 元素都需要配置一个 value 属性，它决定了 v-model 指示器怎样修改与之绑定的数据（name）的值。 Bind Select12345678910111213141516171819202122232425262728293031&lt;template&gt; &lt;div class=&quot;container-fluid&quot;&gt; &lt;div class=&quot;bg-info m-2 p-2 text-white&quot;&gt; &lt;div&gt;Name: &#123;&#123; name &#125;&#125;&lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;bg-primary m-2 p-2 text-white&quot;&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label&gt;Selected Names&lt;/label&gt; &lt;select class=&quot;form-control&quot; v-model=&quot;name&quot;&gt; &lt;option value=&quot;all&quot;&gt;Everyone&lt;/option&gt; &lt;option v-for=&quot;n in allNames&quot; v-bind:key=&quot;n&quot; v-bind:value=&quot;n&quot;&gt;Just &#123;&#123; n &#125;&#125;&lt;/option&gt; &lt;/select&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; name: &quot;app&quot;, data: function () &#123; return &#123; allNames: [&quot;Bob&quot;, &quot;Alice&quot;, &quot;Joe&quot;], name: &quot;Bob&quot; &#125; &#125;&#125;&lt;/script&gt; 注意代码中 v-bind 指示器的使用。这里必须使用 v-bind 设置 option 的 value 属性，因为等号后面的 n 是变量而不是某个具体的值。 Bind Array12345678910111213141516171819202122232425262728293031323334353637&lt;template&gt; &lt;div class=&quot;container-fluid&quot;&gt; &lt;div class=&quot;bg-info m-2 p-2 text-white&quot;&gt; &lt;div&gt;Selected Cities: &#123;&#123; cities &#125;&#125;&lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;form-check m-2&quot; v-for=&quot;city in cityNames&quot; v-bind:key=&quot;city&quot;&gt; &lt;label class=&quot;form-check-label&quot;&gt; &lt;input type=&quot;checkbox&quot; class=&quot;form-check-input&quot; v-model=&quot;cities&quot; v-bind:value=&quot;city&quot; /&gt; &#123;&#123; city &#125;&#125; &lt;/label&gt; &lt;/div&gt; &lt;div class=&quot;text-center&quot;&gt; &lt;button v-on:click=&quot;reset&quot; class=&quot;btn btn-info&quot;&gt;Reset&lt;/button&gt; &lt;/div&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; name: &quot;app&quot;, data: function () &#123; return &#123; cityNames: [&quot;London&quot;, &quot;New York&quot;, &quot;Paris&quot;, &quot;Berlin&quot;], cities: [] &#125; &#125;, methods: &#123; reset() &#123; this.cities = []; &#125; &#125;&#125;&lt;/script&gt; Form 元素自定义值123456789101112131415161718192021222324252627282930&lt;template&gt; &lt;div class=&quot;container-fluid&quot;&gt; &lt;div class=&quot;m-2 p-2 text-white&quot; v-bind:class=&quot;elemClass&quot;&gt; &lt;div&gt;Value: &#123;&#123; elemClass &#125;&#125;&lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;form-check m-2&quot;&gt; &lt;label class=&quot;form-check-label&quot;&gt; &lt;input type=&quot;checkbox&quot; class=&quot;form-check-input&quot; v-model=&quot;dataValue&quot; /&gt; Dark Color &lt;/label&gt; &lt;/div&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; name: &quot;app&quot;, data: function () &#123; return &#123; dataValue: false, &#125; &#125;, computed: &#123; elemClass() &#123; return this.dataValue ? &quot;bg-primary&quot; : &quot;bg-info&quot;; &#125; &#125;&#125;&lt;/script&gt; 通过 computed property 将 checkbox 的 true 和 false 值转换为 &lt;div&gt; 元素的 bg-primary 和 bg-info class 属性。 综合示例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;template&gt; &lt;div class=&quot;container-fluid&quot;&gt; &lt;div class=&quot;m-2 p-2 text-white&quot; v-bind:class=&quot;dataValue&quot;&gt; &lt;div&gt;Value: &#123;&#123; dataValue &#125;&#125;&lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;form-check m-2&quot;&gt; &lt;label class=&quot;form-check-label&quot;&gt; &lt;input type=&quot;checkbox&quot; class=&quot;form-check-input&quot; v-model=&quot;dataValue&quot; v-bind:true-value=&quot;darkColor&quot; v-bind:false-value=&quot;lightColor&quot; /&gt; Dark Color &lt;/label&gt; &lt;/div&gt; &lt;div class=&quot;form-group m-2 p-2 bg-secondary&quot;&gt; &lt;label&gt;Color&lt;/label&gt; &lt;select v-model=&quot;dataValue&quot; class=&quot;form-control&quot;&gt; &lt;option v-bind:value=&quot;darkColor&quot;&gt;Dark Color&lt;/option&gt; &lt;option v-bind:value=&quot;lightColor&quot;&gt;Light Color&lt;/option&gt; &lt;/select&gt; &lt;/div&gt; &lt;div class=&quot;form-check-inline m-2&quot;&gt; &lt;label class=&quot;form-check-label&quot;&gt; &lt;input type=&quot;radio&quot; class=&quot;form-check-input&quot; v-model=&quot;dataValue&quot; v-bind:value=&quot;darkColor&quot; /&gt; Dark Color &lt;/label&gt; &lt;/div&gt; &lt;div class=&quot;form-check-inline m-2&quot;&gt; &lt;label class=&quot;form-check-lable&quot;&gt; &lt;input type=&quot;radio&quot; class=&quot;form-check-input&quot; v-model=&quot;dataValue&quot; v-bind:value=&quot;lightColor&quot; /&gt; Light Color &lt;/label&gt; &lt;/div&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; name: &quot;app&quot;, data: function () &#123; return &#123; darkColor: &quot;bg-primary&quot;, lightColor: &quot;bg-info&quot;, dataValue: &quot;bg-info&quot; &#125; &#125;,&#125;&lt;/script&gt; 参考资料Pro Vue.js 2]]></content>
      <categories>
        <category>Program</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Web</tag>
        <tag>Vue</tag>
        <tag>Frontend</tag>
        <tag>Javascript</tag>
        <tag>Vue.js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows 10 系统添加“从此处打开命令提示符”右键菜单]]></title>
    <url>%2F2020%2F01%2F23%2Fadd-open-cmd-in-right-click-menu%2F</url>
    <content type="text"><![CDATA[之前版本的 Windows 系统中，按住 shift 键的同时在空白处点击右键，可以找到从此处打开命令提示符的菜单项。可惜后面版本的 Win10 系统移除了该菜单项，替换成从此处打开 Powershell 窗口。可能习惯所致，对 Poweshell 不太感冒（启动很慢的感觉[狗头]）。在 cmd 中手动切换目录又过于麻烦，尤其是在跨驱动器的情况下。故尝试在右键菜单中添加“打开命令提示符”选项。 一、添加“从此处打开命令提示符”右键菜单 打开注册表编辑器（CTRL+R -&gt; regedit） 切换到 HKEY_CLASSES_ROOT\Directory\Background\shell\ 新建项 cmd_shell，其中字符串值(默认) 的数据改为“打开命令提示符”（菜单项的名称） 在 cmd_shell 中新建字符串值，名称为 Icon，数据为 C:\Windows\System32\cmd.exe（图标路径） 在 cmd_shell 下新建项 command，修改字符串值(默认) 的数据为 cmd.exe /s /k pushd &quot;%V&quot;（具体执行的命令） 如不想手动添加注册表，以下为可直接双击导入的 open_cmd.reg 文件：12345678Windows Registry Editor Version 5.00[HKEY_CLASSES_ROOT\Directory\Background\shell\cmd_shell]@=&quot;打开命令提示符&quot;&quot;Icon&quot;=&quot;C:\\Windows\\System32\\cmd.exe&quot;[HKEY_CLASSES_ROOT\Directory\Background\shell\cmd_shell\command]@=&quot;cmd.exe /s /k pushd \&quot;%V\&quot;&quot; 二、右键菜单添加“使用 VSCode 编辑文件” 个人习惯问题，感觉右键点击代码源文件，弹出的菜单里包含“使用 VSCode 编辑”会比较方便一点。方法同样是修改注册表。 打开注册表编辑器（CTRL+R -&gt; regedit） 切换到 HKEY_CLASSES_ROOT\*\shell 新建项 vscode，其中字符串值(默认) 的数据改为“Open with VSCode”（菜单项的名称） 在 vscode 中新建字符串值，名称为 Icon，数据类似 &quot;F:\Software\VSCode-win32-x64-1.36.1\Code.exe&quot;（图标路径） 在 vscode 下新建项 command，修改字符串值(默认) 的数据为 &quot;F:\Software\VSCode-win32-x64-1.36.1\Code.exe&quot; &quot;%1&quot;（具体执行的命令） 如不想手动添加注册表，以下为可直接双击导入的 open_with_code.reg 文件：12345678Windows Registry Editor Version 5.00[HKEY_CLASSES_ROOT\*\shell\VSCode]@=&quot;Open with Code&quot;&quot;Icon&quot;=&quot;F:\\Software\\VSCode-win32-x64-1.36.1\\Code.exe&quot;[HKEY_CLASSES_ROOT\*\shell\VSCode\command]@=&quot;\&quot;F:\\Software\\VSCode-win32-x64-1.36.1\\Code.exe\&quot; \&quot;%1\&quot;&quot;]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Tools</tag>
        <tag>Shell</tag>
        <tag>Windows</tag>
        <tag>Cmd</tag>
        <tag>VSCode</tag>
        <tag>Tricks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基本数据结构的 Python 实现及应用]]></title>
    <url>%2F2020%2F01%2F23%2Fbasic-data-structure-and-algorithm-with-python%2F</url>
    <content type="text"><![CDATA[一、内置数据结构的性能ListPython 内置的 List 类型针对不同操作的性能如下： Operation Big-O index O(1) index 赋值 O(1) append O(1) pop() O(1) pop(i) O(n) insert(i, item) O(n) del O(n) iteration O(n) contains (in) O(n) slice [x:y] O(k) del slice O(n) set slice O(n+k) reverse O(n) concatenate O(k) sort O(n log n) multiply O(nk) 几种列表初始化方式的运行时间对比（ concatenate &gt; append &gt; comprehension &gt; list range）：123456789101112131415161718192021222324252627282930313233343536373839from timeit import Timer# concatenatedef test1(): l = [] for i in range(1000): l = l + [i]# appenddef test2(): l = [] for i in range(1000): l.append(i)# comprehensiondef test3(): l = [ i for i in range(1000)]# list rangedef test4(): l = list(range(1000))t1 = Timer("test1()", "from __main__ import test1")print(f"concat &#123;t1.timeit(number=1000)&#125; milliseconds")t2 = Timer("test2()", "from __main__ import test2")print(f"append &#123;t2.timeit(number=1000)&#125; milliseconds")t3 = Timer("test3()", "from __main__ import test3")print(f"comprehension &#123;t3.timeit(number=1000)&#125; milliseconds")t4 = Timer("test4()", "from __main__ import test4")print(f"list range &#123;t4.timeit(number=1000)&#125; milliseconds")# concat 1.3573799000000002 milliseconds# append 0.0650925 milliseconds# comprehension 0.03262469999999995 milliseconds# list range 0.01332690000000003 milliseconds 列表的 pop(0) 方法和 pop() 方法的运行时间对比（pop(0) 为 O(n)，pop() 为 O(1)）：123456789101112131415161718192021from timeit import Timerfrom matplotlib import pyplot as pltpop_zero = Timer("x.pop(0)", "from __main__ import x")pop_end = Timer("x.pop()", "from __main__ import x")X, Ypt, Ypz = [], [], []for i in range(10000, 500001, 10000): x = list(range(i)) pt = pop_end.timeit(number=1000) pz = pop_zero.timeit(number=1000) X.append(i) Ypt.append(pt) Ypz.append(pz)plt.scatter(X, Ypt, c='m', marker='^', label='pop_end')plt.scatter(X, Ypz, c='y', label='pop_zero')plt.legend()plt.show() Dictionary Operation Big-O copy O(n) get item O(1) set item O(1) delete item O(1) contains (in) O(1) iteration O(n) 列表与字典 contains 操作的运行时间对比（列表为 O(n)，字典为 O(1)）：123456789101112131415161718192021222324import timeitimport randomfrom matplotlib import pyplot as pltX, Ylist, Ydict = [], [], []for i in range(10000, 1000001, 20000): t = timeit.Timer(f"random.randrange(&#123;i&#125;) in x", "from __main__ import random, x") x = list(range(i)) list_time = t.timeit(number=1000) x = &#123;j: None for j in range(i)&#125; dict_time = t.timeit(number=1000) X.append(i) Ylist.append(list_time) Ydict.append(dict_time)plt.scatter(X, Ylist, c='m', marker='^', label='list')plt.scatter(X, Ydict, c='y', label='dict')plt.legend()plt.show() 二、StackLIFO（last-in first-out），从顶部添加新项目，移除项目也从顶部开始。即越是最新添加到栈中的项目越是接近栈的顶部位置，同时也最先出栈。类似于在厨房里刷盘子，洗好的盘子摞在顶部，使用时也最先拿顶部（最近洗好）的干净盘子。12345678910111213141516171819202122232425262728293031323334# stack.pyclass Stack: def __init__(self): self.items = [] def is_empty(self): return self.items == [] def push(self, item): self.items.append(item) def pop(self): return self.items.pop() def peek(self): return self.items[len(self.items) - 1] def size(self): return len(self.items)if __name__ == '__main__': s = Stack() print(s.is_empty()) # True s.push(4) s.push('dog') print(s.peek()) # dog s.push(True) print(s.size()) # 3 s.push(8.4) print(s.pop()) # 8.4 print(s.pop()) # True print(s.size()) # 2 进制转换通过短除法将十进制数转换为其他进制：1234567891011121314151617181920from stack import Stackdef base_converter(dec_number, base): digits = "0123456789ABCDEF" rem_stack = Stack() while dec_number &gt; 0: rem = dec_number % base rem_stack.push(rem) dec_number = dec_number // base new_string = "" while not rem_stack.is_empty(): new_string = new_string + digits[rem_stack.pop()] return new_stringprint(base_converter(28, 2)) # 11100print(base_converter(28, 16)) # 1C 短除法每次循环生成的余数从后往前拼接得到最终的目标进制数字。即最先生成的余数为目标进制数字的最后一位，最后生成的余数为目标进制数字的第一位，后进先出。 括号匹配12345678910111213141516171819202122232425262728293031from stack import Stackdef par_checker(symbol_string): s = Stack() balanced = True index = 0 while index &lt; len(symbol_string) and balanced: symbol = symbol_string[index] if symbol in "([&#123;": s.push(symbol) else: if s.is_empty(): balanced = False else: top = s.pop() if not matches(top, symbol): balanced = False index += 1 if balanced and s.is_empty(): return True else: return Falsedef matches(open, close): opens = "([&#123;" closes = ")]&#125;" return opens.index(open) == closes.index(close)print(par_checker('&#123;&#123;([][])&#125;()&#125;')) # Trueprint(par_checker('[&#123;()]')) # False 遇到左半边括号（([{）就 push 到 Stack 中，遇到右半边括号（)]}）就从 Stack 中 pop 出一个左半边括号进行配对。最先遇到的右半边括号肯定需要与最后放入 Stack 中的左半边括号匹配（因此使用 Stack 的 pop 取数据）。最终 Stack 为空，则括号全部匹配。 三、Queues &amp; DequesFIFO（first-in first-out），从队列一端（rear）添加新项目，从另一端（front）弹出项目。类似于生活中的排队点餐，新来的顾客排到队伍最后面，队伍最前面的人优先点餐和付款然后离开队伍。deque 为双向队列。123456789101112131415161718192021222324252627282930313233343536373839# queues.pyclass Queue: def __init__(self): self.items = [] def is_empty(self): return self.items == [] def enqueue(self, item): self.items.insert(0, item) def dequeue(self): return self.items.pop() def size(self): return len(self.items)class Deque: def __init__(self): self.items = [] def is_empty(self): return self.items == [] def add_front(self, item): self.items.append(item) def add_rear(self, item): self.items.insert(0, item) def remove_front(self): return self.items.pop() def remove_rear(self): return self.items.pop(0) def size(self): return len(self.items) Palindrome CheckerPalindrome 是指左右对称的单词，如 radar、toot、madam 等。双向队列 Deque 从队列两端弹出数据，可用于检测目标单词首尾两端的字符是否一一对应，即是否对称。123456789101112131415161718192021from queues import Dequedef pal_checker(a_string): char_deque = Deque() for ch in a_string: char_deque.add_rear(ch) still_equal = True while char_deque.size() &gt; 1 and still_equal: first = char_deque.remove_front() last = char_deque.remove_rear() if first != last: still_equal = False return still_equalprint(pal_checker("lsdkjfskf")) #Falseprint(pal_checker("radar")) # True 四、SortBubble Sort12345678910def bubble_sort(a_list): for pass_num in range(len(a_list) - 1, 0, -1): for i in range(pass_num): if a_list[i] &gt; a_list[i + 1]: a_list[i], a_list[i + 1] = a_list[i + 1], a_list[i]a_list = [54, 26, 93, 17, 77, 31, 44, 55, 20]bubble_sort(a_list)print(a_list)# =&gt; [17, 20, 26, 31, 44, 54, 55, 77, 93] Bubble Sort 会依次比较序列中相邻两个数字的大小关系，必要时交换位置，保证较大的数字排在另一个数字右侧。整个序列执行完一轮完整的两两对比之后，可以保证最大的数字位于序列的最右侧。下一轮则可以将第二大的数字交换到序列中倒数第二的位置，依次类推。 Bubble Sort 通常认为是最低效的排序算法。复杂度为 O(n^2)。 Selection Sort123456789101112def selection_sort(a_list): for fill_slot in range(len(a_list) - 1, 0, -1): pos_of_max = 0 for location in range(1, fill_slot + 1): if a_list[location] &gt; a_list[pos_of_max]: pos_of_max = location a_list[pos_of_max], a_list[location] = a_list[location], a_list[pos_of_max]a_list = [54, 26, 93, 17, 77, 31, 44, 55, 20]selection_sort(a_list)print(a_list)# =&gt; [17, 20, 26, 31, 44, 54, 55, 77, 93] Selection Sort 会在第一轮对所有数字的比较中，记录最大数字的位置，令其与序列中最后位置的数字互换。然后在第二轮比较中找出第二大的数字，与序列中倒数第二位置上的数字互换，依次类推。复杂度为 O(n^2)。相对于 Bubble Sort，Selection Sort 减少了数字位置的交换次数，一轮只需要一次交换。 Insertion Sort123456789101112131415def insertion_sort(a_list): for index in range(1, len(a_list)): current_value = a_list[index] position = index while position &gt; 0 and a_list[position - 1] &gt; current_value: a_list[position] = a_list[position - 1] position = position - 1 a_list[position] = current_valuea_list = [54, 26, 93, 17, 77, 31, 44, 55, 20]insertion_sort(a_list)print(a_list)# =&gt; [17, 20, 26, 31, 44, 54, 55, 77, 93] Insertion Sort 可以理解为在当前序列头部维护着一个长度不断增长的排序好的子序列，每从序列后半段取出一个数字，就根据其与头部序列中数字的大小关系，插入到头部序列的适当位置。复杂度依旧为 O(n^2)。但通常情况下，shift 操作的性能一般要优于 exchange 操作。 Shell SortShell Sort 会从原来的待排序列表中以一定的间隔选取数字组成一系列小的子列表，再依次通过 Insertion Sort 方法进行排序。复杂度大概介于 O(n) 和 O(n^2) 之间。1234567891011121314151617181920212223242526def shell_sort(a_list): sublist_count = len(a_list) // 2 while sublist_count &gt; 0: for start_position in range(sublist_count): gap_insertion_sort(a_list, start_position, sublist_count) print("After increments of size", sublist_count, "The list is", a_list) sublist_count = sublist_count // 2def gap_insertion_sort(a_list, start, gap): for i in range(start + gap, len(a_list), gap): current_value = a_list[i] position = i while position &gt;= gap and a_list[position - gap] &gt; current_value: a_list[position] = a_list[position - gap] position = position - gap a_list[position] = current_valuea_list = [54, 26, 93, 17, 77, 31, 44, 55, 20]shell_sort(a_list)print(a_list)# =&gt; After increments of size 4 The list is [20, 26, 44, 17, 54, 31, 93, 55, 77]# =&gt; After increments of size 2 The list is [20, 17, 44, 26, 54, 31, 77, 55, 93]# =&gt; After increments of size 1 The list is [17, 20, 26, 31, 44, 54, 55, 77, 93]# =&gt; [17, 20, 26, 31, 44, 54, 55, 77, 93] Merge SortMerge Sort 是将原待排序列表递归地一分为二直到成为最小单位，然后在两两合并的过程中进行大小排序。合并操作完成后得到完整的排序好的列表。 Merge Sort 和后面的 Quick Sort 复杂度都为 O(n log n)。Merge Sort 在融合过程中需要使用额外的存储空间，而 Quick Sort 的复杂度有可能提高到 O(n^2) （当分割点不是接近列表的中间位置）。12345678910111213141516171819202122232425262728293031323334353637def merge_sort(a_list): print("Splitting ", a_list) if len(a_list) &gt; 1: mid = len(a_list) // 2 left_half = a_list[:mid] right_half = a_list[mid:] merge_sort(left_half) merge_sort(right_half) i = 0 j = 0 k = 0 while i &lt; len(left_half) and j &lt; len(right_half): if left_half[i] &lt; right_half[j]: a_list[k] = left_half[i] i = i + 1 else: a_list[k] = right_half[j] j = j + 1 k = k + 1 while i &lt; len(left_half): a_list[k] = left_half[i] i = i + 1 k = k + 1 while j &lt; len(right_half): a_list[k] = right_half[j] j = j + 1 k = k + 1 print("Merging ", a_list)a_list = [54, 26, 93, 17, 77, 31, 44, 55, 20]merge_sort(a_list)print(a_list) Quick Sort123456789101112131415161718192021222324252627282930313233343536373839404142def quick_sort(a_list): quick_sort_helper(a_list, 0, len(a_list) - 1)def quick_sort_helper(a_list, first, last): if first &lt; last: split_point = partition(a_list, first, last) quick_sort_helper(a_list, first, split_point - 1) quick_sort_helper(a_list, split_point + 1, last)def partition(a_list, first, last): pivot_value = a_list[first] left_mark = first + 1 right_mark = last done = False while not done: while left_mark &lt;= right_mark and \ a_list[left_mark] &lt;= pivot_value: left_mark = left_mark + 1 while a_list[right_mark] &gt;= pivot_value and \ right_mark &gt;= left_mark: right_mark = right_mark - 1 if right_mark &lt; left_mark: done = True else: temp = a_list[left_mark] a_list[left_mark] = a_list[right_mark] a_list[right_mark] = temp temp = a_list[first] a_list[first] = a_list[right_mark] a_list[right_mark] = temp return right_marka_list = [54, 26, 93, 17, 77, 31, 44, 55, 20]quick_sort(a_list)print(a_list) 参考资料Problem Solving with Algorithms and Data Structures using Python]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Advanced</tag>
        <tag>Python</tag>
        <tag>DataStructure</tag>
        <tag>Algorithm</tag>
        <tag>Sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Haskell 基本语法（一）列表与类型系统]]></title>
    <url>%2F2020%2F01%2F20%2Fbasic-haskell-lists-and-typeclass%2F</url>
    <content type="text"><![CDATA[算术与逻辑运算算术运算：12345678910111213Prelude&gt; 2 + 1517Prelude&gt; 5 / 22.5Prelude&gt; 50 * (100 - 4999)-244950Prelude&gt; 5 * -3&lt;interactive&gt;:4:1: error: Precedence parsing error cannot mix ‘*’ [infixl 7] and prefix `-' [infixl 6] in the same infix expressionPrelude&gt; 5 * (-3)-15 逻辑运算：123456Prelude&gt; True &amp;&amp; FalseFalsePrelude&gt; False || TrueTruePrelude&gt; not (True &amp;&amp; False)True 判断是否相等：12345678Prelude&gt; 5 == 5TruePrelude&gt; 5 == 4FalsePrelude&gt; 5 /= 4TruePrelude&gt; "hello" == "hello"True 函数调用在 Haskell 中，+ - * / 等操作符实际上也是函数，只不过调用时函数名位于两个参数之间，叫做 infix 函数。其他常见的函数为 prefix 函数，通过函数名+空格+参数的格式（fun a b ...）调用。123456Prelude&gt; succ 89Prelude&gt; min 9 109Prelude&gt; succ 9 + max 5 4 + 116 接收两个参数的函数也可以在调用时将函数名放在参数中间，如：1234Prelude&gt; div 10 25Prelude&gt; 10 `div` 25 Haskell 中传递给函数的参数不需要像 C 语言中那样放置在 () 中，因此 bar (bar 3) 实际上等同于 C 中的 bar(bar(3))。 函数定义12345Prelude&gt; doubleMe x = x + xPrelude&gt; doubleMe 918Prelude&gt; doubleMe 8.316.6 12345Prelude&gt; doubleSmallNumber x = if x &gt; 100 then x else x * 2Prelude&gt; doubleSmallNumber 123123Prelude&gt; doubleSmallNumber 80160 Haskell 中的 if 语句是一种表达式。表达式是指某一段有返回值的代码片段。比如 5 是表达式，返回数字 5；x + y 也是表达式，返回 x 与 y 的和。因此 Haskell if 语句中的 else 是必需的（保证一定有返回值）。 listHaskell 中的列表只能存放同一类型的数据项。123Prelude&gt; let a = [1,2,3,4]Prelude&gt; a[1,2,3,4] Haskell 中的字符串实际上是数据项类型为 Char 的列表，&quot;hello&quot; 仅仅是 [&#39;h&#39;,&#39;e&#39;,&#39;l&#39;,&#39;l&#39;,&#39;o&#39;] 的一种语法糖。123456Prelude&gt; ['h','e','l','l','o']"hello"Prelude&gt; ['h','e','l','l','o'] == "hello"TruePrelude&gt; :t "hello""hello" :: [Char] 列表通过 ++ 符号执行连接操作。1234Prelude&gt; [1,2,3,4] ++ [5][1,2,3,4,5]Prelude&gt; "hello" ++ " " ++ "world""hello world" PS：使用 ++ 操作符连接两个列表时，即便右边的列表只包含一个数据项，也需要用 [] 括起来。不管右边添加的列表有多少数据项，左边的列表都会在合并时遍历自身的所有项。 可以使用 : 操作符在列表左侧添加一个数据项。1234Prelude&gt; 'A' : " Small Cat""A Small Cat"Prelude&gt; 5 : [1,2,3,4,5][5,1,2,3,4,5] PS：[1,2,3] 实际上是 1:2:3:[] 的语法糖。12Prelude&gt; 1:2:3:[][1,2,3] 使用 !! 操作符根据索引获取列表中的某个数据项。1234Prelude&gt; [1,2,3,4] !! 01Prelude&gt; "hello" !! 1'e' elem 可以判断某个数据项与列表的包含关系。1234Prelude&gt; elem 4 [3,4,5,6]TruePrelude&gt; elem 100 [3,4,5,6]False 比较列表的大小时，会从列表左侧开始逐个数据项进行比对。123456Prelude&gt; [3,2,1] &gt; [3,1,0]TruePrelude&gt; [3,2,1] &gt; [2,10,100]TruePrelude&gt; [3,4,2] &gt; [3,4]True 常见的作用于列表的函数： head：获取列表的首个元素 tail：获取列表的尾部（除首个元素以外的）元素 last：获取列表的最后一个元素 init：获取列表的前几个（除最后一个元素以外）元素 length：返回列表长度 null：判断列表是否为空 reverse：逆序输出源列表 minimum：获取列表中的最小值 maximum：获取列表中的最大值 sum：获取列表中所有元素的加和 product：获取列表中所有元素的乘积 1234567891011121314Prelude&gt; head [5,4,3,2,1]5Prelude&gt; tail [5,4,3,2,1][4,3,2,1]Prelude&gt; last [5,4,3,2,1]1Prelude&gt; init [5,4,3,2,1][5,4,3,2]Prelude&gt; length [5,4,3,2,1]5Prelude&gt; null [5,4,3,2,1]FalsePrelude&gt; reverse [5,4,3,2,1][1,2,3,4,5] 其他如对列表的 subset 操作，take 函数可以获取列表中的前几个数据项（即生成子列表），drop 可以获取列表中除前几项以外的其他数据项。12345678910Prelude&gt; take 3 [5,4,3,2,1][5,4,3]Prelude&gt; drop 3 [5,4,3,2,1][2,1]Prelude&gt; take 0 [5,4,3,2,1][]Prelude&gt; take 10 [5,4,3,2,1][5,4,3,2,1]Prelude&gt; drop 100 [5,4,3,2,1][] range1234Prelude&gt; [1..10][1,2,3,4,5,6,7,8,9,10]Prelude&gt; ['a' .. 'z']"abcdefghijklmnopqrstuvwxyz" 包含步长的 range，比如获取 2 到 20 之间的所有偶数，和获取 3 到 20 之间所有3 的倍数：1234Prelude&gt; [2,4..20][2,4,6,8,10,12,14,16,18,20]Prelude&gt; [3,6..20][3,6,9,12,15,18] 从语法上看，[] 中需包含前两项以及最后一项（的范围）。因此获取 20 到 1 的数字列表则可以使用 [20,19..1]。12Prelude&gt; [20,19..1][20,19,18,17,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1] 此外，获取从 13 开始共 24 个 13 的倍数，可以使用 [13,26..24*13]，也可以使用 take 24 [13,26..]。没有提供最后一项的范围（如 [13,26..]）时，range 方式会生成无穷列表。Haskell 的计算是 lazy 的，因此不用担心无穷列表会吃掉所有内存。 生成无穷列表还可以使用 cycle 或者 repeat：1234Prelude&gt; take 10 (cycle [1,2,3])[1,2,3,1,2,3,1,2,3,1]Prelude&gt; take 10 (repeat 5)[5,5,5,5,5,5,5,5,5,5] 列表推导Haskell 中的列表推导，写法上很像单纯的数学公式 $S = {2 * x | x \in \mathbb{N}, x &lt;= 10}$12Prelude&gt; [x*2 | x &lt;- [1..10]][2,4,6,8,10,12,14,16,18,20] 等同于 Python 中的如下表达式：12&gt;&gt;&gt; [x * 2 for x in range(1, 11)][2, 4, 6, 8, 10, 12, 14, 16, 18, 20] 更复杂的情况如：12Prelude&gt; [x*2 | x &lt;- [1..10], x*2 &gt;= 12][12,14,16,18,20] 甚至可以有如下用法：1234Prelude&gt; [x*y | x &lt;- [2,5,10], y &lt;- [8,10,11]][16,20,22,40,50,55,80,100,110]Prelude&gt; [x*y | x &lt;- [2,5,10], y &lt;- [8,10,11], x*y &gt; 50][55,80,100,110] 借助列表推导可以定义自己的 length 函数：123Prelude&gt; length xs = sum [1 | _ &lt;- xs]Prelude&gt; length [1,2,3,4]4 定义函数去除某个列表中所有的非大写字符：123Prelude&gt; removeNonUppercase st = [c | c &lt;- st, elem c ['A' .. 'Z']]Prelude&gt; removeNonUppercase "Hahaha! Ahahaha!""HA" TupleHaskell 中的元组相对于列表主要有以下特性： 元组的类型由所含元素的长度和每个元素的类型确定 元组中可以包含不同类型的元素 如 (&quot;Christopher&quot;, &quot;Walken&quot;, 55) 这样的元组是合法的，即单个元组中可以包含字符串（列表）、数字等不同类型；[(1,2),(8,11,5),(4,5)] 和 [(1,2),(&quot;One&quot;,2)] 这样的列表则是不合法的，因为不同长度或者元素类型不同的元组，其类型也是不同的，不能作为同一个列表中的元素。123456Prelude&gt; :t (1,2)(1,2) :: (Num t, Num t1) =&gt; (t1, t)Prelude&gt; :t (8,11,5)(8,11,5) :: (Num t, Num t1, Num t2) =&gt; (t2, t1, t)Prelude&gt; :t ("one",2)("one",2) :: Num t =&gt; ([Char], t) fst 可以返回元组的第一个元素，snd 返回元组的第二个元素。这两个函数只作用于长度为 2 的元组。1234Prelude&gt; fst (8,11)8Prelude&gt; snd ("Wow", False)False zip 可以将两个列表中的每一个元素一一组合成长度为二的元组，最终形成新的以元组为元素的列表。123456Prelude&gt; zip [1,2,3,4,5] [5,5,5,5,5][(1,5),(2,5),(3,5),(4,5),(5,5)]Prelude&gt; zip [1..5] ["one", "two", "three", "four", "five"][(1,"one"),(2,"two"),(3,"three"),(4,"four"),(5,"five")]Prelude&gt; zip [1..] ["apple", "orange", "cherry", "mango"][(1,"apple"),(2,"orange"),(3,"cherry"),(4,"mango")] 类型系统Haskell 是静态类型的语言，每一个表达式在编译时其类型便已知。不同于 Java 等语言，Haskell 支持类型推断。它可以自行推断出某个数字属于 Int 类型。123456789101112Prelude&gt; :t 'a''a' :: CharPrelude&gt; :t TrueTrue :: BoolPrelude&gt; :t "HELLO!""HELLO!" :: [Char]Prelude&gt; :t (True, 'a')(True, 'a') :: (Bool, Char)Prelude&gt; :t ('a','b','c')('a','b','c') :: (Char, Char, Char)Prelude&gt; :t 4 == 54 == 5 :: Bool :: 读作 has type of 。元组的类型取决于其中每一个元素的类型以及元组长度，因此表达式 (&#39;a&#39;,&#39;b&#39;,&#39;c&#39;) 的类型为 (Char, Char, Char)。表达式 4 == 5 总是返回 False，因此其类型为 Bool。 Haskell 中的函数同样有类型。123Prelude&gt; removeNonUppercase st = [ c | c &lt;- st, c `elem` ['A'..'Z']]Prelude&gt; :t removeNonUppercaseremoveNonUppercase :: [Char] -&gt; [Char] removeNoneUppercase 函数的类型为 [Char] -&gt; [Char]，说明该函数的参数类型为字符串，返回值类型为字符串。即函数的类型通过由 -&gt; 符号分隔的参数与返回值的类型表示。 类型变量函数的类型由参数和返回值表示，但是有些函数的参数与返回值的类型并不会固定为某一种。比如 head 函数可以获取列表中的第一个元素，而列表中元素的类型可能由很多种。123456Prelude&gt; head [1,2,3,4]1Prelude&gt; head "hello"'h'Prelude&gt; :t headhead :: [a] -&gt; a head :: [a] -&gt; a 中的 a 即为类型变量，表示该参数或返回值可以是任意类型。包含类型变量的函数叫做多态函数。除了 a 以外，其他如 b、c、d 等也可作为类型变量使用。像前面的 [a] -&gt; a， a 可以表示任意类型，但两个 a 必定是同一类型。1234Prelude&gt; fst ("hello", True)"hello"Prelude&gt; :t fstfst :: (a, b) -&gt; a TypeclassTypeclass 是一种定义了某些行为的接口。如果某个类型属于特定的 typeclass，则意味着该类型实现了由 typeclass 描述的行为，类似于 Java 中的 interface。12Prelude&gt; :t (==)(==) :: Eq a =&gt; a -&gt; a -&gt; Bool 其中 =&gt; 符号前面的部分叫做类约束，可以这样理解：== 函数接收任意两个相同类型（a）的数值，根据其是否相等返回 Bool 值。两个输入参数的类型必须是 Eq 类的成员（因此叫类约束）。 Eq typeclass 为其成员类型提供了测试相等性的接口，任何可以用来比较是否相等的类型都应该是 Eq 类的成员。所有 Haskell 基本类型（除 IO 外）和函数都是 Eq typeclass 的一部分。 以下是一些基本的 typeclass：Eq 用于类型之间的相等性测试，实现的函数有 == 和 /= 。12345678910Prelude&gt; 5 == 5TruePrelude&gt; 5 /= 5FalsePrelude&gt; 'a' == 'a'TruePrelude&gt; "Ho Ho" == "Ho Ho"TruePrelude&gt; 3.432 == 3.432True Ord 用于拥有顺序的类型，包含所有基本的比较函数如 &gt;、&lt; 和 &gt;= 等。123456Prelude&gt; :t (&gt;)(&gt;) :: Ord a =&gt; a -&gt; a -&gt; BoolPrelude&gt; "Abrakadabra" &lt; "Zebra"TruePrelude&gt; 5 &gt;= 2True Show 的成员可以表示为字符串，最常用的用于处理 Show 成员的函数是 show，可以将某个类型的值转换为字符串表示：123456Prelude&gt; show 3"3"Prelude&gt; show 5.334"5.334"Prelude&gt; show True"True" Read 是和 Show 相反的一类 typeclass。read 函数可以接收字符串并返回属于 Read 的某个类型（自行推断或显示指定）：12345678910Prelude&gt; read "True" || FalseTruePrelude&gt; read "8.2" + 3.812.0Prelude&gt; read "[1,2,3,4]" ++ [3][1,2,3,4,3]Prelude&gt; read "[1,2,3,4]"*** Exception: Prelude.read: no parsePrelude&gt; read "[1,2,3,4]" :: [Int][1,2,3,4] Enum 的成员是有顺序的序列类型，可以被枚举。Enum 中的成员都可以使用 range 的方式生成列表，也都可以被自增或自减函数调用。12345678Prelude&gt; ['a'..'e']"abcde"Prelude&gt; [3..5][3,4,5]Prelude&gt; succ 'B''C'Prelude&gt; pred 'C''B' Num 是一个数字类型的 typeclass。它的成员都具有数字类型的属性。12345678Prelude&gt; :t 2020 :: Num t =&gt; tPrelude&gt; 20 :: Float20.0Prelude&gt; 20 :: Double20.0Prelude&gt; :t (*)(*) :: Num a =&gt; a -&gt; a -&gt; a 函数 * 的类型为 Num a =&gt; a -&gt; a -&gt; a，因此其参数必须是 Num typelcass 的成员，且必须是同一类型。123456789Prelude&gt; 5 * (6 :: Float)30.0Prelude&gt; (5 :: Int) * (6 :: Float)&lt;interactive&gt;:56:15: error: • Couldn't match expected type ‘Int’ with actual type ‘Float’ • In the second argument of ‘(*)’, namely ‘(6 :: Float)’ In the expression: (5 :: Int) * (6 :: Float) In an equation for ‘it’: it = (5 :: Int) * (6 :: Float) 参考资料Learn You a Haskell for Great Good!]]></content>
      <categories>
        <category>Program</category>
      </categories>
      <tags>
        <tag>Haskell</tag>
        <tag>Program</tag>
        <tag>Functional</tag>
        <tag>Type</tag>
        <tag>Advanced</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vue.js 学习笔记（一）数据绑定与指示器]]></title>
    <url>%2F2020%2F01%2F18%2Fdata-binding-and-directives-in-vue-js%2F</url>
    <content type="text"><![CDATA[一、安装与项目初始化安装 @vue/cli：$ npm install -g @vue/cli 安装 git：sudo apt-get install git 创建项目：$ vue create todo --default 项目结构12345678910111213141516$ tree todo -I node_modulestodo├── babel.config.js├── package.json├── package-lock.json├── public│ ├── favicon.ico│ └── index.html├── README.md└── src ├── App.vue ├── assets │ └── logo.png ├── components │ └── HelloWorld.vue └── main.js 文件 功能 public/index.html 浏览器加载的 HTML 文件。其中包含用于显示 Vue 应用的标签和加载应用文件的 &lt;script&gt; src/main.js 负责 Vue 应用的基本配置，通常还用于注册应用依赖的第三方组件 src/App.vue Vue 组件，即 Vue 应用的主要构成部分。如需要显示给用户的 HTML 页面、Javascript 代码和 CSS 等 public/index.html：12345678910&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt; &lt;head&gt; &lt;title&gt;todo&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;div id="app"&gt;&lt;/div&gt; &lt;!-- built files will be auto injected --&gt; &lt;/body&gt;&lt;/html&gt; src/main.js：12345678import Vue from 'vue'import App from './App.vue'Vue.config.productionTip = falsenew Vue(&#123; render: h =&gt; h(App),&#125;).$mount('#app') App.vue：12345678910111213141516171819202122232425262728&lt;template&gt; &lt;div id=&quot;app&quot;&gt; &lt;img alt=&quot;Vue logo&quot; src=&quot;./assets/logo.png&quot;&gt; &lt;HelloWorld msg=&quot;Welcome to Your Vue.js App&quot;/&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;import HelloWorld from &apos;./components/HelloWorld.vue&apos;export default &#123; name: &apos;app&apos;, components: &#123; HelloWorld &#125;&#125;&lt;/script&gt;&lt;style&gt;#app &#123; font-family: &apos;Avenir&apos;, Helvetica, Arial, sans-serif; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; text-align: center; color: #2c3e50; margin-top: 60px;&#125;&lt;/style&gt; 开启测试服务器：$ npm run serve 二、数据绑定与指示器准备工作，添加 CSS 库：$ npm install bootstrap@4.0.0 修改 src/main.js 导入 Bootstrap：1234567891011// src/main.jsimport Vue from 'vue'import App from './App.vue'import "bootstrap/dist/css/bootstrap.min.css";Vue.config.productionTip = falsenew Vue(&#123; render: h =&gt; h(App),&#125;).$mount('#app') 1. 数据绑定展示数据给用户是 web 组件最重要的工作之一，数据绑定可以将 &lt;script&gt; 下定义的数据对象关联给 &lt;template&gt; 中的特定元素进行显示。 显示数据修改 src/App.vue 如下：1234567891011121314151617// src/App.vue&lt;template&gt; &lt;div id=&quot;app&quot; class=&quot;bg-primary text-white text-center m-2 p-3&quot;&gt; &lt;h3&gt;Product: &#123;&#123; name &#125;&#125;&lt;/h3&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; name: &quot;app&quot;, data: function () &#123; return &#123; name: &quot;Kayak&quot; &#125; &#125;&#125;&lt;/script&gt; 通过 JavaScript 模块中的 data 属性定义了可以被绑定的数据值：12345data: function () &#123; return &#123; name: "Kayak" &#125;&#125; 再借助数据绑定机制，使用 等语法将 &lt;script&gt; 中定义的数据关联到 template 模块的 HTML 元素中。这种形式的绑定也称为文本注入（text interpolation binding）。 绑定中使用表达式实际上数据绑定不仅仅可以通过预先定义的变量替换 HTML 元素中的文本，还可以直接嵌入复杂的表达式，具体代码如下：1234567891011121314151617181920// src/App.vue&lt;template&gt; &lt;div id=&quot;app&quot; class=&quot;bg-primary text-white text-center m-2 p-3&quot;&gt; &lt;h3&gt;Product: &#123;&#123; name &#125;&#125;&lt;/h3&gt; &lt;h3&gt;Price: $&#123;&#123; (price + (price * (taxRate / 100))).toFixed(2) &#125;&#125;&lt;/h3&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; name: &quot;app&quot;, data: function () &#123; return &#123; name: &quot;Kayak&quot;, price: 275, taxRate: 12 &#125; &#125;&#125;&lt;/script&gt; Computed Properties在数据绑定中使用过于复杂的表达式并不利于代码的阅读、维护和复用。为了使 template 组件可以足够简单，Vue 提供了计算属性模块，可以从 data 属性提供的数据中生成需要的值，从而减少数据绑定中复杂表达式的使用。12345678910111213141516171819202122232425// src/App.vue&lt;template&gt; &lt;div id=&quot;app&quot; class=&quot;bg-primary text-white text-center m-2 p-3&quot;&gt; &lt;h3&gt;Product: &#123;&#123; name &#125;&#125;&lt;/h3&gt; &lt;h3&gt;Price: $&#123;&#123; totalPrice.toFixed(2) &#125;&#125;&lt;/h3&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; name: &quot;app&quot;, data: function () &#123; return &#123; name: &quot;Kayak&quot;, price: 275, taxRate: 12 &#125; &#125;, computed: &#123; totalPrice: function() &#123; return this.price + (this.price * (this.taxRate / 100)); &#125; &#125;&#125;&lt;/script&gt; 关键代码：1234567&lt;h3&gt;Price: $&#123;&#123; totalPrice.toFixed(2) &#125;&#125;&lt;/h3&gt;...computed: &#123; totalPrice: function() &#123; return this.price + (this.price * (this.taxRate / 100)); &#125;&#125; Methods方法相对于计算属性则更加灵活，可以定义自己的参数。1234567891011121314151617181920212223242526272829303132333435// src/App.vue&lt;template&gt; &lt;div id=&quot;app&quot; class=&quot;bg-primary text-white text-center m-2 p-3&quot;&gt; &lt;h3&gt;Product: &#123;&#123; name &#125;&#125;&lt;/h3&gt; &lt;h4&gt;Price: $&#123;&#123; lowTotalPrice.toFixed(2) &#125;&#125; (Low Rate)&lt;/h4&gt; &lt;h4&gt;Price: $&#123;&#123; highTotalPrice.toFixed(2) &#125;&#125; (High Rate)&lt;/h4&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; name: &quot;app&quot;, data: function () &#123; return &#123; name: &quot;Kayak&quot;, price: 275, lowTaxRate: 12, highTaxRate: 20 &#125; &#125;, computed: &#123; lowTotalPrice: function () &#123; return this.getTotalPrice(this.lowTaxRate); &#125;, highTotalPrice: function () &#123; return this.getTotalPrice(this.highTaxRate); &#125;&#125;, methods: &#123; getTotalPrice(taxRate) &#123; return this.price + (this.price * (taxRate / 100)); &#125; &#125;&#125;&lt;/script&gt; 也可以省略掉上面代码中对计算属性的定义，直接在数据绑定时调用方法。这显示了各组件之间组织的灵活性，当然此举也会增加 template 中代码的复杂度：12345678910111213141516171819202122232425262728// src/App.vue&lt;template&gt; &lt;div id=&quot;app&quot; class=&quot;bg-primary text-white text-center m-2 p-3&quot;&gt; &lt;h3&gt;Product: &#123;&#123; name &#125;&#125;&lt;/h3&gt; &lt;h4&gt;Price: $&#123;&#123; getTotalPrice(lowTaxRate).toFixed(2) &#125;&#125; (Low Rate)&lt;/h4&gt; &lt;h4&gt;Price: $&#123;&#123; getTotalPrice(highTaxRate).toFixed(2) &#125;&#125; (High Rate)&lt;/h4&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; name: &quot;app&quot;, data: function () &#123; return &#123; name: &quot;Kayak&quot;, price: 275, lowTaxRate: 12, highTaxRate: 20 &#125; &#125;, methods: &#123; getTotalPrice(taxRate) &#123; return this.price + (this.price * (taxRate / 100)); &#125; &#125;&#125;&lt;/script&gt; Filters过滤器是一种在 filter 模块下定义的函数，可以对需要显示的表达式进行格式化操作：12345678910111213141516171819202122232425262728293031323334// src/App.vue&lt;template&gt; &lt;div id=&quot;app&quot; class=&quot;bg-primary text-white text-center m-2 p-3&quot;&gt; &lt;h3&gt;Product: &#123;&#123; name &#125;&#125;&lt;/h3&gt; &lt;h4&gt;Price: &#123;&#123; getTotalPrice(lowTaxRate) | currency &#125;&#125; (Low Rate)&lt;/h4&gt; &lt;h4&gt;Price: &#123;&#123; getTotalPrice(highTaxRate) | currency &#125;&#125; (High Rate)&lt;/h4&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; name: &quot;app&quot;, data: function () &#123; return &#123; name: &quot;Kayak&quot;, price: 275, lowTaxRate: 12, highTaxRate: 20 &#125; &#125;, methods: &#123; getTotalPrice(taxRate) &#123; return this.price + (this.price * (taxRate / 100)); &#125; &#125;, filters: &#123; currency(value) &#123; return new Intl.NumberFormat(&quot;en-US&quot;, &#123; style: &quot;currency&quot;, currency: &quot;USD&quot; &#125;).format(value); &#125; &#125;&#125;&lt;/script&gt; 复杂 Filter1234567891011121314151617181920212223242526272829303132333435363738394041424344// src/App.vue&lt;template&gt; &lt;div id=&quot;app&quot; class=&quot;bg-primary text-white text-center m-2 p-3&quot;&gt; &lt;h3&gt;Product: &#123;&#123; name | reverse | capitalize &#125;&#125;&lt;/h3&gt; &lt;h4&gt;Price: &#123;&#123; getTotalPrice(lowTaxRate) | currency(3) &#125;&#125; (Low Rate)&lt;/h4&gt; &lt;h4&gt;Price: &#123;&#123; getTotalPrice(highTaxRate) | currency &#125;&#125; (High Rate)&lt;/h4&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; name: &quot;app&quot;, data: function () &#123; return &#123; name: &quot;Lifejacket&quot;, price: 48.95, lowTaxRate: 12, highTaxRate: 20 &#125; &#125;, methods: &#123; getTotalPrice(taxRate) &#123; return this.price + (this.price * (taxRate / 100)); &#125; &#125;, filters: &#123; currency(value, places) &#123; return new Intl.NumberFormat(&quot;en-US&quot;, &#123; style: &quot;currency&quot;, currency: &quot;USD&quot;, minimumFractionDigits: places || 2, maximumFractionDigits: places || 2 &#125;).format(value); &#125;, capitalize(value) &#123; return value[0].toUpperCase() + value.slice(1); &#125;, reverse(value) &#123; return value.split(&quot;&quot;).reverse().join(&quot;&quot;); &#125; &#125;&#125;&lt;/script&gt; 2. Directives指示器 是 template 中可以为 HTML 元素添加 Vue.js 功能的一些特殊属性。比如 v-on:click 指示器可以为 &lt;button&gt; 元素添加对鼠标单击事件的监听，v-text 指示器可以设置某个 HTML 元素的文字内容。 有选择地显示元素使用 v-if 指示器控制 HTML 元素的显示与隐藏：12345678910111213141516171819202122232425262728293031// src/App.vue&lt;template&gt; &lt;div id=&quot;app&quot; class=&quot;container-fluid text-center&quot;&gt; &lt;div class=&quot;bg-primary text-white m-2 p-3&quot;&gt; &lt;h3&gt;Product: &lt;span v-text=&quot;name&quot;&gt;&lt;/span&gt;&lt;/h3&gt; &lt;h4 v-if=&quot;showElements&quot;&gt;&#123;&#123; price &#125;&#125;&lt;/h4&gt; &lt;/div&gt; &lt;button v-on:click=&quot;handleClick&quot; class=&quot;btn btn-primary&quot;&gt; Press Me &lt;/button&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; name: &quot;app&quot;, data: function () &#123; return &#123; name: &quot;Lifejacket&quot;, price: 275, showElements: true &#125; &#125;, methods: &#123; handleClick() &#123; this.showElements = !this.showElements; &#125; &#125;,&#125;&lt;/script&gt; 关键代码：12345678&lt;h4 v-if="showElements"&gt;&#123;&#123; price &#125;&#125;&lt;/h4&gt;&lt;button v-on:click="handleClick" class="btn btn-primary"&gt;...methods: &#123; handleClick() &#123; this.showElements = !this.showElements; &#125; &#125; v-if-else123456789101112131415161718192021222324252627282930313233// src/App.vue&lt;template&gt; &lt;div id=&quot;app&quot; class=&quot;container-fluid text-center&quot;&gt; &lt;div class=&quot;bg-primary text-white m-2 p-3&quot;&gt; &lt;h3 v-if=&quot;counter % 3 == 0&quot;&gt;Product: &#123;&#123;name&#125;&#125;&lt;/h3&gt; &lt;h3 v-else-if=&quot;counter % 3 == 1&quot;&gt;Price: &#123;&#123;price&#125;&#125;&lt;/h3&gt; &lt;h3 v-else&gt;Category: &#123;&#123;category&#125;&#125;&lt;/h3&gt; &lt;/div&gt; &lt;button v-on:click=&quot;handleClick&quot; class=&quot;btn btn-primary&quot;&gt; Press Me &lt;/button&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; name: &quot;app&quot;, data: function () &#123; return &#123; name: &quot;Lifejacket&quot;, price: 275, category: &quot;Waterspots&quot;, counter: 0 &#125; &#125;, methods: &#123; handleClick() &#123; this.counter++; &#125; &#125;,&#125;&lt;/script&gt; 设置元素的 Class 属性 通过 v-bind:class 设置 HTML 元素的 Class 属性：1234567891011121314151617181920212223242526272829303132333435// src/App.vue&lt;template&gt; &lt;div id=&quot;app&quot; class=&quot;container-fluid text-center&quot;&gt; &lt;div class=&quot;bg-primary text-white m-2 p-3&quot;&gt; &lt;h3 v-bind:class=&quot;elemClasses&quot;&gt;Product: &#123;&#123;name&#125;&#125;&lt;/h3&gt; &lt;/div&gt; &lt;button v-on:click=&quot;handleClick&quot; class=&quot;btn btn-primary&quot;&gt; Press Me &lt;/button&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; name: &quot;app&quot;, data: function () &#123; return &#123; name: &quot;Lifejacket&quot;, highlight: false &#125; &#125;, computed: &#123; elemClasses() &#123; return this.highlight ? [&quot;bg-light&quot;, &quot;text-dark&quot;, &quot;display-4&quot;] : [&quot;bg-dark&quot;, &quot;text-light&quot;, &quot;p-2&quot;]; &#125; &#125;, methods: &#123; handleClick() &#123; this.highlight = !this.highlight; &#125; &#125;,&#125;&lt;/script&gt; 设置多个属性v-bind 指示器可以同时设置 HTML 元素的 class、style 等属性，甚至还可以包括原本不存在的由用户自行定义的属性（如下面代码中的 data-size）。12345678910111213141516171819202122232425262728293031323334353637383940414243// src/App.vue&lt;template&gt; &lt;div id=&quot;app&quot; class=&quot;container-fluid text-center&quot;&gt; &lt;div class=&quot;bg-primary text-white m-2 p-3&quot;&gt; &lt;h3 v-bind=&quot;attrValues&quot;&gt;Product: &#123;&#123;name&#125;&#125;&lt;/h3&gt; &lt;/div&gt; &lt;button v-on:click=&quot;handleClick&quot; class=&quot;btn btn-primary&quot;&gt; Press Me &lt;/button&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; name: &quot;app&quot;, data: function () &#123; return &#123; name: &quot;Lifejacket&quot;, highlight: false &#125; &#125;, computed: &#123; attrValues() &#123; return &#123; class: this.highlight ? [&quot;bg-light&quot;, &quot;text-dark&quot;] : [], style: &#123; border: this.highlight ? &quot;5px solid red&quot; : &quot;&quot; &#125;, &quot;data-size&quot;: this.highlight ? &quot;big&quot; : &quot;small&quot; &#125; &#125; &#125;, methods: &#123; handleClick() &#123; this.highlight = !this.highlight; &#125; &#125;,&#125;&lt;/script&gt;&lt;style&gt; [data-size=big] &#123; font-size: 40pt; &#125; [data-size=small] &#123; font-size: 20pt; &#125;&lt;/style&gt; 设置 HTMLElement 属性（不常用）123456789101112131415161718192021222324252627282930313233// src/App.vue&lt;template&gt; &lt;div id=&quot;app&quot; class=&quot;container-fluid text-center&quot;&gt; &lt;div class=&quot;bg-primary text-white m-2 p-3&quot;&gt; &lt;h3 v-bind:text-content.prop=&quot;textContent&quot;&gt;&lt;/h3&gt; &lt;/div&gt; &lt;button v-on:click=&quot;handleClick&quot; class=&quot;btn btn-primary&quot;&gt; Press Me &lt;/button&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; name: &quot;app&quot;, data: function () &#123; return &#123; name: &quot;Lifejacket&quot;, highlight: false &#125; &#125;, computed: &#123; textContent() &#123; return this.highlight ? &quot;Highlight!&quot; : `Product: $&#123;this.name&#125;`; &#125; &#125;, methods: &#123; handleClick() &#123; this.highlight = !this.highlight; &#125; &#125;,&#125;&lt;/script&gt; 3. Repeater DirectiveVue.js 中的 v-for 指示器可以用来操作数组格式的数据、生成表格和 Grid 布局等。 遍历数组v-for 指示器可以遍历数组结构中的数据对象并以循环的方式绑定给多个 HTML 元素。1234567891011121314151617181920212223242526272829303132333435363738394041// src/App.vue&lt;template&gt; &lt;div id=&quot;app&quot; class=&quot;container-fluid text-center&quot;&gt; &lt;h2 class=&quot;bg-primary text-while text-center p-3&quot;&gt;Products&lt;/h2&gt; &lt;table class=&quot;table table-sm table-bordered table-striped text-left&quot;&gt; &lt;tr&gt;&lt;th&gt;Index&lt;/th&gt;&lt;th&gt;Name&lt;/th&gt;&lt;th&gt;Price&lt;/th&gt;&lt;/tr&gt; &lt;tbody&gt; &lt;tr v-for=&quot;(p, i) in products&quot; v-bind:key=&quot;p.name&quot;&gt; &lt;td&gt;&#123;&#123; i + 1 &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; p.name &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; p.price &#125;&#125;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;div&gt; &lt;button v-on:click=&quot;handleClick&quot; class=&quot;btn btn-primary&quot;&gt; Press Me &lt;/button&gt; &lt;/div&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; name: &quot;app&quot;, data: function () &#123; return &#123; products: [ &#123; name: &quot;Kayak&quot;, price: 275 &#125;, &#123; name: &quot;Lifejacket&quot;, price: 48.95 &#125;, &#123; name: &quot;Soccer Ball&quot;, price: 19.50 &#125;, ] &#125; &#125;, methods: &#123; handleClick() &#123; this.products.push(this.products.shift()); &#125; &#125;,&#125;&lt;/script&gt; 关键代码：12345&lt;tr v-for=&quot;(p, i) in products&quot; v-bind:key=&quot;p.name&quot;&gt; &lt;td&gt;&#123;&#123; i + 1 &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; p.name &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; p.price &#125;&#125;&lt;/td&gt;&lt;/tr&gt; 遍历对象注意此处遍历的数据结构是 JavaScript 对象而不是上面代码中的数组。123456789101112131415161718192021222324252627282930313233343536373839404142434445// src/App.vue&lt;template&gt; &lt;div id=&quot;app&quot; class=&quot;container-fluid text-center&quot;&gt; &lt;h2 class=&quot;bg-primary text-while text-center p-3&quot;&gt;Products&lt;/h2&gt; &lt;table class=&quot;table table-sm table-bordered table-striped text-left&quot;&gt; &lt;tr&gt;&lt;th&gt;Index&lt;/th&gt;&lt;th&gt;Key&lt;/th&gt;&lt;th&gt;Name&lt;/th&gt;&lt;th&gt;Price&lt;/th&gt;&lt;/tr&gt; &lt;tbody&gt; &lt;tr v-for=&quot;(p, key, i) in products&quot; v-bind:key=&quot;p.name&quot;&gt; &lt;td&gt;&#123;&#123; i + 1 &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; key &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; p.name &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; p.price &#125;&#125;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;div&gt; &lt;button v-on:click=&quot;handleClick&quot; class=&quot;btn btn-primary&quot;&gt; Press Me &lt;/button&gt; &lt;/div&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;import Vue from &quot;vue&quot;;export default &#123; name: &quot;app&quot;, data: function () &#123; return &#123; products: &#123; &quot;kayak&quot;: &#123; name: &quot;Kayak&quot;, price: 275 &#125;, 22: &#123; name: &quot;Lifejacket&quot;, price: 48.95 &#125;, 3: &#123; name: &quot;Soccer Ball&quot;, price: 19.50 &#125;, 4: &#123; name: &quot;Corner Flags&quot;, price: 39.95 &#125; &#125; &#125; &#125;, methods: &#123; handleClick() &#123; Vue.set(this.products, 5, &#123; name: &quot;Running Shoes&quot;, price: 100 &#125;); &#125; &#125;,&#125;&lt;/script&gt; PS：更新表格数据应使用 Vue.set()，不要使用类似 this.products[index] = xx 这样的形式。1Vue.set(this.products, 5, &#123; name: &quot;Running Shoes&quot;, price: 100 &#125;); v-for 与 Computed Propertiesv-for 指示器可以搭配计算属性和方法等一起使用，参考（细品）下面的分页示例：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859// src/App.vue&lt;template&gt; &lt;div id=&quot;app&quot; class=&quot;container-fluid text-center&quot;&gt; &lt;h2 class=&quot;bg-primary text-while text-center p-3&quot;&gt;Products&lt;/h2&gt; &lt;table class=&quot;table table-sm table-bordered table-striped text-left&quot;&gt; &lt;tr&gt;&lt;th&gt;Name&lt;/th&gt;&lt;th&gt;Price&lt;/th&gt;&lt;/tr&gt; &lt;tbody&gt; &lt;tr v-for=&quot;p in pageItems&quot; v-bind:key=&quot;p.name&quot;&gt; &lt;td&gt;&#123;&#123; p.name &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; p.price &#125;&#125;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;div&gt; &lt;!-- eslint-disable-next-line vue/require-v-for-key --&gt; &lt;button v-for=&quot;i in pageCount&quot; v-on:click=&quot;selectPage(i)&quot; class=&quot;btn btn-secondary m-1&quot; v-bind:class=&quot;&#123;&apos;bg-primary&apos;: currentPage == i&#125;&quot;&gt; &#123;&#123; i &#125;&#125; &lt;/button&gt; &lt;/div&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; data: function () &#123; return &#123; pageSize: 3, currentPage: 1, products: [ &#123; name: &quot;Kayak&quot;, price: 275 &#125;, &#123; name: &quot;Lifejacket&quot;, price: 48.95 &#125;, &#123; name: &quot;Soccer Ball&quot;, price: 19.50 &#125;, &#123; name: &quot;Corner Flags&quot;, price: 39.95 &#125;, &#123; name: &quot;Stadium&quot;, price: 79500 &#125;, &#123; name: &quot;Thinking Cap&quot;, price: 16 &#125;, &#123; name: &quot;Unsteady Chair&quot;, price: 29.95 &#125;, &#123; name: &quot;Human Chess Board&quot;, price: 75 &#125;, &#123; name: &quot;Bling Bling King&quot;, price: 1200 &#125; ] &#125; &#125;, computed: &#123; pageCount() &#123; return Math.ceil(this.products.length / this.pageSize); &#125;, pageItems() &#123; let start = (this.currentPage - 1) * this.pageSize; return this.products.slice(start, start + this.pageSize); &#125; &#125;, methods: &#123; selectPage(page) &#123; this.currentPage = page; &#125; &#125;&#125;&lt;/script&gt; 参考资料Pro Vue.js 2]]></content>
      <categories>
        <category>Program</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Web</tag>
        <tag>Development</tag>
        <tag>Vue</tag>
        <tag>Frontend</tag>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python3 中的字符串格式化语法]]></title>
    <url>%2F2020%2F01%2F14%2Fstring-format-in-python3%2F</url>
    <content type="text"><![CDATA[一、旧式的字符串格式化% 操作符参考以下示例：123&gt;&gt;&gt; name = "Eric"&gt;&gt;&gt; "Hello, %s." % name'Hello, Eric.' 当有多个变量需要插入到字符串中时：1234&gt;&gt;&gt; name = "Eric"&gt;&gt;&gt; age = 74&gt;&gt;&gt; "Hello, %s. You are %s." % (name, age)'Hello, Eric. You are 74.' 当需要替换的变量进一步增多时，使用 % 操作符格式化字符串会导致代码可读性变得很差：1234567&gt;&gt;&gt; first_name = "Eric"&gt;&gt;&gt; last_name = "Idle"&gt;&gt;&gt; age = 74&gt;&gt;&gt; profession = "comedian"&gt;&gt;&gt; affiliation = "Monty Python"&gt;&gt;&gt; "Hello, %s %s. You are %s. You are a %s. You were a member of %s." % (first_name, last_name, age, profession, affiliation)'Hello, Eric Idle. You are 74. You are a comedian. You were a member of Monty Python.' str.format()str.format() 是对 % 方式的改进，它使用常见的函数调用的语法，并且可以通过定义对象本身的 __format__() 方法控制字符串格式化的具体行为。 基本用法：1234&gt;&gt;&gt; name = "Eric"&gt;&gt;&gt; age = 74&gt;&gt;&gt; "Hello, &#123;&#125;. You are &#123;&#125;.".format(name, age)'Hello, Eric. You are 74.' str.format() 相对于 % 操作符有着更强的灵活性。比如可以通过数字索引来关联替换到字符串中的变量：1234&gt;&gt;&gt; name = "Eric"&gt;&gt;&gt; age = 74&gt;&gt;&gt; "Hello, &#123;1&#125;. You are &#123;0&#125;.".format(age, name)'Hello, Eric. You are 74.' 为了提高代码可读性，{} 中也可以使用有具体含义的参数名：1234&gt;&gt;&gt; name = "Eric"&gt;&gt;&gt; age = 74&gt;&gt;&gt; "Hello, &#123;name&#125;. You are &#123;age&#125;".format(name=name, age=age)'Hello, Eric. You are 74' 针对字典结构的数据：123&gt;&gt;&gt; person = &#123;'name': 'Eric', 'age': 74&#125;&gt;&gt;&gt; "Hello, &#123;name&#125;. You are &#123;age&#125;.".format(name=person['name'], age=person['age'])'Hello, Eric. You are 74.' 或者更简洁的方式：123&gt;&gt;&gt; person = &#123;'name': 'Eric', 'age': 74&#125;&gt;&gt;&gt; "Hello, &#123;name&#125;. You are &#123;age&#125;.".format(**person)'Hello, Eric. You are 74.' 问题在于当需要替换的变量很多时，str.format() 方式依然会导致代码变得过于冗长：12345678910&gt;&gt;&gt; first_name = "Eric"&gt;&gt;&gt; last_name = "Idle"&gt;&gt;&gt; age = 74&gt;&gt;&gt; profession = "comedian"&gt;&gt;&gt; affiliation = "Monty Python"&gt;&gt;&gt; "Hello, &#123;first_name&#125; &#123;last_name&#125;. You are &#123;age&#125;. \ You are a &#123;profession&#125;. You were a member of &#123;affiliation&#125;."\ .format(first_name=first_name, last_name=last_name, age=age, \ profession=profession, affiliation=affiliation)'Hello, Eric Idle. You are 74. You are a comedian. You were a member of Monty Python.' 二、f-string基本用法1234&gt;&gt;&gt; name = "Eric"&gt;&gt;&gt; age = 74&gt;&gt;&gt; f"Hello, &#123;name&#125;. You are &#123;age&#125;."'Hello, Eric. You are 74.' 嵌入表达式123456789101112&gt;&gt;&gt; f"&#123;2 * 37&#125;"'74'&gt;&gt;&gt; def to_lowercase(input):... return input.lower() &gt;&gt;&gt; name = "Eric Idle"&gt;&gt;&gt; f"&#123;to_lowercase(name)&#125; is funny"'eric idle is funny'&gt;&gt;&gt; f"&#123;name.lower()&#125; is funny"'eric idle is funny' f-string 中还可以直接嵌入某个对象实例，只要其内部实现了 __str__ 或者 __repr__ 方法：12345678910111213class Comedian: def __init__(self, first_name, last_name, age): self.first_name = first_name self.last_name = last_name self.age = age def __str__(self): return f"&#123;self.first_name&#125; &#123;self.last_name&#125; is &#123;self.age&#125;"new_comedian = Comedian("Eric", "Idle", 74)print(f"&#123;new_comedian&#125;")# Eric Idle is 74 多行 f-string12345678910&gt;&gt;&gt; name = "Eric"&gt;&gt;&gt; profession = "comedian"&gt;&gt;&gt; affiliation = "Monty Python"&gt;&gt;&gt; message = (... f"Hi &#123;name&#125;. "... f"You are a &#123;profession&#125;. "... f"You were in &#123;affiliation&#125;."... )&gt;&gt;&gt; message'Hi Eric. You are a comedian. You were in Monty Python.' 参考资料Python 3’s f-Strings: An Improved String Formatting Syntax (Guide)]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Python</tag>
        <tag>Basic</tag>
        <tag>String</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 通过 ldap3 操作 Windows 域账号]]></title>
    <url>%2F2020%2F01%2F14%2Fmanipulate-windows-ad-account-with-python-ldap3%2F</url>
    <content type="text"><![CDATA[ldap3 是一个严格遵守 RFC 4510 规范，完全由纯 Python 代码实现的 LDAPv3 客户端。ldap3 只依赖于 Python 标准库和 pyasn1，无需使用 C 编译器编译或者安装其他二进制程序，直接使用 pip 命令安装即可（pip install ldap3）。 一、连接服务器12345&gt;&gt;&gt; from ldap3 import Server, Connection, ALL&gt;&gt;&gt; server = Server('&lt;hostname_or_ip&gt;')&gt;&gt;&gt; conn = Connection(server)&gt;&gt;&gt; conn.bind()True 或者也可以使用更简短的形式：123&gt;&gt;&gt; conn = Connection('&lt;hostname_or_ip&gt;', auto_bind=True)&gt;&gt;&gt; connConnection(server=Server(host='xx.xx.xx.xx', port=389, use_ssl=False, allowed_referral_hosts=[('*', True)], get_info='SCHEMA', mode='IP_V6_PREFERRED'), auto_bind='NO_TLS', version=3, authentication='ANONYMOUS', client_strategy='SYNC', auto_referrals=True, check_names=True, read_only=False, lazy=False, raise_exceptions=False, fast_decoder=True, auto_range=True, return_empty_attributes=True, auto_encode=True, auto_escape=True, use_referral_cache=False) 获取服务器信息：12345678910&gt;&gt;&gt; server = Server('&lt;hostname_or_ip&gt;', get_info=ALL)&gt;&gt;&gt; conn = Connection(server, auto_bind=True)&gt;&gt;&gt; server.infoDSA info (from DSE): Supported LDAP versions: 3, 2 Naming contexts: DC=example,DC=com CN=Configuration,DC=example,DC=com CN=Schema,CN=Configuration,DC=example,DC=com... 用户绑定12345&gt;&gt;&gt; from ldap3 import Server, Connection, ALL&gt;&gt;&gt; server = Server('&lt;hostname_or_ip&gt;', get_info=ALL)&gt;&gt;&gt; conn = Connection(server, user='admin@example.com', password='admin@123', auto_bind=True)&gt;&gt;&gt; conn.extend.standard.who_am_i()'u:EXAMPLE\\admin' PS：通常在对域账号进行修改等操作时，需要启用 SSL 连接以符合安全规范。在构造 Server 对象时传入 use_ssl=True 即可：1server = Server(&apos;&lt;hostname_or_ip&gt;&apos;, port=636, use_ssl=True, get_info=ALL) 如有需要，TLS 的启用可以参考官方文档 https://ldap3.readthedocs.io/ssltls.html 二、对象检索使用 FreeIPA 开放的 LDAP 示例服务测试搜索操作：1234567891011&gt;&gt;&gt; from ldap3 import Server, Connection, ALL&gt;&gt;&gt; server = Server('ipa.demo1.freeipa.org', get_info=ALL)&gt;&gt;&gt; conn = Connection(server, 'uid=admin,cn=users,cn=accounts,dc=demo1,dc=freeipa,dc=org', 'Secret123', auto_bind=True)&gt;&gt;&gt; conn.search('dc=demo1,dc=freeipa,dc=org', '(objectclass=person)')True&gt;&gt;&gt; conn.entries[DN: uid=admin,cn=users,cn=accounts,dc=demo1,dc=freeipa,dc=org - STATUS: Read - READ TIME: 2020-01-13T18:57:39.837356, DN: uid=manager,cn=users,cn=accounts,dc=demo1,dc=freeipa,dc=org - STATUS: Read - READ TIME: 2020-01-13T18:57:39.837594, DN: uid=employee,cn=users,cn=accounts,dc=demo1,dc=freeipa,dc=org - STATUS: Read - READ TIME: 2020-01-13T18:57:39.837722, DN: uid=helpdesk,cn=users,cn=accounts,dc=demo1,dc=freeipa,dc=org - STATUS: Read - READ TIME: 2020-01-13T18:57:39.837845] search 方法有两个参数是必需的： search_base 用于指定搜索的起始位置 search_filter 用于指定搜索的筛选条件 filter 的定义语法支持 =、&lt;=、&gt;= 等比较运算符和 &amp;、|、! 等逻辑运算符。如：(&amp;(givenName=John)(mail=*@example.com)) 表示寻找名字为 John 且邮箱以 ``@example.com 结尾的域账号。 以下搜索条件则表示寻找名字为 Fred 或 John，并且邮箱以 ``@example.com 结尾的域账号：1234567(&amp; (| (givenName=Fred) (givenName=John) ) (mail=*@example.com)) attributes参考如下代码：12345678910111213141516&gt;&gt;&gt; conn.search('dc=demo1,dc=freeipa,dc=org', '(&amp;(objectclass=person)(uid=admin))', attributes=['sn', 'krbLastPwdChange', 'objectclass'])True&gt;&gt;&gt; conn.entries[0]DN: uid=admin,cn=users,cn=accounts,dc=demo1,dc=freeipa,dc=org - STATUS: Read - READ TIME: 2020-01-13T19:14:20.657761 krbLastPwdChange: 2019-01-25 15:16:11+00:00 objectclass: top person posixaccount krbprincipalaux krbticketpolicyaux inetuser ipaobject ipasshuser ipaSshGroupOfPubKeys ipaNTUserAttrs sn: Administrator 其中 (&amp;(objectclass=person)(uid=admin) 用于指定查找对象类型为 person 且 uid 为 admin 的用户账号； attributes 参数则用于指定搜索结果中额外包含该账户的 sn、krbLastPwdChange 和 objectclass 属性。 PS：设置 attributes = [&#39;*&#39;] 可以在搜索结果中显示对象的所有属性。 可以使用 Entry 对象的 entry_to_json 方法将该对象的所有属性以 JSON 格式输出：123456789101112131415161718192021222324&gt;&gt;&gt; print(conn.entries[0].entry_to_json())&#123; "attributes": &#123; "krbLastPwdChange": [ "2019-01-25 15:16:11+00:00" ], "objectclass": [ "top", "person", "posixaccount", "krbprincipalaux", "krbticketpolicyaux", "inetuser", "ipaobject", "ipasshuser", "ipaSshGroupOfPubKeys", "ipaNTUserAttrs" ], "sn": [ "Administrator" ] &#125;, "dn": "uid=admin,cn=users,cn=accounts,dc=demo1,dc=freeipa,dc=org"&#125; 此外还可以使用 paged_size 参数控制每页显示的结果数量。综合实例如下：12345678910111213141516&gt;&gt;&gt; searchParameters = &#123;'search_base': 'dc=demo1,dc=freeipa,dc=org',... 'search_filter': '(objectClass=Person)',... 'attributes': ['cn', 'givenName'],... 'paged_size': 3&#125;&gt;&gt;&gt; conn.search(**searchParameters)True&gt;&gt;&gt; conn.entries[DN: uid=admin,cn=users,cn=accounts,dc=demo1,dc=freeipa,dc=org - STATUS: Read - READ TIME: 2020-01-13T19:23:50.396926 cn: Administrator, DN: uid=manager,cn=users,cn=accounts,dc=demo1,dc=freeipa,dc=org - STATUS: Read - READ TIME: 2020-01-13T19:23:50.397214 cn: Test Manager givenName: Test, DN: uid=employee,cn=users,cn=accounts,dc=demo1,dc=freeipa,dc=org - STATUS: Read - READ TIME: 2020-01-13T19:23:50.397509 cn: Test Employee givenName: Test] 三、数据库操作创建条目新建 OU：12&gt;&gt;&gt; conn.add('ou=ldap3-tutorial,dc=demo1,dc=freeipa,dc=org', 'organizationalUnit')True 新建用户：12&gt;&gt;&gt; conn.add('cn=b.young,ou=ldap3-tutorial,dc=demo1,dc=freeipa,dc=org', 'inetOrgPerson', &#123;'givenName': 'Beatrix', 'sn': 'Young', 'departmentNumber': 'DEV', 'telephoneNumber': 1111&#125;)True 查看 objectClass 结构：12345678910&gt;&gt;&gt; server.schema.object_classes['person']Object class: 2.5.6.6 Short name: person Type: Structural Superior: top Must contain attributes: sn, cn May contain attributes: userPassword, telephoneNumber, seeAlso, description Extensions: X-ORIGIN: RFC 4519 OidInfo: ('2.5.6.6', 'OBJECT_CLASS', 'person', 'RFC4519') 重命名条目12&gt;&gt;&gt; conn.modify_dn('cn=b.young,ou=ldap3-tutorial,dc=demo1,dc=freeipa,dc=org', 'cn=b.smith')True 移动条目1234&gt;&gt;&gt; conn.add('ou=moved,ou=ldap3-tutorial,dc=demo1,dc=freeipa,dc=org','organizationalUnit')True&gt;&gt;&gt; conn.modify_dn('cn=b.smith,ou=ldap3-tutorial,dc=demo1,dc=freeipa,dc=org', 'cn=b.smith', new_superior='ou=moved, ou=ldap3-tutorial,dc=demo1,dc=freeipa,dc=org')True 更新条目添加属性值：12345678910&gt;&gt;&gt; from ldap3 import MODIFY_ADD, MODIFY_REPLACE, MODIFY_DELETE&gt;&gt;&gt; conn.modify('cn=b.smith,ou=moved,ou=ldap3-tutorial,dc=demo1,dc=freeipa,dc=org', &#123;'sn': [(MODIFY_ADD, ['Smyth'])]&#125;)True&gt;&gt;&gt; conn.search('ou=moved,ou=ldap3-tutorial,dc=demo1,dc=freeipa,dc=org', '(cn=b.smith)', attributes=['cn', 'sn'])True&gt;&gt;&gt; conn.entries[0]DN: cn=b.smith,ou=moved,ou=ldap3-tutorial,dc=demo1,dc=freeipa,dc=org - STATUS: Read - READ TIME: 2020-01-14T13:50:45.461241 cn: b.smith sn: Young Smyth 移除属性值：12345678&gt;&gt;&gt; conn.modify('cn=b.smith,ou=moved,ou=ldap3-tutorial,dc=demo1,dc=freeipa,dc=org', &#123;'sn': [(MODIFY_DELETE, ['Young'])]&#125;)True&gt;&gt;&gt; conn.search('ou=moved,ou=ldap3-tutorial,dc=demo1,dc=freeipa,dc=org', '(cn=b.smith)', attributes=['cn', 'sn'])True&gt;&gt;&gt; conn.entries[0]DN: cn=b.smith,ou=moved,ou=ldap3-tutorial,dc=demo1,dc=freeipa,dc=org - STATUS: Read - READ TIME: 2020-01-14T13:52:43.586339 cn: b.smith sn: Smyth 替换属性值：12345678&gt;&gt;&gt; conn.modify('cn=b.smith,ou=moved,ou=ldap3-tutorial,dc=demo1,dc=freeipa,dc=org', &#123;'sn': [(MODIFY_REPLACE, ['Smith'])]&#125;)True&gt;&gt;&gt; conn.search('ou=moved,ou=ldap3-tutorial,dc=demo1,dc=freeipa,dc=org', '(cn=b.smith)', attributes=['cn', 'sn'])True&gt;&gt;&gt; conn.entries[0]DN: cn=b.smith,ou=moved,ou=ldap3-tutorial,dc=demo1,dc=freeipa,dc=org - STATUS: Read - READ TIME: 2020-01-14T13:53:28.834019 cn: b.smith sn: Smith 判断属性是否为某个特定值：1234&gt;&gt;&gt; conn.compare('cn=b.smith,ou=moved,ou=ldap3-tutorial,dc=demo1,dc=freeipa,dc=org', 'departmentNumber', 'DEV')True&gt;&gt;&gt; conn.compare('cn=b.smith,ou=moved,ou=ldap3-tutorial,dc=demo1,dc=freeipa,dc=org', 'departmentNumber', 'QA')False 四、域账号操作修改账户密码：12345678910&gt;&gt;&gt; from ldap3 import Server, Connection&gt;&gt;&gt; server = Server('&lt;hostname_or_ip', use_ssl=True)&gt;&gt;&gt; conn = Connection(server, user='admin@example.com', password='admin@123', auto_bind=True)&gt;&gt;&gt; conn.search('ou=Domain Users,dc=example,dc=com', '(&amp;(objectClass=person)(sAMAccountName=admin))')True&gt;&gt;&gt; dn = conn.entries[0].entry_dn&gt;&gt;&gt; dn'CN=admin,OU=Domain Users,DC=example,DC=com'&gt;&gt;&gt; conn.extend.microsoft.modify_password(dn, 'new_password')True 解锁账户：12&gt;&gt;&gt; conn.extend.microsoft.unlock_account(dn)True 此外该模块下还有 addMembersToGroups 和 removeMembersFromGroups 等函数。 参考资料ldap3 官方文档ldap3 项目主页]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Python</tag>
        <tag>LDAP</tag>
        <tag>ActiveDirectory</tag>
        <tag>Practical</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 绘图库 Matplotlib 代码示例]]></title>
    <url>%2F2020%2F01%2F08%2Fsample-plots-in-matplotlib%2F</url>
    <content type="text"><![CDATA[Line Plot1234567import matplotlib.pyplot as pltX = range(100)Y = [value ** 2 for value in X]plt.plot(X, Y)plt.show() Using Numpy12345678import numpy as npimport matplotlib.pyplot as pltX = np.linspace(0, 2 * np.pi, 100)Y = np.sin(X)plt.plot(X, Y)plt.show() 等同于如下代码：123456789import mathimport matplotlib.pyplot as pltT = range(100)X = [(2 * math.pi * t) / len(T) for t in T]Y = [math.sin(value) for value in X]plt.plot(X, Y)plt.show() Multiple Line Plot12345678910import numpy as npimport matplotlib.pyplot as pltX = np.linspace(0, 2 * np.pi, 100)Ya = np.sin(X)Yb = np.cos(X)plt.plot(X, Ya)plt.plot(X, Yb)plt.show() 从文本文件中读取数据1234567# my_data.txt0 01 12 44 165 256 36 1234567import numpy as npimport matplotlib.pyplot as pltdata = np.loadtxt('my_data.txt')plt.plot(data[:, 0], data[:, 1])plt.show() 等同于如下代码：12345678910import matplotlib.pyplot as pltX, Y = [], []for line in open('my_data.txt', 'r'): values = [float(s) for s in line.split()] X.append(values[0]) Y.append(values[1])plt.plot(X, Y)plt.show() 其他类型的图形Scatter Plot123456789101112131415import numpy as npimport matplotlib.pyplot as pltdata = np.random.rand(1024, 2)print(data)# [[0.74566428 0.27225566]# [0.49387305 0.22290731]# [0.78644733 0.44918945]# ...# [0.42446667 0.31317443]# [0.06518628 0.21378513]# [0.85117629 0.83458943]]plt.scatter(data[:, 0], data[:, 1])plt.show() Bar Charts123456import matplotlib.pyplot as pltdata = [5., 25., 50., 20.]plt.bar(range(len(data)), data)plt.show() Multiple Bar Charts12345678910111213import numpy as npimport matplotlib.pyplot as pltdata = [[5., 25., 50., 20.], [4., 23., 51., 17.], [6., 22., 52., 19.]]X = np.arange(4)plt.bar(X + 0.00, data[0], color='b', width=0.25)plt.bar(X + 0.25, data[1], color='g', width=0.25)plt.bar(X + 0.50, data[2], color='r', width=0.25)plt.show() Histogram1234567import numpy as npimport matplotlib.pyplot as pltX = np.random.randn(1000)plt.hist(X, bins=20)plt.show() Pie Charts12345678910111213import matplotlib.pyplot as plt# Pie chart, where the slices will be ordered and plotted counter-clockwise:labels = 'Frogs', 'Hogs', 'Dogs', 'Logs'sizes = [15, 30, 45, 10]explode = (0, 0.1, 0, 0) # only "explode" the 2nd slice (i.e. 'Hogs')fig1, ax1 = plt.subplots()ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%', shadow=True, startangle=90)ax1.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.plt.show() Colormatplotlib 中定义颜色的方式有以下几种： (R, G, B, A)，如 (1.0, 0.0, 0.0) 表示红色，第四项数字 A （可省略）表示透明度 字符 b、g、r、c、m、y、k、w，分别表示蓝、绿、红、青、洋红、黄、黑、白 HTML 颜色字符串 #RRGGBB，如 #FFFFFF 表示纯白色 灰度字符串，介于 0 和 1 之间的浮点数，如 0.75 表示中度浅灰 示例一：123456789101112import numpy as npimport matplotlib.pyplot as pltA = np.random.standard_normal((100, 2))A += np.array((-1, -1))B = np.random.standard_normal((100, 2))B += np.array((1, 1))plt.scatter(A[:, 0], A[:, 1], color='.75')plt.scatter(B[:, 0], B[:, 1], color='y')plt.show() 示例二：Iris 文本数据下载自 http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data，格式如下：123454.6,3.2,1.4,0.2,Iris-setosa5.3,3.7,1.5,0.2,Iris-setosa5.0,3.3,1.4,0.2,Iris-setosa7.0,3.2,4.7,1.4,Iris-versicolor6.4,3.2,4.5,1.5,Iris-versicolor 12345678910111213141516171819202122import numpy as npimport matplotlib.pyplot as pltlabel_set = ( b'Iris-setosa', b'Iris-versicolor', b'Iris-virginica')# convert label to index number.# Iris-setosa -&gt; 0, Iris-versicolor -&gt; 1, Iris-virginica -&gt; 2.def read_label(label): return label_set.index(label)data = np.loadtxt('iris.data', delimiter=',', converters=&#123;4: read_label&#125;)color_set = ('b', 'r', 'm')color_list = [color_set[int(label)] for label in data[:, 4]]plt.scatter(data[:, 0], data[:, 1], color=color_list)plt.show() 上面的示例中只用到前两列和最后一列数据，将最后一列数据 label 替换为对应的 index 数字，以便在作图时根据 index 施以不同的着色。 Line Pattern123456789101112131415import numpy as npimport matplotlib.pyplot as pltdef pdf(X, mu, sigma): a = 1. / (sigma * np.sqrt(2. * np.pi)) b = -1. / (2. * sigma ** 2) return a * np.exp(b * (X - mu) ** 2)X = np.linspace(-6, 6, 1024)plt.plot(X, pdf(X, 0., 1.), color='r', linestyle='solid')plt.plot(X, pdf(X, 0., .5), color='g', linestyle='dashed')plt.plot(X, pdf(X, 0., .25), color='m', linestyle='dashdot')plt.show() Marker Style123456789101112import numpy as npimport matplotlib.pyplot as pltA = np.random.standard_normal((100, 2))A += np.array((-1, -1))B = np.random.standard_normal((100, 2))B += np.array((1, 1))plt.scatter(A[:, 0], A[:, 1], color='m', marker='x', size=100)plt.scatter(B[:, 0], B[:, 1], color='g', marker='^')plt.show() Title and Label12345678910111213import numpy as npimport matplotlib.pyplot as pltX = np.linspace(-4, 4, 1024)Y = .25 * (X + 4.) * (X + 1.) * (X - 2.)plt.title('Power curve for airfoil KV873')plt.xlabel('Air speed')plt.ylabel('Total drag')plt.text(-0.5, -0.25, 'Brackmard minimum')plt.plot(X, Y, c='k')plt.show() Legend123456789101112131415import numpy as npimport matplotlib.pyplot as pltX = np.linspace(0, 6, 1024)Y1 = np.sin(X)Y2 = np.cos(X)plt.xlabel('X')plt.ylabel('Y')plt.plot(X, Y1, c='k', lw=3., label='sin(X)')plt.plot(X, Y2, c='.5', lw=3., ls='--', label='cos(X)')plt.legend()plt.show() Figures1234567891011121314151617import numpy as npfrom matplotlib import pyplot as pltT = np.linspace(-np.pi, np.pi, 1024)grid_size = (4, 2)plt.subplot2grid(grid_size, (0, 0), rowspan=3, colspan=1)plt.plot(np.sin(2 * T), np.cos(0.5 * T), c='k')plt.subplot2grid(grid_size, (0, 1), rowspan=3, colspan=1)plt.plot(np.cos(3 * T), np.sin(T), c='k')plt.subplot2grid(grid_size, (3, 0), rowspan=1, colspan=3)plt.plot(np.cos(5 * T), np.sin(7 * T), c='k')plt.tight_layout()plt.show() Subplots12345678910111213import matplotlib.pyplot as pltimport numpy as npnp.random.seed(19680801)data = np.random.randn(2, 100)fig, axs = plt.subplots(2, 2, figsize=(5, 5))axs[0, 0].hist(data[0])axs[1, 0].scatter(data[0], data[1])axs[0, 1].plot(data[0], data[1])axs[1, 1].hist2d(data[0], data[1])plt.show() User Interface123456789101112131415161718192021222324252627282930313233343536373839404142434445import numpy as npfrom matplotlib import pyplot as pltfrom matplotlib.widgets import Sliderdef supershape_radius(phi, a, b, m, n1, n2, n3): theta = .25 * m * phi cos = np.fabs(np.cos(theta) / a) ** n2 sin = np.fabs(np.sin(theta) / b) ** n3 r = (cos + sin) ** (-1. / n1) r /= np.max(r) return rphi = np.linspace(0, 2 * np.pi, 1024)m_init = 3n1_init = 2n2_init = 18n3_init = 18fig = plt.figure()ax = fig.add_subplot(111, polar=True)ax_m = plt.axes([0.05, 0.05, 0.25, 0.025])ax_n1 = plt.axes([0.05, 0.10, 0.25, 0.025])ax_n2 = plt.axes([0.7, 0.05, 0.25, 0.025])ax_n3 = plt.axes([0.7, 0.10, 0.25, 0.025])slider_m = Slider(ax_m, 'm', 1, 20, valinit=m_init)slider_n1 = Slider(ax_n1, 'n1', .1, 10, valinit=n1_init)slider_n2 = Slider(ax_n2, 'n2', .1, 20, valinit=n2_init)slider_n3 = Slider(ax_n3, 'n3', .1, 20, valinit=n3_init)r = supershape_radius(phi, 1, 1, m_init, n1_init, n2_init, n3_init)lines, = ax.plot(phi, r, lw=3.)def update(val): r = supershape_radius(phi, 1, 1, np.floor(slider_m.val), slider_n1.val, slider_n2.val, slider_n3.val) lines.set_ydata(r) fig.canvas.draw_idle()slider_n1.on_changed(update)slider_n2.on_changed(update)slider_n3.on_changed(update)slider_m.on_changed(update)plt.show() 参考资料matplotlib Plotting CookbookSample plots in Matplotlib]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Python</tag>
        <tag>Data</tag>
        <tag>Plot</tag>
        <tag>Matplotlib</tag>
        <tag>Graphics</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 设计模式——MVC模式]]></title>
    <url>%2F2020%2F01%2F06%2Fpython-design-patterns-mvc-pattern%2F</url>
    <content type="text"><![CDATA[模型 - 视图 - 控制器模式MVC 不仅仅是一种实现用户界面的软件模式，同时也是一种易于修改和维护的架构。通常 MVC 模式将应用程序分为 3 个基本部分：模型（Model）、视图（View）和控制器（Controller）。这 3 个部分相互关联，有助于将信息的处理与信息的呈现分开。 MVC 模式的工作机制为：模型提供数据和业务逻辑（如何存储和查询信息），视图负责数据的展示（如何呈现），而控制器则是两者之间的粘合剂，根据用户要求的呈现方式协调模型和视图。视图和控制器依赖于模型，但模型是可以独立工作的。 模型：定义针对数据的所有操作（如创建、修改和删除等），并提供与数据使用有关的方法 视图：提供相应的方法，帮助根据上下文和应用程序的需要构建 Web 或 GUI 界面 控制器：从请求接收数据，并将其发送到系统的其他部分。需要提供用于路由请求的方法 MVC 模式的主要意图： 将数据和数据的展示隔离开 使类的维护和实现更加简单 灵活地改变数据的存储和显示方式，两者相互独立 模型是应用程序的基石，提供客户端请求的数据，必须在多个操作中保持一致。视图用来将数据展示在接口上供用户查看。可以独立开发，但不应包含复杂的逻辑；需要足够灵活，适应多种平台；应避免与数据库直接交互。控制器应该作为模型和视图之间的粘合剂，要尽可能薄；不应该进行数据库调用或参与数据的展示。 示例代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849class Model: services = &#123; 'email': &#123;'number': 1000, 'price': 2&#125;, 'sms': &#123;'number': 1000, 'price': 10&#125;, 'voice': &#123;'number': 1000, 'price': 15&#125; &#125;class View: def list_services(self, services): for svc in services: print(svc, ' ') def list_pricing(self, services): for svc in services: print("For", Model.services[svc]['number'], svc, 'message you pay $', Model.services[svc]['price'])class Controller: def __init__(self): self.model = Model() self.view = View() def get_services(self): services = self.model.services.keys() return (self.view.list_services(services)) def get_pricing(self): services = self.model.services.keys() return (self.view.list_pricing(services))if __name__ == '__main__': controller = Controller() print("Services Provided:") controller.get_services() print("Pricing for Services:") controller.get_pricing()# =&gt; Services Provided:# =&gt; email# =&gt; sms# =&gt; voice# =&gt; Pricing for Services:# =&gt; For 1000 email message you pay $ 2# =&gt; For 1000 sms message you pay $ 10# =&gt; For 1000 voice message you pay $ 15 现实世界中的 MVC 模式目录结构：123456mvc├── server.py└── templates ├── base.html ├── index.html └── new.html server.py 源代码：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374import tornadoimport tornado.webimport tornado.ioloopimport tornado.httpserverimport sqlite3def _execute(sql): db = sqlite3.connect('sqlite3.db') cursor = db.cursor() cursor.execute(sql) res = cursor.fetchall() db.commit() db.close() return resclass IndexHandler(tornado.web.RequestHandler): def get(self): query = "select * from task;" todos = _execute(query) print(todos) self.render('index.html', todos=todos)class NewHandler(tornado.web.RequestHandler): def post(self): name = self.get_argument('name', None) query = "create table if not exists task (id INTEGER \ PRIMARY KEY, name TEXT, status NUMERIC);" _execute(query) query = "insert into task (name, status) values ('%s', %d);" % (name, 1) _execute(query) self.redirect('/') def get(self): self.render('new.html')class UpdateHandler(tornado.web.RequestHandler): def get(self, id, status): query = "update task set status=%d where \ id=%s;" % (int(status), id) _execute(query) print(query) self.redirect('/')class DeleteHandler(tornado.web.RequestHandler): def get(self, id): query = "delete from task where id=%s;" % id _execute(query) self.redirect('/')class RunApp(tornado.web.Application): def __init__(self): Handlers = [ (r'/', IndexHandler), (r'/todo/new', NewHandler), (r'/todo/update/(\d+)/(\d+)', UpdateHandler), (r'/todo/delete/(\d+)', DeleteHandler), ] settings = dict( debug=True, template_path='templates', static_path='static', ) tornado.web.Application.__init__(self, Handlers, **settings)if __name__ == '__main__': http_server = tornado.httpserver.HTTPServer(RunApp()) http_server.listen(5000) tornado.ioloop.IOLoop.instance().start() templates/base.html 源代码：123456789&lt;!DOCTYPE&gt;&lt;html&gt; &lt;head&gt; &#123;% block header %&#125;&#123;% end%&#125; &lt;/head&gt; &lt;body&gt; &#123;% block body %&#125;&#123;% end %&#125; &lt;/body&gt;&lt;/html&gt; templates/index.html 源代码：1234567891011121314151617181920212223242526272829303132333435&#123;% extends 'base.html' %&#125;&lt;title&gt;ToDo&lt;/title&gt;&#123;% block body %&#125;&lt;h3&gt;Your Tasks&lt;/h3&gt;&lt;table border="1"&gt; &lt;tr align="center"&gt; &lt;td&gt;Id&lt;/td&gt; &lt;td&gt;Name&lt;/td&gt; &lt;td&gt;Status&lt;/td&gt; &lt;td&gt;Update&lt;/td&gt; &lt;td&gt;Delete&lt;/td&gt; &lt;/tr&gt; &#123;% for todo in todos %&#125; &lt;tr align="center"&gt; &lt;td&gt;&#123;&#123; todo[0] &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; todo[1] &#125;&#125;&lt;/td&gt; &#123;% if todo[2] %&#125; &lt;td&gt;Open&lt;/td&gt; &#123;% else %&#125; &lt;td&gt;Closed&lt;/td&gt; &#123;% end %&#125; &#123;% if todo[2] %&#125; &lt;td&gt;&lt;a href="/todo/update/&#123;&#123;todo[0]&#125;&#125;/0"&gt;Close Task&lt;/a&gt;&lt;/td&gt; &#123;% else %&#125; &lt;td&gt;&lt;a href="/todo/update/&#123;&#123;todo[0]&#125;&#125;/1"&gt;Open Task&lt;/a&gt;&lt;/td&gt; &#123;% end %&#125; &lt;td&gt;&lt;a href="/todo/delete/&#123;&#123;todo[0]&#125;&#125;"&gt;X&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &#123;% end %&#125;&lt;/table&gt;&lt;div&gt; &lt;h3&gt;&lt;a href="/todo/new"&gt;Add Task&lt;/a&gt;&lt;/h3&gt;&lt;/div&gt;&#123;% end %&#125; templates/new.html 源代码：1234567891011&#123;% extends 'base.html' %&#125;&lt;title&gt;ToDo&lt;/title&gt;&#123;% block body %&#125;&lt;div&gt; &lt;h3&gt;Add Task to your List&lt;/h3&gt; &lt;form action="/todo/new" method="post" id="new"&gt; &lt;p&gt;&lt;input type="text" name="name" placeholder="Enter task" /&gt; &lt;input type="submit" class="submit" value="add" /&gt;&lt;/p&gt; &lt;/form&gt;&lt;/div&gt;&#123;% end %&#125; 运行 python server.py 命令，浏览 http://localhost:5000/ ，效果如下： PS：需安装 tornado 模块（pip install tornado）]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Python</tag>
        <tag>Development</tag>
        <tag>Pattern</tag>
        <tag>OOP</tag>
        <tag>Design</tag>
        <tag>MVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 设计模式——理解面向对象编程]]></title>
    <url>%2F2020%2F01%2F06%2Fpython-design-patterns-understanding-OOP%2F</url>
    <content type="text"><![CDATA[面向对象编程面向对象的编程范式引入了对象的概念，对象具有属性和用来处理属性的成员函数。比如对象 Car 拥有多种属性，如 fuel_level（油位）、is_sedan（是否为轿车）、speed（速度）、steering_wheel（方向盘）和 coordinates（坐标）等。同时还拥有一些方法，比如 accelerate() 方法用来提升速度，takeleft() 方法让车左转等。 在 Python 中，一切皆对象。每个类的实例或变量都有它自己的内存地址或身份。对象就是类的实例，应用开发就是通过对象交互来实现目的的过程。 对象： 表示所开发的应用程序内的实体 实体之间可以通过交互来解决现实世界的问题 如 Person 是实体，Car 也是实体。Person 可以驾驶 Car，从一个地方开到另一个地方 类： 类可以定义对象的属性和行为。属性是数据成员，行为由成员函数表示 类包含了构造函数，为对象提供初始状态 类就像模板，非常易于重复使用 方法： 表示对象的行为 可以对属性进行处理，实现所需的功能 12345678910111213class Person: def __init__(self, name, age): self.name = name self.age = age def get_person(self,): return f"&lt;Person (&#123;self.name&#125;, &#123;self.age&#125;&gt;)"p = Person("John", 32)print(f"Type of Object: &#123;type(p)&#125;, Memory Address: &#123;id(p)&#125;")print(p.get_person())# =&gt; Type of Object: &lt;class '__main__.Person'&gt;, Memory Address: 140586467650144# =&gt; &lt;Person (John, 32&gt;) 主要概念封装 对象的行为对于外部是不可见的，或者说对象的状态信息是私密的 客户端不能通过直接操作来改变对象的内部状态。需要通过发送消息来请求对象改变其内部状态，对象则根据请求通过特定的成员函数完成内部状态的修改 在 Python 中，封装的概念不是隐式的，它没有提供封装所需的诸如 public、private 和 protected 等关键字 多态 多态有两种类型。对象根据输入的参数提供方法的不同实现；不同类型的对象可以使用相同的接口 对于 Python 而言，多态是内置功能。如操作符 + 既可以应用于两个整数进行加法运算，也可以应用于字符串用来连接它们 12345&gt;&gt;&gt; a = "John"&gt;&gt;&gt; b = (1, 2, 3)&gt;&gt;&gt; c = [3, 4, 6, 8, 9]&gt;&gt;&gt; print(a[1], b[0], c[2])o 1 6 继承 表示一个类可以继承父类的（大部分）功能 可以重用基类中定义的功能并允许子类独立地进行扩展 可以利用不同类对象之间的关系建立层次结构。Python 支持多重继承（继承多个基类） 设计原则开放/封闭原则类或对象及其方法对于扩展来说应该是开放的，对于修改来说应该是封闭的。即在开发软件的时候，一定确保以通用的方式来编写类或模块，以便需要扩展类或对象行为的时候不必修改类本身。 优点： 现有的类不会被修改，退化的可能性较小 有助于保持以前代码的向后兼容性 控制反转原则高层级的模块不应该依赖于低层级的模块，应该都依赖于抽象。细节依赖于抽象，而不是抽象依赖于细节。该原则建议任何两个模块都不应以紧密方式相互依赖。基本模块和从属模块应当在它们之间提供一个抽象层来耦合。类的细节应描绘抽象。 优点： 削弱了模块间的紧耦合，消除了系统中的复杂性和刚性 在依赖模块之间有一个明确的抽象层，便于通过更好的方式处理模块之间的依赖关系 接口隔离原则客户端不应依赖于它们不需要使用的接口。 优点： 强制开发人员编写“瘦身型”接口，并使方法与接口紧密相关 防止向接口中随意添加方法 单一职责原则类的职责单一，引起类变化的原因单一。当我们在开发类时，它应该为特定的功能服务。若一个类实现了两个功能，则最好将它们分开。 优点： 每当一个功能发生变化时，除了特定的类需要改变外，其他类无需变动 若一个类有多种功能，那么依赖它的类必定会由于多种原因经历多次修改。这是应该避免的 替换原则派生类必须能够完全取代基类。当应用程序开发人员编写派生类时，该原则的含义就是他们应该扩展基类。此外，派生类应该尽可能对基类封闭，以致于派生类本身可以替换基类而无需修改任何代码。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Python</tag>
        <tag>Development</tag>
        <tag>Pattern</tag>
        <tag>OOP</tag>
        <tag>Object</tag>
        <tag>Design</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基本算法问题的 Python 解法（递归与搜索）]]></title>
    <url>%2F2020%2F01%2F05%2Fclassic-compute-problems-with-python%2F</url>
    <content type="text"><![CDATA[一、斐波那契数列递归函数123456789def fib(n: int) -&gt; int: if n &lt; 2: return n return fib(n - 2) + fib(n - 1)if __name__ == '__main__': for i in range(10): print(fib(i), end=' ')# =&gt; 0 1 1 2 3 5 8 13 21 34 不要尝试调用 fib(50)（这个我试过了，因为等得不耐烦 Ctrl+C 掉了）。在上面版本的程序中，每次对 fib() 函数的调用都会导致额外的两次对 fib() 自身的调用（即 fib(n -2) 和 fib(n - 1)）。这个行为模式会一直传递下去，直到每一个新的调用分支都满足 n &lt; 2。比如 fib(4) 最终会执行以下函数：123456789fib(4) -&gt; fib(3), fib(2)fib(3) -&gt; fib(2), fib(1)fib(2) -&gt; fib(1), fib(0)fib(2) -&gt; fib(1), fib(0)fib(1) -&gt; 1fib(1) -&gt; 1fib(1) -&gt; 1fib(0) -&gt; 0fib(0) -&gt; 0 计算 fib(4) 最终会调用 9 次 fib() 函数，fib(5) 调用 15 次，fib(10) 调用 177 次，计算 fib(20) 则需要执行整整 21891 次。换句话说，函数的调用树会以指数级的速度扩展。 MemoizationMemoization 是指将计算任务执行后得到的结果保存在某个地方，后面需要用到时就可以直接取出使用，而不必再次计算。1234567891011from typing import Dictmemo: Dict[int, int] = &#123;0: 0, 1: 1&#125; # base casesdef fib2(n: int) -&gt; int: if n not in memo: memo[n] = fib2(n -1) + fib2(n - 2) # memoization return memo[n]if __name__ == '__main__': print(fib2(50))# =&gt; 12586269025 lru_cachePython 提供了一个内置的装饰器 ``@functools.lru_cache()用来自动记录（缓存）某个函数的执行结果。因此上面的fib2() 可以改为如下形式：1234567891011from functools import lru_cache@lru_cache(maxsize=None)def fib3(n: int) -&gt; int: if n &lt; 2: return n return fib3(n - 2) + fib3(n - 1)if __name__ == '__main__': print(fib3(50))# =&gt; 12586269025 迭代式方案1234567891011def fib4(n: int) -&gt; int: if n == 0: return n last: int = 0 next: int = 1 for _ in range(1, n): last, next = next, last + next return nextif __name__== '__main__': print(fib4(50))# =&gt; 12586269025 上面的程序算是这几个方案中性能最好的一个，for 循环最多只执行 n-1 次。递归式方案借助逆向思维，而迭代式方案则是正向的逻辑。在某些情况下，原始的递归计算方式会带来过多的性能消耗。但是任何可以通过递归计算解决的问题，同样可以用迭代的方式解决。 生成器123456789101112131415from typing import Generatordef fib5(n: int) -&gt; Generator[int, None, None]: yield 0 if n &gt; 0: yield 1 last: int = 0 next: int = 1 for _ in range(1, n): last, next = next, last + next yield nextif __name__ == '__main__': for i in fib5(50): print(i, end=' ')# =&gt; 0 1 1 2 3 5 8 13 21 34 55 89 144 233 377 610 987 1597 2584 4181 6765 10946 17711 28657 46368 75025 121393 196418 317811 514229 832040 1346269 2178309 3524578 5702887 9227465 14930352 24157817 39088169 63245986 102334155 165580141 267914296 433494437 701408733 1134903170 1836311903 2971215073 4807526976 7778742049 12586269025 二、汉诺塔问题关于汉诺塔问题的简单描述： 有三根柱子，柱子 A 上摞有 n 个不同大小的圆盘，需要将所有圆盘借助柱子 B 转移到柱子 C 每次只能转移一个圆盘 大的圆盘必须放置在小的圆盘下面 递归解法的逻辑如下： 利用 C 作中转，移动 A 顶部的 n-1 个圆盘到柱子 B 移动 A 底部剩下的最大号圆盘到柱子 C 利用 A 作中转，移动 B 上的 n-1 个圆盘到柱子 C（此时问题由最初的将 n 个圆盘从 A 转移到 C，变成将 n-1 个圆盘从 B 转移到 C） 重复以上步骤 实现代码如下：1234567891011121314151617181920212223242526272829303132333435363738from typing import TypeVar, Generic, ListT = TypeVar('T')class Stack(Generic[T]): def __init__(self) -&gt; None: self._container: List[T] = [] def push(self, item: T) -&gt; None: self._container.append(item) def pop(self) -&gt; T: return self._container.pop() def __repr__(self) -&gt; str: return repr(self._container)def hanobi(begin: Stack[int], end: Stack[int], temp: Stack[int], n: int) -&gt; None: if n == 1: end.push(begin.pop()) else: hanobi(begin, temp, end, n - 1) hanobi(begin, end, temp, 1) hanobi(temp, end, begin, n - 1)if __name__ == '__main__': num_discs: int = 10 tower_a: Stack[int] = Stack() tower_b: Stack[int] = Stack() tower_c: Stack[int] = Stack() for i in range(1, num_discs + 1): tower_a.push(i) hanobi(tower_a, tower_c, tower_b, num_discs) print(tower_a) # [] print(tower_b) # [] print(tower_c) # [1, 2, 3] 这只是一个简单的演示程序，Stack 类抽象出单根柱子与圆盘的模型，hanobi 函数则以递归的方式定义了圆盘移动的过程。如果是真人来操作的话，每次移动一个圆盘花费 1 秒钟时间。解决由 50 个圆盘组成的汉诺塔问题，共需要耗费多长时间？约等于 3570.2 万年。 三、DNA 检索在计算机软件中，基因（Gene）一般通过由 A、C、G、T 组成的字符序列表示。其中每个字符代表一个核苷酸（nucleotide），每相邻的三个核苷酸（碱基）组成一个密码子（codon）。 基因的数据模型如下：12345678910111213141516171819202122232425262728293031323334353637383940from enum import IntEnumfrom typing import Tuple, ListNucleotide: IntEnum = IntEnum('Nucleotide', ('A', 'C', 'G', 'T'))Codon = Tuple[Nucleotide, Nucleotide, Nucleotide]Gene = List[Codon]def string_to_gene(s: str) -&gt; Gene: gene: Gene = [] for i in range(0, len(s), 3): if (i + 2) &gt;= len(s): return gene codon: Codon = (Nucleotide[s[i]], Nucleotide[s[i + 1]], Nucleotide[s[i + 2]]) gene.append(codon) return genegene_str: str = "ACGTGGCTCTCTAACGTACGTACGTACGGGGTTTATATATACCCTAGGACTCCCTTT"my_gene: Gene = string_to_gene(gene_str)for conda in my_gene: print(conda)# =&gt; (&lt;Nucleotide.A: 1&gt;, &lt;Nucleotide.C: 2&gt;, &lt;Nucleotide.G: 3&gt;)# =&gt; (&lt;Nucleotide.T: 4&gt;, &lt;Nucleotide.G: 3&gt;, &lt;Nucleotide.G: 3&gt;)# =&gt; (&lt;Nucleotide.C: 2&gt;, &lt;Nucleotide.T: 4&gt;, &lt;Nucleotide.C: 2&gt;)# =&gt; (&lt;Nucleotide.T: 4&gt;, &lt;Nucleotide.C: 2&gt;, &lt;Nucleotide.T: 4&gt;)# =&gt; (&lt;Nucleotide.A: 1&gt;, &lt;Nucleotide.A: 1&gt;, &lt;Nucleotide.C: 2&gt;)# =&gt; (&lt;Nucleotide.G: 3&gt;, &lt;Nucleotide.T: 4&gt;, &lt;Nucleotide.A: 1&gt;)# =&gt; (&lt;Nucleotide.C: 2&gt;, &lt;Nucleotide.G: 3&gt;, &lt;Nucleotide.T: 4&gt;)# =&gt; (&lt;Nucleotide.A: 1&gt;, &lt;Nucleotide.C: 2&gt;, &lt;Nucleotide.G: 3&gt;)# =&gt; (&lt;Nucleotide.T: 4&gt;, &lt;Nucleotide.A: 1&gt;, &lt;Nucleotide.C: 2&gt;)# =&gt; (&lt;Nucleotide.G: 3&gt;, &lt;Nucleotide.G: 3&gt;, &lt;Nucleotide.G: 3&gt;)# =&gt; (&lt;Nucleotide.G: 3&gt;, &lt;Nucleotide.T: 4&gt;, &lt;Nucleotide.T: 4&gt;)# =&gt; (&lt;Nucleotide.T: 4&gt;, &lt;Nucleotide.A: 1&gt;, &lt;Nucleotide.T: 4&gt;)# =&gt; (&lt;Nucleotide.A: 1&gt;, &lt;Nucleotide.T: 4&gt;, &lt;Nucleotide.A: 1&gt;)# =&gt; (&lt;Nucleotide.T: 4&gt;, &lt;Nucleotide.A: 1&gt;, &lt;Nucleotide.C: 2&gt;)# =&gt; (&lt;Nucleotide.C: 2&gt;, &lt;Nucleotide.C: 2&gt;, &lt;Nucleotide.T: 4&gt;)# =&gt; (&lt;Nucleotide.A: 1&gt;, &lt;Nucleotide.G: 3&gt;, &lt;Nucleotide.G: 3&gt;)# =&gt; (&lt;Nucleotide.A: 1&gt;, &lt;Nucleotide.C: 2&gt;, &lt;Nucleotide.T: 4&gt;)# =&gt; (&lt;Nucleotide.C: 2&gt;, &lt;Nucleotide.C: 2&gt;, &lt;Nucleotide.C: 2&gt;)# =&gt; (&lt;Nucleotide.T: 4&gt;, &lt;Nucleotide.T: 4&gt;, &lt;Nucleotide.T: 4&gt;) Linear search线性搜索会按照原始数据结构中的元素排列顺序，逐个检查搜索空间中的每一个元素，是最简单直观的搜索方式，复杂度为 O(n)。12345678910def linear_contains(gene: Gene, key_codon: Codon) -&gt; bool: for codon in gene: if codon == key_codon: return True return Falseacg: Codon = (Nucleotide.A, Nucleotide.C, Nucleotide.G)gat: Codon = (Nucleotide.G, Nucleotide.A, Nucleotide.T)print(linear_contains(my_gene, acg)) # Trueprint(linear_contains(my_gene, gat)) # False Binary search12345678910111213141516def binary_contains(gene: Gene, key_codon: Codon) -&gt; bool: low: int = 0 high: int = len(gene) - 1 while low &lt;= high: mid: int = (low + high) if gene[mid] &lt; key_codon: low = mid + 1 elif gene[mid] &gt; key_codon: high = mid - 1 else: return True return Falsemy_sorted_gene: Gene = sorted(my_gene)print(binary_contains(my_sorted_gene, acg))print(binary_contains(my_sorted_gene, gat)) Binary Search 将搜索对象与有序列表中间位置的值进行比对，根据大小关系确定下一次搜索在序列的前半或者后半部分继续进行。依照此规则持续进行检索，每一次比较都会将下一次的搜索空间减小一半（类似猜数字游戏）。 Binary Search 在最坏情况下的复杂度为 O(lg n)，前提是序列中的所有元素已经根据大小排序。最好的排序算法复杂度为 O(n lg n)。因此在需要对无序列表执行多次搜索的场景下，可以先对列表元素排序再执行 Binary Search。 通用示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# generic_search.pyfrom typing import TypeVar, Iterable, Sequence, Generic, List, Callable, Set, Deque, Dict, Any, Optionalfrom typing import Protocolfrom heapq import heappush, heappopT = TypeVar('T')def linear_contains(iterable: Iterable[T], key: T) -&gt; bool: for item in iterable: if item == key: return True return FalseC = TypeVar("C", bound="Comparable")class Comparable(Protocol): def __eq__(self, other: Any) -&gt; bool: return self == other def __lt__(self, other: C) -&gt; bool: return self &lt; other def __gt__(self: C, other: C) -&gt; bool: return (not self &lt; other) and self != other def __le__(self: C, other: C) -&gt; bool: return self &lt; other or self == other def __ge__(self: C, other: C) -&gt; bool: return not self &lt; otherdef binary_contains(sequence: Sequence[C], key: C) -&gt; bool: low: int = 0 high: int = len(sequence) - 1 while low &lt;= high: mid: int = (low + high) // 2 if sequence[mid] &lt; key: low = mid + 1 elif sequence[mid] &gt; key: high = mid - 1 else: return True return Falseif __name__ == '__main__': print(linear_contains([1, 5, 15, 15, 15, 15, 20], 5)) print(binary_contains(["a", "d", "e", "f", "z"], "f")) print(binary_contains(["join", "mark", "ronald", "sarah"], "sheila")) 四、迷宫问题迷宫建模：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# maze.pyfrom enum import Enumfrom typing import List, NamedTuple, Callable, Optionalimport randomfrom math import sqrtclass Cell(str, Enum): EMPTY = " " BLOCKED = "X" START = "S" GOAL = "G" PATH = "*"class MazeLocation(NamedTuple): row: int column: intclass Maze: def __init__(self, rows: int = 10, columns: int = 10, sparseness: float = 0.2, start: MazeLocation = MazeLocation(0, 0), goal: MazeLocation = MazeLocation(9, 9)) -&gt; None: self._rows: int = rows self._columns: int = columns self.start: MazeLocation = start self.goal: MazeLocation = goal self._grid: List[List[Cell]] = [[Cell.EMPTY for c in range(columns)] for r in range(rows)] self._randomly_fill(rows, columns, sparseness) self._grid[start.row][start.column] = Cell.START self._grid[goal.row][goal.column] = Cell.GOAL def _randomly_fill(self, rows: int, columns: int, sparseness: float): for row in range(rows): for column in range(columns): if random.uniform(0, 1.0) &lt; sparseness: self._grid[row][column] = Cell.BLOCKED def __str__(self) -&gt; str: output: str = "" for row in self._grid: output += "".join([c.value for c in row]) + "\n" return outputmaze: Maze = Maze()print(maze) 12345678910SX X X XX X X X X XXX X X X X XXX X X G 为 Maze 类创建如下两个方法，goal_test 用于确定当前 Cell 是否为目标地点；successors 用于判断与当前 Cell 相邻的哪些 Cell 可以作为下一步的落脚点，返回其列表：123456789101112131415# maze.py continued def goal_test(self, ml: MazeLocation) -&gt; bool: return ml == self.goal def successors(self, ml: MazeLocation) -&gt; List[MazeLocation]: locations: List[MazeLocation] = [] if ml.row + 1 &lt; self._rows and self._grid[ml.row + 1][ml.column] != Cell.BLOCKED: locations.append(MazeLocation(ml.row + 1, ml.column)) if ml.row - 1 &gt;= 0 and self._grid[ml.row - 1][ml.column] != Cell.BLOCKED: locations.append(MazeLocation(ml.row - 1, ml.column)) if ml.column + 1 &lt; self._columns and self._grid[ml.row][ml.column + 1] != Cell.BLOCKED: locations.append(MazeLocation(ml.row, ml.column + 1)) if ml.column - 1 &gt;= 0 and self._grid[ml.row][ml.column - 1] != Cell.BLOCKED: locations.append(MazeLocation(ml.row, ml.column - 1)) return locations DFS（depth-first search）算法我理解的 DFS 算法，就是“一条道儿走到黑”。只要当前的路径能走通就一直走下去，不去考虑途中其他可能的方案。一旦遇到障碍走入“死胡同”，则回退到上一个节点尝试之前未选择的路径。最终到达目标地点后停止，或者一路回退到起点，则证明不存在可行的方案。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061# generic_search.py continuedclass Stack(Generic[T]): def __init__(self) -&gt; None: self._container: List[T] = [] @property def empty(self) -&gt; bool: return not self._container # not is true for empty container def push(self, item: T) -&gt; None: self._container.append(item) def pop(self) -&gt; T: return self._container.pop() # LIFO def __repr__(self) -&gt; str: return repr(self._container)class Node(Generic[T]): def __init__(self, state: T, parent: Optional[Node], cost: float = 0.0, heuristic: float = 0.0) -&gt; None: self.state: T = state self.parent: Optional[Node] = parent self.cost: float = cost self.heuristic: float = heuristic def __lt__(self, other: Node) -&gt; bool: return (self.cost + self.heuristic) &lt; (other.cost + other.heuristic)def dfs(initial: T, goal_test: Callable[[T], bool], successors: Callable[[T], List[T]]) -&gt; Optional[Node[T]]: # frontier is where we've yet to go frontier: Stack[Node[T]] = Stack() frontier.push(Node(initial, None)) # explored is where we've been explored: Set[T] = &#123;initial&#125; # keep going while there is more to explore while not frontier.empty: current_node: Node[T] = frontier.pop() current_state: T = current_node.state # if we found the goal, we're done if goal_test(current_state): return current_node # check where we can go next and haven't explored for child in successors(current_state): if child in explored: # skip children we already explored continue explored.add(child) frontier.push(Node(child, current_node)) return None # went through everything and never found goaldef node_to_path(node: Node[T]) -&gt; List[T]: path: List[T] = [node.state] # work backwards from end to front while node.parent is not None: node = node.parent path.append(node.state) path.reverse() return path 其中 Node 类可以算作 MazeLocation 上的又一层封装，为其添加 parent-child 关系方便后续连接为路径。其 cost 和 heuristic 属性会在后面的 A* 算法中用到。 dfs 函数中的 frontier 使用 Stack 数据结构记录每一步选择中出现的可行路径节点，其 pop 方法用于回溯到上一个节点。若 frontier 为空则说明已回溯到起点，未找到合适路径。explored 使用 Set 数据结构记录所有已经尝试过的路径选择，避免回溯时重复之前的路径。 node_to_path 函数则可以从终点开始反向查找，将 Node 节点（即带有 parent-child 关系的 MazeLocation）逐步扩展连接成完整路径存放在列表中。 补充 maze.py 代码：1234567891011121314151617181920212223242526272829# maze.py continuedfrom generic_search import dfs, node_to_path, Node def mark(self, path: List[MazeLocation]): for maze_location in path: self._grid[maze_location.row][maze_location.column] = Cell.PATH self._grid[self.start.row][self.start.column] = Cell.START self._grid[self.goal.row][self.goal.column] = Cell.GOAL def clear(self, path: List[MazeLocation]): for maze_location in path: self._grid[maze_location.row][maze_location.column] = Cell.EMPTY self._grid[self.start.row][self.start.column] = Cell.START self._grid[self.goal.row][self.goal.column] = Cell.GOALif __name__ == '__main__': m: Maze = Maze() print(m)# test DFS solution1: Optional[Node[MazeLocation]] = dfs(m.start, m.goal_test, m.successors) if solution1 is None: print("No solution found using depth-first search") else: path1: List[MazeLocation] = node_to_path(solution1) m.mark(path1) print(m) m.clear(path1) 结果如下：123456789101112131415161718192021SX XX X X XX X X X X XX XX X XX GSX XX X**X *XX*X** X X* *****X****XX *X ***X X* XX****G BFS（breadth-first search）算法寻找最短路径BFS 算法更倾向于一步一个脚印，每一步都要尝试过所有可能的方案，层层递进直到其中任何一种方案走通。假如共有 100 种路径都可以到达迷宫终点，各条路径或长或短。BFS 每次都会在所有 100 种路径上各走一步，直到其中某一条路径刚好到达终点后停止。由于对所有可行路径的尝试是同步进行的，因此该算法找到的路径总是最短的。12345678910111213141516171819202122232425262728293031323334353637383940# generic_search.py continuedclass Queue(Generic[T]): def __init__(self) -&gt; None: self._container: Deque[T] = Deque() @property def empty(self) -&gt; bool: return not self._container # not is true for empty container def push(self, item: T) -&gt; None: self._container.append(item) def pop(self) -&gt; T: return self._container.popleft() # FIFO def __repr__(self) -&gt; str: return repr(self._container)def bfs(initial: T, goal_test: Callable[[T], bool], successors: Callable[[T], List[T]]) -&gt; Optional[Node[T]]: # frontier is where we've yet to go frontier: Queue[Node[T]] = Queue() frontier.push(Node(initial, None)) # explored is where we've been explored: Set[T] = &#123;initial&#125; # keep going while there is more to explore while not frontier.empty: current_node: Node[T] = frontier.pop() current_state: T = current_node.state # if we found the goal, we're done if goal_test(current_state): return current_node # check where we can go next and haven't explored for child in successors(current_state): if child in explored: # skip children we already explored continue explored.add(child) frontier.push(Node(child, current_node)) return None # went through everything and never found goal 其中 Queue 数据结构底层使用 Deque 而不是 List，目的是提升 popleft 方法的效率。相对于 DFS 中的 Stack 数据结构，Queue 的 pop 方法是从序列的最左侧（Stack 是从最右侧）弹出项目。由此使得 BFS 可以从起点开始最大程度地尝试所有可行方案，即广度优先原则。 12345678910# maze.py continued# test BFS solution2: Optional[Node[MazeLocation]] = bfs(m.start, m.goal_test, m.successors) if solution2 is None: print("No solution found using breadth-first search!") else: path2: List[MazeLocation] = node_to_path(solution2) m.mark(path2) print(m) m.clear(path2) 执行结果：123456789101112131415161718192021S******* X X X *XX********* X X********** X *XX ******* * X XXXX*X **** X****XXGS*X X X XX** X X**** XXX***** X* XXXX X **** X XXG A* 算法寻找最优解粗略地说，DFS 可以较快地找到合适路径，BFS 则可以寻求最短路径（但时间花费较高）。 A* 算法则引入了 heuristic 概念，大概就是在做出决策前先根据一定的指导原则确定路径选择的优先级。即优先选择可能最短（离终点最近）的路径作为下一步的节点，而不是随机尝试所有可行的节点，以此来降低 BFS 导致的时间损耗。1234567891011121314151617181920212223242526272829303132333435363738394041# generic_search.py continuedclass PriorityQueue(Generic[T]): def __init__(self) -&gt; None: self._container: List[T] = [] @property def empty(self) -&gt; bool: return not self._container # not is true for empty container def push(self, item: T) -&gt; None: heappush(self._container, item) # in by priority def pop(self) -&gt; T: return heappop(self._container) # out by priority def __repr__(self) -&gt; str: return repr(self._container)def astar(initial: T, goal_test: Callable[[T], bool], successors: Callable[[T], List[T]], heuristic: Callable[[T], float]) -&gt; Optional[Node[T]]: # frontier is where we've yet to go frontier: PriorityQueue[Node[T]] = PriorityQueue() frontier.push(Node(initial, None, 0.0, heuristic(initial))) # explored is where we've been explored: Dict[T, float] = &#123;initial: 0.0&#125; # keep going while there is more to explore while not frontier.empty: current_node: Node[T] = frontier.pop() current_state: T = current_node.state # if we found the goal, we're done if goal_test(current_state): return current_node # check where we can go next and haven't explored for child in successors(current_state): new_cost: float = current_node.cost + 1 # 1 assumes a grid, need a cost function for more sophisticated apps if child not in explored or explored[child] &gt; new_cost: explored[child] = new_cost frontier.push(Node(child, current_node, new_cost, heuristic(child))) return None # went through everything and never found goal 其中 PriorityQueue 数据结构使用 heappop 方法确保每次从队列中取出的数据项都是（对算法而言）优先级最高的。 下面 maze.py 中添加的 manhattan_distance 函数则以意向节点与目标节点的路线距离作为下一步路径选择的依据。123456789101112131415161718# maze.py continueddef manhattan_distance(goal: MazeLocation) -&gt; Callable[[MazeLocation], float]: def distance(ml: MazeLocation) -&gt; float: xdist: int = abs(ml.column - goal.column) ydist: int = abs(ml.row - goal.row) return (xdist + ydist) return distance# ... # Test A* distance: Callable[[MazeLocation], float] = manhattan_distance(m.goal) solution3: Optional[Node[MazeLocation]] = astar(m.start, m.goal_test, m.successors, distance) if solution3 is None: print("No solution found using A*!") else: path3: List[MazeLocation] = node_to_path(solution3) m.mark(path3) print(m) 执行结果：1234567891011121314151617181920212223242526272829303132S******X X ********* **X X********** X XX*X X** XX***X * ****X*XX***XX * X GS X*X**X X**** X XX*X X * XXX * XXX * XX X******GS X*X**X X*******X XX X ** X XX***X X*XX XX * X G 参考资料Classic Computer Science Problems in Pythondavecom/ClassicComputerScienceProblemsInPython]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Advanced</tag>
        <tag>Python</tag>
        <tag>DataStructure</tag>
        <tag>Algorithm</tag>
        <tag>Search</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python Cookbook —— 类与对象]]></title>
    <url>%2F2020%2F01%2F02%2Fpython-cookbook-class-and-object%2F</url>
    <content type="text"><![CDATA[一、实例对象的字符串表示修改实例对象的 __str__() 和 __repr__() 方法可以改变该实例生成的字符串输出。123456789101112131415class Pair: def __init__(self, x, y): self.x = x self.y = y def __repr__(self): return 'Pair(&#123;0.x!r&#125;, &#123;0.y!r&#125;)'.format(self) def __str__(self): return '(&#123;0.x!s&#125;, &#123;0.y!s&#125;)'.format(self)# test&gt;&gt;&gt; p = Pair(3, 4)&gt;&gt;&gt; pPair(3, 4) # __repr__() output&gt;&gt;&gt; print(p) # __str__() output(3, 4) 二、自定义字符串格式化通过定义实例的 __format__ 方法，可以配置实例对象接受字符串格式化操作时的表现（即定义被 format 函数调用的方式与调用后的输出结果）。123456789101112131415161718192021222324252627_formats = &#123; 'ymd' : '&#123;d.year&#125;-&#123;d.month&#125;-&#123;d.day&#125;', 'mdy' : '&#123;d.month&#125;/&#123;d.day&#125;/&#123;d.year&#125;', 'dmy' : '&#123;d.day&#125;/&#123;d.month&#125;/&#123;d.year&#125;'&#125;class Date: def __init__(self, year, month, day): self.year = year self.month = month self.day = day def __format__(self, code): if code == '': code = 'ymd' fmt = _formats[code] return fmt.format(d=self)d = Date(2012, 12, 21)print(format(d))print(format(d, 'mdy'))print('The date is &#123;:ymd&#125;'.format(d))# =&gt; 2012-12-21# =&gt; 12/21/2012# =&gt; The date is 2012-12-21 三、使对象支持 Context-Management 协议为了使某个对象支持 Context-Management（即 with 语句），需要在类中实现 __enter__() 和 __exit__() 方法。12345678910111213141516171819202122232425262728293031from socket import socket, AF_INET, SOCK_STREAMclass LazyConnection: def __init__(self, address, family=AF_INET, type=SOCK_STREAM): self.address = address self.family = family self.type = type self.sock = None def __enter__(self): if self.sock is not None: raise RuntimeError('Already connected') self.sock = socket(self.family, self.type) self.sock.connect(self.address) return self.sock def __exit__(self, exc_ty, exc_val, tb): self.sock.close() self.sock = None# test codefrom functools import partialconn = LazyConnection(('www.python.org', 80))with conn as s: s.send(b'GET /index.htm HTTP/1.0\r\n') s.send(b'Host: www.python.org\r\n') s.send(b'\r\n') resp = b''.join(iter(partial(s.recv, 8192), b'')) print(resp) 四、创建自定义属性有些时候，在设置或者获取某个实例属性的值时，需要对其添加额外的操作，比如类型检查或者属性值的合法性检查等。这类需求可以使用 @property 装饰器来完成。 12345678910111213141516171819202122232425262728class Person: def __init__(self, first_name): self._first_name = first_name # Getter function @property def first_name(self): return self._first_name # Setter function @first_name.setter def first_name(self, value): if not isinstance(value, str): raise TypeError('Expected a string') self._first_name = value # Deleter function(optional) @first_name.deleter def first_name(self): raise AttributeError("Can't delete attribute")# test codea = Person('Guido')print(a.first_name) # =&gt; Guidoa.first_name = 'Linus'print(a.first_name) # =&gt; Linusa.first_name = 42 # =&gt; TypeError: Expected a stringdel a.first_name # =&gt; AttributeError: can't delete attribute PS：和 Java 等语言的使用习惯不同，Python 的 Property 属性应该只用在访问属性时需要对其进行额外处理的情况下。并不是所有对属性的访问都需要由 getter 或 setter 处理。 Property 还可以用来创建按需计算的属性。即属性值并非预先存放在某个地方，而是在访问它时实时地计算并返回。12345678910111213141516171819import mathclass Circle: def __init__(self, radius): self.radius = radius @property def area(self): return math.pi * self.radius ** 2 @property def perimeter(self): return 2 * math.pi * self.radiusc = Circle(4.0) print(c.radius) # =&gt; 4.0print(c.area) # =&gt; 50.26548245743669print(c.perimeter) # =&gt; 25.132741228718345 五、简化数据结构的初始化有些时候，程序中会包含很多需要用类去定义的数据结构，导致出现类似下面的代码：12345678910111213141516171819class Stock: def __init__(self, name, shares, price): self.name = name self.shares = shares self.price = priceclass Point: def __init__(self, x, y): self.x = x self.y = yclass Circle: def __init__(self, radius): self.radius = radius def area(self): return math.pi * self.radius ** 2 上述多个数据结构（Stock、Point、Circle）都是通过 __init__ 方法进行初始化的。实际上可以先定义一个基类，在其中抽象出 __init__ 方法的逻辑，使其可以作为一个通用的方法简化重复的初始化操作。1234567891011121314151617181920212223242526272829class Structure: # Class variable that specifies expected fields _fields = [] def __init__(self, *args, **kwargs): if len(args) != len(self._fields): raise TypeError('Expected &#123;&#125; arguments'.format(len(self._fields))) # Set the arguments for name, value in zip(self._fields, args): setattr(self, name, value) # Set the additional arguments (if any) extra_args = kwargs.keys() - self._fields for name in extra_args: setattr(self, name, kwargs.pop(name)) if kwargs: raise TypeError('Duplicate values for &#123;&#125;'.format(','.join(kwargs)))# Example useif __name__ == '__main__': class Stock(Structure): _fields = ['name', 'shares', 'price'] s1 = Stock('ACME', 50, 91.1) s2 = Stock('ACME', 50, 91.1, date='8/2/2012') print(s1.shares) # =&gt; 50 print(s2.date) # =&gt; 8/2/2012 六、定义额外的构造器类方法可以作为除 __init__() 方法以外的，另一个用来创建类实例的构造方法。123456789101112131415161718192021222324import timeclass Date: # Primary constructor def __init__(self, year, month, day): self.year = year self.month = month self.day = day # Alternate constructor @classmethod def today(cls): t = time.localtime() return cls(t.tm_year, t.tm_mon, t.tm_mday) def __repr__(self): return f'&#123;self.year&#125;-&#123;self.month&#125;-&#123;self.day&#125;'a = Date(2019, 12, 23)print(a) # =&gt; 2019-12-23b = Date.today()print(b) # =&gt; 2019-12-23 七、通过 Mixin 扩展类123456789101112131415161718192021222324252627282930313233343536373839404142# mixins.pyclass LoggedMappingMixin: ''' Add logging to get/set/delete operations for debugging. ''' __slots__ = () def __getitem__(self, key): print(f'Getting &#123;key&#125;') return super().__getitem__(key) def __setitem__(self, key, value): print(f'Setting &#123;key&#125; = &#123;value&#125;') return super().__setitem__(key, value) def __delitem__(self, key): print(f'Deleting &#123;key&#125;') return super().__delitem__(key)class SetOnceMappingMixin: ''' Only allow a key to be set once. ''' __slots__ = () def __setitem__(self, key, value): if key in self: raise KeyError(f'&#123;key&#125; already set') return super().__setitem__(key, value)class StringKeysMappingMixin: ''' Restrict keys to strings only. ''' __slots__ = () def __setitem__(self, key, value): if not isinstance(key, str): raise TypeError('keys must be strings') return super().__setitem__(key, value) 测试代码：12345678910111213141516171819202122&gt;&gt;&gt; from mixins import *&gt;&gt;&gt; class LoggedDict(LoggedMappingMixin, dict):... pass...&gt;&gt;&gt; d = LoggedDict()&gt;&gt;&gt; d['x'] = 23Setting x = 23&gt;&gt;&gt; d['x']Getting x23&gt;&gt;&gt; del d['x']Deleting x&gt;&gt;&gt;&gt;&gt;&gt; class SetOnceStringDict(StringKeysMappingMixin, SetOnceMappingMixin, dict):... pass...&gt;&gt;&gt; d2 = SetOnceStringDict()&gt;&gt;&gt; d2['x'] = 23&gt;&gt;&gt; d2['x'] = 10KeyError: 'x already set'&gt;&gt;&gt; d2[3] = 42TypeError: keys must be strings 八、使类支持比较运算符1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859from functools import total_orderingclass Room: def __init__(self, name, length, width): self.name = name self.length = length self.width = width self.square_feet = self.length * self.width@total_orderingclass House: def __init__(self, name, style): self.name = name self.style = style self.rooms = list() @property def living_space_footage(self): return sum(r.square_feet for r in self.rooms) def add_room(self, room): self.rooms.append(room) def __str__(self): return f'&#123;self.name&#125;: &#123;self.living_space_footage&#125; square foot &#123;self.style&#125;' def __eq__(self, other): return self.living_space_footage == other.living_space_footage def __lt__(self, other): return self.living_space_footage &lt; other.living_space_footage# Build a few houses, and add rooms to themh1 = House('h1', 'Cape')h1.add_room(Room('Master Bedroom', 14, 21))h1.add_room(Room('Living Room', 18, 20))h1.add_room(Room('Kitchen', 12, 16))h1.add_room(Room('Office', 12, 12))h2 = House('h2', 'Ranch')h2.add_room(Room('Master Bedroom', 14, 21))h2.add_room(Room('Living Room', 18, 20))h2.add_room(Room('Kitchen', 12, 16))h3 = House('h3', 'Split')h3.add_room(Room('Master Bedroom', 14, 21))h3.add_room(Room('Living Room', 18, 20))h3.add_room(Room('Office', 12, 16))h3.add_room(Room('Kitchen', 15, 17))houses = [h1, h2, h3]print('Is h1 bigger than h2?', h1 &gt; h2) # =&gt; Trueprint('Is h2 smaller than h3?', h2 &lt; h3) # =&gt; Trueprint('Is h2 greater than or equal to h1?', h2 &gt;= h1) # =&gt; Falseprint('Which one is biggest?', max(houses)) # =&gt; h3: 1101 square foot Splitprint('Which is smallest?', min(houses)) # =&gt; h2: 846 square foot Ranch 参考资料Python Cookbook, 3rd Edition]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Tricks</tag>
        <tag>Program</tag>
        <tag>Advanced</tag>
        <tag>Python</tag>
        <tag>Class</tag>
        <tag>OOP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 服务器上的大文件查找及清理实践]]></title>
    <url>%2F2019%2F12%2F29%2Flinux-server-big-file-find-and-clean%2F</url>
    <content type="text"><![CDATA[生产上的 Linux 服务器磁盘空间不足，后面排查得知是某个应用频繁写 log 导致。于是加了一条自动清理过期日志的 crontab 。具体的排查过程记录如下，都是很基础的命令。 一、dfdf -h 命令查看当前磁盘空间的使用情况：12345678# df -hFilesystem Size Used Avail Use% Mounted on/dev/vda1 50G 50G 0G 100% /devtmpfs 3.9G 0 3.9G 0% /devtmpfs 3.9G 24K 3.9G 1% /dev/shmtmpfs 3.9G 476K 3.9G 1% /runtmpfs 3.9G 0 3.9G 0% /sys/fs/cgrouptmpfs 783M 0 783M 0% /run/user/0 系统只有一个磁盘分区 /dev/vda1，大小为 50G，已挂载到根目录下，用量为 100%，确实没有剩余空间。 以此可断定并非存在分区划分不合理的情况。比如磁盘大部分容量分配给了其他分区，挂载到诸如 /home、/usr 等目录下导致 / 路径下没有足够的空间。 二、lsblklsblk 命令查看硬盘的分区与挂载点：12345# lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsr0 11:0 1 37M 0 romvda 253:0 0 50G 0 disk`-vda1 253:1 0 50G 0 part / 当前只有一块硬盘 vda，大小为 50G，全部分配给了唯一的分区 vda1，不存在剩余空间。 此处可以确定硬盘的所有容量都已被分配使用。不存在剩余空间（未分配区域）或者因为 LVM 卷导致仍有空闲存储未被使用等情况。 三、dudu 命令统计文件和目录占用的磁盘空间大小。 du 命令默认会以递归的方式输出当前路径中包含的所有文件的大小（以目录为单位显示），信息量有时会比较庞大。可以使用 -s 选项获取当前目录下所有文件的大小总和。或者使用 -d 选项指定遍历的深度，即只统计到某一层目录而无需展开到更深层的子目录。 当前 Linux 服务器上的应用都部署在某个特定的路径下，因此切换到该目录并统计其中文件占用的磁盘空间大小总和：12# du -sh12G . 通过 -d 选项指定遍历的层数为 1，显示当前路径下包含的每一个子目录各自占用的磁盘空间总和：12345678910# du -hd180K ./work7.6M ./lib12G ./logs236K ./conf4.0K ./temp221M ./webapps15M ./backup860K ./bin12G . 可以看到 logs 子目录下的文件总共占用了 12G 存储空间，几乎与整个目录大小相当。因此基本可以确定 logs 目录为需要进一步排查的对象。 PS：如当前路径下子目录众多，也可以使用 sort 命令对输出结果按大小进行排序。12345678910# du -d1 | sort -nr12448764 .12199320 ./logs225988 ./webapps14432 ./backup7736 ./lib860 ./bin236 ./conf80 ./work4 ./temp sort 命令的 -n 选项表示以数字大小为排序依据，-r 则表示逆序输出排序结果。du 命令去掉 -h 选项则避免将文件大小（bytes）自动转换为 KB、MB、GB 等导致单位不一致。可以使用 -k 或 -m 等选项手动指定 du 命令的单位。 四、lsls 命令获取指定目录下包含的文件列表（及详细信息）。 123456789# ls -Slh logs | head -8total 12G-rw-r--r-- 1 tomcat Devops 3.5G Dec 29 01:40 catalina.out-rw-r----- 1 root root 108M Nov 15 00:00 localhost_access.2019-11-14.log-rw-r----- 1 root root 107M Nov 22 00:00 localhost_access.2019-11-21.log-rw-r----- 1 root root 106M Nov 14 00:00 localhost_access.2019-11-13.log-rw-r----- 1 root root 104M Nov 17 00:00 localhost_access.2019-11-16.log-rw-r----- 1 root root 104M Nov 23 00:00 localhost_access.2019-11-22.log-rw-r----- 1 root root 104M Nov 13 00:00 localhost_access.2019-11-12.log 其中 -S 选项用于将输出结果按文件大小排序，-l 选项指定输出各文件的详细信息。由于 logs 目录下文件众多，使用 head -8 筛选前 8 条输出进行显示。 此时即可根据对文件大小和功能的判断手动执行删除操作。 五、findfind 命令筛选指定时期内创建的文件 logs 目录下每天都会创建新的日志文件，导致占用的磁盘空间与日俱增。因此需要定期删除指定日期以前的旧文件，释放不必要的空间占用。 如删除当前目录下只在 60 天以前修改过的文件，保留最近两个月的日志记录：1# find . -mtime +60 -type f -exec rm &#123;&#125; \; 将该命令添加到 crontab 中，设置好定时规则，即可定期执行清理任务，避免过高的磁盘占用。 命令总结 du -h：查看当前系统中磁盘空间的使用情况 lsblk：查看当前系统中磁盘的分区和挂载情况 du -hd1：查看当前目录下各子目录分别占用的磁盘空间大小 ls -Slh | head -8：列出当前目录下所有文件的详细信息，结果由大到小排序，输出前 8 条 find . -mtime +60 -type f -exec rm {} \;：查找当前目录下所有 60 天之前修改过的文件并删除]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Server</tag>
        <tag>Admin</tag>
        <tag>Tools</tag>
        <tag>Disk</tag>
        <tag>Tricks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible Playbooks 基本功能介绍及示例代码]]></title>
    <url>%2F2019%2F12%2F29%2Fansible-playbooks-basic-code-examples%2F</url>
    <content type="text"><![CDATA[一、基本结构用于安装或升级 apache 服务的 playbook 完整示例：1234567891011121314151617181920212223242526---- hosts: webservers remote_user: root vars: http_port: 80 max_clients: 200 tasks: - name: ensure apache is at the latest version yum: name: httpd state: latest - name: write the apache config file template: src: /srv/httpd.j2 dest: /etc/httpd.conf notify: - restart apache - name: ensure apache is running service: name: httpd state: started handlers: - name: restart apache service: name: httpd state: restarted targettarget 部分用于指定执行 playbook 任务时面向的目标主机和远程用户。123---- hosts: webservers remote_user: root 远程用户也可以在特定的 task 中额外进行定义：1234567---- hosts: webservers remote_user: root tasks: - name: test connection ping: remote_user: yourname 执行任务时允许远程用户通过 sudo 提升权限：12345---- hosts: webservers remote_user: yourname become: yes become_method: sudo 执行任务时切换到其他用户身份：12345---- hosts: webservers remote_user: yourname become: yes become_user: postgres variablevariable 部分用于定义变量，作用域为当前 play。123vars: http_port: 80 max_clients: 200 通过 vars_files 定义变量：1234vars_files: conf/country-AU.yml conf/datacenter-SYD.yml conf/cluster-mysql.yml 交互式地从用户输入中获取变量的值。如将用户输入赋值给变量 https_passphrase：1234vars_prompt: - name: https_passphrase prompt: Key Passphrase private: yes tasktask 部分包含了一系列我们希望在目标机器上执行的动作。12345tasks:- name: ensure apache is at the latest version yum: name: httpd state: latest handlerhandler 与 task 有着相同的语法和类似的功能。但是 handler 只可以在特定的条件下由 task 调用后执行。 如配置文件替换成功后触发重启服务的动作：123456789101112tasks: - name: copy the DHCP config copy: src: dhcp/dhcpd.conf dest: /etc/dhcp/dhcpd.conf notify: restart dhcphandlers:- name: restart dhcp service: name: dhcpd state: restarted 可以在单个 task 中同时调用多个 handler：123456789101112131415161718192021222324252627---- hosts: qroud tasks: - name: checkout Qroud git: repo:git@github.com:smarthall/Qroud.git dest: /opt/apps/Qroud force=no notify: - migrate db - generate static - restart httpdhandlers:- name: migrate db command: ./manage.py migrate –all args: chdir: /opt/apps/Qroud- name: generate static command: ./manage.py collectstatic -c –noinput args: chdir: /opt/apps/Qroud- name: restart httpd service: name: httpd state: restarted 二、playbook 模块templatetemplate 模块一般用于定义配置文件的主体框架，并为 Ansible 中的变量预留好位置以便在需要时渲染。类似于 Flask 应用依据模板文件动态地生成 HTML 文档。其模板功能由 Jinja2 提供，支持条件语句、for 循环和宏等高级语法。123&#123;% for ip in ansible_all_ipv4_addresses %&#125; &#123;&#123; ip &#125;&#125;;&#123;% endfor %&#125; 12345tasks:- name: write the apache config file template: src: /srv/httpd.j2 dest: /etc/httpd.conf pausepause 模块会将执行中的 playbook 暂停一段时间。比如部署了一个新版本的 web 应用，需要用户手动确认一切正常才能继续执行后面的任务。123456789---- hosts: localhost tasks: - name: wait on user input pause: prompt: "Warning! Press ENTER to continue or CTRL-C to quit." - name: timed wait pause: seconds: 30 wait_for等待某个特定的 TCP 端口可以被远程主机访问连通。1234567891011121314151617---- hosts: webapps tasks: - name: Install Tomcat yum: name: tomcat7 state: latest - name: Start Tomcat service: name: tomcat7 state: started - name: Wait for Tomcat to start wait_for: port: 8080 state: started group_bygroup_by 模块可以在 task 中基于收集到的 facts 信息动态地对 hosts 进行分组。1234567891011121314151617---- name: Create operating system group hosts: all tasks: - group_by: key=os_&#123;&#123; ansible_distribution &#125;&#125;- name: Run on CentOS hosts only hosts: os_CentOS tasks: - name: Install Apache yum: name=httpd state=latest- name: Run on Ubuntu hosts only hosts: os_Ubuntu tasks: - name: Install Apache apt: pkg=apache2 state=latest 三、Playbooks 进阶Looping1234567891011tasks:- name: Secure config files file file: path: "/etc/&#123;&#123; item &#125;&#125;" mode: 0600 owner: root group: root with_items: - my.cnf - shadow - fstab 条件语句123456789101112131415161718192021---- name: Install VIM hosts: all tasks: - name: Install VIM via yum yum: name: vim-enhanced state: latest when: ansible_os_family == "RedHat" - name: Install VIM via apt apt: name: vim state: latest when: ansible_os_family == "Debian" - name: Unexpected OS family debug: msg: "OS Family &#123;&#123; ansible_os_family &#125;&#125; is not supported" fail: yes when: ansible_os_family != "RedHat" and ansible_os_family != "Debian" 123456# Copy a file to the remote server if the hosts file doesn't existtasks:- stat: path=/etc/hosts register: hosts_file- copy: src=path/to/local/file dest=/path/to/remote/file when: not hosts_file.stat.exists 123456# Downgrade PHP version if the current version contains '7.0'.tasks:- shell: php --version register: php_version- shell: yum -y downgrade php* when: "'7.0' in php_version.stdout" 注册变量123456789101112131415- name: Using register hosts: ansibletest remote_user: root tasks: - name: Get /tmp info file: dest: /tmp state: directory register: tmp - name: Set mode on /tmp/subtmp file: dest: /tmp/subtmp mode: "&#123;&#123; tmp.mode &#125;&#125;" state: directory debug 查看变量的值：1234- name: capture output of id command command: id -un register: login- debug: msg="Logged in as user &#123;&#123; login.stdout &#125;&#125;" filterJinja2 模板提供的 filter 功能可以将原始数据转换为用户需要的格式123456789101112---- name: Create user accounts hosts: all vars: users: tasks: - name: Create accounts user: name=&#123;&#123; item|lower &#125;&#125; state=present with_items: - Fred - John - DanielH 常用 filter： min：参数为列表，返回列表中最小的项目 max：参数为列表，返回列表中最大的项目 random：参数为列表，随机返回列表中的某个值 default(x)：指定变量不存在时，以 x 为该变量的默认值 unique：参数为列表，返回该列表去除重复项后的版本 replace(x, y)：将字符串中出现的所有 x 替换为 y join(x)：参数为列表，返回由 x 拼接所有列表项后形成的字符串 针对文件路径的常用 filter： basename：返回路径中包含的文件名 dirname：返回文件所在的目录 expanduser：将路径中包含的 ~ 替换为 home 目录 realpath：文件的真实路径 12345vars: homepage: /usr/share/nginx/html/index.htmltasks:- name: copy home page copy: src=files/&#123;&#123; homepage | basename &#125;&#125; dest=&#123;&#123; homepage &#125;&#125; Lookuplookups 允许 Ansible 从多种类型的源头（如文本文档、CSV 文件等）读取配置数据。 file：读取文本文件内容作为参数12- name: Add my public key as an EC2 key ec2_key: name=mykey key_material="&#123;&#123; lookup('file', '/Users/lorin/.ssh/id_rsa.pub') &#125;&#125;" pipe：在远程机器上执行某个外部程序并关联其标准输出12- name: get SHA of most recent commit debug: msg="&#123;&#123; lookup('pipe', 'git rev-parse HEAD') &#125;&#125;" env：获取远程机器上的某个环境变量12- name: get the current shell debug: msg="&#123;&#123; lookup('env', 'SHELL') &#125;&#125;" password：生成随机密码，并将该密码写入指定文件1234- name: create deploy postgres user postgresql_user: name: deploy password: "&#123;&#123; lookup('password', 'deploy-password.txt') &#125;&#125;" redis-kv：获取 redis 服务器上某个 key 的值（需要在远程机器上安装 redis Python 库）12- name: look up value in Redis debug: msg="&#123;&#123; lookup('redis_kv', 'redis://localhost:6379,weather') &#125;&#125;" 复杂循环 名称 输入 循环规则 with_items 列表 遍历所有列表项 with_lines 命令 遍历命令输出的所有行 with_fileglob Glob 遍历文件（文件名可使用通配符） with_first_found 路径列表 路径中检索到的第一个文件目标 with_dict 字典 遍历字典中的数据项 with_flattened 多层列表 遍历展开后的多层列表 with_inventory Host 模式 遍历匹配的主机 with_lines：12345# files/turing.txtLeslie LamportSilvio MicaliShafi GoldwasserJudea Pearl 1234567- name: Send out a slack message slack: domain: example.slack.com token: "&#123;&#123; slack_token &#125;&#125;" msg: "&#123;&#123; item &#125;&#125; was in the list" with_lines: - cat files/turing.txt with_fileglob：12345- name: add public keys to account authorized_key: user=deploy key="&#123;&#123; lookup('file', item) &#125;&#125;" with_fileglob: - /var/keys/*.pub - keys/*.pub with_dict：123- name: iterate over ansible_eth0 debug: msg=&#123;&#123; item.key &#125;&#125;=&#123;&#123; item.value &#125;&#125; with_dict: "&#123;&#123; ansible_eth0.ipv4 &#125;&#125;" 参考资料Ansible Configuration Management - Second Edition]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Admin</tag>
        <tag>Ansible</tag>
        <tag>DevOps</tag>
        <tag>Playbooks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python3 中的时间与日期模块详解]]></title>
    <url>%2F2019%2F12%2F22%2Fpython3-date-and-time-manual%2F</url>
    <content type="text"><![CDATA[Python 中不包含表示日期和时间的基本数据类型，但是提供了如下三个模块用于操作时间日期类型的数据： time：提供与时间相关的功能。包含时钟时间、处理器运行时间、基本的格式化工具等 datetime：提供处理时间日期的高级接口。如时间日期之间的算术计算和大小比较等 calendar：提供类似日历的年、月、日、周的格式化输出和其他日历相关的功能 一、timetime 模块包含多种类型的“时钟”时间，方便处理多种不同需求的任务。如： time() 返回自纪年以来的秒数。纪年指 time.gmtime(0) 函数的返回值，大多数系统中是 1970年1月1日00:00:00（UTC） monotonic() 可以用来测量长时间运行的进程，它不会因为系统时间被修改而发生变化 perf_counter() 提供了精度最高的时间量度，因此多用于获取短时间段的高精度结果 process_time() 返回当前进程中系统和用户 CPU 时间的总和。不包括 sleep() 时间 测试程序：1234567891011121314151617181920212223import textwrapimport timeavailable_clocks = [ ('time', time.time), ('monotonic', time.monotonic), ('perf_counter', time.perf_counter), ('process_time', time.process_time),]for clock_name, func in available_clocks: print(textwrap.dedent('''\ &#123;name&#125;: adjustable : &#123;info.adjustable&#125; implementation: &#123;info.implementation&#125; monotonic : &#123;info.monotonic&#125; resolution : &#123;info.resolution&#125; result : &#123;result&#125; ''').format( name=clock_name, info=time.get_clock_info(clock_name), result=func()) ) 输出中包含了各时钟函数的实现方式、精度和执行结果等：123456789101112131415161718192021222324252627time: adjustable : True implementation: clock_gettime(CLOCK_REALTIME) monotonic : False resolution : 1e-09 result : 1576935284.1307783monotonic: adjustable : False implementation: clock_gettime(CLOCK_MONOTONIC) monotonic : True resolution : 1e-09 result : 1653915.765674168perf_counter: adjustable : False implementation: clock_gettime(CLOCK_MONOTONIC) monotonic : True resolution : 1e-09 result : 1653915.765707337process_time: adjustable : False implementation: clock_gettime(CLOCK_PROCESS_CPUTIME_ID) monotonic : True resolution : 1e-09 result : 0.017164144 上述几个时钟函数中，只有 time.time() 在计算时间时有明确的参考点（time.gmtime(0)），另外三个函数都没有定义绝对的起点作为基准，因此常用来计算某个过程耗费的时间总和（多次执行并计算时间差），而无法获取一个标准的绝对时间。1234&gt;&gt;&gt; start = time.perf_counter()&gt;&gt;&gt; end = time.perf_counter()&gt;&gt;&gt; end - start8.590425299999993 上述函数返回的都是以秒为单位精度较高的浮点数。对于需要记录或者打印方便阅读的时间日期时，可以使用 ctime() 函数：12345&gt;&gt;&gt; time.ctime()'Sat Dec 21 21:56:41 2019'&gt;&gt;&gt; later = time.time() + 30&gt;&gt;&gt; time.ctime(later)'Sat Dec 21 21:57:19 2019' time 模块中还定义了 struct_time 结构用来表示日期和时间中的每一项独立的值（年月日、时分秒等）。1234567&gt;&gt;&gt; loc_time = time.localtime()&gt;&gt;&gt; loc_timetime.struct_time(tm_year=2019, tm_mon=12, tm_mday=21, tm_hour=22, tm_min=20, tm_sec=32, tm_wday=5, tm_yday=355, tm_isdst=0)&gt;&gt;&gt; loc_time.tm_year2019&gt;&gt;&gt; loc_time.tm_hour22 时间的格式化输出strftime() 函数可以用来将 struct_time 格式的时间值转换为字符串的形式表示。strptime() 函数的行为则相反。如：1234567891011&gt;&gt;&gt; import time&gt;&gt;&gt; loc_time = time.localtime()&gt;&gt;&gt; loc_timetime.struct_time(tm_year=2019, tm_mon=12, tm_mday=21, tm_hour=23, tm_min=21, tm_sec=33, tm_wday=5, tm_yday=355, tm_isdst=0)&gt;&gt;&gt; time.strftime('%Y-%m-%d %H:%M:%S', loc_time)'2019-12-21 23:21:33'&gt;&gt;&gt; now = time.ctime()&gt;&gt;&gt; now'Sat Dec 21 23:23:31 2019'&gt;&gt;&gt; time.strptime(now)time.struct_time(tm_year=2019, tm_mon=12, tm_mday=21, tm_hour=23, tm_min=23, tm_sec=31, tm_wday=5, tm_yday=355, tm_isdst=-1) 常见的字符串形式的时间日期格式如下：1234&gt;&gt;&gt; time.strftime('%Y-%m-%d %H:%M:%S')'2019-12-21 23:26:40'&gt;&gt;&gt; time.strftime('%a %b %d %H:%M:%S %Y')'Sat Dec 21 23:27:15 2019' strftime() 函数支持的更多格式定义可参考 help(time.strftime) 。 二、datetimedatetime 模块中定义的函数和类可以对日期和时间进行转换、格式化输出、算术计算等操作。 timetime 类可以表示包含时、分、秒、时区等信息的时间对象。123456789101112&gt;&gt;&gt; import datetime&gt;&gt;&gt; t = datetime.time(1, 2, 3)&gt;&gt;&gt; print(t)01:02:03&gt;&gt;&gt; t.hour1&gt;&gt;&gt; t.minute2&gt;&gt;&gt; t.second3&gt;&gt;&gt; t.tzinfo&gt;&gt;&gt; datedate 类可以表示包含年、月、日等信息的日期值。其 today() 方法可以获取当天的日期。12345678910&gt;&gt;&gt; from datetime import date&gt;&gt;&gt; today = date.today()&gt;&gt;&gt; todaydatetime.date(2019, 12, 21)&gt;&gt;&gt; today.year2019&gt;&gt;&gt; today.month12&gt;&gt;&gt; today.day21 datetimedatetime 模块中的 datetime 类可以表示完整的日期和时间，类似 time 类和 date 类的结合。1234567891011121314151617&gt;&gt;&gt; import datetime&gt;&gt;&gt; now = datetime.datetime.now()&gt;&gt;&gt; nowdatetime.datetime(2019, 12, 22, 0, 30, 21, 372631)&gt;&gt;&gt; print(now)2019-12-22 00:30:21.372631&gt;&gt;&gt; t = datetime.time(1, 2, 3)&gt;&gt;&gt; print(t)01:02:03&gt;&gt;&gt; d = datetime.date.today()&gt;&gt;&gt; print(d)2019-12-22&gt;&gt;&gt; dt = datetime.datetime.combine(d, t)&gt;&gt;&gt; dtdatetime.datetime(2019, 12, 22, 1, 2, 3)&gt;&gt;&gt; print(dt)2019-12-22 01:02:03 timedeltatimedelta 类可以表示某个特定长度的时间段（以年月日或时分秒等为单位）。两个 datetime 相减会得到 timedelta 对象，也可以用 datetime 加上或者减去 timedelta 得到新的时间值。 日期加减：123456789&gt;&gt;&gt; import datetime&gt;&gt;&gt; today = datetime.date.today()&gt;&gt;&gt; todaydatetime.date(2019, 12, 22)&gt;&gt;&gt; twodays = datetime.timedelta(days=2)&gt;&gt;&gt; print(twodays)2 days, 0:00:00&gt;&gt;&gt; today - twodaysdatetime.date(2019, 12, 20) 时间加减：1234567891011&gt;&gt;&gt; import datetime&gt;&gt;&gt; now = datetime.datetime.now()&gt;&gt;&gt; print(now)2019-12-22 00:35:30.298198&gt;&gt;&gt; delta = datetime.timedelta(days=1, minutes=30)&gt;&gt;&gt; print(delta)1 day, 0:30:00&gt;&gt;&gt; now - deltadatetime.datetime(2019, 12, 21, 0, 5, 30, 298198)&gt;&gt;&gt; print(now - delta)2019-12-21 00:05:30.298198 比较大小12345678910111213141516&gt;&gt;&gt; t1 = datetime.time(12, 30, 20)&gt;&gt;&gt; print(t1)12:30:20&gt;&gt;&gt; t2 = datetime.time(11, 20, 40)&gt;&gt;&gt; print(t2)11:20:40&gt;&gt;&gt; t2 &gt; t1False&gt;&gt;&gt; today = datetime.date.today()&gt;&gt;&gt; print(today)2019-12-22&gt;&gt;&gt; tomorrow = today + datetime.timedelta(days=1)&gt;&gt;&gt; print(tomorrow)2019-12-23&gt;&gt;&gt; today &lt; tomorrowTrue 格式化输出datetime 类中也提供了 strftime 和 strptime 方法，使用示例如下：12345678910&gt;&gt;&gt; import datetime&gt;&gt;&gt; format = "%a %b %d %H:%M:%S %Y"&gt;&gt;&gt; now = datetime.datetime.now()&gt;&gt;&gt; nowdatetime.datetime(2019, 12, 22, 1, 7, 53, 505983)&gt;&gt;&gt; s = now.strftime(format)&gt;&gt;&gt; s'Sun Dec 22 01:07:53 2019'&gt;&gt;&gt; datetime.datetime.strptime(s, format)datetime.datetime(2019, 12, 22, 1, 7, 53) 三、calendar这部分的功能目前还没用到，简单示例如下：12345678910111213141516171819202122232425262728293031&gt;&gt;&gt; import calendar&gt;&gt;&gt; c = calendar.TextCalendar(calendar.SUNDAY)&gt;&gt;&gt; c.prmonth(2019, 12) December 2019Su Mo Tu We Th Fr Sa 1 2 3 4 5 6 7 8 9 10 11 12 13 1415 16 17 18 19 20 2122 23 24 25 26 27 2829 30 31&gt;&gt;&gt; cal = calendar.TextCalendar(calendar.SUNDAY)&gt;&gt;&gt; print(cal.formatyear(2020, 2, 1, 1, 3)) 2020 January February MarchSu Mo Tu We Th Fr Sa Su Mo Tu We Th Fr Sa Su Mo Tu We Th Fr Sa 1 2 3 4 1 1 2 3 4 5 6 7 5 6 7 8 9 10 11 2 3 4 5 6 7 8 8 9 10 11 12 13 1412 13 14 15 16 17 18 9 10 11 12 13 14 15 15 16 17 18 19 20 2119 20 21 22 23 24 25 16 17 18 19 20 21 22 22 23 24 25 26 27 2826 27 28 29 30 31 23 24 25 26 27 28 29 29 30 31 April May JuneSu Mo Tu We Th Fr Sa Su Mo Tu We Th Fr Sa Su Mo Tu We Th Fr Sa 1 2 3 4 1 2 1 2 3 4 5 6 5 6 7 8 9 10 11 3 4 5 6 7 8 9 7 8 9 10 11 12 1312 13 14 15 16 17 18 10 11 12 13 14 15 16 14 15 16 17 18 19 2019 20 21 22 23 24 25 17 18 19 20 21 22 23 21 22 23 24 25 26 2726 27 28 29 30 24 25 26 27 28 29 30 28 29 30 31... 参考资料THE PYTHON 3 STANDARD LIBRARY BY EXAMPLE]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Python</tag>
        <tag>Basic</tag>
        <tag>Datastructure</tag>
        <tag>Datetime</tag>
        <tag>Date</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django REST framework 实现文件上传的两种方式]]></title>
    <url>%2F2019%2F12%2F21%2Ffile-upload-by-django-rest-framework-two-ways%2F</url>
    <content type="text"><![CDATA[一、基于 Django modelsDjango 框架的数据模型（models 类）中定义了 ImageField 和 FileField 等类型的字段，可以用来存储图片或者文件对象。ImageField 和 FileField 针对文件对象的属性和行为封装了易于使用的 API，配合 Django REST framework 提供的一系列组件，可以在编写很少量代码的情况下完成初步的文件上传功能。 各组件代码Models12345from django.db import modelsclass FileModel(models.Model): name = models.CharField(max_length=50) file = models.FileField(upload_to='upload') Serializers12345678from .models import FileModelfrom rest_framework import serializersclass FileSerializer(serializers.ModelSerializer): class Meta: model = FileModel fields = '__all__' Views1234567from rest_framework import viewsetsfrom .models import FileModelfrom .serializers import FileSerializerclass FileViewSet(viewsets.ModelViewSet): queryset = FileModel.objects.all() serializer_class = FileSerializer Urls12345678910from django.urls import path, includefrom &lt;appname&gt;.views import FileViewSetfrom rest_framework import routersrouter = routers.DefaultRouter()router.register(r'upload', FileViewSet)urlpatterns = [ path('', include(router.urls)),] 功能测试使用 HTTPie 工具利用 POST 方法以 Form 表单的形式（-f）提交上传的文件：12345678$ http -f POST http://127.0.0.1:8000/upload/ name="test" file@test.txtHTTP/1.1 201 Created&#123; "file": "http://127.0.0.1:8000/upload/upload/test.txt", "id": 4, "name": "test"&#125; 同时也可以直接访问 http://127.0.0.1:8000/upload/ ，通过 Django REST framework 提供的前端界面手动上传文件。 或者也可以自定义前端界面，HTML 上传页面示例代码：1234567891011121314151617&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;form action="http://xx.xx.xx.xx:8000/upload/" method="post" enctype="multipart/form-data"&gt; &lt;input type="text" name="name" placeholder="name"&gt;&lt;br&gt; &lt;input type="file" name="file"&gt;&lt;br&gt; &lt;input type="submit" value="submit"&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 二、FileField对于 FileField 类型的文件字段，后台的视图代码可以通过 requests.FILES 获取上传的文件数据。如 requests.FILES[&#39;file&#39;]。只有当请求方法为 POST 且前端的 &lt;form&gt; 带有属性 enctype=&quot;multipart/form-data&quot; 时，request.FILES 才能接收到数据，否则为空。 FileField 字段的 upload_to 属性用于指定上传文件的保存位置，以 settings.py 中定义的 MEDIA_ROOT 为路径前缀。upload_to 属性可以接收包含 strftime() 格式的日期字符串（/%Y/%m/%d），用来定义类似 /year/month/day 格式的路径。如：12# 文件上传至类似 MEDIA_ROOT/uploads/2019/12/20 的路径下upload = models.FileField(upload_to='uploads/%Y/%m/%d/') 可以使用 models 提供的查询接口获取已上传文件的相关信息：1234567891011121314$ python manage.py shell(InteractiveConsole)&gt;&gt;&gt; from &lt;appname&gt;.models import FileModel&gt;&gt;&gt; test = FileModel.objects.get(name='test') # 获取某一条数据记录&gt;&gt;&gt; test.file # 数据记录关联的文件对象&lt;FieldFile: upload/test.txt&gt;&gt;&gt;&gt; test.file.name # 文件名'upload/test.txt'&gt;&gt;&gt; test.file.url # 文件 URL'upload/test.txt'&gt;&gt;&gt; test.file.size # 文件大小22&gt;&gt;&gt; test.file.path # 文件路径'/home/starky/program/python/web/django/filestorage/media/upload/test.txt' 通过数据模型检索到的文件（test.file）为 FieldFile 对象。FieldFile 类封装了一些便捷的 API 可以用来操作关联的底层文件，以下是一些简单的示例。 读取文件内容1234567&gt;&gt;&gt; test = FileModel.objects.get(name='test')&gt;&gt;&gt; test.file&lt;FieldFile: upload/test.txt&gt;&gt;&gt;&gt; with test.file.open('rb') as f:... f.read()...b'sdfsdfsdfweofssdnvdvs\n' 写入新的内容123456&gt;&gt;&gt; with test.file.open('wb') as f:... f.write(b'Hello, World')...12&gt;&gt;&gt; test.file.open().read()b'Hello, World' 删除关联的底层文件123&gt;&gt;&gt; test.file.delete()&gt;&gt;&gt; test.file&lt;FieldFile: None&gt; 新建文件语法格式为 FieldFile.save(name, content, save=True)其中 content 参数必须接收 django.core.files.File 类或者其子类的实例，比如 ContentFile，不能直接使用 Python 内置的 file 对象。 不管是删除（FieldFile.delete()）还是新建（FieldFile.save()）文件，save 参数默认都为 True。即自动调用模型实例的 save() 方法提交对数据库的改动。 12345678910&gt;&gt;&gt; testnew = FileModel(name='testnew', file=None)&gt;&gt;&gt; testnew.file&lt;FieldFile: None&gt;&gt;&gt;&gt; from django.core.files.base import ContentFile&gt;&gt;&gt; content = ContentFile('Hello, Django!')&gt;&gt;&gt; testnew.file.save('testnew.txt', content)&gt;&gt;&gt; testnew.file&lt;FieldFile: upload/testnew.txt&gt;&gt;&gt;&gt; testnew.file.open().read()b'Hello, Django!' 三、FileUploadParserDjango REST framework 提供了 parsers.FileUploadParser 类，可以用来处理原始格式的文件内容的上传。后端获取到的 request.data 为字典结构，其中包含的 &#39;file&#39; 键对应的值即为上传的文件对象。 如果 FileUploadParser 类被包含 filename 参数的 URL 调用，则该参数会作为文件保存到服务端后的文件名。若 URL 中不包含 filename 参数，则客户端发起的请求必须包含 Content-Disposition 请求头及 filename 参数。如 Content-Disposition: attachment; filename=upload.jpg。 示例代码12345678910111213141516# views.pyfrom rest_framework.views import APIViewfrom rest_framework.response import Responsefrom rest_framework.parsers import FileUploadParserclass FileUploadView(APIView): parser_classes = [FileUploadParser, ] def put(self, request, filename, format=None): file_obj = request.data['file'] with open(filename, 'wb') as f: for chunk in file_obj.chunks(): f.write(chunk) return Response(f'&#123;filename&#125; uploaded',status=204) 123456# urls.pyfrom django.urls import re_pathurlpatterns = [ re_path(r'^files/(?P&lt;filename&gt;[^/]+)$', views.FileUploadView.as_view()),] 上传接口的 URL 为 http://xx.xx.xx.xx/files/&lt;filename&gt; ，其中 &lt;filenmae&gt; 用于指定上传成功后在服务器端的文件名。客户端使用 PUT 请求上传文件。 使用 postman 测试文件上传，截图如下： 前端上传代码示例如下（使用 jQuery，有可能出现跨域问题，可参考网上资料解决）：12345678910111213141516171819202122232425262728293031323334&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;文件上传&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;form&gt; &lt;p&gt;上传文件： &lt;input type="file" name="files" id='files' /&gt;&lt;/p&gt; &lt;input type="button" value="上传" onclick="doUpload()" /&gt; &lt;/form&gt; &lt;script src="https://cdn.bootcss.com/jquery/3.4.1/jquery.js"&gt;&lt;/script&gt; &lt;script type="text/javascript"&gt; function doUpload() &#123; $.ajax(&#123; url: 'http://xx.xx.xx.xx:8000/files/test.jpg', type: 'PUT', data: $('#files')[0].files[0], cache: false, processData: false, contentType: false, async: false &#125;).done(function (res) &#123; alert("上传成功") &#125;).fail(function (res) &#123; alert("上传失败：" + res) &#125;); &#125; &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 参考资料Managing filesmodels.FileFieldparsers]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Python</tag>
        <tag>Web</tag>
        <tag>Development</tag>
        <tag>Django</tag>
        <tag>REST</tag>
        <tag>API</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高效 Python 代码——类与继承]]></title>
    <url>%2F2019%2F12%2F14%2Feffective-python-class-and-inherit%2F</url>
    <content type="text"><![CDATA[一、用辅助类（而不是字典）来维护程序的状态Python 内置的字典类型可以很好地保存某个对象在其生命周期中的（动态）内部状态。如下面的成绩单类：12345678910111213141516171819202122class SimpleGradebook(object): def __init__(self): self._grades = &#123;&#125; def add_student(self, name): self._grades[name] = [] def report_grade(self, name, score): self._grades[name].append(score) def average_grade(self, name): grades = self._grades[name] return sum(grades) / len(grades)book = SimpleGradebook()book.add_student('Isaac Newton')book.report_grade('Isaac Newton', 90)book.report_grade('Isaac Newton', 80)print(book.average_grade('Isaac Newton'))# =&gt; 85.0 在上面的 SimpleGradebook 类中，学生名字及其对应的成绩都保存在 _grades 字典结构中，这样就不必把每个学生都表示成对象并预设一个用于存放名字的属性了。 字典类型用起来方便，但也容易因为过度使用导致一些问题。如果需要扩充上面成绩单类的功能，把学生成绩按照科目保存。则 _grades 字典中需要嵌入另一个字典存储科目与多次成绩的键值对。即类似这样的结构：{&#39;Einstein&#39;: {&#39;Math&#39;: [80, 90]}}123456789101112131415161718192021222324252627282930class BySubjectGradebook(object): def __init__(self): self._grades = &#123;&#125; def add_student(self, name): self._grades[name] = &#123;&#125; def report_grade(self, name, subject, grade): by_subject = self._grades[name] grade_list = by_subject.setdefault(subject, []) grade_list.append(grade) def average_grade(self, name): by_subject = self._grades[name] total, count = 0, 0 for grades in by_subject.values(): total += sum(grades) count += len(grades) return total / countbook = BySubjectGradebook()book.add_student('Albert Einstein')book.report_grade('Albert Einstein', 'Math', 80)book.report_grade('Albert Einstein', 'Math', 90)book.report_grade('Albert Einstein', 'Gym', 70)book.report_grade('Albert Einstein', 'Gym', 80)print(book.average_grade('Albert Einstein'))# =&gt; 80.0 假设需求再次改变，在记录某个分数的同时，还需要记录该次成绩占该科目历次成绩的权重。。。此时用于保存成绩的数据结构可以改成这样：{&#39;Einstein&#39;: {&#39;Math&#39;: [(80, 0.4), (90, 0.6)]}}但是对于新的 average_grade 方法来说，处理上述数据记录的代码就比较难以理解了。 把嵌套结构重构为类用来保存程序状态的数据结构一旦过于复杂（如包含多层嵌套），则应该将其拆解为类，提供更为明确的接口，同时更好的封装数据。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657from collections import namedtupleGrade = namedtuple('Grade', ('score', 'weight'))# 科目类。_grades 属性用于保存带权重的分数（Grade()）对象# average_grade 方法用于按权重计算本科成绩的平均分class Subject(object): def __init__(self): self._grades = [] def report_grade(self, score, weight): self._grades.append(Grade(score, weight)) def average_grade(self): total, total_weight = 0, 0 for grade in self._grades: total += grade.score * grade.weight total_weight += grade.weight return total / total_weight# 学生类。_subjects 属性用于保存该学生的所有科目（Subject()）对象# average_grade 方法用于计算该学生所有科目成绩的平均分class Student(object): def __init__(self): self._subjects = &#123;&#125; def subject(self, name): if name not in self._subjects: self._subjects[name] = Subject() return self._subjects[name] def average_grade(self): total, count = 0, 0 for subject in self._subjects.values(): total += subject.average_grade() count += 1 return total / count# 成绩单类。_students 属性保存所有的学生（Student()）对象class Gradebook(object): def __init__(self): self._students = &#123;&#125; def student(self, name): if name not in self._students: self._students[name] = Student() return self._students[name]book = Gradebook()albert = book.student('Albert Einstein')math = albert.subject('Math')math.report_grade(80, 0.4)math.report_grade(90, 0.6)print(albert.average_grade())# =&gt; 86.0 要点 尽量不使用多层嵌套的字典（如包含其他字典的字典）存储程序状态，也不要使用过长的元组 容器中包含简单又不可变的数据，可以先使用 namedtuple 表示，有需要时再改为完整的类 用于保存程序内部状态的字典若过于复杂，应将其拆解为多个辅助类 二、用 super 初始化父类初始化父类的传统方式，是在子类里直接调用父类的 __init__ 方法：1234567class MyBaseClass(object): def __init__(self, value): self.value = valueclass MyChildClass(MyBaseClass): def __init__(self): MyBaseClass.__init__(self, 5) 上述方法对于简单的继承行为是可行的，但是很多情况下仍会出现问题。首先若子类受到多重继承的影响，则直接调用父类的 __init__ 方法会产生无法预知的行为（调用顺序不确定）。1234567891011121314151617181920212223242526272829class MyBaseClass(object): def __init__(self, value): self.value = valueclass TimesTwo(object): def __init__(self): self.value *= 2class PlusFive(object): def __init__(self): self.value += 5class OneWay(MyBaseClass, TimesTwo, PlusFive): def __init__(self, value): MyBaseClass.__init__(self, value) TimesTwo.__init__(self) PlusFive.__init__(self)class AnotherWay(MyBaseClass, TimesTwo, PlusFive): def __init__(self, value): MyBaseClass.__init__(self, value) PlusFive.__init__(self) TimesTwo.__init__(self)foo = OneWay(5)print(f"First ordering is (5 * 2) + 5 = &#123;foo.value&#125;")bar = AnotherWay(5)print(f"Second ordering still is &#123;foo.value&#125;") OneWay 与 AnotherWay 中定义了两种完全不同的调用父类 __init__ 方法的顺序，但实际执行的结果却是相同的，导致子类代码中定义的调用顺序与子类实际产生的行为不一致。 此外在菱形继承中，直接调用父类的构造器也会出现问题。菱形继承是指子类继承自两个单独的超类，而这两个父类又都继承自同一个公共基类。这种继承方式会使菱形顶部的公共基类多次执行其 __init__ 方法，产生意想不到的行为。12345678910111213141516171819202122class MyBaseClass(object): def __init__(self, value): self.value = valueclass TimesFive(MyBaseClass): def __init__(self, value): MyBaseClass.__init__(self, value) self.value *= 5class PlusTwo(MyBaseClass): def __init__(self, value): MyBaseClass.__init__(self, value) self.value += 2class ThisWay(TimesFive, PlusTwo): def __init__(self, value): TimesFive.__init__(self, value) PlusTwo.__init__(self, value)foo = ThisWay(5)print(f"Should be (5 * 5) + 2 = 27 but actully is &#123;foo.value&#125;")# =&gt; Should be (5 * 5) + 2 = 27 but actully is 7 最终结果为 7，原因是在调用第二个父类的构造器（即 PlusTwo.__init__）时，公共基类的构造器（即 MyBaseClass.__init__）会再次被调用导致 value 重新变成 5，而不能保持 TimesFive.__init__ 之后的 25。 通过 super 调用父类的构造器：123456789101112131415161718192021class MyBaseClass(object): def __init__(self, value): self.value = valueclass TimesFive(MyBaseClass): def __init__(self, value): super(__class__, self).__init__(value) self.value *= 5class PlusTwo(MyBaseClass): def __init__(self, value): super(__class__, self).__init__(value) self.value += 2class ThisWay(TimesFive, PlusTwo): def __init__(self, value): super(__class__, self).__init__(value)foo = ThisWay(5)print(f"Should be (5 * 5) + 2 = 27 but actully is &#123;foo.value&#125;")# =&gt; Should be (5 * 5) + 2 = 27 but actully is 35 此时程序的行为可以说和预期相符合了，注意后三个类中 super 的使用。其中传入 super 的第一个参数 __class__ 用来指代当前类本身。 三、只在使用 Mix-in 制作工具类时进行多重继承应在 Python 编程中尽量避开多重继承。若一定要利用多重继承带来的便捷及封装性，应考虑编写 mix-in 类。mix-in 是一种“小型”类，其中只定义了其他类可能需要提供的一套附加方法，但是不定义自身的实例属性，也不要求继承者调用自己的 __init__ 构造器。 可以在 mix-in 里面通过动态检测机制编写一套通用的功能代码，根据对各类对象当前状态的判定，确定代码实际的行为。从而将 mix-in 应用到多个不同的类上面。分层地组合 mix-in 类可以减少重复代码并提升代码复用程度。如需要将内存中的 Python 对象转换为字典结构（即通常所说的序列化操作），可以创建下面的 mix-in 类实现此功能并添加 public 方法供其他类继承。重点在于通过 hasattr 动态地访问实例的属性、用 isinstance 动态地检测对象类型、用 __dict__ 访问实例内部的字典。12345678910111213141516171819202122232425262728293031323334353637# todict.pyclass ToDictMixin(object): def to_dict(self): return self._traverse_dict(self.__dict__) def _traverse_dict(self, instance_dict): output = &#123;&#125; for key, value in instance_dict.items(): output[key] = self._traverse(key, value) return output def _traverse(self, key, value): if isinstance(value, ToDictMixin): return value.to_dict() elif isinstance(value, dict): return self._traverse_dict(value) elif isinstance(value, list): return [self._traverse(key, i) for i in value] elif hasattr(value, '__dict__'): return self._traverse_dict(value.__dict__) else: return value# 利用 mix-in 将二叉树表示为字典class BinaryTree(ToDictMixin): def __init__(self, value, left=None, right=None): self.value = value self.left = left self.right = rightif __name__ == '__main__': tree = BinaryTree(10, left=BinaryTree(7, right=BinaryTree(9)), right=BinaryTree(13, left=BinaryTree(11))) print(tree.to_dict())# =&gt; &#123;'value': 10, 'left': &#123;'value': 7, 'left': None, 'right': &#123;'value': 9, 'left': None, 'right': None&#125;&#125;, 'right': &#123;'value': 13, 'left': &#123;'value': 11, 'left': None, 'right': None&#125;, 'right': None&#125;&#125; mix-in 最大的优势在于，可以随时向基类中添加额外的通用功能，并且在必要时覆盖重写某些方法。多个 mix-in 之间也可以相互组合。在前面 todict.py 代码的基础上，可以再定义一个 JsonMixin 用来为任意类提供通用的 JSON 序列化功能。JsonMixin 的定义代码决定了继承自它的类需要包含 to_dict 方法（比如可以从 ToDictMixin 中继承），且其 __init__ 方法接受关键字参数：123456789101112131415161718192021222324252627282930313233343536373839404142import jsonfrom todict import ToDictMixinclass JsonMixin(object): @classmethod def from_json(cls, data): kwargs = json.loads(data) return cls(**kwargs) def to_json(self): return json.dumps(self.to_dict())class DatacenterRack(ToDictMixin, JsonMixin): def __init__(self, switch=None, machines=None): self.switch = Switch(**switch) self.machines = [ Machine(**kwargs) for kwargs in machines ]class Switch(ToDictMixin, JsonMixin): def __init__(self, ports=None, speed=None): self.ports = ports self.speed = speedclass Machine(ToDictMixin, JsonMixin): def __init__(self, cores=None, ram=None, disk=None): self.cores = cores self.ram = ram self.disk = diskserialized = """&#123; "switch": &#123;"ports": 5, "speed": 1e9&#125;, "machines": [ &#123;"cores": 8, "ram": 32e9, "disk": 5e12&#125;, &#123;"cores": 4, "ram": 16e9, "disk": 1e12&#125;, &#123;"cores": 2, "ram": 4e9, "disk": 500e9&#125; ]&#125;"""deserialized = DatacenterRack.from_json(serialized)roundtrip = deserialized.to_json()assert json.loads(serialized) == json.loads(roundtrip) ToDictMixin 和 ToJsonMixin 两个 mix-in 中分别定义了不同的通用功能组件，符合规范的多重继承下的子类则可以直接使用这两者提供的 to_dict 和 to_json 方法，达到功能整合的效果。 要点 能用 mix-in 组件实现的效果，就不用多重继承来做 将各功能实现为可插拔的 mix-in 组件，让子类选择继承需要的组件 简单行为封装到 mix-in 组件里，多个 mix-in 组合成复杂行为 四、多使用 public 属性Python 类的属性有 public 和 private 两种，任何人都可以在对象上通过 dot 操作符（.）访问 public 属性。private 属性是名称中以两个下划线开头的属性，可以被当前类中的方法访问。但从类外部直接访问 private 属性会报 AttributeError 异常。12345678910111213141516class MyObject(object): def __init__(self): self.public_field = 5 self.__private_field = 10 def get_private_field(self): return self.__private_fieldfoo = MyObject()print(foo.public_field)# =&gt; 5print(foo.get_private_field())# =&gt; 10print(foo.__private_field)# =&gt; AttributeError: 'MyObject' object has no attribute '__private_field' 类方法可以访问当前类的私有属性。子类无法访问父类的私有字段。1234567891011121314151617181920class MyObject(object): def __init__(self): self.__private_field = 71 @classmethod def get_private_field(cls, instance): return instance.__private_fieldclass MyChildObject(MyObject): def get_private_field(self): return self.__private_fieldbar = MyObject()print(MyObject.get_private_field(bar))# =&gt; 71bar_child = MyChildObject()print(bar_child.get_private_field())# =&gt; AttributeError: 'MyChildObject' object has no attribute '_MyChildObject__private_field' Python 会对私有属性的名称做一些简单的变换，这种变换导致了私有属性对类外部不可见，同时子类也无法访问父类的私有属性。也就是说，Python 并没有从语法上严格保证 private 字段的私密性。在子类的继承体系发生变化时，对 private 字段的引用很容易失效，从而导致子类出现错误。 为了尽量减少无意义的访问内部属性导致的意外，Python 习惯用单下划线开头的字段表示受保护（protected）字段，当前类之外的代码使用这些字段时应格外注意。一般来说，宁可让子类更多地访问父类的 protected 属性，也尽量不要把这些属性设置成 private。并且应该在文档中说明每个 protected 字段的含义，在扩展代码时如何保证数据安全。123456class MyClass(object): def __init__(self, value): # This stores the user-supplied value for the object. # It should be coercible to a string. Once assigned for # the object it should be treated as immutable. self._value = value 要点 Python 编译器无法严格保证 private 字段的私密性 应多使用 protected 属性，并将合理用法在文档中说明 只有子类不受自己控制时，为避免命名冲突才考虑使用 private 属性 五、继承 collections.abc 以实现自定义的容器类型大部分的 Python 编程都是在定义类，类可以包含数据且能够描述数据与对象之间的交互方式。Python 中的类从某种程度上说都是封装了属性与功能容器。 如果要设计功能比较简单的序列，可以直接继承 Python 内置的 list 类型。如创建一种可以统计各元素出现频率的自定义列表：12345678910111213141516class FrequencyList(list): def __init__(self, members): super().__init__(members) def frequency(self): counts = &#123;&#125; for item in self: counts.setdefault(item, 0) counts[item] += 1 return countsfoo = FrequencyList(['a', 'b', 'a', 'c', 'b', 'a', 'd'])print(f'Length is &#123;len(foo)&#125;')print(f'Frequency: ', foo.frequency())# =&gt; Length is 7# =&gt; Frequency: &#123;'a': 3, 'b': 2, 'c': 1, 'd': 1&#125; 假设某对象本身并不是 list 类型的子类，但是需要它表现得像 list 一样，可以通过下标访问其元素。Python 用一些名称比较特殊的实例方法来实现与容器有关的行为。如需要用下标访问序列中的元素，可以考虑实现序列对象的 __getitem__ 方法：12345&gt;&gt;&gt; bar = [1, 2, 3]&gt;&gt;&gt; bar[0]1&gt;&gt;&gt; bar.__getitem__(0)1 如下面的二叉树类实现了 __getitem__ 方法，使得不仅可以按深度优先的次序遍历（_traverse()）二叉树中的对象，还可以通过下标访问：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253# binarynode.pyclass BinaryNode(object): def __init__(self, value, left=None, right=None): self.value = value self.left = left self.right = rightclass IndexableNode(BinaryNode): def _traverse(self): if self.left is not None: yield from self.left._traverse() yield self if self.right is not None: yield from self.right._traverse() def __getitem__(self, index): for i, item in enumerate(self._traverse()): if i == index: return item.value raise IndexError(f'Index &#123;index&#125; is out of range')class SequenceNode(IndexableNode): def __len__(self): for count, _ in enumerate(self._traverse(), 1): pass return countif __name__ == '__main__': tree = SequenceNode( 10, left=SequenceNode( 5, left=SequenceNode(2), right=SequenceNode( 6, right=SequenceNode(7))), right=SequenceNode( 15, left=SequenceNode(11))) print('LRR is', tree.left.right.right.value) # =&gt; LRR is 7 print('Index 0 is', tree[0]) # =&gt; Index 0 is 2 print('11 in the tree?', 11 in tree) # =&gt; 11 in the tree? True print('Tree is', list(tree)) # =&gt; Tree is [2, 5, 6, 7, 10, 11, 15] print('Tree length is', len(tree)) # =&gt; Tree length is 7 为了使序列可以通过内置的 len() 函数获取长度，SequenceNode 类中还实现了 __len__ 方法。而更多的功能就意味着需要额外实现更多的特殊方法。为了避免这些麻烦，可以使用内置的 collections.abc 模块。此模块定义了一系列抽象基类，提供了每一种容器类型所应具备的常用方法。继承这样的基类，如果忘记实现某个方法，collections.abc 模块会报错；如果实现了抽象基类要求的每一个方法，则基类会自动实现剩下的所有方法。1234567891011121314151617181920212223from binarynode import SequenceNodefrom collections.abc import Sequenceclass BetterNode(SequenceNode, Sequence): passtree = BetterNode( 10, left=BetterNode( 5, left=BetterNode(2), right=BetterNode( 6, right=BetterNode(7))), right=BetterNode( 15, left=BetterNode(11)))print('Index of 7 is', tree.index(7))# =&gt; Index of 7 is 3print('Count of 10 is', tree.count(10))# =&gt; Count of 10 is 1 SequenceNode 中已经实现了 Sequence 要求的 __getitem__ 和 __len__ 方法，因此 Sequence 基类为继承的 BetterNode 子类自动实现了 index() 和 count() 方法。 要点 如自定义的容器子类比较简单，可直接继承 Python 内置的容器类型（如 list、dict 等） 正确实现自定义容器类型可能需要编写大量的特殊方法 编写自定义容器类型时，可以从 collections.abc 模块中的抽象基类继承，这些基类能保证子类具备统一的接口及行为 参考资料Effective Python]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Advanced</tag>
        <tag>Python</tag>
        <tag>Class</tag>
        <tag>OOP</tag>
        <tag>Inherit</tag>
        <tag>Effective</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python3 中作为一等对象的函数]]></title>
    <url>%2F2019%2F12%2F10%2Ffirst-class-function-python-3-functional-programming%2F</url>
    <content type="text"><![CDATA[在 Python 语言中，函数与整数、字符串、字典等基本数据类型一样，都是一等对象。所谓一等对象，即满足如下三个条件： 在运行时创建 能赋值给变量 能作为函数的参数或返回值 以下 IDLE 中的代码即在运行时创建了函数 factorial：1234567891011121314151617&gt;&gt;&gt; def factorial(n):... '''calculates n!'''... return 1 if n &lt; 2 else n * factorial(n-1)...&gt;&gt;&gt; factorial(5)120&gt;&gt;&gt; factorial.__doc__'calculates n!'&gt;&gt;&gt; type(factorial)&lt;class 'function'&gt;&gt;&gt;&gt; fact = factorial&gt;&gt;&gt; fact&lt;function factorial at 0x7f55bc771c10&gt;&gt;&gt;&gt; fact(5)120&gt;&gt;&gt; list(map(fact, range(10)))[1, 1, 2, 6, 24, 120, 720, 5040, 40320, 362880] 从输出中可以看出，factorial 是 function 类的实例对象，__doc__ 是 factorial 对象众多属性中的一个。可以把 factorial 函数赋值给变量 fact，通过 fact 变量调用 factorial 函数。还可以把 factorial 作为参数传递给 map 函数。这些行为表现了函数作为一等对象的特性。 一、高阶函数接受函数作为参数，或者把函数作为返回值的函数即为高阶函数。如内置用于排序的 sorted 函数，它的 key 参数用于传入一个函数，在需要排序的每个元素上执行特定的操作。如根据单词长度对多个字符串进行排序：123&gt;&gt;&gt; fruits = ['strawberry', 'fig', 'apple', 'cherry', 'raspberry', 'banana']&gt;&gt;&gt; sorted(fruits, key=len)['fig', 'apple', 'cherry', 'banana', 'raspberry', 'strawberry'] 任何单参数的函数都可以作为 key 的值传给 sorted 函数，如把单词反向拼写作为排序条件：1234567&gt;&gt;&gt; def reverse(word):... return word[::-1]...&gt;&gt;&gt; reverse('test')'tset'&gt;&gt;&gt; sorted(fruits, key=reverse)['banana', 'apple', 'fig', 'raspberry', 'strawberry', 'cherry'] map、filter 与 reduce函数式编程语言通常会提供 map、filter 和 reduce 三个高阶函数或者实现了类似功能的函数。Python3 中的列表推导和生成器即具有 map 和 filter 函数的功能。参考如下示例：1234567891011&gt;&gt;&gt; def fact(n):... return 1 if n &lt; 2 else n * fact(n-1)...&gt;&gt;&gt; list(map(fact, range(6)))[1, 1, 2, 6, 24, 120]&gt;&gt;&gt; [fact(n) for n in range(6)][1, 1, 2, 6, 24, 120]&gt;&gt;&gt; list(map(fact, filter(lambda n: n % 2, range(6))))[1, 6, 120]&gt;&gt;&gt; [fact(n) for n in range(6) if n % 2][1, 6, 120] 通过列表推导可以完成与 map 或 filter 函数类似的工作，且可读性更高，也避免了使用 lambda 表达式。 reduce 在 Python2 中是内置函数，但在 Python3 中被移到了 functools 模块中。reduce 可以把某个操作连续地应用到某个序列上，累计所有的结果，把产生的一系列值规约成一个值。因此常用于求和计算，但内置的 sum 函数在可读性和性能方面更优。123456&gt;&gt;&gt; from functools import reduce&gt;&gt;&gt; from operator import add&gt;&gt;&gt; reduce(add, range(101))5050&gt;&gt;&gt; sum(range(101))5050 二、匿名函数可以使用 lambda 关键字在 Python 表达式内创建匿名函数。在函数的参数列表中最适合使用匿名函数。如前面的根据字符串反序后的结果对单词列表进行排序，可以使用 lambda 匿名函数替代传入 sorted 的 reverse 函数：123&gt;&gt;&gt; fruits = ['strawberry', 'fig', 'apple', 'cherry', 'raspberry', 'banana']&gt;&gt;&gt; sorted(fruits, key=lambda word: word[::-1])['banana', 'apple', 'fig', 'raspberry', 'strawberry', 'cherry'] lambda 表达式 lambda words: words[::-1] 即等同于之前的 reverse 函数：12def reverse(word): return word[::-1] 除了作为参数传给某个高阶函数外，Python 很少使用匿名函数。 三、可调用对象除了用户自定义的函数，其他可调用对象也可以使用调用运算符（即 ()）。Python 的数据模型中共包含 7 种可调用对象： 用户自定义函数：使用 def 语句或 lambda 表达式创建的函数 内置函数：由 C 语言（CPython）实现的函数，如 len 或 time.strftime 等 内置方法：使用 C 语言实现的方法，如 dict.get 方法：在类的定义体中定义的函数 类：类在调用时会使用 __new__ 方法创建实例，然后运行 __init__ 初始化实例，最后将实例返回给调用方。调用类相当于调用函数。 类的实例：如果类的定义中实现了 __call__ 方法，则其实例可以作为函数调用 生成器：使用 yield 关键字的函数或方法。可以返回生成器对象。 使用内置的 callable() 函数可以确认对象是否可调用。 任何 Python 对象都可以表现得像函数，只需实现该实例的 __call__ 方法。如下面的 bingocall.py，从列表中随机取出一个元素：123456789101112131415161718192021222324import randomclass BingoCage: def __init__(self, items): self._items = list(items) random.shuffle(self._items) def pick(self): try: return self._items.pop() except IndexError: raise LookupError('pick from empty BingoCage') def __call__(self): return self.pick()bingo = BingoCage(range(50))print(bingo.pick())# =&gt; 38print(bingo())# =&gt; 22print(callable(bingo))# =&gt; True bingo 是 BingoCage 类的一个实例，由于 BingoCage 类中实现了 __call__ 方法，则 bingo 对象是可调用的（bingo()）。 四、支持函数式编程的模块operator在函数式编程中，经常需要将算术运算符当作函数使用。如不使用递归计算阶乘。 使用 reduce 和 lambda 表达式计算阶乘：123456&gt;&gt;&gt; from functools import reduce&gt;&gt;&gt; def fact(n):... return reduce(lambda a, b: a*b, range(1, n+1))...&gt;&gt;&gt; fact(5)120 Python 中的 operator 为多个运算符提供了对应的函数，可以避免写 lambda a, b: a*b 这种匿名函数。使用 reduce 和 operator.mul 计算阶乘：1234567&gt;&gt;&gt; from operator import mul&gt;&gt;&gt; from functools import reduce&gt;&gt;&gt; def fact(n):... return reduce(mul, range(1, n+1))...&gt;&gt;&gt; fact(5)120 operator 模块中还有一类 itemgetter 和 attrgetter 函数，可以替代从序列中取出元素或读取属性的 lambda 表达式。如根据元组中的第二个元素对多个元组进行排序：12345678910111213141516&gt;&gt;&gt; metro_data = [... ('Tokyo', 'JP', 36.933, (35.689722, 139.691667)),... ('Delhi NCR', 'IN', 21.935, (28.613889, 77.208889)),... ('Mexico City', 'MX', 20.142, (19.433333, -99.133333)),... ('New York-Newark', 'US', 20.104, (40.808611, -74.020386)),... ('Sao Paulo', 'BR', 19.649, (-23.547778, -46.635833)),... ]&gt;&gt;&gt; from operator import itemgetter&gt;&gt;&gt; for city in sorted(metro_data, key=itemgetter(1)):... print(city)...('Sao Paulo', 'BR', 19.649, (-23.547778, -46.635833))('Delhi NCR', 'IN', 21.935, (28.613889, 77.208889))('Tokyo', 'JP', 36.933, (35.689722, 139.691667))('Mexico City', 'MX', 20.142, (19.433333, -99.133333))('New York-Newark', 'US', 20.104, (40.808611, -74.020386)) 如果把多个参数传递给 itemgetter，则该函数会返回由提取的值构成的元组：123456789&gt;&gt;&gt; cc_name = itemgetter(1, 0)&gt;&gt;&gt; for city in metro_data:... print(cc_name(city))...('JP', 'Tokyo')('IN', 'Delhi NCR')('MX', 'Mexico City')('US', 'New York-Newark')('BR', 'Sao Paulo') attrgetter 与 itemgetter 作用类似，可以根据名称提取对象的属性。 operator 模块中还有一个 methodcaller 函数，可以用来在某个对象上调用由参数指定的方法。12345678&gt;&gt;&gt; from operator import methodcaller&gt;&gt;&gt; s = 'The time has come'&gt;&gt;&gt; upcase = methodcaller('upper')&gt;&gt;&gt; upcase(s)'THE TIME HAS COME'&gt;&gt;&gt; hiphenate = methodcaller('replace', ' ', '-')&gt;&gt;&gt; hiphenate(s)'The-time-has-come' functools.partial高阶函数 functools.partial 用来部分应用某个函数。即基于某个函数创建一个新的可调用对象，并把原函数的某些参数固定。 如使用 partial 把一个接受双参数的函数改编成单参数的可调用对象：1234567&gt;&gt;&gt; from operator import mul&gt;&gt;&gt; from functools import partial&gt;&gt;&gt; triple = partial(mul, 3)&gt;&gt;&gt; triple(7)21&gt;&gt;&gt; list(map(triple, range(1, 10)))[3, 6, 9, 12, 15, 18, 21, 24, 27] partial() 函数返回一个 functools.partial 对象，该对象提供对原函数的访问和固定原函数参数的行为。123456789&gt;&gt;&gt; def greeting(words, name):... return f'&#123;words&#125;, &#123;name&#125;!'...&gt;&gt;&gt; from functools import partial&gt;&gt;&gt; greeting2 = partial(greeting, name='skitar')&gt;&gt;&gt; greeting2("what's up")"what's up, skitar!"&gt;&gt;&gt; greeting2functools.partial(&lt;function greeting at 0x7f70f31788b0&gt;, name='skitar') 参考资料Fluent Python]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Functional</tag>
        <tag>Function</tag>
        <tag>Advanced</tag>
        <tag>Python</tag>
        <tag>Lambda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang 基本语法速查——变量、控制结构与函数]]></title>
    <url>%2F2019%2F12%2F10%2Fgo-basic-syntax-variable-control-structure-function%2F</url>
    <content type="text"><![CDATA[一、基本结构hello world 程序：1234567package mainimport "fmt"func main()&#123; fmt.Println("你好，世界")&#125; 直接运行：12$ go run hello.go你好，世界 构建可执行程序：123$ go build hello.go$ ./hello你好，世界 PS Package 用于组织代码架构，类似于其他语言中的库或命名空间 每个 go 源文件都必须属于（且只属于一个）特定的 package，一个 package 可以包含多个 go 代码文件 import 导入某个 package ，意味着获取了该 package 中可见对象的访问权限 import 导入的 package 未在后面的代码中使用会报错，no unnecessary code! 原则 main 函数没有任何参数且不返回任何值，它通常作为程序执行的入口 导入多个包：1234import ( "fmt" "os") 二、变量变量定义和赋值：var identifier [type] = value12345var a intvar b boolvar str string = "hello"var i = 5GOROOT := os.Getenv("GOROOT") PS b := false 等同于 var b = false 。借助 Go 语言的类型推断可以省略类型声明 := 或者 var 形式的变量赋值，包含变量初始化动作。即 a = 1 表示将 1 赋值给变量 a（a 必须已经创建），a := 1 表示新建变量 a，并将 1 赋值给 a。 使用未定义的变量，定义的本地变量未在后续代码中使用，新建变量的名称已存在等都会报错 推荐使用 := 的形式，但只应该在函数内部使用 三、字符串连接字符串，+：123s := "hel" + "lo"s += " world"fmt.Println(s) // prints out "hello world" 前缀匹配：strings.HasPrefix(s, prefix string) bool 后缀匹配：strings.HasSuffix(s, suffix string) bool 包含关系：strings.Contains(s, substr string) bool 字符串替换：strings.Replace(str, old, new, n) string 计算子字符串出现次数：strings.Count(s, str string) int 分割字符串：strings.Split(s, sep string) []string join 字符串：strings.join(sl []string, sep string) string 示例代码：123456789101112131415161718192021222324package mainimport ( "fmt" "strings")func main() &#123; str := "The quick brown fox jumps over the lazy dog" sl := strings.Split(str, " ") fmt.Printf("Splitted in slice: %v\n", sl) // 字符串分割后的返回值 sl 是数组 for _, val := range sl &#123; fmt.Printf("%s,", val) &#125; fmt.Println() str2 := strings.Join(sl, "/") fmt.Printf("sl joined by / is: %s\n", str2)&#125;// output// Splitted in slice: [The quick brown fox jumps over the lazy dog]// The,quick,brown,fox,jumps,over,the,lazy,dog,// sl joined by / is: The/quick/brown/fox/jumps/over/the/lazy/dog 四、控制结构if-elseif-else 结构语法如下：1234567if condition1 &#123; // do something&#125; else if condition2 &#123; // do something&#125; else &#123; // catch-all or default&#125; PS：else 旁边的 } 和 { 不能隔行，否则无法编译通过。 switch12345678switch var1 &#123;case val1: // do somethingcase val2: // do somethingdefault: // catch-all or default&#125; 12345678switch &#123;case condition1: // do somethingcase condition2: // do somethingdefault: // catch-all or default&#125; 12345678switch initialization &#123;case val1: // do somethingcase val2: // do somethingdefault: // catch-all or default&#125; 示例代码：123456789101112131415161718192021222324package mainimport ( "fmt")func Abs(x int) int &#123; if x &lt; 0 &#123; return -x &#125; return x&#125;func main() &#123; switch num := Abs(-5); &#123; case num &gt; 0: fmt.Println("Result is positive") case num &lt; 0: fmt.Println("Never gonna happen") default: fmt.Println("Exact 0") &#125;&#125;// Result is positive for参考如下示例：1234567891011121314151617package mainimport ( "fmt")func main() &#123; str := "Go is a beautiful language" for ix :=0; ix &lt; len(str); ix ++ &#123; fmt.Printf("Character on position %d is: %c \n", ix, str[ix]) &#125; for pos, char := range str &#123; fmt.Printf("Character on position %d is: %c \n", pos, char) &#125;&#125; 五、函数定义函数语法：12func g() &#123;&#125; 注意不能写成如下形式：123func g()&#123;&#125; 函数调用语法：pack1.Function(arg1,arg2, ... ,argn) Go 中的函数可以接收另一个函数作为参数，比如有下面两个函数：f1(a, b, c int) 接收三个参数f2(a, b int) (int, int, int) 有两个参数和三个返回值则可以这样调用：f1(f2(a, b)) 函数本身可以赋值给变量，如 add := binOp 参数与返回值Go 中的函数可以接收 0 个或多个参数，返回 0 个或多个结果。传给函数的参数通常会有名称，但是也可以没有名称只包含类型：func f(int, int, float64) Go 函数的传参默认是按值传递，即实际传给函数的是参数值的复制。如调用 Function(arg1)，函数 Function 收到的是 arg1 指向的值的副本，而不是 arg1 本身。如果需要函数操作传入的参数本身，即 Function(arg1) 操作 arg1 本体的值，则需要传入参数的指针（内存地址）。使用如下形式：Function(&amp;arg1)。 大部分函数都需要返回值，可以是命名的也可以不命名。 数量未知的参数函数的最后一个参数可以是 ...type 这样的形式，即 func myFunc(a, b, arg ...int) {} 。这表示函数可以接收相同类型的不定数量的参数。参考如下示例：1234567891011121314151617181920212223242526272829package mainimport ( "fmt")func main() &#123; x := Min(1, 3, 2, 0) fmt.Printf("The minimum is: %d\n", x) arr := []int&#123;7, 9, 3, 5, 1&#125; x = Min(arr...) fmt.Printf("The minimum in the array arr is: %d", x)&#125;func Min(a ...int) int &#123; if len(a) == 0 &#123; return 0 &#125; min := a[0] for _, v := range a &#123; if v &lt; min &#123; min = v &#125; &#125; return min&#125;// The minimum is: 0// The minimum in the array arr is: 1 Deferdefer 关键字用于“延迟”执行某个函数或命令，由 defer 修饰的语句会在外部函数返回结果之后再执行。123456789101112131415161718package mainimport ( "fmt")func main() &#123; fmt.Printf("In Main function at the top\n") defer Function2() fmt.Printf("In Main function at the bottom\n")&#125;func Function2() &#123; fmt.Printf("Function2: Deferred until the end of the calling function")&#125;// In Main function at the top// In Main function at the bottom// Function2: Deferred until the end of the calling function% 如果 defer 语句中包含变量参数，则该参数的值在 defer 的位置已经确定。参考如下代码：1234567891011121314package mainimport ( "fmt")func main() &#123; i := 0 defer fmt.Println(i) i++ fmt.Println("The number is:")&#125;// The number is:// 0 由 defer 修饰的 Println 函数虽然在程序执行流的最后输出 i 值。但变量 i 在 defer 处的值为 0，因此最后输出 0 而不是执行 i++ 后的 1 。 当代码中包含有多个 defer 语句时，这些语句会以 LIFO（后进先出，类似 stack）的顺序执行。123456789101112package mainimport ( "fmt")func main() &#123; for i := 0; i &lt; 5; i++ &#123; defer fmt.Printf("%d", i) &#125;&#125;// 43210 递归函数12345678910111213141516171819202122package mainimport ( "fmt")func main() &#123; result := 0 for i := 0; i &lt;= 10; i++ &#123; result = fibonacci(i) fmt.Printf("fibonacci(%d) is: %d\n", i, result) &#125;&#125;func fibonacci(n int) (res int) &#123; if n &lt;= 1 &#123; res = 1 &#125; else &#123; res = fibonacci(n-1) + fibonacci(n-2) &#125; return&#125; 高阶函数函数作为参数12345678910111213141516package mainimport "fmt"func main() &#123; callback(1, Add)&#125;func Add(a, b int) &#123; fmt.Printf("The sum of %d and %d is: %d\n", a, b, a+b)&#125;func callback(y int, f func(int, int)) &#123; f(y, 2)&#125;// =&gt; The sum of 1 and 2 is: 3 （匿名）函数赋值给变量123456789101112131415package mainimport "fmt"func main() &#123; for i := 0; i &lt; 4; i++ &#123; g := func(i int) &#123; fmt.Printf("%d", i) &#125; g(i) fmt.Printf(" - g is of type %T and has value %v\n", g, g) &#125;&#125;// =&gt; 0 - g is of type func(int) and has value 0x4839d0// =&gt; 1 - g is of type func(int) and has value 0x4839d0// =&gt; 2 - g is of type func(int) and has value 0x4839d0// =&gt; 3 - g is of type func(int) and has value 0x4839d0 函数作为返回值12345678910111213141516171819202122232425package mainimport "fmt"func main() &#123; p2 := Add2() fmt.Printf("Call Add2 for 3 returns: %v\n", p2(3)) TwoAdder := Adder(2) fmt.Printf("The result is: %v\n", TwoAdder(3))&#125;func Add2() func(b int) int &#123; return func(b int) int &#123; return b + 2 &#125;&#125;func Adder(a int) func(b int) int &#123; return func(b int) int &#123; return a + b &#125;&#125;// =&gt; Call Add2 for 3 returns: 5// =&gt; The result is: 5 另一个版本的累加器，涉及到闭包：12345678910111213141516171819package mainimport "fmt"func main() &#123; f := Adder() fmt.Print(f(1), " - ") fmt.Print(f(20), " - ") fmt.Print(f(300))&#125;func Adder() func(int) int &#123; var x int return func(delta int) int &#123; x += delta return x &#125;&#125;// =&gt; 1 - 21 - 321 参考资料The Way To Go: A Thorough Introduction To The Go Programming Language]]></content>
      <categories>
        <category>Golang</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Golang</tag>
        <tag>Go</tag>
        <tag>Basic</tag>
        <tag>Code</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vim 进阶——按键映射与 VimScript 脚本编程]]></title>
    <url>%2F2019%2F12%2F10%2Fvim-key-binding-and-vimscript-programming%2F</url>
    <content type="text"><![CDATA[一、按键映射Vim 中的快捷键绑定可以通过以下命令配置： :imap：只在 Insert 模式下生效的快捷键 :cmap：只在 Command-line 模式下生效 :nmap：只在 Normal 模式下生效 :vmap：只在 Visual 模式下生效 :map：在以上所有模式下生效 :noremap：包含 :inoremap、:nnoremap 等，非递归映射 PS：关于递归映射，如 :map a b，:map b c。根据按键映射之间的传递，则有 a -&gt; c 的关系。而 nore 则用于禁止这种递归行为。 做快捷键映射时，各功能按键在 Vim 中的名称如下： 名称 对应按键 &lt;BS&gt; 退格键 &lt;Tab&gt; 制表键 &lt;CR&gt;或&lt;Enter&gt;或&lt;Return&gt; 回车 &lt;Esc&gt; Escape &lt;Space&gt; 空格键 &lt;Up&gt; 上方向键 &lt;Down&gt; 下方向键 &lt;Left&gt; 左方向键 &lt;Right&gt; 右方向键 &lt;F1&gt; - &lt;F12&gt; 功能键 F1 到 F12 #1, #2..#9,#0 F1 到 F10 &lt;Insert&gt; Insert &lt;Del&gt; Delete &lt;Home&gt; Home &lt;End&gt; End &lt;PageUp&gt; 上翻页 &lt;PageDown&gt; 下翻页 示例12345678" save file (ctrl-s):map &lt;C-s&gt; :w&lt;cr&gt;" copy selected text (ctrl-c):vmap &lt;C-c&gt; y" Paste clipboard contents (ctrl-v):imap &lt;C-v&gt; &lt;esc&gt;P" cut selected text (ctrl-x):vmap &lt;C-x&gt; x :map &lt;C-s&gt; :w&lt;cr&gt; 表示将 Ctrl+S 组合键映射为 :w&lt;cr&gt;（保存修改，写入文件）其中 &lt;C-s&gt; 在 Vim 中即表示 Ctrl+S，类似的用法还有 &lt;A-s&gt; （Alt+S）、&lt;M-s&gt; （Meta+S）、&lt;C-S-s&gt;（Ctrl+Shift+S）等。:w 后面的 &lt;cr&gt; 表示按下回车键。如命令最后没有加上 &lt;cr&gt;，则按下组合键 &lt;C-s&gt; 后只会将对应的 :w 输入到命令栏而不执行。 上面映射的保存文件功能还可以更加细化一些：:imap &lt;C-s&gt; &lt;esc&gt;:w&lt;cr&gt;a即该组合键适用于插入模式，按下 Ctrl+S 意味着会依照如下顺序执行命令： &lt;esc&gt;：退出插入模式 :w&lt;cr&gt;：将之前的修改写入文件 a：回到插入模式继续编辑文件 对于 Gvim 下的按键映射，还可以调出对话框完成 Open 和 save-as 功能：1234"Open new file dialog (ctrl-n):map &lt;C-n&gt; :browse confirm e&lt;cr&gt;"Open save-as dialog (ctrl-shift-s):map &lt;C-S-s&gt; :browse confirm saveas&lt;cr&gt; 对于依次按下多个按键的组合键，如：:map $1 :MyFunction1()&lt;cr&gt;当按下 $ 键后，Vim 会等待一秒钟，若一秒钟之内又按下了 1 键，则执行映射的 MyFunction1() 函数；若一秒钟之内没有任何按键按下，则执行 $ 键原本的功能（移动光标到行尾）。 二、Vim 脚本Vim 脚本是指用 VimScript 编写的为 Vim 添加自定义功能的单独的文件。如下面的 hello.vim 脚本：12345678" hello.vimfunction! SayHello() echo 'Hello, World!'endfunctioncommand! Hello call SayHello()nnoremap Q :Hello&lt;CR&gt; 其中 function! 用于定义 SayHello() 函数，command! 用于将调用该函数的行为绑定给 Hello 命令，nnoremap Q 则用于将 :Hello 命令的执行绑定给键盘上的 Q 按键。 在 Vim 中使用 :source 命令导入刚刚创建的脚本：:source hello.vim之后执行 :Hello 命令或者按下 Q 按键即可在命令栏输出 Hello, World! 字符串。 变量变量的赋值使用 :let 命令：1234:let mystring = "a string":let mynumber = 123:let mylist = [1, 2, "three", 0x04 ,["five", "six"]]:let mydict = &#123;1: "one", 2: "two", "others": &#123;3: "three", 4: "four"&#125;&#125; Vim 脚本中支持以下类型的变量： String：字符串，如 &quot;this is a string&quot; Number：数字，包含十进制（123）、十六进制（0x8A）和八进制（012） List：有序列表，列表项支持多种数据类型混合 Dictionary：字典，无序键值对 Funcref：函数引用 PS：不同进制的数字之间可以直接进行算术运算由单引号（&#39;）包裹的字符串不会转义 \n 等转义字符 关于字符串和数字之间的自动类型转换，参考以下规则： Input (type) Result (type) “hello” . “world” “hello world” (string) “number” . 123 “number 123” (string) “123” + 10 133 (number) “123” - 10 . “hits” “113 hits” (string) “123” - 10 + “hits” 113 (number) 变量作用域Vim 中变量的作用域通过不同的前缀来指定： v：Vim 预定义的全局作用域 g：全局变量前缀 b：Buffer 范围内生效的变量 t：Tab 范围内生效的变量 w：Window 范围内生效的变量 l：即 local，Function 范围内生效 s：即 source，通过 :source 载入的当前脚本内生效 a：即 argument，用来修饰函数的参数 当变量没有任何作用域前缀修饰时，默认为全局变量（除非该变量在函数内部定义）。 变量作用域前缀的使用参考如下脚本：1234567891011let g:sum = 10function SumNumbers(num1, num2) let l:sum = a:num1 + a:num2 if g:sum &lt; l:sum let g:sum = l:sum endif return l:sumendfunctionecho SumNumbers(3, 4)echo g:sum 条件语句Vim 脚本中的 if-else 语句语法格式如下：12345if condition1 code-to-execute-if-condition1-is-trueelseif condition2 code-to-execute-if-condition2-is-trueendif 其中判断条件 condition 可以有以下几种形式： val1 == val2 val1 != val2 val1 &gt; val1 val1 &lt; val2 val1 &lt;= val2 val1 &gt;= val2 str1 =~ str2 str1 !~ str2 字符串比较中的 str2 可以是某个模式，支持正则表达式。 if-else 语句的使用可以参考如下脚本，根据当前时间切换不同的配色：1234567891011121314151617" note addition of zero" this guarantees return from function is numericlet currentHour = strftime ("%H")echo "currentHour is " currentHourif currentHour &lt; 6 + 0 colorscheme darkblue echo "setting colorscheme to darkblue"elseif currentHour &lt; 12 + 0 colorscheme morning echo "setting colorscheme to morning"elseif currentHour &lt; 18 + 0 colorscheme shine echo "setting colorscheme to shine"else colorscheme evening echo "setting colorscheme to evening"endif 循环For 循环的语法格式如下：123for var in range do-somethingendfor 或123for var in list do-somthingendfor 代码示例12345678910111213141516" rangefor myvar in range(1,10) echo myvarendfor" listlet mylist = ['a','b','c','d','e','f','g','h','i','j','k']for itemvar in mylist echo itemvarendfor" dictionarylet mydict = &#123;"a": "apple", "b":"banana", "c": "citrus" &#125;for keyvar in keys(mydict) echo mydict[keyvar]endfor While 循环的语法格式：123while condition execute-this-codeendwhile 代码示例：12345let x=0while x &lt;= 5 echo "x is now " x let x+=1endwhile 列表与字典关于 Vim 中列表与字典的操作，可以参考如下代码：123456789101112131415161718192021222324252627282930let mylist = [1, 2, "three"]echo mylist[2]" =&gt; threelet mylist2 = [[1, 2, 3], ["four", "five", "six"]]echo mylist2[1][0]" =&gt; fourecho mylist2[0][-1]" =&gt; 3let mylist3 = [1, 2, 3, 4]call add(mylist3, [5, 6])echo mylist3" =&gt; [1, 2, 3, 4, [5, 6]]let mylist4 = [1, 2, 3, 4]let mylist4 = mylist4 + [5, 6]echo mylist4" =&gt; [1, 2, 3, 4, 5, 6]let mylist5 = [1, 2, 3, 4]call remove(mylist5, 3)echo mylist5" =&gt; [1, 2, 3]let mydict = &#123;'banana': 'yellow', 'apple': 'green'&#125;echo mydict['banana']" =&gt; yellowecho mydict.apple" =&gt; green get map split join 可以对列表或字典中的值应用某个函数（如 join 和 map 等）以完成特定的需求，常见示例如下：12345678910111213141516171819let a = split("one two")echo a" =&gt; onelet mylist = ["one", "two", "three"]call map(mylist, '"&lt;" . v:val . "&gt;"')echo mylist" =&gt; ['&lt;one&gt;', '&lt;two&gt;', '&lt;three&gt;']let mylist2 = ["one", "two", "three"]echo get(mylist2, 2, "none")" =&gt; threeecho get(mylist2, 3, "none")" =&gt; nonelet mylist3 = ["one", "two", "three"]let mystring = join(mylist3, "+")echo mystring" =&gt; one+two+three 更复杂的示例（好神奇，没看懂。。。）：12345678let mynumbers = &#123;0:'zero', 1:'one', 2:'two', 3:'three', 4:'four', 5:'five', 6:'six', 7:'seven', 8:'eight', 9:'nine'&#125;function mynumbers.convert(numb) dict return join(map(split(a:numb, '\zs'), 'get(self, v:val, "unknown")'))endfunctionecho mynumbers.convert(12345)" =&gt; one two three four five 函数Vim 中定义函数的语法如下：123function Name(arg1, arg2,...argN) keyword code-to-execute-when-function-is-calledendfunction 所有在函数体中定义的变量只在该函数内部可见，即作用域为 local。如果需要使用函数外部的变量，可以将其作为参数传递给函数，或者直接调用（需要在该变量名前加上全局作用域前缀 g:）。函数定义代码中使用由参数传递的变量时，需要加上 a: 作用域前缀。 参数列表 参考如下代码：12345678910111213function PrintSum(num1, num2, ...) let sum = a:num1 + a:num2 let argnum = 1 while argnum &lt;= a:0 let sum += a:&#123;argnum&#125; let argnum += 1 endwhile echo "The sum is" sum return sumendfunctionlet sum = PrintSum(1, 2, 3, 4)" =&gt; The sum is 10 注意代码中 a:0（不定参数的长度）和 a:{argnum}（第 argnum 个额外参数）的用法。 此外还可以通过 a:000 以列表的方式获取所有额外的参数：1234567891011function PrintSum(num1, num2, ...) let sum = a:num1 + a:num2 for arg in a:000 let sum += arg endfor echo "The sum is" sum return sumendfunctionlet sum = PrintSum(1, 2, 3, 4)" =&gt; The sum is 10 综合示例根据当前时间自动切换 Vim 配色的脚本：12345678910let g:Favcolorschemes = ["darkblue", "morning", "shine", "evening"]function SetTimeOfDayColors() " currentHour will be 0, 1, 2 or 3 let CurrentHour = (strftime("%H") + 0) / 6 execute "colorscheme " . g:Favcolorschemes[CurrentHour] echo "set color scheme to " . g:Favcolorschemes[CurrentHour]endfunctioncall SetTimeOfDayColors() 三、AutocommandsAutocommands 即在特定条件下自动执行的命令，这些命令包括所有合法的 Vim 命令。Vim 定义了一些事件（event）作为触发命令自动执行的开关，常见的 event 如下： BufNewFile：在开始编辑一个新的文件时触发 BufReadPre：在 Vim 移动到一个新的 buffer 前触发 BufRead, BufReadPost：开始编辑新的 buffer 时，读取文件之后触发 BufWrite, BufWritePre：在将 buffer 内容写入文件之前触发 FileType：在确定了文件类型（filetype）之后触发 VimResized：更改 Vim 的窗口大小后触发 WinEnter, WinLeave：进入或离开某个 Vim 窗口时触发 CursorMoved, CursorMovedI：Normal 或 Insert 模式下，光标移动后触发 Autocommands 代码示例12345augroup demo autocmd! autocmd BufReadPost * echo 'Reading: ' . expand('&lt;afile&gt;') autocmd BufWritePost * echo 'Writing: ' . expand('&lt;afile&gt;')augroup END 上述脚本会添加如下功能：打开文件时 Vim 命令栏输出 “Reading: “；在使用 :w 等命令保存文件时，命令栏输出 “Writing: “。 又如根据源文件类型设置不同的缩进风格：123filetype onautocmd FileType ruby setlocal tabstop=2 softtabstop=2 shiftwidth=2 expandtabautocmd FileType javascript setlocal ts=4 sts=4 sw=4 noet 参考资料Hacking Vim 7.2Modern Vim]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Tools</tag>
        <tag>Program</tag>
        <tag>Vim</tag>
        <tag>Script</tag>
        <tag>VimScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu 18.04 搭建私有软件镜像源（支持 Ubuntu 和 CentOS）]]></title>
    <url>%2F2019%2F12%2F04%2Fubuntu-18-04-create-ubuntu-and-centos-software-mirrors%2F</url>
    <content type="text"><![CDATA[系统环境为 Ubuntu 18.04，搭建支持 Ubuntu 系和 CentOS 系的双私有软件仓库。Ubuntu 本地软件镜像源使用 apt-mirror 工具与远程仓库同步，CentOS 本地镜像源使用 reposync 工具与远程仓库同步。上述两个工具都可以通过 Ubuntu 的包管理器 apt-get 命令直接安装使用。 一、环境准备我这里搭建了 Ubuntu 18.04、Ubuntu 16.04 和 CentOS7 三个镜像源，从远程仓库拉取的软件包总共耗费了约 300G 硬盘空间，其中两个 Ubuntu 占用了约 261G，CentOS7（包含 epel 源）约 29G 。创建镜像源前需保证本地有足够的存储空间。 建议给磁盘分区时使用 LVM（逻辑卷管理） 的方式，便于之后对存储空间进行扩容等操作。关于 Linux 系统磁盘分区和 LVM 的介绍可以参考 Linux 磁盘设备和 LVM 管理命令详解。此处不作赘述。 安装同步工具：$ sudo apt-get install apt-mirror reposync createrepo 安装 web 服务器（nginx）：$ sudo apt-get install nginx 二、Ubuntu 镜像源搭建编辑 /etc/apt/mirror.list 配置文件，修改远程仓库的地址为国内的阿里镜像站，本地的 Ubuntu 软件仓库将定期从阿里源同步软件包。1234567891011121314151617181920set nthreads 20set _tilde 0set base_path /opt/mirrors/ubuntuset defaultarch amd64#Ubuntu 16.04deb http://mirrors.aliyun.com/ubuntu/ xenial main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ xenial-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ xenial-backports main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ xenial-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ xenial-proposed main restricted universe multiverse#Ubuntu 18.04deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverseclean http://mirrors.aliyun.com/ubuntu 上述配置文件中 base_path 指定的目录，即本地仓库存放软件包的路径。$ sudo mkdir -p /opt/mirrors/ubuntu 运行 apt-mirror 命令拉取软件包，同步完成花费的时间视网速而定：$ sudo apt-mirror 配置 web 服务镜像源同步完成之后，需配置 web 服务使得本地仓库可以被其他 Linux 机器使用。编辑 /etc/nginx/sites-available/default 配置文件，开启目录浏览（auto_index）功能：1234567891011121314server &#123; listen 80 default_server; listen [::]:80 default_server; root /var/www/html; index index.html index.htm index.nginx-debian.html; server_name _; location / &#123; try_files $uri $uri/ =404; autoindex on; autoindex_exact_size off; autoindex_localtime on; &#125;&#125; 创建软链接，将软件包存储路径指向到 web 目录下：$ sudo ln -s /opt/mirrors/ubuntu/mirror/mirrors.aliyun.com/ubuntu /var/www/html/ubuntu 重新载入 nginx 服务：$ sudo service nginx reload 此时访问 http://127.0.0.1/ubuntu ，应该可以在 web 界面中浏览本地仓库中的软件包。 使用本地镜像源前面的配置完成后，即可进入任意一台 Ubuntu 主机，配置其镜像源为刚刚创建的本地软件仓库。编辑 /etc/apt/sources.list 文件，修改镜像源（Ubuntu 18.04）：12345deb http://127.0.0.1/ubuntu/ bionic main restricted universe multiversedeb http://127.0.0.1/ubuntu/ bionic-updates main restricted universe multiversedeb http://127.0.0.1/ubuntu/ bionic-backports main restricted universe multiversedeb http://127.0.0.1/ubuntu/ bionic-security main restricted universe multiversedeb http://127.0.0.1/ubuntu/ bionic-proposed main restricted universe multiverse 运行 sudo apt-get update 命令更新索引文件，之后即可使用 sudo apt-get install 命令从本地仓库中安装软件包了。 效果如下：123456789101112131415$ sudo apt-get updateHit:1 http://127.0.0.1/ubuntu bionic InReleaseHit:2 http://127.0.0.1/ubuntu bionic-updates InReleaseHit:3 http://127.0.0.1/ubuntu bionic-backports InReleaseHit:4 http://127.0.0.1/ubuntu bionic-security InReleaseHit:5 http://127.0.0.1/ubuntu bionic-proposed InReleaseReading package lists... Done$ sudo apt-get install nmap...Get:1 http://127.0.0.1/ubuntu bionic/main amd64 libblas3 amd64 3.7.1-4ubuntu1 [140 kB]Get:2 http://127.0.0.1/ubuntu bionic/main amd64 liblinear3 amd64 2.1.0+dfsg-2 [39.3 kB]Get:3 http://127.0.0.1/ubuntu bionic-updates/main amd64 liblua5.3-0 amd64 5.3.3-1ubuntu0.18.04.1 [115 kB]Get:4 http://127.0.0.1/ubuntu bionic/main amd64 nmap amd64 7.60-1ubuntu5 [5174 kB]Fetched 5467 kB in 1s (9200 kB/s)... 三、CentOS 镜像源搭建创建 /opt/mirrors/CentOS-7.repo 配置文件，添加远程软件仓库的地址。这里使用清华大学开源软件镜像站。12345678910111213141516171819202122232425262728293031323334353637383940[base]name=CentOS-7 - Basebaseurl=https://mirrors.tuna.tsinghua.edu.cn/centos/7/os/x86_64/#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=osgpgcheck=0#gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7#released updates[updates]name=CentOS-7 - Updatesbaseurl=https://mirrors.tuna.tsinghua.edu.cn/centos/7/updates/x86_64/#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=updatesgpgcheck=0#gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7#additional packages that may be useful[extras]name=CentOS-7 - Extrasbaseurl=https://mirrors.tuna.tsinghua.edu.cn/centos/7/extras/x86_64/#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=extrasgpgcheck=0#gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7#additional packages that extend functionality of existing packages[centosplus]name=CentOS-7 - Plusbaseurl=https://mirrors.tuna.tsinghua.edu.cn/centos/7/centosplus/x86_64/#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=centosplusgpgcheck=0enabled=0#gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7[epel]name=Extra Packages for Enterprise Linux 7baseurl=https://mirrors.tuna.tsinghua.edu.cn/epel/7/x86_64#mirrorlist=https://mirrors.fedoraproject.org/metalink?repo=epel-7&amp;arch=$basearchfailovermethod=priorityenabled=1gpgcheck=0# gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7 此处为了简单起见，gpgcheck 都设置为 0 关闭了 GPG KEY 检查。 创建软件仓库本地路径：$ sudo mkdir -p /opt/mirrors/centos 拉取远程仓库到本地：$ sudo reposync -np /opt/mirrors/centos -c /opt/mirrors/CentOS-7.repo 同步完成后，/opt/mirrors/centos 路径下会生成如下 4 个文件夹：12$ ls /opt/mirrors/centosbase epel extras updates 切换到 root 用户，使用 createrepo 命令在上述 4 个文件夹中分别创建私有仓库的索引文件：1234$ cd /opt/mirrors/centos$ for i in base extras updates epel; docreaterepo $idone 索引创建完成后，上述四个路径中都会多出 repodata 和 .repodata 两个文件夹：12$ ls -a base. .. Packages repodata .repodata 配置 web 服务创建软链接，将 CentOS 软件包存储路径指向到 web 目录下：$ sudo ln -s /opt/mirrors/centos /var/www/html/centos 重新载入 nginx 服务：$ sudo service nginx reload 此时访问 http://127.0.0.1/centos ，应该可以在 web 界面中浏览本地 CentOS 仓库中的软件包。 使用本地镜像源登录任意一台 CentOS 主机，备份 /etc/yum.repos.d 目录下的所有 .repo 配置文件到其他位置。创建软件仓库配置文件 /etc/yum.repos.d/CentOS-7.repo，编辑远程仓库地址（baseurl）为前面搭建的私有仓库：12345678910111213141516171819202122232425262728293031323334353637383940[base]name=CentOS-7 - Basebaseurl=http://127.0.0.1/centos/base#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=osgpgcheck=0#gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7#released updates[updates]name=CentOS-7 - Updatesbaseurl=http://127.0.0.1/centos/updates#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=updatesgpgcheck=0#gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7#additional packages that may be useful[extras]name=CentOS-7 - Extrasbaseurl=http://127.0.0.1/centos/extras#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=extrasgpgcheck=0#gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7#additional packages that extend functionality of existing packages[centosplus]name=CentOS-7 - Plusbaseurl=http://127.0.0.1/centos/centosplus#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=centosplusgpgcheck=0enabled=0#gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7[epel]name=Extra Packages for Enterprise Linux 7baseurl=http://127.0.0.1/centos/epel#mirrorlist=https://mirrors.fedoraproject.org/metalink?repo=epel-7&amp;arch=$basearchfailovermethod=priorityenabled=1gpgcheck=0# gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7 运行 sudo yum clean all &amp;&amp; yum makecache 命令重建软件包索引。之后即可通过 sudo yum install 命令从本地的私有仓库中安装软件了。 四、crontab创建 crontab 计划任务，让本地仓库定期从远程仓库拉取有更新的软件包：$ sudo crontab -e 参考配置：120 3 * * 0 reposync -np /opt/mirrors/centos -c /opt/mirrors/CentOS-7.repo0 22 * * 6 apt-mirror 每周日凌晨 3 点运行 reposync 命令同步 CentOS 仓库。每周六晚上 10 点运行 apt-mirror 命令同步 Ubuntu 仓库。 参考文章centos 下创建本地镜像源，结合 nginx]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Server</tag>
        <tag>Software</tag>
        <tag>Ubuntu</tag>
        <tag>CentOS</tag>
        <tag>Mirror</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTPie 命令语法速查]]></title>
    <url>%2F2019%2F12%2F01%2Fhttpie-as-powerful-http-client%2F</url>
    <content type="text"><![CDATA[HTTPie 是一个基于命令行的 HTTP 客户端，类似于 Linux 系统中的 curl 工具。它凭借非常简单直观的语法和着色的格式化输出等特性，提供了一种友好的与 Web 服务交互的方式。 一、安装HTTPie 的安装方法有很多种，可以通过 pip 命令以 Python 模块的方式安装，相对简单且通用：$ pip install httpie 语法格式：$ http [flags] [METHOD] URL [ITEM [ITEM]] 基本示例 $ http httpie.org 以 GET 方法访问 Web 服务，获取 HTML 文档或其他类型的响应 $ http PUT example.org X-API-TOKEN:123 name=John 自定义 HTTP 请求头、HTTP 方法及上传的 JSON 数据在上面的示例中，PUT 为自定义的请求方法，X-API-Token 为请求头选项，name=John 即通过 PUT 方法提交的 JSON 数据。 $ http -f POST example.org hello=world 提交 form 表单 $ http example.org &lt; file.json 通过重定向上传文件 http --download exmaple.org/file 下载文件（类似 wget 命令） 二、语法详解HTTP 方法http 命令默认使用 GET 方法（无请求数据时）或 POST 方法（有提供请求数据时）访问 Web 服务，也支持 PUT、DELETE 等标准的 HTTP 动词：http &lt;method&gt; &lt;url&gt;。 如：$ http DELETE example.org/todos/7，实际向服务器发送了类似这样的请求：DELETE /todos/7 HTTP/1.1。 Request 选项http 允许在请求命令中添加 HTTP 请求头、JSON 或表单数据、文件和 URL 参数等请求选项。参考下表： Item 类型 描述 HTTP 请求头 Name:Value 如 X-API-Token:123 URL 参数 name==value 通过 == 符号向 URL 中附加 query string 参数 Data Fields field=value, field=@file.txt 此类数据在提交时会序列化为 JSON 对象，或者编码为 form 格式上传（--form, -f） Raw JSON field:=json, field:=@file.json 用于提交 Boolean、Number、Array 等原始格式的 JSON 数据。如 meals:=&#39;[&quot;ham&quot;,&quot;spam&quot;]&#39; 表单文件 file@/dir/file 配合 --form 或 -f 使用，以 multipart/form-data 的形式提交文件 Querystring对于 URL 链接中包含的 querystring 参数（如 /?param1=value1&amp;param2=value2），http 命令可以通过简单的 param==value 语法来指定。 如 $ http www.google.com search==&#39;HTTPie logo&#39; tbm==isch效果类似于 GET /?search=HTTPie+logo&amp;tbm=isch HTTP/1.1 Non-string JSONhttp 命令中包含的请求数据默认都会序列化为 JSON 格式再提交给服务器，即请求头中 Content-Type 和 Accept 选项的默认值都为 application/json 。 可以使用 := 操作符提交非字符串形式的 JSON 数据；Text 和 JSON 文件则可以分别使用 =@ 和 :=@ 嵌入到请求中。如：12345$ http PUT api.example.com/person/1 \ name=John \ # Text JSON age:=29 married:=false hobbies:=&apos;[&quot;http&quot;, &quot;pies&quot;]&apos; \ # Raw JSON description=@about-john.txt \ # Embed text file bookmarks:=@bookmarks.json # Embed JSON file 表单常规表单提交表单和发送 JSON 请求的方式非常相似，只是需要在命令中添加 --form 或 -f 选项，以确保请求数据的 Content-Type 被设置为 application/x-www-form-urlencoded; charset=utf-8 。 $ http -f POST api.example.org/person/1 name=&#39;John Smith&#39;1234POST /person/1 HTTP/1.1Content-Type: application/x-www-form-urlencoded; charset=utf-8name=John+Smith 文件上传表单如果表单请求中有包含文件项，则该请求的 Content-Type 会被设置成 multipart/form-data 。 $ http -f POST example.com/jobs name=&#39;John Smith&#39; cv@~/Documents/cv.pdf上述命令的效果等同于如下 HTML 表单：1234&lt;form enctype="multipart/form-data" method="post" action="http://example.com/jobs"&gt; &lt;input type="text" name="name" /&gt; &lt;input type="file" name="cv" /&gt;&lt;/form&gt; 其他常用语法Cookies$ http example.org &#39;Cookie:sessionid=foo;another-cookie=bar&#39; 基本认证$ http -a username:password example.org Digest 认证$ http -A digest -a username:password example.org 提示手动输入密码$ http -a username example.org 代理$ http --proxy=http:http://10.10.1.10:3128 --proxy=https:https://10.10.1.10:1080 example.org 带认证的代理$ http --proxy=http:http://user:pass@10.10.1.10:3128 example.org SOCKS 代理需安装依赖库：$ pip install requests[socks]$ http --proxy=http:socks5://user:pass@host:port --proxy=https:socks5://user:pass@host:port example.org 跳过 SSL 证书认证$ http --verify=no https://example.org 自定义 CA$ http --verify=/ssl/custom_ca_bundle https://example.org 客户端 SSL 证书$ http --cert=client.pem https://example.org 或$ http --cert=client.crt --cert-key=client.key https://example.org 三、命令输出默认情况下，http 命令会输出最终的完整响应信息（包含 headers 和 body），可以通过如下选项控制显示的结果： 选项 含义 --headers, -h 只输出响应头信息 --body, -b 只输出响应中的 body 信息 --verbose, -b 输出所有的 HTTP 交互信息（包含请求和响应） --print, -p 自由组合需要显示的部分 --print 或 -p 选项可以携带多个不同的字符对应特定的内容进行显示： 字符 含义 H 请求头 B 请求体 h 响应头 b 响应体 如：http --print=Hh PUT httpbin.org/put hello=world 输出重定向保存文件：$ http example.org/Movie.mov &gt; Movie.mov 保存图片后使用 ImageMagick 改变大小再上传：$ http octodex.github.com/images/original.jpg | convert - -resize 25% - | http example.org/Octocats 下载模式（响应头定向至 stderr，传输过程中显示进度条）：http --download https://github.com/jakubroztocil/httpie/archive/master.tar.gz 下载过程中使用管道重定向：$ http -d https://github.com/jakubroztocil/httpie/archive/master.tar.gz | tar zxf - 参考资料HTTPie Documentation]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Tools</tag>
        <tag>Tricks</tag>
        <tag>Python</tag>
        <tag>Efficiency</tag>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 通过 Flask 框架构建 REST API（三）——基于 Token 的身份认证]]></title>
    <url>%2F2019%2F11%2F30%2Fpython-build-rest-api-with-flask-3-authorization-by-token%2F</url>
    <content type="text"><![CDATA[接上文Python 通过 Flask 框架构建 REST API（二）——优化项目架构。前面介绍了如何通过 Flask 和 marshmallow 框架写一个完整的架构清晰的项目，作为 REST API 实现基本的增删改查功能。本篇主要介绍在前文的基础上，借助 JWT（JSON Web Tokens）创建基于 Token 的身份认证机制。 一、安装依赖在前文创建的 Python 虚拟环境中，额外安装如下两个 Python 库：$ pip install passlib flask-jwt-extended 其中 passlib 用来提供对明文密码的哈希处理及验证，flask-jwt-extended 则引入了对 JWT 认证的支持。 users 数据库模型编辑 src/api/models/users.py 文件，创建 User 数据库模型和 UserSchema 序列化对象：123456789101112131415161718192021222324252627282930313233343536373839# src/api/models/users.pyfrom api.utils.database import dbfrom passlib.hash import pbkdf2_sha256 as sha256from marshmallow_sqlalchemy import ModelSchemafrom marshmallow import fieldsclass User(db.Model): __tablename__ = 'users' id = db.Column(db.Integer, primary_key=True) username = db.Column(db.String(120), unique=True, nullable=False) password = db.Column(db.String(120), nullable=False) def create(self): db.session.add(self) db.session.commit() return self @classmethod def find_by_username(cls, username): return cls.query.filter_by(username=username).first() @staticmethod def generate_hash(password): return sha256.hash(password) @staticmethod def verify_hash(password, hash): return sha256.verify(password, hash)class UserSchema(ModelSchema): class Meta(ModelSchema.Meta): model = User sqla_session = db.session id = fields.Number(dump_only=True) username = fields.String(required=True) 三、路由和响应逻辑编辑 src/api/routes/users.py 文件，加入 users 路由和对应的 POST 响应逻辑。其中 create_user() 用于创建用户并将用户信息存入数据库表，authenticate_user() 用于完成用户认证并返回 Token 字符串作为之后的访问令牌。123456789101112131415161718192021222324252627282930313233343536373839404142from flask import Blueprintfrom flask import requestfrom flask import url_for, render_template_stringfrom api.utils.responses import response_withfrom api.utils import responses as respfrom api.models.users import User, UserSchemafrom api.utils.database import dbfrom flask_jwt_extended import create_access_tokenimport datetimeuser_routes = Blueprint("user_routes", __name__)@user_routes.route('/', methods=['POST'])def create_user(): try: data = request.get_json() data['password'] = User.generate_hash(data['password']) user_schmea = UserSchema() user = user_schmea.load(data) result = user_schmea.dump(user.create()) return response_with(resp.SUCCESS_201) except Exception as e: print(e) return response_with(resp.INVALID_INPUT_422)@user_routes.route('/login', methods=['POST'])def authenticate_user(): try: data = request.get_json() current_user = User.find_by_username(data['username']) if not current_user: return response_with(resp.SERVER_ERROR_404) if User.verify_hash(data['password'], current_user.password): access_token = create_access_token(identity=data['username']) return response_with(resp.SUCCESS_201, value=&#123;'message': 'Logged in as &#123;&#125;'.format(current_user.username), "access_token": access_token&#125;) else: return response_with(resp.UNAUTHORIZED_401) except Exception as e: print(e) return response_with(resp.INVALID_INPUT_422) 四、配置编辑 src/main.py 文件，添加如下两行代码注册 users 路由：12from api.routes.users import user_routesapp.register_blueprint(user_routes, url_prefix='/api/users') 在 main.py 的 db.init_app(app) 代码前添加如下内容初始化 JWT 模块：12from flask_jwt_extended import JWTManagerjwt = JWTManager(app) 编辑 src/api/config/config.py 文件，在 ProductionConfig、DevelopmentConfig、TestingConfig 添加 JWT_SECRET_KEY 定义：1JWT_SECRET_KEY = &apos;SOME-RADOM-JWT-SECRET&apos; 编辑 src/api/utils/responses.py 文件，添加“未认证”和“禁止访问”的标准响应格式：1234567891011FORBIDDEN_403 = &#123; "http_code": 403, "code": "notAuthorized", "message": "You are not authorised to execute this."&#125;UNAUTHORIZED_401 = &#123; "http_code": 401, "code": "notAuthorized", "message": "Invalid authentication."&#125; 在 src/api/routes/authors.py 和 src/api/routes/books.py 两个路由文件的响应逻辑中，对 POST、PATCH、PUT 和 DELETE 请求加入验证 Token 的访问条件，以限制匿名用户对后台数据的修改。只需要在响应函数前加入 @jwt_required 装饰器即可，如：123456789from flask_jwt_extended import jwt_required@author_routes.route('/&lt;int:id&gt;', methods=['DELETE'])@jwt_requireddef delete_author(id): get_author = Author.query.get_or_404(id) db.session.delete(get_author) db.session.commit() return response_with(resp.SUCCESS_204) 五、测试运行 python run.py，使用 httpie 工具进行测试。 创建用户：1234$ http POST 127.0.0.1:5000/api/users/ username=admin password=flask&#123; "code": "success"&#125; 用户登录获取 Token：123456$ http POST 127.0.0.1:5000/api/users/login username=admin password=flask&#123; "access_token": "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpYXQiOjE1NzUwODkyMTQsIm5iZiI6MTU3NTA4OTIxNCwianRpIjoiMTdiZjViZTEtMmJjMS00OWY2LWI2ZDgtZDRmZGZkZGE2MDI1IiwiZXhwIjoxNTc1MDkwMTE0LCJpZGVudGl0eSI6ImFkbWluIiwiZnJlc2giOmZhbHNlLCJ0eXBlIjoiYWNjZXNzIn0.iipDvS-BFwOQ9IfybEZxn2adrBu7sC7MznDoXfnWEsI", "code": "success", "message": "Logged in as admin"&#125; 使用 POST 方法向 authors 数据表中插入作者信息：12345678910$ http POST 127.0.0.1:5000/api/authors/ first_name=Jack last_name=SparrowHTTP/1.0 401 UNAUTHORIZEDContent-Length: 44Content-Type: application/jsonDate: Sat, 30 Nov 2019 04:53:15 GMTServer: Werkzeug/0.16.0 Python/3.7.3&#123; "msg": "Missing Authorization Header"&#125; 提示缺少 Authorization 请求头，即 POST 请求需要添加 Token 认证信息。 添加 Authorization 请求头（Token），重新发起 POST 请求：123456789101112131415161718$ http POST 127.0.0.1:5000/api/authors/ Authorization:"Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpYXQiOjE1NzUwODkyMTQsIm5iZiI6MTU3NTA4OTIxNCwianRpIjoiMTdiZjViZTEtMmJjMS00OWY2LWI2ZDgtZDRmZGZkZGE2MDI1IiwiZXhwIjoxNTc1MDkwMTE0LCJpZGVudGl0eSI6ImFkbWluIiwiZnJlc2giOmZhbHNlLCJ0eXBlIjoiYWNjZXNzIn0.iipDvS-BFwOQ9IfybEZxn2adrBu7sC7MznDoXfnWEsI" first_name=Jack last_name=SparrowHTTP/1.0 201 CREATEDAccess-Control-Allow-Origin: *Content-Length: 171Content-Type: application/jsonDate: Sat, 30 Nov 2019 04:57:05 GMTserver: Flask REST API&#123; "author": &#123; "books": [], "created": "2019-11-30 04:57:05", "first_name": "Jack", "id": 1.0, "last_name": "Sparrow" &#125;, "code": "success"&#125; 成功创建数据。 注意 Authorization 请求头的格式为 Authorization:&quot;Bearer &lt;token&gt;&quot;。 参考资料Building REST APIs with Flask]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Python</tag>
        <tag>Web</tag>
        <tag>Development</tag>
        <tag>REST</tag>
        <tag>API</tag>
        <tag>Flask</tag>
        <tag>Token</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 通过 Flask 框架构建 REST API（二）——优化项目架构]]></title>
    <url>%2F2019%2F11%2F30%2Fpython-build-rest-api-with-flask-2-project-structure%2F</url>
    <content type="text"><![CDATA[接上文 Python 通过 Flask 框架构建 REST API（一）——数据库建模。前面介绍了如何通过 Flask 和 marshmallow 框架写一个完整的单页 Web 应用，作为 REST API 实现基本的增删改查功能。本篇主要介绍在前文的基础上，如何将单页应用合理地组织到一个架构清晰的项目中。标准化的同时也方便日后的维护。 一、环境搭建见如下代码：12345678910# 创建项目文件夹$ mkdir author-manager &amp;&amp; cd author-manager# 创建 Python 虚拟环境$ pip install virtualenv$ virtualenv venv$ source venv/bin/activate# 安装依赖库(venv) $ pip install flask marshmallow-sqlalchemy flask-sqlalchemy# 创建文件夹存放源代码$ mkdir src &amp;&amp; cd src 二、初始化应用创建 main.py 源代码文件初始化 Flask 应用：123456789101112131415# main.pyimport osfrom flask import Flaskfrom flask import jsonifyapp = Flask(__name__)if os.environ.get('WORK_ENV') == 'PROD': app_config = ProductionConfigelif os.environ.get('WORK_ENV') == 'TEST': app_config = TestingConfigelse: app_config = DevelopmentConfigapp.config.from_object(app_config) 创建 run.py 文件作为运行 Web 应用的入口：1234# run.pyfrom main import app as applicationif __name__ == "__main__": application.run(port=5000, host="0.0.0.0", use_reloader=False) Config创建 api/config 目录，在其中创建空的 __init__.py 和 config.py 文件，编辑 config.py 加入 config 对象：$ mkdir -p api/config &amp;&amp; touch api/config/__init__.py$ vim api/config/config.py 12345678910111213141516171819# src/config/config.pyclass Config(object): DEBUG = False TESTING = False SQLALCHEMY_TRACK_MODIFICATIONS = Falseclass ProductionConfig(Config):# SQLALCHEMY_DATABASE_URI = &lt;Production DB RUL&gt; passclass DevelopmentConfig(Config): DEBUG = True SQLALCHEMY_DATABASE_URI = "sqlite:///../authors.db" SQLALCHEMY_ECHO = Falseclass TestingConfig(Config): TESTING = True# SQLALCHEMY_DATABASE_URI = &lt;Testing DB URL&gt; SQLALCHEMY_ECHO = False PS：每个目录中包含的 __init__.py 空文件用来指示该目录中包含有可供其他代码文件导入的 Python 模块 Database创建 api/utils 文件夹并编辑 database.py 文件：$ mkdir -p api/utils &amp;&amp; touch api/utils/__init__.py$ vim api/utils/database.py 1234# src/api/utils/database.pyfrom flask_sqlalchemy import SQLAlchemydb = SQLAlchemy() 将 main.py 改为如下版本以导入 config 和 db 对象：1234567891011121314151617181920# main.pyimport osfrom flask import Flaskfrom flask import jsonifyfrom api.config.config import *from api.utils.database import dbif os.environ.get('WORK_ENV') == 'PROD': app_config = ProductionConfigelif os.environ.Get('WORK_ENV') == 'TEST': app_config = TestingConfigelse: app_config = DevelopmentConfigapp = Flask(__name__)app.config.from_object(app_config)db.init_app(app)with app.app_context(): db.create_all() 此时整个项目的目录结构如下：1234567891011121314author-manager├── src│ ├── api│ │ ├── __init__.py│ │ ├── config│ │ │ ├── __init__.py│ │ │ └── config.py│ │ └── utils│ │ ├── __init__.py│ │ └── database.py│ ├── main.py│ ├── requirements.txt│ └── run.py└── venv 三、数据库关系模型创建 api/models 文件夹，在其中编辑 books.py 文件作为数据库模型：$ mkdir -p api/models &amp;&amp; touch api/models/__init__.py books 数据表模型：123456789101112131415161718192021222324252627282930313233# src/api/models/books.pyfrom api.utils.database import dbfrom marshmallow_sqlalchemy import ModelSchemafrom marshmallow import fieldsclass Book(db.Model): __talbename__ = 'books' id = db.Column(db.Integer, primary_key=True, autoincrement=True) title = db.Column(db.String(50)) year = db.Column(db.Integer) author_id = db.Column(db.Integer, db.ForeignKey('authors.id')) def __init__(self, title, year, author_id=None): self.title = title self.year = year self.author_id = author_id def create(self): db.session.add(self) db.session.commit() return selfclass BookSchema(ModelSchema): class Meta(ModelSchema.Meta): model = Book sqla_session = db.session id = fields.Number(dump_only=True) title = fields.String(required=True) year = fields.Integer(required=True) author_id = fields.Integer() authors 数据表模型：12345678910111213141516171819202122232425262728293031323334353637# src/api/models/authors.pyfrom api.utils.database import dbfrom marshmallow_sqlalchemy import ModelSchemafrom marshmallow import fieldsfrom api.models.books import BookSchemaclass Author(db.Model): __tablename__ = 'authors' id = db.Column(db.Integer, primary_key=True, autoincrement=True) first_name = db.Column(db.String(20)) last_name = db.Column(db.String(20)) created = db.Column(db.DateTime, server_default=db.func.now()) books = db.relationship('Book', backref='Author', cascade="all, delete-orphan") def __init__(self, first_name, last_name, books=[]): self.first_name = first_name self.last_name = last_name self.books = books def create(self): db.session.add(self) db.session.commit() return selfclass AuthorSchema(ModelSchema): class Meta(ModelSchema.Meta): model = Author sqla_session = db.session id = fields.Number(dump_only=True) first_name = fields.String(required=True) last_name = fields.String(required=True) created = fields.String(dump_only=True) books = fields.Nested(BookSchema, many=True, only=['title', 'year', 'id']) 四、HTTP 标准响应在 api/utils 目录下创建 responses.py ，作为 REST API 通用的响应格式：123456789101112131415161718192021222324# src/api/utils/responses.pyfrom flask import make_response, jsonifydef response_with(response, value=None, message=None, error=None, headers=&#123;&#125;, pagination=None): result = &#123;&#125; if value is not None: result.update(value) if response.get('message', None) is not None: result.update(&#123;'message': response['message']&#125;) result.update(&#123;'code': response['code']&#125;) if error is not None: result.update(&#123;'errors': error&#125;) if pagination is not None: result.update(&#123;'pagination': pagination&#125;) headers.update(&#123;'Access-Control-Allow-Origin': '*'&#125;) headers.update(&#123;'server': 'Flask REST API'&#125;) return make_response(jsonify(result), response['http_code'], headers) 在 responses.py 文件的 response_with 函数前面插入如下代码，定义 http_code：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# src/api/utils/responses.pyINVALID_FIELD_NAME_SENT_422 = &#123; "http_code": 422, "code": "invalidField", "message": "Invalid fields found" &#125;INVALID_INPUT_422 = &#123; "http_code": 422, "code": "missingParameter", "message": "Missing parameters" &#125;BAD_REQUEST_400 = &#123; "http_code": 400, "code": "badRequest", "message": "Bad request" &#125;SERVER_ERROR_500 = &#123; "http_code": 500, "code": "serverError", "message": "Server error" &#125;SERVER_ERROR_404 = &#123; "http_code": 404, "code": "notFound", "message": "Resource not found" &#125;UNAUTHORIZED_403 = &#123; "http_code": 403, "code": "notAuthorized", "message": "You are not authorized" &#125;SUCCESS_200 = &#123; 'http_code': 200, 'code': 'success', &#125;SUCCESS_201 = &#123; 'http_code': 201, 'code': 'success', &#125;SUCCESS_204 = &#123; 'http_code': 204, 'code': 'success' &#125; 在 main.py 中添加如下代码，导入 status code 定义和 response_with 函数：1234# src/main.pyimport api.utils.responses as respfrom api.utils.responses import response_withimport logging 在 main.py 中 db.init_app(app) 前面添加如下代码，引入错误场景下的标准响应格式：12345678910111213141516171819# src/main.py@app.after_requestdef add_header(response): return response@app.errorhandler(400)def bad_request(e): logging.error(e) return response_with(resp.BAD_REQUEST_400)@app.errorhandler(500)def server_error(e): logging.error(e) return response_with(resp.SERVER_ERROR_500)@app.errorhandler(404)def not_found(e): logging.error(e) return response_with(resp.SERVER_ERROR_404) 五、API endpoints接下来创建 REST API 的访问端点及其对应的路由。编辑 api/routes/authors.py 文件，加入对 POST、GET 等方法的响应逻辑。$ mkdir -p api/routes &amp;&amp; touch api/routes/__init__.py 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374# src/api/routes/authors.pyfrom flask import Blueprintfrom flask import requestfrom api.utils.responses import response_withfrom api.utils import responses as respfrom api.models.authors import Author, AuthorSchemafrom api.utils.database import dbauthor_routes = Blueprint("author_routes", __name__)@author_routes.route('/', methods=['POST'])def create_author(): try: data = request.get_json() author_schema = AuthorSchema() author = author_schema.load(data) result = author_schema.dump(author.create()) return response_with(resp.SUCCESS_201, value=&#123;"author": result&#125;) except Exception as e: print(e) return response_with(resp.INVALID_INPUT_422)@author_routes.route('/', methods=['GET'])def get_author_list(): fetched = Author.query.all() author_schema = AuthorSchema(many=True, only=['first_name', 'last_name','id']) authors = author_schema.dump(fetched) return response_with(resp.SUCCESS_200, value=&#123;"authors": authors&#125;)@author_routes.route('/&lt;int:author_id&gt;', methods=['GET'])def get_author_detail(author_id): fetched = Author.query.get_or_404(author_id) author_schema = AuthorSchema() author = author_schema.dump(fetched) return response_with(resp.SUCCESS_200, value=&#123;"author": author&#125;)@author_routes.route('/&lt;int:id&gt;', methods=['PUT'])def update_author_detail(id): data = request.get_json() get_author = Author.query.get_or_404(id) get_author.first_name = data['first_name'] get_author.last_name = data['last_name'] db.session.add(get_author) db.session.commit() author_schema = AuthorSchema() author = author_schema.dump(get_author) return response_with(resp.SUCCESS_200, value=&#123;"author": author&#125;)@author_routes.route('/&lt;int:id&gt;', methods=['PATCH'])def modify_author_detail(id): data = request.get_json() get_author = Author.query.get(id) if data.get('first_name'): get_author.first_name = data['first_name'] if data.get('last_name'): get_author.last_name = data['last_name'] db.session.add(get_author) db.session.commit() author_schema = AuthorSchema() author = author_schema.dump(get_author) return response_with(resp.SUCCESS_200, value=&#123;"author": author&#125;)@author_routes.route('/&lt;int:id&gt;', methods=['DELETE'])def delete_author(id): get_author = Author.query.get_or_404(id) db.session.delete(get_author) db.session.commit() return response_with(resp.SUCCESS_204) 然后在 main.py 文件中导入上面创建的 author_routes：from api.routes.authors import author_routes 并加入以下代码（在 ``@app.after_request之前）以完成路由的注册：app.register_blueprint(author_routes, url_prefix=’/api/authors’) 测试运行 python run.py 启动 Web 服务，使用 httpie 工具进行测试：1234567891011$ http POST 127.0.0.1:5000/api/authors/ first_name=Jack last_name=Sparrow&#123; "author": &#123; "books": [], "created": "2019-11-29 04:41:46", "first_name": "Jack", "id": 2.0, "last_name": "Sparrow" &#125;, "code": "success"&#125; 1234567891011$ http 127.0.0.1:5000/api/authors/&#123; "authors": [ &#123; "first_name": "Jack", "id": 1.0, "last_name": "Sparrow" &#125;, ], "code": "success"&#125; 1234567891011$ http 127.0.0.1:5000/api/authors/1&#123; "author": &#123; "books": [], "created": "2019-11-29 03:22:22", "first_name": "Jack", "id": 1.0, "last_name": "Sparrow" &#125;, "code": "success"&#125; 同样的方式，创建 api/routes/books.py 文件，添加 book_routes 的响应逻辑：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869# src/api/routes/books.pyfrom flask import Blueprint, requestfrom api.utils.responses import response_withfrom api.utils import responses as respfrom api.models.books import Book, BookSchemafrom api.utils.database import dbbook_routes = Blueprint("book_routes", __name__)@book_routes.route('/', methods=['POST'])def create_book(): try: data = request.get_json() book_schema = BookSchema() book = book_schema.load(data) result = book_schema.dump(book.create()) return response_with(resp.SUCCESS_201, value=&#123;"book": result&#125;) except Exception as e: print(e) return response_with(resp.INVALID_INPUT_422)@book_routes.route('/', methods=['GET'])def get_book_list(): fetched = Book.query.all() book_schema = BookSchema(many=True, only=['author_id', 'title', 'year']) books = book_schema.dump(fetched) return response_with(resp.SUCCESS_200, value=&#123;"books": books&#125;)@book_routes.route('/&lt;int:id&gt;', methods=['GET'])def get_book_detail(id): fetched = Book.query.get_or_404(id) book_schema = BookSchema() books = book_schema.dump(fetched) return response_with(resp.SUCCESS_200, value=&#123;"books": books&#125;)@book_routes.route('/&lt;int:id&gt;', methods=['PUT'])def update_book_detail(id): data = request.get_json() get_book = Book.query.get_or_404(id) get_book.title = data['title'] get_book.year = data['year'] db.session.add(get_book) db.session.commit() book_schema = BookSchema() book = book_schema.dump(get_book) return response_with(resp.SUCCESS_200, value=&#123;"book": book&#125;)@book_routes.route('/&lt;int:id&gt;', methods=['PATCH'])def modify_book_detail(id): data = request.get_json() get_book = Book.query.get_or_404(id) if data.get('title'): get_book.title = data['title'] if data.get('year'): get_book.year = data['year'] db.session.add(get_book) db.session.commit() book_schema = BookSchema() book = book_schema.dump(get_book) return response_with(resp.SUCCESS_200, value=&#123;"book": book&#125;)@book_routes.route('/&lt;int:id&gt;', methods=['DELETE'])def delete_book(id): get_book = Book.query.get_or_404(id) db.session.delete(get_book) db.session.commit() return response_with(resp.SUCCESS_204) 在 main.py 中导入 book_routes 并使用 app.register_blueprint 方法注册。同时在 main.py 末尾加入 logging 配置代码，最终效果如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354# src/main.pyimport osimport sysimport loggingfrom flask import Flaskfrom flask import jsonifyfrom api.config.config import *from api.utils.database import dbfrom api.utils.responses import response_withimport api.utils.responses as respfrom api.routes.authors import author_routesfrom api.routes.books import book_routesif os.environ.get('WORK_ENV') == 'PROD': app_config = ProductionConfigelif os.environ.get('WORK_ENV') == 'TEST': app_config = TestingConfigelse: app_config = DevelopmentConfigapp = Flask(__name__)app.config.from_object(app_config)app.register_blueprint(author_routes, url_prefix='/api/authors')app.register_blueprint(book_routes, url_prefix='/api/books')@app.after_requestdef add_header(response): return response@app.errorhandler(400)def bad_request(e): logging.error(e) return response_with(resp.BAD_REQUEST_400)@app.errorhandler(500)def server_error(e): logging.error(e) return response_with(resp.SERVER_ERROR_500)@app.errorhandler(404)def not_found(e): logging.error(e) return response_with(resp.SERVER_ERROR_404)db.init_app(app)with app.app_context(): db.create_all()logging.basicConfig( stream=sys.stdout, format='%(asctime)s|%(levelname)s|%(filename)s:%(lineno)s|%(message)s', level=logging.DEBUG) 参考资料Building REST APIs with Flask]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Python</tag>
        <tag>Web</tag>
        <tag>Development</tag>
        <tag>REST</tag>
        <tag>API</tag>
        <tag>Flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 通过 Flask 框架构建 REST API（一）——数据库建模]]></title>
    <url>%2F2019%2F11%2F28%2Fpython-build-rest-api-with-flask-1-modeling%2F</url>
    <content type="text"><![CDATA[一、REST 简介REST（Representational State Transfer）是一种软件架构风格或者开发模式，主要面向可以在多种系统之间提供标准的数据通信功能的 Web 服务。而 REST 风格的 Web 服务则允许请求端通过统一的、预先定义好的无状态行为来访问和操作服务端数据。 下面简要说明 REST 风格的特点。 Uniform Interface：统一接口即使用 HTTP 提供的一系列方法（或动词，GET、POST 等）操作基于名词的 URI 表示的资源 Representations：RESTful 服务关注资源以及资源的访问，representation 即机器可读的对资源当前状态的定义。推荐使用 JSON Messages：客户端与服务器之间的请求/响应，以及其中包含的元数据（请求头、响应码等） Links Between Resources：REST 架构的核心概念即资源，资源可以包含 link 用于驱动多个资源之间的连接和跳转 Caching：缓存，REST API 中的缓存由 HTTP 头控制 Stateless：每个请求都必须是独立的，服务器不保存客户端的状态信息；客户端发送的请求必须包含能够让服务器理解请求的所有信息，因此客户端请求可以被任何可用的服务器应答。无状态原则为 REST 服务的可伸缩性（横向扩展）和 Caching 等特性提供了便利。 二、搭建开发环境virtualenv 创建 Python 虚拟环境：1234$ mkdir flask-mysql &amp;&amp; cd flask-mysql$ pip install virtualenv$ virtualenv venv$ source venv/bin/activate 虚拟环境中安装 Flask：$ pip install flask 最简单 Flask 应用代码：123456from flask import Flaskapp = Flask(__name__)@app.route(&apos;/&apos;)def hello_world(): return &apos;Hello, From Flask!&apos; 使用 $ FLASK_APP=app.py flask run 命令运行上面创建的 app.py 源文件。 SQLAlchemyFlask 是一个灵活的轻量级 Web 开发框架，它以插件的方式提供了针对各种数据源的交互支持。这里使用 ORM（Object Relational Mapper）类型的框架 sqlalchemy 作为与数据库交互的工具。安装命令如下：$ pip install flask-sqlalchemy pymysql 数据库配置代码：123app = Flask(__name__)app.config['SQLALCHEMY_DATABASE_URI'] = 'mysql+pymysql://&lt;mysql_username&gt;:&lt;mysql_password&gt;@&lt;mysql_host&gt;:&lt;mysql_port&gt;/&lt;mysql_db&gt;'db = SQLAlchemy(app) 如未安装 Mysql 服务，可以改为使用 Sqlite3 数据库引擎：app.config[&#39;SQLALCHEMY_DATABASE_URI&#39;] = &#39;sqlite:///./&lt;dbname&gt;.db&#39; 三、数据库建模创建 Authors 模型的代码如下：123456789101112131415161718class Authors(db.Model): id = db.Column(db.Integer, primary_key=True) name = db.Column(db.String(20)) specialisation = db.Column(db.String(50)) def create(self): db.session.add(self) db.session.commit() return self def __init__(self, name, specialisation): self.name = name self.specialisation = specialisation def __repr__(self): return '&lt;Author %d&gt;' % self.iddb.create_all() 上述模型代码会在关联的数据库中创建一张名为 authors 的表，同时 sqlalchemy 框架提供的基于模型的 API 也会用来与该数据表进行交互。 模型中的字段定义等同于如下的 SQL 语句：12345678910mysql&gt; show create table authors\G*************************** 1. row *************************** Table: authorsCreate Table: CREATE TABLE `authors` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(20) DEFAULT NULL, `specialisation` varchar(50) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=latin11 row in set (0.00 sec) 序列化序列化是指将 Web API 提供的后台数据以特定的形式（如 json 格式）展示给用户，方便前端程序调用。反序列化则是此过程的逆向操作，将前端发送给 API 的 json 格式的数据持久化到后端数据库中。 这里需要安装 marshmallow 框架将 SQLAlchemy 返回的数据对象转换成 JSON 格式。$ pip install marshmallow-sqlalchemy 添加如下代码创建 AuthorSchema 序列化器：1234567891011from marshmallow_sqlalchemy import ModelSchemafrom marshmallow import fieldsclass AuthorsSchema(ModelSchema): class Meta(ModelSchema.Meta): model = Authors sqla_session = db.session id = fields.Number(dump_only=True) name = fields.String(required=True) specialisation = fields.String(required=True) 四、Entrypoint创建 /authors entrypoint，响应 GET 方法获取 authors 模型中的所有数据对象并以 JSON 格式返回给用户。12345678from flask import Flask, request, jsonify, make_response@app.route('/authors', methods=['GET'])def index(): get_authors = Authors.query.all() author_schema = AuthorsSchema(many=True) authors = author_schema.dump(get_authors) return make_response(jsonify(&#123;"authors": authors&#125;)) 以 id 为筛选条件获取某条特定的数据纪录：123456@app.route('/authors/&lt;id&gt;', methods=['GET'])def get_author_by_id(id): get_author = Authors.query.get(id) author_schema = AuthorsSchema() author = author_schema.dump(get_author) return make_response(jsonify(&#123;"author": author&#125;)) 依次添加 POST、PUT、DELETE 等方法的响应逻辑，最终代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192from flask import Flask, request, jsonify, make_responsefrom flask_sqlalchemy import SQLAlchemyfrom marshmallow_sqlalchemy import ModelSchemafrom marshmallow import fieldsapp = Flask(__name__)app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///./test.db'db = SQLAlchemy(app)class Authors(db.Model): id = db.Column(db.Integer, primary_key=True) name = db.Column(db.String(20)) specialisation = db.Column(db.String(50)) def create(self): db.session.add(self) db.session.commit() return self def __init__(self, name, specialisation): self.name = name self.specialisation = specialisation def __repr__(self): return '&lt;Author %d&gt;' % self.iddb.create_all()class AuthorsSchema(ModelSchema): class Meta(ModelSchema.Meta): model = Authors sqla_session = db.session id = fields.Number(dump_only=True) name = fields.String(required=True) specialisation = fields.String(required=True)@app.route('/authors', methods=['GET'])def index(): get_authors = Authors.query.all() author_schema = AuthorsSchema(many=True) authors = author_schema.dump(get_authors) return make_response(jsonify(&#123;"authors": authors&#125;))@app.route('/authors/&lt;id&gt;', methods=['GET'])def get_author_by_id(id): get_author = Authors.query.get(id) author_schema = AuthorsSchema() author = author_schema.dump(get_author) return make_response(jsonify(&#123;"author": author&#125;))@app.route('/authors', methods=['POST'])def create_author(): data = request.get_json() author_schema = AuthorsSchema() author = author_schema.load(data) result = author_schema.dump(author.create()) return make_response(jsonify(&#123;"author": result&#125;), 200)@app.route('/authors/&lt;id&gt;', methods=['PUT'])def update_author_by_id(id): data = request.get_json() get_author = Authors.query.get(id) if data.get('specialisation'): get_author.specialisation = data['specialisation'] if data.get('name'): get_author.name = data['name'] db.session.add(get_author) db.session.commit() author_schema = AuthorsSchema(only=['id', 'name', 'specialisation']) author = author_schema.dump(get_author) return make_response(jsonify(&#123;"author": author&#125;))@app.route('/authors/&lt;id&gt;', methods=['DELETE'])def delete_author_by_id(id): get_author = Authors.query.get(id) db.session.delete(get_author) db.session.commit() return make_response("", 204)if __name__ == "__main__": app.run(host='0.0.0.0', debug=True) 五、测试运行 python app.py 命令开启 Web 服务，使用 httpie 工具测试 REST API。 POST 方法添加新的数据纪录：1234567891011121314$ http POST 127.0.0.1:5000/authors name="starky" specialisation="Python"HTTP/1.0 200 OKContent-Length: 92Content-Type: application/jsonDate: Wed, 27 Nov 2019 02:12:41 GMTServer: Werkzeug/0.16.0 Python/3.7.4&#123; "author": &#123; "id": 1.0, "name": "starky", "specialisation": "Python" &#125;&#125; GET 方法获取数据纪录：12345678910$ http GET 127.0.0.1:5000/authors&#123; "authors": [ &#123; "id": 1.0, "name": "starky", "specialisation": "Python" &#125; ]&#125; PUT 方法更新已有的数据纪录：12345678$ http PUT 127.0.0.1:5000/authors/1 name="skitar" specialisation="Go"&#123; "author": &#123; "id": 1.0, "name": "skitar", "specialisation": "Go" &#125;&#125; DELETE 方法删除某条数据：123456$ http DELETE 127.0.0.1:5000/authors/1$ http GET 127.0.0.1:5000/authors&#123; "authors": []&#125; 参考资料Building REST APIs with Flask]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Python</tag>
        <tag>Web</tag>
        <tag>Development</tag>
        <tag>REST</tag>
        <tag>API</tag>
        <tag>Flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 3.7 通过 asyncio 实现异步编程]]></title>
    <url>%2F2019%2F11%2F07%2Fpython-37-async-programming-with-asyncio%2F</url>
    <content type="text"><![CDATA[Python 中通过 asyncio 实现的异步编程主要包含如下三个模块： 事件循环（event loop）：每一个需要异步执行的任务都会在事件循环中注册，事件循环负责管理这些任务之间的执行流程 协程（Coroutine）：指用于执行具体某个异步任务的函数。函数体中的 await 关键字可以将协程的控制权释放给事件循环 Future：表示已经执行或者尚未执行的任务的结果 在异步程序的世界里，所有代码都运行在事件循环中，可以同时执行多个协程。这些协程异步地执行，直到遇到 await 关键字，此时该协程会让出程序控制权给事件循环，使得其他协程有机会发挥作用。需要注意的是，不能在同一个函数中同时包含异步和同步代码。即在同步函数中无法使用 await 关键字。 一、Hello World以下是一段简单的使用了 async 关键字的 Hello World 程序：12345678910import asyncioasync def hello(first_print, second_print): print(first_print) await asyncio.sleep(1) print(second_print)asyncio.run(hello("Welcome", "Good-bye"))# =&gt; Welcome# =&gt; Good-bye 上述代码的行为看上去更像是同步代码，先输出 Welcome，等待一秒钟之后，再输出 Good-bye。在进一步探究之前，先看下上述异步代码中出现的几个基本概念： Python 语言中，任何由 async def 定义的函数（即上面的 hello()）都可以称之为协程。调用协程函数所返回的对象称为协程对象。 函数 asyncio.run 是所有异步代码的主入口，只应该被调用一次。它负责组织传入的协程对象，同时管理 asyncio 的事件循环。 await 关键字用于将协程运行时获取的程序控制权移交给事件循环，并中断该协程的执行流程。 一个更现实的异步程序的示例如下：1234567891011121314151617181920212223242526import asyncioimport timeasync def say_something(delay, words): print(f"Started: &#123;words&#125;") await asyncio.sleep(delay) print(f"Finished: &#123;words&#125;")async def main(): print(f"Starting Tasks: &#123;time.strftime('%X')&#125;") task1 = asyncio.create_task(say_something(1, "First task")) task2 = asyncio.create_task(say_something(2, "Second task")) await task1 await task2 print(f"Finished Tasks: &#123;time.strftime('%X')&#125;")asyncio.run(main())# =&gt; Starting Tasks: 20:32:28# =&gt; Started: First task# =&gt; Started: Second task# =&gt; Finished: First task# =&gt; Finished: Second task# =&gt; Finished Tasks: 20:32:30 从同步执行的逻辑来看，应该是 task1 开始，等待一秒钟，结束；task2 开始，等待两秒钟，结束。共耗时 3 秒以上。异步程序实际的执行流程为，task1 和 task2 同时开始，各自等待一段时间后，先后结束。共耗时 2 秒。具体如下： task1 中的 say_something 协程开始执行 say_something 遇到 await 关键字时（await asyncio.sleep(delay)），协程暂停执行并等待 1 秒钟，在暂停的同时将程序控制权转移给事件循环 task2 从事件循环获取控制权开始执行，同样遇到 await 关键字时暂停协程并等待 2 秒钟，在暂停的同时将程序控制权转移给事件循环 task1 等待时间结束后，事件循环将控制权移交给 task1，恢复其协程的运行直至结束 task1 运行结束，task2 等待时间完成，task2 获取程序控制权并恢复运行直至结束。两个任务执行完成。 二、Awaitable 对象await 关键字用于将程序控制权移交给事件循环并中断当前协程的执行。它有以下几个使用规则： 只能用在由 async def 修饰的函数中，在普通函数中使用会抛出异常 调用一个协程函数后，就必须等待其执行完成并返回结果 await func() 中的 func() 必须是一个 awaitable 对象。即一个协程函数或者一个在内部实现了 __await__() 方法的对象，该方法会返回一个生成器 Awaitable 对象包含协程、Task 和 Future 等。 协程关于被 await 调用的协程，即上面的第二条规则，可以参考如下代码：12345678910111213141516171819202122232425import asyncioasync def mult(first, second): print(f"Calculating multiply of &#123;first&#125; and &#123;second&#125;") await asyncio.sleep(1) num_mul = first * second print(f"Multiply is &#123;num_mul&#125;") return num_mulasync def sum(first, second): print(f"Calculating sum of &#123;first&#125; and &#123;second&#125;") await asyncio.sleep(1) num_sum = first + second print(f"Sum is &#123;num_sum&#125;") return num_sumasync def main(first, second): await sum(first, second) await mult(first, second)asyncio.run(main(7, 8))# =&gt; Calculating sum of 7 and 8# =&gt; Sum is 15# =&gt; Calculating multiply of 7 and 8# =&gt; Multiply is 56 上述代码中由 await 修饰的两个协程函数 sum 和 mult 即为 awaitable 对象，从输出结果中可以看出，sum 函数先执行完毕并输出结果，随后 mult 函数执行并输出结果。即 await 调用的协程函数必须执行完毕后才能继续执行另外的 await 协程，这看上去并不符合异步程序的定义。 Tasks协程异步执行的关键在于 Tasks。当任意一个协程函数被类似于 asyncio.create_task() 的函数调用时，该协程就会自动排进由事件循环管理的执行流程里。在 asyncio 的定义中，由事件循环控制运行的协程即被称为任务。绝大多数情况下，编写异步代码即意味着需要使用 create_task() 方法将协程放进事件循环。 参考如下代码：12345678910111213141516171819202122232425262728import asyncioasync def mul(first, second): print(f"Calculating multiply of &#123;first&#125; and &#123;second&#125;") await asyncio.sleep(1) num_mul = first * second print(f"Multiply is &#123;num_mul&#125;") return num_mulasync def sum(first, second): print(f"Calculating sum of &#123;first&#125; and &#123;second&#125;") await asyncio.sleep(1) num_sum = first + second print(f"Sum is &#123;num_sum&#125;") return num_sumasync def main(first, second): sum_task = asyncio.create_task(sum(first, second)) mul_task = asyncio.create_task(mul(first, second)) await sum_task await mul_taskasyncio.run(main(7, 8))# =&gt; Calculating sum of 7 and 8# =&gt; Calculating multiply of 7 and 8# =&gt; Sum is 15# =&gt; Multiply is 56 对比上一段代码示例，从输出中可以看出，sum_task 和 mul_task 两个任务的执行流程符合异步程序的逻辑。sum_task 遇到 await asyncio.sleep(1) 语句后并没有让整个程序等待自己返回计算结果，而是中断执行并把控制权通过事件循环移交给 mul_task。两个任务先后执行并进入等待，最后在各自的等待时间结束后输出结果。 除 create_task() 函数以外，还可以使用 asyncio.gather() 函数创建异步任务：123456789101112131415161718192021222324import asyncioimport timeasync def greetings(): print("Welcome") await asyncio.sleep(1) print("Good by")async def main(): await asyncio.gather(greetings(), greetings())def say_greet(): start = time.perf_counter() asyncio.run(main()) elasped = time.perf_counter() - start print(f"Total time elasped: &#123;elasped&#125;")say_greet()# =&gt; Welcome# =&gt; Welcome# =&gt; Good by# =&gt; Good by# =&gt; Total time elasped: 1.0213364 实际两个任务完成的时间略大于 1 秒而不是 2 秒。 FuturesFutures 代表异步操作的预期结果，即该异步操作可能已经执行也可能尚未执行完毕。通常情况下并不需要在代码中显式地管理 Future 对象，这些工作一般由 asyncio 库隐式地处理。 当一个 Future 实例被创建成功以后，即代表该实例关联的异步操作还没有完成，但是会在未来的某个时间返回结果。asyncio 有一个 asyncio.wait_for(aws, timeout, *) 方法可以为异步任务设置超时时间。如果超过指定时间后异步操作仍未执行完毕，则该任务被取消并抛出 asyncio.TimeoutError 异常。timeout 的默认值为 None，即程序会阻塞并一直等待直到 Future 对象关联的操作返回结果。123456789101112131415import asyncioasync def long_time_taking_method(): await asyncio.sleep(4000) print("Completed the work")async def main(): try: await asyncio.wait_for(long_time_taking_method(), timeout=2) except asyncio.TimeoutError: print("Timeout occurred")asyncio.run(main())# =&gt; Timeout occurred 三、Async 实例代码通过创建子进程异步执行 Shell 命令：12345678910111213141516171819202122232425262728293031323334353637import asyncioasync def run(cmd): proc = await asyncio.create_subprocess_shell( cmd, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE) stdout, stderr = await proc.communicate() print(f'[&#123;cmd!r&#125; exited with &#123;proc.returncode&#125;]') if stdout: print(f'[stdout]\n&#123;stdout.decode()&#125;') if stderr: print(f'[stderr]\n&#123;stderr.decode()&#125;')async def main(): await asyncio.gather( run('sleep 2; echo "world"'), run('sleep 1; echo "hello"'), run('ls /zzz'))asyncio.run(main())# =&gt; ['ls /zzz' exited with 2]# =&gt; [stderr]# =&gt; ls: cannot access '/zzz': No such file or directory# =&gt; ['sleep 1; echo "hello"' exited with 0]# =&gt; [stdout]# =&gt; hello# =&gt; ['sleep 2; echo "world"' exited with 0]# =&gt; [stdout]# =&gt; world 通过 Queue 将工作负载分发给多个异步执行的 Task 处理：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576import asyncioimport randomimport timeasync def worker(name, queue): while True: # Get a "work item" out of the queue. sleep_for = await queue.get() # Sleep for the "sleep_for" seconds. await asyncio.sleep(sleep_for) # Notify the queue that the "work item" has been processed. queue.task_done() print(f'&#123;name&#125; has slept for &#123;sleep_for:.2f&#125; seconds')async def main(): # Create a queue that we will use to store our "workload". queue = asyncio.Queue() # Generate random timings and put them into the queue. total_sleep_time = 0 for _ in range(20): sleep_for = random.uniform(0.05, 1.0) total_sleep_time += sleep_for queue.put_nowait(sleep_for) # Create three worker tasks to process the queue concurrently. tasks = [] for i in range(3): task = asyncio.create_task(worker(f'worker-&#123;i&#125;', queue)) tasks.append(task) # Wait until the queue is fully processed. started_at = time.monotonic() await queue.join() total_slept_for = time.monotonic() - started_at # Cancel our worker tasks. for task in tasks: task.cancel() # Wait until all worker tasks are cancelled. await asyncio.gather(*tasks, return_exceptions=True) print('====') print(f'3 workers slept in parallel for &#123;total_slept_for:.2f&#125; seconds') print(f'total expected sleep time: &#123;total_sleep_time:.2f&#125; seconds')asyncio.run(main())# =&gt; worker-2 has slept for 0.12 seconds# =&gt; worker-1 has slept for 0.28 seconds# =&gt; worker-1 has slept for 0.12 seconds# =&gt; worker-0 has slept for 0.46 seconds# =&gt; worker-0 has slept for 0.49 seconds# =&gt; worker-2 has slept for 0.90 seconds# =&gt; worker-1 has slept for 0.62 seconds# =&gt; worker-1 has slept for 0.67 seconds# =&gt; worker-0 has slept for 0.85 seconds# =&gt; worker-2 has slept for 0.94 seconds# =&gt; worker-1 has slept for 0.45 seconds# =&gt; worker-2 has slept for 0.19 seconds# =&gt; worker-0 has slept for 0.99 seconds# =&gt; worker-2 has slept for 0.86 seconds# =&gt; worker-1 has slept for 0.97 seconds# =&gt; worker-0 has slept for 0.74 seconds# =&gt; worker-1 has slept for 0.58 seconds# =&gt; worker-2 has slept for 0.73 seconds# =&gt; worker-1 has slept for 0.27 seconds# =&gt; worker-0 has slept for 0.57 seconds# =&gt; ====# =&gt; 3 workers slept in parallel for 4.10 seconds# =&gt; total expected sleep time: 11.80 seconds 参考资料asyncio — Asynchronous I/O]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Advanced</tag>
        <tag>Python</tag>
        <tag>Concurrency</tag>
        <tag>Performance</tag>
        <tag>Async</tag>
        <tag>Eventloop</tag>
        <tag>Coroutine</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 通过 Celery 框架实现分布式任务队列]]></title>
    <url>%2F2019%2F11%2F06%2Fpython-celery-distributed-message-queue%2F</url>
    <content type="text"><![CDATA[Celery 是一个简单、灵活且可靠的分布式消息处理系统，主要用来作为任务队列对海量消息数据进行实时的处理，在多个程序线程或者主机之间传递和分发工作任务。同时也支持计划任务等需求。 一、环境配置Celery 框架自身并不对传入的消息进行存储，因此在使用前需要先安装第三方的 Message Broker。如 RabbitMQ 和 Redis 等。 安装 RabbitMQ对于 Linux 系统，执行以下命令：12345$ sudo apt-get install rabbitmq-server # 安装 RabbitMQ$ sudo rabbitmqctl add_user myuser mypassword # 添加用户 myuser/mypassword$ sudo rabbitmqctl add_vhost myvhost # 添加 vhost$ sudo rabbitmqctl set_user_tags myuser mytag$ sudo rabbitmqctl set_permissions -p myvhost myuser ".*" ".*" ".*" # 为用户 myuser 设置访问 myvhost 的权限 通过 Docker 安装的步骤如下：123456$ docker pull rabbitmq:3.8-management # 拉取 docker 镜像（包含 web 管理）# 启动 rabbitmq 容器$ docker run -d --name rabbitmq -p 5672:5672 -p 15672:15672 --hostname myRabbit \-e RABBITMQ_DEFAULT_VHOST=myvhost \-e RABBITMQ_DEFAULT_USER=myuser \-e RABBITMQ_DEFAULT_PASS=mypassword rabbitmq:3.8-management 安装 Redis$ sudo apt-get install redis-server 安装 Celery$ pip install celery 二、创建 Celery 应用Celery 应用是该框架所能提供的所有功能（如管理 tasks 和 workers 等）的入口，须确保它可以被其他模块导入。以下是一段简单的 Celery app 代码 tasks.py：12345678910# tasks.pyfrom celery import Celeryapp = Celery('tasks', broker='pyamqp://myuser:mypassword@localhost:5672/myvhost', backend='redis://localhost:6379/0')@app.taskdef add(x, y): return x + y 使用 RabbitMQ 作为 broker 接收和发送任务消息，使用 Redis 作为 backend 存储计算结果。 运行 Celery worker 服务$ celery -A tasks worker --loglevel=info 123456789101112131415161718192021222324$ celery -A tasks worker --loglevel=info -------------- celery@skitarniu-ubuntu18 v4.3.0 (rhubarb)---- **** -------- * *** * -- Linux-4.15.0-60-generic-x86_64-with-debian-buster-sid 2019-11-01 07:21:34-- * - **** ---- ** ---------- [config]- ** ---------- .&gt; app: tasks:0x7f4f30b84a90- ** ---------- .&gt; transport: amqp://myuser:**@localhost:5672/myvhost- ** ---------- .&gt; results: redis://localhost:6379/0- *** --- * --- .&gt; concurrency: 2 (prefork)-- ******* ---- .&gt; task events: OFF (enable -E to monitor tasks in this worker)--- ***** ----- -------------- [queues] .&gt; celery exchange=celery(direct) key=celery[tasks] . tasks.add[2019-11-01 07:21:35,316: INFO/MainProcess] Connected to amqp://myuser:**@127.0.0.1:5672/myvhost[2019-11-01 07:21:35,367: INFO/MainProcess] mingle: searching for neighbors[2019-11-01 07:21:36,535: INFO/MainProcess] mingle: all alone[2019-11-01 07:21:36,782: INFO/MainProcess] celery@skitarniu-ubuntu18 ready. 任务测试进入 Python Shell，执行以下命令发布任务并获取结果：12345678910&gt;&gt;&gt; from tasks import add&gt;&gt;&gt; result = add.delay(4, 4)&gt;&gt;&gt; result&lt;AsyncResult: 6f435bc7-f194-469c-837f-54d77f880ace&gt;&gt;&gt;&gt; result.ready()True&gt;&gt;&gt; result.get()8&gt;&gt;&gt; result.traceback&gt;&gt;&gt; delay() 方法用于发布任务消息，它是 apply_async() 方法的简写，即以异步的方式将任务需求提交给前面启动好的 worker 去处理。delay() 方法返回一个 AsyncResult 对象。result.ready() 方法可以用来检查提交的任务是否已经完成，返回布尔值。 result.get() 方法则用于获取执行完成后的结果。如任务未完成，则程序会一直等待直到有结果返回。因此该方法是阻塞的，并不常用。可以传入 timeout 参数指定等待的时间上限。如 result.get(timeout=1)，尝试获取任务执行后的结果，等待 1 秒。若 1 秒之后结果仍未返回，抛出 celery.exceptions.TimeoutError: The operation timed out. 异常。 如果任务执行过程中有抛出异常，则使用 get() 方法获取结果时会重新抛出该异常导致程序中断。可以通过修改 propagate 参数避免此情况：result.get(propagate=False)result.traceback 则用于获取任务的 traceback 信息。 三、Calling TasksCelery 定义了一些可供 task 实例调用的通用的 Calling API，包括三个方法和一些标准的执行选项： apply_async(args[, kwargs[, ...]])：发送任务消息给 worker delay(*args, **kwargs)：发送任务消息的简写形式，不支持执行选项 calling (__call__)：即在本地进程中直接执行任务函数，不通过 worker 异步执行 以下是一些常见的调用示例： T.delay(arg, kwarg=value) T.apply_async((arg,), {&#39;kwarg&#39;: value}) T.apply_async(countdown=10)10 秒之后开始执行某个任务 T.apply_async(eta=now + timedelta(seconds=10))10 秒之后开始执行某个任务 T.apply_async(countdown=60, expires=120)预计 1 分钟后开始执行，但 2 分钟后还未执行则失效 T.apply_async(expires=now + timedelta(days=2))2 天后失效 通过 countdown 设置任务的延迟执行：123456789101112131415&gt;&gt;&gt; from tasks import add&gt;&gt;&gt; result = add.apply_async((2, 3))&gt;&gt;&gt; result.get()5&gt;&gt;&gt; delay_result = add.apply_async((2, 3), countdown=15)&gt;&gt;&gt; delay_result.ready()False&gt;&gt;&gt; delay_result.ready()False&gt;&gt;&gt; delay_result.ready()False&gt;&gt;&gt; delay_result.ready()True&gt;&gt;&gt; delay_result.get()5 还可以通过 eta（estimated time of arrival） 设置延迟执行的时间：1234&gt;&gt;&gt; from datetime import datetime, timedelta&gt;&gt;&gt; tomorrow = datetime.utcnow() + timedelta(days=1)&gt;&gt;&gt; add.apply_async((2, 3), eta=tomorrow)&lt;AsyncResult: c7dc6d7f-8b87-49d1-8077-73d7f046d709&gt; 此时 worker 在命令行的日志输出如下：12[2019-11-06 05:16:21,362: INFO/MainProcess] Received task: tasks.add[c7dc6d7f-8b87-49d1-8077-73d7f046d709]ETA:[2019-11-07 05:16:06.652736+00:00] 四、计划任务Celery 允许像使用 crontab 那样按计划地定时执行某个任务。参考代码如下：12345678910111213141516171819# tasks.pyfrom celery import Celeryapp = Celery('tasks', broker='pyamqp://myuser:mypassword@localhost:5672/myvhost', backend='redis://localhost:6379/1')app.conf.beat_schedule = &#123; 'add-every-60-seconds': &#123; 'task': 'tasks.add', 'schedule': 60.0, 'args': (16, 16) &#125;,&#125;app.conf.timezone = 'UTC'@app.taskdef add(x, y): print(x + y) 运行 celery -A tasks worker -B 启动 worker 服务。-B 选项表示 beat，即 celery beat 服务，负责执行计划任务。 输出如下（每隔一分钟执行一次）：12345678$ celery -A tasks worker -B...[2019-11-06 05:41:34,057: WARNING/ForkPoolWorker-3] 32[2019-11-06 05:42:33,998: WARNING/ForkPoolWorker-3] 32[2019-11-06 05:43:34,056: WARNING/ForkPoolWorker-3] 32[2019-11-06 05:44:34,105: WARNING/ForkPoolWorker-3] 32[2019-11-06 05:45:34,157: WARNING/ForkPoolWorker-3] 32... 同时 Celery 也支持更复杂的 crontab 类型的时间规划：12345678910from celery.schedules import crontabapp.conf.beat_schedule = &#123; # Executes every Monday morning at 7:30 a.m. 'add-every-monday-morning': &#123; 'task': 'tasks.add', 'schedule': crontab(hour=7, minute=30, day_of_week=1), 'args': (16, 16), &#125;,&#125; Crontab 表达式支持的语法如下： Example Meaning crontab() 每分钟执行一次 crontab(minute=0, hour=0) 每天半夜 0 点执行 crontab(minute=0, hour=&#39;*/3&#39;) 每隔 3 小时执行一次（从 0 时开始） crontab(minute=0, hour=&#39;0,3,6,9,12,15,18,21&#39;) 同上一条 crontab(day_of_week=&#39;sunday&#39;) 只在周日执行，每隔一分钟执行一次 crontab(minute=&#39;*&#39;, hour=&#39;*&#39;, day_of_week=&#39;sun&#39;) 同上一条 crontab(minute=&#39;*/10&#39;, hour=&#39;3,17,22&#39;, day_of_week=&#39;thu,fri&#39;) 只在周四、周五的 3、17、22 时执行，每隔 10 分钟执行一次 crontab(minute=0, hour=&#39;*/2,*/3&#39;) 只在能被 2 或者 3 整除的整点执行 crontab(minute=0, hour=&#39;*/3,8-17&#39;) 在能被 3 整除的整点，和 8-17 点之间的整点执行 crontab(0, 0, day_of_month=&#39;2&#39;) 在每个月的第二天的 0 时执行 crontab(0, 0, day_of_month=&#39;11&#39;, month_of_year=&#39;5&#39;) 在每年的 5 月 11 号 0 点执行 参考资料Celery 4.3.0 documentation]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Advanced</tag>
        <tag>Python</tag>
        <tag>Message</tag>
        <tag>Concurrency</tag>
        <tag>Async</tag>
        <tag>Celery</tag>
        <tag>Distributed</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 中的协程（coroutine）简介]]></title>
    <url>%2F2019%2F11%2F05%2Fpython-coroutines-with-generators%2F</url>
    <content type="text"><![CDATA[Python 中的协程（Coroutine）是一种比线程（Thread）更加轻量的代码执行机构。与线程不同的是，协程完全是由程序本身控制，不需要操作系统内核对其进行调度，因而没有线程切换的开销。同时也不需要多线程中数据同步所依赖的锁机制，执行效率与多线程相比要高出很多。从句法上看，协程可以看作对生成器（Generator）的一种扩展，都是定义体中包含 yield 关键字的函数。启动生成器和协程所需的开销，与调用函数的开销相差无几。 英文中的 yield 有两个意思：产出和让步。 Python 生成器中的 yield 刚好符合了上述两个释义。yield item 会“产出”一个值提供给 next() 的调用方，同时做出“让步”，暂停生成器函数的执行，将程序控制权移交给调用方。直到调用方再次执行 next() 函数，生成器则继续“产出”下一个值。而协程中的 yield 通常出现在表达式右边（如 data = yield），可以产出值，也可以不产出。调用方可以通过 .send(data) 方法向协程提供数据。不管数据如何流动，yield 都是一种用来实现协作式多任务的流程控制工具。协程通过 yield 把控制器让步给中心调度程序，再由调度程序激活其他协程。 一、用作协程的生成器一个最简单的协程实现代码如下：12345# coroutine.pydef simple_coroutine(): print('-&gt; coroutine started') x = yield print('-&gt; coroutine received: ', x) 在 Python Shell 中进行测试，结果如下：123456789101112&gt;&gt;&gt; from coroutine import simple_coroutine&gt;&gt;&gt; my_coro = simple_coroutine()&gt;&gt;&gt; my_coro&lt;generator object simple_coroutine at 0x00000000021B4DC8&gt;&gt;&gt;&gt; next(my_coro)-&gt; coroutine started&gt;&gt;&gt; my_coro.send(42)-&gt; coroutine received: 42Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;StopIteration&gt;&gt;&gt; 上述代码的执行流程为： 主函数调用 next() 函数启动生成器。生成器在 yield 语句处暂停，没有产出值（None） my_coro.send(42) 向协程发送数据 42，协程恢复运行，抛出 StopIteration 异常 协程的状态可以使用 inspect.getgeneratorstate 获取协程的运行状态，共包含以下四种： GEN_CREATED：等待开始执行 GEN_RUNNING：协程正在执行 GEN_SUSPENDED：在 yield 表达式处暂停 GEN_CLOSE：协程执行结束 参考如下代码：123456def simple_coro2(a): print('-&gt; Started: a=', a) b = yield a print('-&gt; Received: b=', b) c = yield a + b print('-&gt; Received: c=', c) 1234567891011121314151617181920&gt;&gt;&gt; my_coro2 = simple_coro2(14)&gt;&gt;&gt; from inspect import getgeneratorstate&gt;&gt;&gt; getgeneratorstate(my_coro2)'GEN_CREATED'&gt;&gt;&gt; next(my_coro2)-&gt; Started: a= 1414&gt;&gt;&gt; getgeneratorstate(my_coro2)'GEN_SUSPENDED'&gt;&gt;&gt; my_coro2.send(28)-&gt; Received: b= 2842&gt;&gt;&gt; my_coro2.send(99)-&gt; Received: c= 99Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;StopIteration&gt;&gt;&gt; getgeneratorstate(my_coro2)'GEN_CLOSED'&gt;&gt;&gt; 协程 simple_coro2 的执行流程分为如下三个阶段： 调用 next(my_coro2)，协程启动，打印消息 Started: a= 14，执行 yield a，产出数字 14 调用 my_coro2.send(28)，把 28 赋值给 b，打印 Received: b= 28，执行 yield a + b，产出数字 42 调用 my_coro2.send(99)，把 99 赋值给 c，打印 Received: c= 99，协程终止 参考如下示意图： 二、使用协程计算移动平均值12345678910# coroaverager.pydef averager(): total = 0.0 count = 0 average = None while True: term = yield average total += term count += 1 average = total/count 在 Python Shell 中进行测试：12345678910&gt;&gt;&gt; from coroaverager import averager&gt;&gt;&gt; coro_avg = averager()&gt;&gt;&gt; next(coro_avg)&gt;&gt;&gt; coro_avg.send(10)10.0&gt;&gt;&gt; coro_avg.send(30)20.0&gt;&gt;&gt; coro_avg.send(5)15.0&gt;&gt;&gt; 从执行结果看，只要调用方不断把数据发送给协程 averager()，协程就会一直接收值并返回平均值的计算结果。其中 yield 表达式用于暂停协程的执行，返回计算结果给调用方，同时等待调用方继续发送数据给协程以恢复循环。 使用装饰器预激协程使用协程之前必须预激（即通过 next() 调用启动协程），可以创建如下的用于预激协程的装饰器：12345678910# coroutil.pyfrom functools import wrapsdef coroutine(func): @wraps(func) def primer(*args, **kwargs): gen = func(*args, **kwargs) next(gen) return gen return primer 此时 coroaverager.py 则可以改为如下版本：123456789101112from coroutil import coroutine@coroutinedef averager(): total = 0.0 count = 0 average = None while True: term = yield average total += term count += 1 average = total/count 123456789&gt;&gt;&gt; from coroaverager import averager&gt;&gt;&gt; coro_avg = averager()&gt;&gt;&gt; coro_avg.send(10)10.0&gt;&gt;&gt; coro_avg.send(20)15.0&gt;&gt;&gt; coro_avg.send(15)15.0&gt;&gt;&gt; 三、协程返回值1234567891011121314151617# coroaverager2.pyfrom collections import namedtupleResult = namedtuple('Result', 'count average')def averager(): total = 0.0 count = 0 average = None while True: term = yield if term is None: break total += term count += 1 average = total/count return Result(count, average) 1234567891011&gt;&gt;&gt; from coroaverager2 import averager&gt;&gt;&gt; coro_avg = averager()&gt;&gt;&gt; next(coro_avg)&gt;&gt;&gt; coro_avg.send(10)&gt;&gt;&gt; coro_avg.send(20)&gt;&gt;&gt; coro_avg.send(15)&gt;&gt;&gt; coro_avg.send(None)Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;StopIteration: Result(count=3, average=15.0)&gt;&gt;&gt; 此处的 yield 表达式只接收数据而不返回任何结果，直到协程收到 None，循环终止协程结束，返回最终结果 Result(...)。return 表达式返回的值会传递给调用方，赋值给 StopIteration 异常的一个属性。因此最终结果需要通过 try...except 语句来捕获。好在 yield from 结构会在内部自动捕获 StopIteration 异常，并把 value 属性的值变成 yield from 表达式的值。 四、yield fromyield from 可以用来简化 for 循环中的 yield 表达式。12345678910111213141516def gen(): for c in 'AB': yield c for i in range(1, 3): yield iprint(list(gen()))# =&gt; ['A', 'B', 1, 2]def gen2(): yield from 'AB' yield from range(1, 3)print(list(gen2()))# =&gt; ['A', 'B', 1, 2] yield from 表示的含义为，在生成器 gen 中使用 yield from subgen() 时，subgen 会获得控制权，其产出的值传递给 gen 的调用方。同时 gen 会阻塞，等待 subgen 终止。 使用 yield from 可以连接多个可迭代对象：123456789def chain(*iterables): for it in iterables: yield from its = 'ABC't = tuple(range(3))print(list(chain(s, t)))# =&gt; ['A', 'B', 'C', 0, 1, 2] yield from 的主要功能是打开双向通道，把最外层的调用方与最内层的子生成器连接起来，使得两者可以直接发送和产出值，而不必在位于中间的协程中添加大量处理异常（StopIteration）的代码。 使用 yield from 计算移动平均值：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566from collections import namedtupleResult = namedtuple('Result', 'count average')# the subgeneratordef averager(): # &lt;1&gt; total = 0.0 count = 0 average = None while True: term = yield # &lt;2&gt; if term is None: # &lt;3&gt; break total += term count += 1 average = total/count return Result(count, average) # &lt;4&gt;# the delegating generatordef grouper(results, key): # &lt;5&gt; while True: # &lt;6&gt; results[key] = yield from averager() # &lt;7&gt;# the client code, a.k.a. the callerdef main(data): # &lt;8&gt; results = &#123;&#125; for key, values in data.items(): group = grouper(results, key) next(group) # &lt;9&gt; for value in values: group.send(value) # &lt;10&gt; group.send(None) # &lt;11&gt; report(results)# output reportdef report(results): for key, result in sorted(results.items()): group, unit = key.split(';') print('&#123;:2&#125; &#123;:5&#125; averaging &#123;:.2f&#125;&#123;&#125;'.format( result.count, group, result.average, unit))data = &#123; 'girls;kg': [40.9, 38.5, 44.3, 42.2, 45.2, 41.7, 44.5, 38.0, 40.6, 44.5], 'girls;m': [1.6, 1.51, 1.4, 1.3, 1.41, 1.39, 1.33, 1.46, 1.45, 1.43], 'boys;kg': [39.0, 40.8, 43.2, 40.8, 43.1, 38.6, 41.4, 40.6, 36.3], 'boys;m': [1.38, 1.5, 1.32, 1.25, 1.37, 1.48, 1.25, 1.49, 1.46],&#125;if __name__ == '__main__': main(data)# =&gt; 9 boys averaging 40.42kg# =&gt; 9 boys averaging 1.39m# =&gt; 10 girls averaging 42.04kg# =&gt; 10 girls averaging 1.43m 注释： ：averager 协程作为被调用的子生成器，计算移动平均值 ：调用方函数 main 发送的值都会绑定给 term 变量 ：终止条件，若无此句代码，子生成器永不终止，yield from 也会一直阻塞 ：返回的 Result 对象将作为 grouper 函数中 yield from 表达式的值 ：grouper 函数作为委派生成器，相当于子生成器和调用方之间的“管道” ：这里 while 循环的每次遍历都会创建一个 averager 协程实例 ：grouper 通过 .send 发送的每一个值都会被 yield from 导向给 averager 实例，待 averager 处理完所有 grouper 发送的值之后，最终的计算结果绑定给 results[key]。while 循环则继续创建另一个 averager 实例用来处理更多的值 ：main 即客户端代码，子生成器的调用方 ：预激协程对象 ：发送数据给 grouper，该数据实际上对 grouper 并不可见，而是通过 yield from 传递给了 averager 中的 term = yield。 我要吐了。再见参考资料Fluent Python]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Advanced</tag>
        <tag>Python</tag>
        <tag>Concurrency</tag>
        <tag>Performance</tag>
        <tag>Coroutine</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 通过 concurrent.futures 模块以异步方式处理并发需求]]></title>
    <url>%2F2019%2F10%2F30%2Fpython-concurrent-futures-async-programming%2F</url>
    <content type="text"><![CDATA[对于计算机程序的执行流而言，I/O 操作通常是时间占比非常大的一块。在当前的硬件设备中，绝大多数 I/O 操作要比 CPU 慢上几个数量级。比如大约花费 1 毫秒写入一个网络 socket，对应到 2.4GHz 的处理器上，同样的时间则可以执行 24000000 条指令。 在一般的同步执行的程序中，当代码遇到 I/O 操作时（如读取一个文件或者写入一个网络 socket），必须暂时中止和内核的交互，去请求 I/O 并等待传输完成。这种因 I/O 阻塞而产生的等待在某些情况下往往导致执行效率的低下和响应的延迟。 而在异步执行的流程中，当一个程序进入 I/O 等待时，其控制权会被移交给程序的其他部分，直到 I/O 操作完成时才可以重新获取（这称为上下文切换）。异步程序中一般会有一个事件循环用来监听事件并分派任务。比如用一个异步程序做一次网络写操作，该请求会立即返回（程序控制权移交给事件循环），即便写操作实际上并未发生。此时程序允许执行另外的函数和运算。当写操作完成时，会触发一个特定的事件，由事件循环响应该事件并执行关联的操作。 同步程序下载网络资源以下代码为使用同步的方式下载网络中存放的多张国旗图片：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# flags.pyimport osimport timeimport sysimport requestsPOP20_CC = ('CN IN US ID BR PK NG BD RU JP ' 'MX PH VN ET EG DE IR TR CD FR').split()BASE_URL = 'http://flupy.org/data/flags'DEST_DIR = 'downloads/'def save_flag(img, filename): if not os.path.exists(DEST_DIR): os.makedirs(DEST_DIR) path = os.path.join(DEST_DIR, filename) with open(path, 'wb') as fp: fp.write(img)def get_flag(cc): url = '&#123;&#125;/&#123;cc&#125;/&#123;cc&#125;.gif'.format(BASE_URL, cc=cc.lower()) resp = requests.get(url) return resp.contentdef show(text): print(text, end=' ') sys.stdout.flush()def download_many(cc_list): for cc in sorted(cc_list): image = get_flag(cc) show(cc) save_flag(image, cc.lower() + '.gif') return len(cc_list)def main(download_many): t0 = time.time() count = download_many(POP20_CC) elapsed = time.time() - t0 msg = '\n&#123;&#125; flags downloaded in &#123;:.2f&#125;s' print(msg.format(count, elapsed))if __name__ == '__main__': main(download_many)# =&gt; BD BR CD CN DE EG ET FR ID IN IR JP MX NG PH PK RU TR US VN# =&gt; 20 flags downloaded in 218.70s 使用 concurrent.futures 模块下载concurrent.futures 模块的主要特色是包含 ThreadPoolExecutor 和 ProcessPoolExecutor 两个类，它们实现的接口可以分别在不同的线程或进程中执行可调用的对象，并且它们内部都维护着一个工作线程（或进程）池和一个任务队列。 下载代码如下（引用了上一个源文件 flags.py 中的几个功能函数）：12345678910111213141516171819202122232425from concurrent import futuresfrom flags import save_flag, get_flag, show, mainMAX_WORKERS = 20def download_one(cc): image = get_flag(cc) show(cc) save_flag(image, cc.lower() + '.gif') return ccdef download_many(cc_list): workers = min(MAX_WORKERS, len(cc_list)) with futures.ThreadPoolExecutor(workers) as executor: res = executor.map(download_one, sorted(cc_list)) return len(list(res))if __name__ == "__main__": main(download_many)# =&gt; EG BD NG CD IN ET RU ID CN FR US PK PH MX IR VN BR JP DE TR# =&gt; 20 flags downloaded in 83.36s 其中最关键的部分为 download_many 函数。workers 变量用于指定 ThreadPoolExecutor 对象使用的工作线程的数量，取预设的最大线程数（MAX_WORKERS）和实际下载数目（len(cc_list)）中的较小的值；with 语句用于使用指定数量（workers）的工作线程初始化 ThreadPoolExecutor 对象；map 方法类似于内置的 map 函数，目的是使 download_one 函数可以被多个工作线程并行地调用。它会返回一个生成器对象，该生成器可以被遍历以获取每一个 download_one 执行后的结果。 Future 对象Python 标准库中包含两个名为 Future 的类：concurrent.futures.Future 和 asyncio.Future 。这两个类的实例都表示可能已经完成或者尚未完成的延迟计算。Future 对象并不是一个立即产生的实际结果，更像是一种“承诺”，需要等待其执行完毕并被我们期待的值所填充。在等待“承诺”兑现的过程中程序可以同时执行其他运算。 Future 是 concurrent.futures 模块和 asyncio 库的重要组件，但是在上面的代码中并没有直接调用 Future 对象。通常情况下，Future 不应该由用户显式地创建，而只能由并发框架实例化。Future 如同它的名字一样，代表将要发生的事情，而确定某件事未来会发生的唯一方式是其执行时间已经排定。Executor.submit() 方法会接收一个可调用对象作为参数并为其排期，返回一个 Future 对象。 用户代码也不应该改变 Future 对象的状态。并发框架会在 Future 代表的延迟计算结束后自动改变 Future 的状态，没有办法人为地控制延迟计算何时结束。Future 具有非阻塞的 .done() 方法，返回布尔值表明 Future 对应的调用对象是否已经执行完毕。此外还有 .add_done_callback() 方法用于在 Future 运行结束后执行特定的回调函数。concurrency.futures.Future 实例还有 .results() 方法用以获取 Future 执行的可调用对象的结果。该方法会阻塞调用方所在的线程，直到可调用对象运行结束并返回结果。result() 方法可以接收可选的 timeout 参数用于设定超时时间。 从更现实的角度理解 Future 对象，可以参考如下代码：12345678910111213141516171819202122232425262728293031323334from concurrent import futuresfrom flags import save_flag, get_flag, show, mainimport timeMAX_WORKERS = 20def download_one(cc): image = get_flag(cc) show(cc) save_flag(image, cc.lower() + '.gif') return ccdef download_many(cc_list): cc_list = cc_list[:5] with futures.ThreadPoolExecutor(max_workers=3) as executor: to_do = [] for cc in sorted(cc_list): future = executor.submit(download_one, cc) to_do.append(future) msg = 'Scheduled for &#123;&#125;: &#123;&#125;' print(msg.format(cc, future)) results = [] for future in futures.as_completed(to_do): res = future.result() msg = '&#123;&#125; result: &#123;!r&#125;' print(msg.format(future, res)) results.append(res) return len(results)if __name__ == '__main__': main(download_many) 此处的代码只通过 3 个工作线程获取 5 个国家的国旗图片。和之前的代码相比，将 download_many 函数中较抽象的 executor.map 替换成了两个 for 循环： executor.submit 用于排定可调用对象（即 download_one(cc)）给多个工作线程执行，返回一个 Future 对象表示这个待执行的操作。 futures.as_completed 则用于在 Future 运行结束后获取可执行对象（即 download_one(cc)）返回的结果。 本例中的 future.result() 方法绝不会阻塞，因为 future 是由 as_completed 函数返回的。 最终输出如下：123456789101112Scheduled for BR: &lt;Future at 0x4524a48 state=running&gt;Scheduled for CN: &lt;Future at 0x3ca46c8 state=running&gt;Scheduled for ID: &lt;Future at 0x453f7c8 state=running&gt;Scheduled for IN: &lt;Future at 0x2ab1308 state=pending&gt;Scheduled for US: &lt;Future at 0x4530888 state=pending&gt;ID BR CN &lt;Future at 0x453f7c8 state=finished returned str&gt; result: &apos;ID&apos;&lt;Future at 0x3ca46c8 state=finished returned str&gt; result: &apos;CN&apos;&lt;Future at 0x4524a48 state=finished returned str&gt; result: &apos;BR&apos;IN &lt;Future at 0x2ab1308 state=finished returned str&gt; result: &apos;IN&apos;US &lt;Future at 0x4530888 state=finished returned str&gt; result: &apos;US&apos;5 flags downloaded in 1.57s 从输出中可以看出，前三个 Future 的状态是 running，后两个 Future 的状态是 pending，因为只有三个工作线程可供分配。同时，如果多运行几次，输出结果的顺序也是有变化的。 关于 GILCython 解释器不是线程安全的，它通过 GIL（Global Interpreter Lock，全局解释器锁）强制性地一次只允许一个线程执行 Python 代码。所以通常一个 Python 进程并不能同时使用多个 CPU 核心，即不能够将一个 Python 进程拆分成多个独立执行的线程在多个 CPU 核心上以并行的方式运行。但是 Python 标准库中所有执行阻塞型 I/O 操作的函数，在等待系统返回结果时都会释放 GIL。即在 I/O 密集型的需求场景下，Python 程序可以通过多线程来提升性能。 参考资料Fluent Python]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Advanced</tag>
        <tag>Python</tag>
        <tag>Concurrency</tag>
        <tag>Performance</tag>
        <tag>Async</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python Cookbook —— 数据结构技巧]]></title>
    <url>%2F2019%2F10%2F27%2Fpython-cookbook-data-structure-tricks%2F</url>
    <content type="text"><![CDATA[一、序列展开与多重赋值任何数据序列（或可迭代对象）都可以只通过一个赋值操作展开自身并同时赋值给多个变量。只需要确保被赋值的变量的数目和结构与序列相符合即可。如：123456&gt;&gt;&gt; p = (4, 5)&gt;&gt;&gt; x, y = p&gt;&gt;&gt; x4&gt;&gt;&gt; y5 对于嵌套的多层次序列，此种方式的多重赋值仍然适用：123456789101112131415&gt;&gt;&gt; data = [ 'ACME', 50, 91.1, (2012, 12, 21) ]&gt;&gt;&gt; name, shares, price, date = data&gt;&gt;&gt; name'ACME'&gt;&gt;&gt; date(2012, 12, 21)&gt;&gt;&gt; name, shares, price, (year, mon, day) = data&gt;&gt;&gt; name'ACME'&gt;&gt;&gt; year2012&gt;&gt;&gt; mon12&gt;&gt;&gt; day21 序列展开同样适用于任何可迭代对象（即内部实现了 __iter__ 方法的对象，如字符串等），示例如下：12345678&gt;&gt;&gt; s = 'Hello'&gt;&gt;&gt; a, b, c, d, e = s&gt;&gt;&gt; a'H'&gt;&gt;&gt; b'e'&gt;&gt;&gt; e'o' 忽略特定的值在序列展开并赋值时，可以忽略指定项目，方法如下：123456&gt;&gt;&gt; data = [ 'ACME', 50, 91.1, (2012, 12, 21) ]&gt;&gt;&gt; _, shares, price, _ = data&gt;&gt;&gt; shares50&gt;&gt;&gt; price91.1 展开为固定长度在序列展开并赋值时，被赋值的变量数目和结构如果与序列本身不符合，则会报出 ValueError ：12345&gt;&gt;&gt; p = (4, 5, 6)&gt;&gt;&gt; x, y = pTraceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;ValueError: too many values to unpack (expected 2) 如上面的示例，当展开的序列长度大于期望的变量数目时，可以对变量使用 * 操作符将多个项目保存在列表结构中，如：123456789def drop_first_last(grades): first, *middle, last = sorted(grades) return sum(middle) / len(middle)grades = [ 100, 94, 96, 88, 70, 62, 80 ]print(f"&#123; drop_first_last(grades) &#125;")# =&gt; 85.6print(sum([94, 96, 88, 70, 80]) / 5)# =&gt; 85.6 其他应用示例如：12345678&gt;&gt;&gt; record = ('Dave', 'dave@example.com', '773-555-1212', '847-555-1212')&gt;&gt;&gt; name, email, *phone_numbers = record&gt;&gt;&gt; name'Dave'&gt;&gt;&gt; email'dave@example.com'&gt;&gt;&gt; phone_numbers['773-555-1212', '847-555-1212'] * 操作符的特性使其可以很方便地应用在字符串分割中：12345678&gt;&gt;&gt; line = 'nobody:*:-2:-2:Unprivileged User:/var/empty:/usr/bin/false'&gt;&gt;&gt; uname, *fields, homedir, sh = line.split(':')&gt;&gt;&gt; uname'nobody'&gt;&gt;&gt; homedir'/var/empty'&gt;&gt;&gt; sh'/usr/bin/false' 结合 _ 还可以写出如下代码以在赋值时忽略序列中的多个项目：123456&gt;&gt;&gt; record = ('ACME', 50, 123.45, (12, 18, 2012))&gt;&gt;&gt; name, *_, (*_, year) = record&gt;&gt;&gt; name'ACME'&gt;&gt;&gt; year2012 二、检索序列中最大或最小的 N 个项目Python 的 heapq 模块包含 nlargest() 和 nsmallest() 函数，可以用来筛选某个数据序列中最大或最小的 N 个值。12345678import heapqnums = [1, 8, 2, 23, 7, -4, 18, 23, 42, 37, 2]print(heapq.nlargest(3, nums))print(heapq.nsmallest(3, nums))# =&gt; [42, 37, 23]# =&gt; [-4, 1, 2] 上面两个函数也可以接收一个名为 key 的参数，使其可以应用在更复杂的数据结构中：123456789101112131415161718import heapqportfolio = [ &#123;'name': 'IBM', 'shares': 100, 'price': 91.1&#125;, &#123;'name': 'AAPL', 'shares': 50, 'price': 543.22&#125;, &#123;'name': 'FB', 'shares': 200, 'price': 21.09&#125;, &#123;'name': 'HPQ', 'shares': 35, 'price': 31.75&#125;, &#123;'name': 'YHOO', 'shares': 45, 'price': 16.35&#125;, &#123;'name': 'ACME', 'shares': 75, 'price': 115.65&#125;]cheap = heapq.nsmallest(2, portfolio, key=lambda s: s['price'])expensive = heapq.nlargest(2, portfolio, key=lambda s: s['price'])print(cheap)# =&gt; [&#123;'name': 'YHOO', 'shares': 45, 'price': 16.35&#125;, &#123;'name': 'FB', 'shares': 200, 'price': 21.09&#125;]print(expensive)# =&gt; [&#123;'name': 'AAPL', 'shares': 50, 'price': 543.22&#125;, &#123;'name': 'ACME', 'shares': 75, 'price': 115.65&#125;] heapq 中的 nlargest() 和 nsmallest() 两个函数的原理都是将数据序列转换为列表结构并且以堆（heap）的形式进行组织。heap 最重要的属性为， heap[0] 永远是序列中最小的值。使用 heapq.heappop() 方法可以获取 heap 中的第一个值（即最小值），而之前第二小的值则移动到第一的位置。即不断调用 heappop() 可以一直获取当前序列中最小的值。123456789101112131415&gt;&gt;&gt; nums = [1, 8, 2, 23, 7, -4, 18, 23, 42, 37, 2]&gt;&gt;&gt; import heapq&gt;&gt;&gt; heapq.heapify(nums)&gt;&gt;&gt; nums[-4, 2, 1, 23, 7, 2, 18, 23, 42, 37, 8]&gt;&gt;&gt; heapq.heappop(nums)-4&gt;&gt;&gt; heapq.heappop(nums)1&gt;&gt;&gt; heapq.heappop(nums)2&gt;&gt;&gt; heapq.heappop(nums)2&gt;&gt;&gt; heapq.heappop(nums)7 PS：如果只想检索某一个最大值或最小值，min() 或者 max() 更快；如果 nlargest(N, items) 或 nsmallest(N, items) 中的 N 与 items 集合的大小很接近，则先对集合进行排序再分片的方式更快一点，即 sorted(itmes)[:N]（实际 nlargest 和 nsmallest 内部本身也是这样实现的） 三、实现一个加权队列以下的代码实现了一种支持加权的队列，即队列中的项目会按指定的权重排序，并且每次调用 pop 方法都可以返回权重最高的项目。1234567891011121314151617181920212223242526272829import heapqclass PriorityQueue: def __init__(self): self._queue = [] self._index = 0 def push(self, item, priority): heapq.heappush(self._queue, (-priority, self._index, item)) self._index += 1 def pop(self): return heapq.heappop(self._queue)[-1]# test codeq = PriorityQueue()q.push('foo', 1)q.push('bar', 5)q.push('spam', 4)q.push('grok', 1)print(q.pop())# =&gt; barprint(q.pop())# =&gt; spamprint(q.pop())# =&gt; fooprint(q.pop())# =&gt; grok 其中 heapq.heappush() 函数可以向 _queue 序列中插入数据，之后再使用 heapq.heappop() 函数获取序列中的数据时，总能保证取出的数据是当时队列中最小的那个。pop 和 push 操作的复杂度为 O(logN)，比普通列表形式的操作（复杂度为 O(N)）效率更高。同时数据是以元组 (-priority, _index, item) 的形式存入到 _queue 队列中的，元组可以依据自身的每个数据项依次进行比对并确定大小关系。因而权重 -priority 可以作为排序的首要依据（加负号是为了使权重高的值更小，可以优先被 pop() 返回）。当权重一样即 -priority 的值相同时，则根据插入的顺序（_index）返回数据。 四、比较字典中的 Value参考下面的代码示例：12345678910prices = &#123; 'ACME': 45.23, 'AAPL': 612.78, 'IBM': 205.55, 'HPQ': 37.20, 'FB': 10.75&#125;print(min(prices)) # =&gt; 'AAPL'print(max(prices)) # =&gt; 'IBM' 从输出中可以看出，min(prices) 和 max(prices) 函数只是处理字典 prices 中的 keys，对 values 则不做任何操作。可以将其改为如下形式：12min(prices.values()) # =&gt; 10.75max(prices.values()) # =&gt; 612.78 则此时上述两个函数又只对字典中的 values 有效，输出的结果中也只包含 values，不包含与之关联的 key 的值。 如果想根据 values 对字典中的数据进行排序，同时输出的结果中既包含 value，又包含与之关联的 key。则可以使用 zip() 函数。zip() 函数以多个可迭代的对象作为参数，将各对象中位置对应的元素打包成一个个元组。回到前面的需求，则可以将字典的 keys 和 values 拆分到两个列表中，再通过 zip() 函数将其中的数据合并成一个个元组（等同于之前的键值对），而 value 作为元组的第一个元素。12345678910111213141516171819prices = &#123; 'ACME': 45.23, 'AAPL': 612.78, 'IBM': 205.55, 'HPQ': 37.20, 'FB': 10.75&#125;for item in zip(prices.values(), prices.keys()): print(item)# =&gt; (45.23, 'ACME')# =&gt; (612.78, 'AAPL')# =&gt; (205.55, 'IBM')# =&gt; (37.2, 'HPQ')# =&gt; (10.75, 'FB')max_price = max(zip(prices.values(), prices.keys()))print(max_price)# =&gt; (612.78, 'AAPL') 五、去除序列中的重复元素集合（set）是 Python 中的一种数据结构，它包含了一系列无序的不重复元素。因此可以通过将其他类型的数据转为 set 类型，为序列中的数据去重。但此种方法不能保留原序列中数据项原本的排列顺序（因为 set 是无序的）。123&gt;&gt;&gt; a = [1, 5, 2, 1, 9, 1, 5, 10]&gt;&gt;&gt; set(a)&#123;1, 2, 5, 9, 10&#125; 下面的函数 dedupe 则实现了去重并保留原本的排列顺序：123456789101112def dedupe(items): seen = set() for item in items: if item not in seen: yield item seen.add(item)a = [1, 5, 2, 1, 9, 1, 5, 10]print(list(dedupe(a)))# =&gt; [1, 5, 2, 9, 10] 而对于更复杂的数据结构，比如对如下的列表进行去重操作：[{&#39;x&#39;:1, &#39;y&#39;:2}, {&#39;x&#39;:1, &#39;y&#39;:3}, {&#39;x&#39;:1, &#39;y&#39;:2}, {&#39;x&#39;:2, &#39;y&#39;:4}] 则可以将 dedupe 函数改为如下形式：123456789101112131415def dedupe(items, key=None): seen = set() for item in items: val = item if key is None else key(item) if val not in seen: yield item seen.add(val)a = [&#123;'x':1, 'y':2&#125;, &#123;'x':1, 'y':3&#125;, &#123;'x':1, 'y':2&#125;, &#123;'x':2, 'y':4&#125;]print(list(dedupe(a, key=lambda d: (d['x'],d['y']))))# =&gt; [&#123;'x': 1, 'y': 2&#125;, &#123;'x': 1, 'y': 3&#125;, &#123;'x': 2, 'y': 4&#125;]print(list(dedupe(a, key=lambda d: (d['x']))))# =&gt; [&#123;'x': 1, 'y': 2&#125;, &#123;'x': 2, 'y': 4&#125;] 额，自行体会吧。。。 六、找出序列中最常出现的项collections.Counter 类可以用来寻找序列中出现次数最多的几个项目。1234567891011121314151617181920212223from collections import Counterwords = [ 'look', 'into', 'my', 'eyes', 'look', 'into', 'my', 'eyes', 'the', 'eyes', 'the', 'eyes', 'the', 'eyes', 'not', 'around', 'the', 'eyes', "don't", 'look', 'around', 'the', 'eyes', 'look', 'into', 'my', 'eyes', "you're", 'under']word_counts = Counter(words)top_three = word_counts.most_common(3)print(top_three)# =&gt; [('eyes', 8), ('the', 5), ('look', 4)]morewords = ['why', 'are', 'you', 'not', 'looking', 'in', 'my', 'eyes']word_counts.update(morewords)print(word_counts.most_common(3))# =&gt; [('eyes', 9), ('the', 5), ('look', 4)]a = Counter(words)b = Counter(morewords)print(a + b)# =&gt; Counter(&#123;'eyes': 9, 'the': 5, 'look': 4, 'my': 4, 'into': 3, 'not': 2, 'around': 2, "don't": 1, "you're": 1, 'under': 1, 'why': 1, 'are': 1, 'you': 1, 'looking': 1, 'in': 1&#125;) 参考资料Python Cookbook, 3rd Edition]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Tricks</tag>
        <tag>Program</tag>
        <tag>Advanced</tag>
        <tag>Python</tag>
        <tag>Cookbook</tag>
        <tag>Datastructure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows 10 通过命令行查看 Wi-Fi 密码]]></title>
    <url>%2F2019%2F10%2F27%2Ffind-wlan-password-in-windows-10%2F</url>
    <content type="text"><![CDATA[本方法仅适用于 Win10 系统，且已连接过该 WiFi 并勾选了记住密码选项。即电脑可自动连接某热点，但之后又不记得该热点密码，无法手动接入其他设备。方法来自于油管上的某视频分享。 前提 Win10 系统 管理员权限 已连接过某热点并保存了密码 步骤一、管理员权限打开命令行可以按下 win+R 组合键调出运行窗口，输出 cmd 并回车。如打开的是普通用户的命令提示符窗口，可右击任务栏中的命令行图标，再右击弹出的 命令提示符 文字，选择 以管理员身份运行。 步骤二、netsh 命令netsh 是 Windows 下的网络配置命令，直接输入该命令并回车，即可进入一个交互式的命令行。运行 wlan show profile 即可获取当前系统中保存的无线热点信息，输出如下：12345678910111213141516C:\Users\Administrator&gt;netshnetsh&gt;wlan show profile接口 WLAN 上的配置文件:组策略配置文件(只读)--------------------------------- &lt;无&gt;用户配置文件------------- 所有用户配置文件 : 3-1-2102 所有用户配置文件 : 103netsh&gt; 上面的 3-1-2102 和 103 即表示此台计算机连接过并记住了密码的热点名称。 步骤三、获取热点密码继续使用 wlan show profile &lt;SSID&gt; key=clear 命令即可获取某热点（由 &lt;SSID&gt; 指定）的具体连接信息：12345678910111213141516171819202122232425262728293031323334353637383940netsh&gt;wlan show profile 103 key=clear接口 WLAN 上的配置文件 103:=======================================================================已应用: 所有用户配置文件配置文件信息------------------- 版本 : 1 类型 : 无线局域网 名称 : 103 控制选项 : 连接模式 : 自动连接 网络广播 : 只在网络广播时连接 AutoSwitch : 请勿切换到其他网络 MAC 随机化: 禁用连接设置--------------------- SSID 数目 : 1 SSID 名称 :“103” 网络类型 : 结构 无线电类型 : [ 任何无线电类型 ] 供应商扩展名 : 不存在安全设置----------------- 身份验证 : WPA2 - 个人 密码 : CCMP 身份验证 : WPA2 - 个人 密码 : GCMP 安全密钥 : 存在 关键内容 : House1886753****费用设置------------- 费用 : 不可用netsh&gt; 其中 关键内容 条目中的 House1886753**** 即代表无线热点 103 的连接密码。 命令列表 netsh wlan show profile wlan show profile &lt;SSID&gt; key=clear]]></content>
      <categories>
        <category>Hack</category>
      </categories>
      <tags>
        <tag>Security</tag>
        <tag>Windows</tag>
        <tag>Wlan</tag>
        <tag>Network</tag>
        <tag>Hack</tag>
        <tag>WiFi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 中的同步编程与异步编程（async）实例对比]]></title>
    <url>%2F2019%2F10%2F11%2Fexamples-about-python-sync-and-async-program%2F</url>
    <content type="text"><![CDATA[同步程序（synchronous program）即每次只执行一个步骤，只有在当前操作的步骤彻底完成之后，才会移动到下一个步骤继续执行。异步程序（asynchronous program）同样每次只接受一个操作步骤，但是它并不会等待当前的操作步骤执行完成后才移动到下一个步骤。 一、同步编程下面的代码负责从队列（queue）中依次取出某个特定的任务并执行。队列是 Python 中的一种实现了 FIFO （先入先出）规则的数据结构，可以调用其 put() 和 get() 方法以相同的顺序存入和取出数据。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import queuedef task(name, work_queue): if work_queue.empty(): print(f"Task &#123;name&#125; nothing to do") else: while not work_queue.empty(): count = work_queue.get() total = 0 print(f"Task &#123;name&#125; running") for x in range(count): total += 1 print(f"Task &#123;name&#125; total: &#123;total&#125;")def main(): """ This is the main entry point for the program. """ # Create the queue of 'work' work_queue = queue.Queue() # Put some 'work' in the queue for work in [15, 10, 5, 2]: work_queue.put(work) # Create some synchronous tasks tasks = [ (task, "One", work_queue), (task, "Two", work_queue) ] # Run the tasks for t, n, q in tasks: t(n, q)if __name__ == "__main__": main()# =&gt; Task One running# =&gt; Task One total: 15# =&gt; Task One running# =&gt; Task One total: 10# =&gt; Task One running# =&gt; Task One total: 5# =&gt; Task One running# =&gt; Task One total: 2# =&gt; Task Two nothing to do 其中的 task() 函数接收字符串和队列作为参数，可以从队列中不断地取出数字并完成计数动作，直到队列为空。而 main() 函数则依次指派两个 task() 函数用于处理同一个队列中的数据。从输出结果中可以看出，排在前面的 Task One 处理了队列中的所有数据，待数据处理完成即 Task One 中的循环退出之后，排在后面的 Task Two 继续执行，但已经没有任何数据需要处理。 二、协作下面版本的程序允许两个工作函数共同处理位于同一队列中的多个任务，达到“协作”的效果。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import queuedef task(name, queue): while not queue.empty(): count = queue.get() total = 0 print(f"Task &#123;name&#125; running") for x in range(count): total += 1 yield print(f"Task &#123;name&#125; total: &#123;total&#125;")def main(): """ This is the main entry point for the program. """ # Create the queue of 'work' work_queue = queue.Queue() # Put some 'work' in the queue for work in [15, 10, 5, 2]: work_queue.put(work) # Create some tasks tasks = [ task("One", work_queue), task("Two", work_queue) ] # Run the tasks done = False while not done: for t in tasks: try: next(t) except StopIteration: tasks.remove(t) if len(tasks) == 0: done = Trueif __name__ == "__main__": main()# =&gt; Task One running# =&gt; Task Two running# =&gt; Task Two total: 10# =&gt; Task Two running# =&gt; Task One total: 15# =&gt; Task One running# =&gt; Task Two total: 5# =&gt; Task One total: 2 代码中最关键的部分即 yield 关键字，它将 task() 函数转变成了生成器（generator）。 生成器函数和其他 Python 函数在调用时并没有太大区别，但是当生成器中的 yield 语句执行时，对程序的控制权会被返还给调用生成器的函数（caller）。有趣的地方在于，还可以通过将生成器传递给 next() 函数，将程序的控制权再次转移给生成器本身。结合前面生成器中的 yield 关键字，最终达到在程序中来回切换上下文的效果。 上面的 main() 函数通过调用 next(t) 将程序控制权转移给某个 Task() 生成器，而 Task() 代码中的 yield 又会在执行完指派给它的某个任务之后，返回结果并将控制权还给 main() 主程序。而 main() 函数继续通过 next(t) 将队列中的下一个任务分配给另一个 Task() 执行，直到任务队列为空。从输出结果中也可以看出，Task One 和 Task Two 都参与了队列中任务的处理。 虽然 Task Two total: 10 最后先于 Task One total: 15 输出，但并不代表该程序是异步执行的。Task Two 先输出的原因仅在于它执行的计数次数少。从逻辑上看，这种通过生成器函数切换程序上下文的方式虽然使多个工作函数同时参与到了任务中，但仍旧总是在当前任务执行完之后才进行上下文的切换。因此仍属于同步程序。 三、阻塞式请求下面的代码示例和上一个版本基本相同，只不过在 Task() 代码中使用 time.sleep(delay) 函数用于模拟阻塞请求，取代了之前的计数操作。阻塞请求是指在一定时间内阻止 CPU 去处理其他任何事件的代码，比如 time.sleep(delay) 就会阻止 CPU 做其他任何操作直到等待的时间结束。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758import timeimport queuedef task(name, queue): while not queue.empty(): delay = queue.get() start_time = time.time() print(f"Task &#123;name&#125; running") time.sleep(delay) print(f"Task &#123;name&#125; total elapsed time: &#123;time.time() - start_time:.1f&#125;") yielddef main(): """ This is the main entry point for the program. """ # Create the queue of 'work' work_queue = queue.Queue() # Put some 'work' in the queue for work in [15, 10, 5, 2]: work_queue.put(work) tasks = [ task("One", work_queue), task("Two", work_queue) ] # Run the tasks start_time = time.time() done = False while not done: for t in tasks: try: next(t) except StopIteration: tasks.remove(t) if len(tasks) == 0: done = True print(f"\nTotal elapsed time: &#123;time.time() - start_time:.1f&#125;")if __name__ == "__main__": main()# =&gt; Task One running# =&gt; Task One total elapsed time: 15.0# =&gt; Task Two running# =&gt; Task Two total elapsed time: 10.0# =&gt; Task One running# =&gt; Task One total elapsed time: 5.0# =&gt; Task Two running# =&gt; Task Two total elapsed time: 2.0# =&gt; Total elapsed time: 32.0 从输出的结果中可以看出，协作的方式并没有加速程序的运行。整个程序执行完耗费的全部时间刚好是阻塞代码引起的延迟时间之和。 四、非阻塞式请求12345678910111213141516171819202122232425262728293031323334353637383940414243import asyncioimport timeasync def task(name, work_queue): while not work_queue.empty(): delay = await work_queue.get() start_time = time.time() print(f"Task &#123;name&#125; running") await asyncio.sleep(delay) print(f"Task &#123;name&#125; total elapsed time: &#123;time.time() - start_time:.1f&#125;")async def main(): """ This is the main entry point for the program. """ # Create the queue of 'work' work_queue = asyncio.Queue() # Put some 'work' in the queue for work in [15, 10, 5, 2]: await work_queue.put(work) # Run the tasks start_time = time.time() await asyncio.gather( asyncio.create_task(task("One", work_queue)), asyncio.create_task(task("Two", work_queue)), ) print(f"\nTotal elapsed time: &#123;time.time() - start_time:.1f&#125;")if __name__ == "__main__": asyncio.run(main())# =&gt; Task One running# =&gt; Task Two running# =&gt; Task Two total elapsed time: 10.0# =&gt; Task Two running# =&gt; Task Two total elapsed time: 5.0# =&gt; Task Two running# =&gt; Task One total elapsed time: 15.0# =&gt; Task Two total elapsed time: 2.0# =&gt; Total elapsed time: 17.0 同上一个版本的程序不同，此处使用 await asyncio.sleep(delay) 替代了之前的 time.sleep(delay) 和 yield 语句，用来创建一个非阻塞的延迟并将程序控制权返还给调用者（即 main() 函数）。而最后一行代码 asyncio.run(main()) 将创建一个事件循环（event loop），用于执行 main() 函数也就是两个 task() 实例。 事件循环是 Python 中 async 机制的核心内容，它负责调用执行所有的工作代码。当具体的某个工作任务在执行过程中遇到 await 语句时，则程序将控制权返还给主事件循环。同时事件循环持续不断地监视着所有工作任务的状态，并根据触发的某个具体事件将程序控制权分配给对应的工作代码。由此保证 CPU 一直处于“紧张”状态，不会被某个 IO 密集型操作阻塞而处于等待状态。await asyncio.sleep(delay) 对于 CPU 而言是非阻塞的。在处理该代码时，CPU 并不会等待延迟的时间结束，而是在事件循环的任务队列中注册一个 sleep 事件，紧接着将程序的控制权直接交还给了事件循环，由事件循环监视可能会触发的事件（比如延迟结束）并分配任务给工作代码。 五、同步 HTTP 请求代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869import queueimport requestsimport timedef task(name, work_queue): with requests.Session() as session: while not work_queue.empty(): url = work_queue.get() print(f"Task &#123;name&#125; getting URL: &#123;url&#125;") start = time.perf_counter() session.get(url) elapsed = time.perf_counter() - start print(f"Task &#123;name&#125; elapsed time: &#123;elapsed&#125;") yielddef main(): """ This is the main entry point for the program """ # Create the queue of work work_queue = queue.Queue() # Put some work in the queue for url in [ "https://www.baidu.com", "https://www.jianshu.com/", "https://www.jd.com/", "https://www.tmall.com/", "https://www.zhihu.com/", "https://www.douban.com/", "https://www.bilibili.com/", ]: work_queue.put(url) tasks = [task("One", work_queue), task("Two", work_queue)] # Run the tasks done = False start = time.perf_counter() while not done: for t in tasks: try: next(t) except StopIteration: tasks.remove(t) if len(tasks) == 0: done = True elapsed = time.perf_counter() - start print(f"Total elapsed time: &#123;elapsed&#125;")if __name__ == "__main__": main()# =&gt; Task One getting URL: https://www.baidu.com# =&gt; Task One elapsed time: 0.1149543260000001# =&gt; Task Two getting URL: https://www.jianshu.com/# =&gt; Task Two elapsed time: 0.09059067599999993# =&gt; Task One getting URL: https://www.jd.com/# =&gt; Task One elapsed time: 0.06162170499999986# =&gt; Task Two getting URL: https://www.tmall.com/# =&gt; Task Two elapsed time: 0.16310405699999975# =&gt; Task One getting URL: https://www.zhihu.com/# =&gt; Task One elapsed time: 5.111851316# =&gt; Task Two getting URL: https://www.douban.com/# =&gt; Task Two elapsed time: 0.31463871600000015# =&gt; Task One getting URL: https://www.bilibili.com/# =&gt; Task One elapsed time: 0.18364096799999974# =&gt; Total elapsed time: 6.082241783 六、异步 HTTP 请求1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162import asyncioimport aiohttpimport timeasync def task(name, work_queue): async with aiohttp.ClientSession() as session: while not work_queue.empty(): url = await work_queue.get() print(f"Task &#123;name&#125; getting URL: &#123;url&#125;") start = time.perf_counter() async with session.get(url) as response: await response.text() elapsed = time.perf_counter() - start print(f"Task &#123;name&#125; elapsed time: &#123;elapsed&#125;")async def main(): """ This is the main entry point for the program """ # Create the queue of work work_queue = asyncio.Queue() # Put some work in the queue for url in [ "https://www.baidu.com", "https://www.jianshu.com/", "https://www.jd.com/", "https://www.tmall.com/", "https://www.zhihu.com/", "https://www.douban.com/", "https://www.bilibili.com/", ]: await work_queue.put(url) # Run the tasks start = time.perf_counter() await asyncio.gather( asyncio.create_task(task("One", work_queue)), asyncio.create_task(task("Two", work_queue)), ) elapsed = time.perf_counter() - start print(f"Total elapsed time: &#123;elapsed&#125;")if __name__ == "__main__": asyncio.run(main())# =&gt; Task One getting URL: https://www.baidu.com# =&gt; Task Two getting URL: https://www.jianshu.com/# =&gt; Task One elapsed time: 0.21159282599999996# =&gt; Task One getting URL: https://www.jd.com/# =&gt; Task One elapsed time: 0.09301454900000006# =&gt; Task One getting URL: https://www.tmall.com/# =&gt; Task One elapsed time: 0.09578595199999995# =&gt; Task One getting URL: https://www.zhihu.com/# =&gt; Task Two elapsed time: 0.4948436540000001# =&gt; Task Two getting URL: https://www.douban.com/# =&gt; Task One elapsed time: 0.218484707# =&gt; Task One getting URL: https://www.bilibili.com/# =&gt; Task Two elapsed time: 0.2670722139999997# =&gt; Task One elapsed time: 0.22822054000000014# =&gt; Total elapsed time: 0.867767489 参考资料Getting Started With Async Features in Python]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Python</tag>
        <tag>Development</tag>
        <tag>async</tag>
        <tag>concurency</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django REST framework 教程（2）—— 序列化]]></title>
    <url>%2F2019%2F10%2F11%2Fdjango-rest-framework-2-serializer%2F</url>
    <content type="text"><![CDATA[参考自 Django REST framework 官方文档 ，权作笔记。 一、环境搭建通过 Python3 内置的 venv 模块创建虚拟开发环境：123$ python3 -m venv env # 创建名为 env 的虚拟环境$ source env/bin/activate # 启用虚拟环境# env\Scripts\activate Windows 系统启用虚拟环境 安装依赖库：123$ pip install django$ pip install djangorestframework$ pip install pygments # We&apos;ll be using this for the code highlighting 初始化项目123$ django-admin startproject tutorial$ cd tutorial$ python manage.py startapp snippets 编辑 tutorial/tutorial/settings.py 配置文件，将 rest_framework 和 snippets APP 添加到 INSTALLED_APPS 选项中。12345INSTALLED_APPS = [ ... &apos;rest_framework&apos;, &apos;snippets.apps.SnippetsConfig&apos;,] 二、创建模型编辑 tutorial/snippets/models.py 文件创建数据模型。内容如下：12345678910111213141516171819from django.db import modelsfrom pygments.lexers import get_all_lexersfrom pygments.styles import get_all_stylesLEXERS = [item for item in get_all_lexers() if item[1]]LANGUAGE_CHOICES = sorted([(item[1][0], item[0]) for item in LEXERS])STYLE_CHOICES = sorted([(item, item) for item in get_all_styles()])class Snippet(models.Model): created = models.DateTimeField(auto_now_add=True) title = models.CharField(max_length=100, blank=True, default=&apos;&apos;) code = models.TextField() linenos = models.BooleanField(default=False) language = models.CharField(choices=LANGUAGE_CHOICES, default=&apos;python&apos;, max_length=100) style = models.CharField(choices=STYLE_CHOICES, default=&apos;friendly&apos;, max_length=100) class Meta: ordering = [&apos;created&apos;] 使用以下命令完成数据库迁移操作：12$ python manage.py makemigrations snippets$ python manage.py migrate 三、创建序列化器序列化是指将 Web API 提供的后台数据已特定的形式（如 json 格式）展示给用户，方便前端程序调用。 以下代码反映了一个序列化器的基本逻辑。编辑 tutorial/snippets/serializers.py 文件，内容如下：1234567891011121314151617181920212223242526272829from rest_framework import serializersfrom snippets.models import Snippet, LANGUAGE_CHOICES, STYLE_CHOICESclass SnippetSerializer(serializers.Serializer): id = serializers.IntegerField(read_only=True) title = serializers.CharField(required=False, allow_blank=True, max_length=100) code = serializers.CharField(style=&#123;&apos;base_template&apos;: &apos;textarea.html&apos;&#125;) linenos = serializers.BooleanField(required=False) language = serializers.ChoiceField(choices=LANGUAGE_CHOICES, default=&apos;python&apos;) style = serializers.ChoiceField(choices=STYLE_CHOICES, default=&apos;friendly&apos;) def create(self, validated_data): &quot;&quot;&quot; Create and return a new `Snippet` instance, given the validated data. &quot;&quot;&quot; return Snippet.objects.create(**validated_data) def update(self, instance, validated_data): &quot;&quot;&quot; Update and return an existing `Snippet` instance, given the validated data. &quot;&quot;&quot; instance.title = validated_data.get(&apos;title&apos;, instance.title) instance.code = validated_data.get(&apos;code&apos;, instance.code) instance.linenos = validated_data.get(&apos;linenos&apos;, instance.linenos) instance.language = validated_data.get(&apos;language&apos;, instance.language) instance.style = validated_data.get(&apos;style&apos;, instance.style) instance.save() return instance ModelSerializerDjango REST framework 框架通过 serializers 中的某些类对序列化器的逻辑功能做了封装与抽象，因此可以通过这些类完成与上面代码同样的需求，同时代码的冗余度大大降低。可以将 tutorial/snippets/serializers.py 文件改为如下版本：1234567from rest_framework import serializersfrom snippets.models import Snippetclass SnippetSerializer(serializers.ModelSerializer): class Meta: model = Snippet fields = [&apos;id&apos;, &apos;title&apos;, &apos;code&apos;, &apos;linenos&apos;, &apos;language&apos;, &apos;style&apos;] 四、Django Shell 操作 Serializer运行以下命令进入 Django Shell：$ python manage.py shell 。 通过 Snippet 模型创建数据纪录：12345678&gt;&gt;&gt; from snippets.models import Snippet&gt;&gt;&gt; from snippets.serializers import SnippetSerializer&gt;&gt;&gt; from rest_framework.renderers import JSONRenderer&gt;&gt;&gt; from rest_framework.parsers import JSONParser&gt;&gt;&gt; snippet = Snippet(code=&apos;foo = &quot;bar&quot;\n&apos;)&gt;&gt;&gt; snippet.save()&gt;&gt;&gt; snippet = Snippet(code=&apos;print(&quot;hello, world&quot;)\n&apos;)&gt;&gt;&gt; snippet.save() 序列化数据对象并以 JSON 的形式展示：123456&gt;&gt;&gt; serializer = SnippetSerializer(snippet)&gt;&gt;&gt; serializer.data&#123;&apos;id&apos;: 2, &apos;title&apos;: &apos;&apos;, &apos;code&apos;: &apos;print(&quot;hello, world&quot;)\n&apos;, &apos;linenos&apos;: False, &apos;language&apos;: &apos;python&apos;, &apos;style&apos;: &apos;friendly&apos;&#125;&gt;&gt;&gt; content = JSONRenderer().render(serializer.data)&gt;&gt;&gt; contentb&apos;&#123;&quot;id&quot;:2,&quot;title&quot;:&quot;&quot;,&quot;code&quot;:&quot;print(\\&quot;hello, world\\&quot;)\\n&quot;,&quot;linenos&quot;:false,&quot;language&quot;:&quot;python&quot;,&quot;style&quot;:&quot;friendly&quot;&#125;&apos; 反序列化：12345678910&gt;&gt;&gt; import io&gt;&gt;&gt; stream = io.BytesIO(content)&gt;&gt;&gt; data = JSONParser().parse(stream)&gt;&gt;&gt; serializer = SnippetSerializer(data=data)&gt;&gt;&gt; serializer.is_valid()True&gt;&gt;&gt; serializer.validated_dataOrderedDict([(&apos;title&apos;, &apos;&apos;), (&apos;code&apos;, &apos;print(&quot;hello, world&quot;)&apos;), (&apos;linenos&apos;, False), (&apos;language&apos;, &apos;python&apos;), (&apos;style&apos;, &apos;friendly&apos;)])&gt;&gt;&gt; serializer.save()&lt;Snippet: Snippet object (3)&gt; 序列化多个模型实例：123&gt;&gt;&gt; serializer = SnippetSerializer(Snippet.objects.all(), many=True)&gt;&gt;&gt; serializer.data[OrderedDict([(&apos;id&apos;, 1), (&apos;title&apos;, &apos;&apos;), (&apos;code&apos;, &apos;foo = &quot;bar&quot;\n&apos;), (&apos;linenos&apos;, False), (&apos;language&apos;, &apos;python&apos;), (&apos;style&apos;, &apos;friendly&apos;)]), OrderedDict([(&apos;id&apos;, 2), (&apos;title&apos;, &apos;&apos;), (&apos;code&apos;, &apos;print(&quot;hello, world&quot;)\n&apos;), (&apos;linenos&apos;, False), (&apos;language&apos;, &apos;python&apos;), (&apos;style&apos;, &apos;friendly&apos;)]), OrderedDict([(&apos;id&apos;, 3), (&apos;title&apos;, &apos;&apos;), (&apos;code&apos;, &apos;print(&quot;hello, world&quot;)&apos;), (&apos;linenos&apos;, False), (&apos;language&apos;, &apos;python&apos;), (&apos;style&apos;, &apos;friendly&apos;)])] 五、视图编辑 tutorial/snippets/views.py 文件，创建 snippet_list 和 snippet_detail 两个视图函数，并添加上对 GET、POST 等请求的响应逻辑。内容如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051from django.http import HttpResponse, JsonResponsefrom django.views.decorators.csrf import csrf_exemptfrom rest_framework.parsers import JSONParserfrom snippets.models import Snippetfrom snippets.serializers import SnippetSerializer@csrf_exemptdef snippet_list(request): &quot;&quot;&quot; List all code snippets, or create a new snippet. &quot;&quot;&quot; if request.method == &apos;GET&apos;: snippets = Snippet.objects.all() serializer = SnippetSerializer(snippets, many=True) return JsonResponse(serializer.data, safe=False) elif request.method == &apos;POST&apos;: data = JSONParser().parse(request) serializer = SnippetSerializer(data=data) if serializer.is_valid(): serializer.save() return JsonResponse(serializer.data, status=201) return JsonResponse(serializer.errors, status=400)@csrf_exemptdef snippet_detail(request, pk): &quot;&quot;&quot; Retrieve, update or delete a code snippet. &quot;&quot;&quot; try: snippet = Snippet.objects.get(pk=pk) except Snippet.DoesNotExist: return HttpResponse(status=404) if request.method == &apos;GET&apos;: serializer = SnippetSerializer(snippet) return JsonResponse(serializer.data) elif request.method == &apos;PUT&apos;: data = JSONParser().parse(request) serializer = SnippetSerializer(snippet, data=data) if serializer.is_valid(): serializer.save() return JsonResponse(serializer.data) return JsonResponse(serializer.errors, status=400) elif request.method == &apos;DELETE&apos;: snippet.delete() return HttpResponse(status=204) 六、路由配置编辑 tutorial/snippets/urls.py 文件，完成视图与 URL 路径的关联：1234567from django.urls import pathfrom snippets import viewsurlpatterns = [ path(&apos;snippets/&apos;, views.snippet_list), path(&apos;snippets/&lt;int:pk&gt;/&apos;, views.snippet_detail),] 在 tutorial/tutorial/urls.py 配置文件中引入 snippets 应用的路由配置：1234567from django.contrib import adminfrom django.urls import pathurlpatterns = [ path(&apos;&apos;, include(&apos;snippets.urls&apos;)), path(&apos;admin/&apos;, admin.site.urls),] 七、测试运行 $ python manage.py runserver 命令开启测试服务，使用 httpie 工具对 API 进行访问测试，结果如下： GET 方法获取数据：12345678910111213141516171819$ http -b 172.20.19.76:8000/snippets/[ &#123; &quot;code&quot;: &quot;foo = \&quot;bar\&quot;\n&quot;, &quot;id&quot;: 1, &quot;language&quot;: &quot;python&quot;, &quot;linenos&quot;: false, &quot;style&quot;: &quot;friendly&quot;, &quot;title&quot;: &quot;&quot; &#125;, &#123; &quot;code&quot;: &quot;print(\&quot;hello, world\&quot;)\n&quot;, &quot;id&quot;: 2, &quot;language&quot;: &quot;python&quot;, &quot;linenos&quot;: false, &quot;style&quot;: &quot;friendly&quot;, &quot;title&quot;: &quot;&quot; &#125;] POST 方法添加新的数据：123456789$ http -b POST 172.20.19.76:8000/snippets/ code=&quot;a = 1\nb = 2\nprint(a + b)&quot;&#123; &quot;code&quot;: &quot;a = 1\\nb = 2\\nprint(a + b)&quot;, &quot;id&quot;: 4, &quot;language&quot;: &quot;python&quot;, &quot;linenos&quot;: false, &quot;style&quot;: &quot;friendly&quot;, &quot;title&quot;: &quot;&quot;&#125;]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Python</tag>
        <tag>Web</tag>
        <tag>Development</tag>
        <tag>Django</tag>
        <tag>REST</tag>
        <tag>API</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python Web 开发之 Django Models 详解]]></title>
    <url>%2F2019%2F10%2F09%2Fpython-web-development-django-models%2F</url>
    <content type="text"><![CDATA[Django 是由 Python 语言编写的基于 MVC（即 Model View Controller）架构的 Web 开发框架。其架构中的模型（Model）主要负责处理 Web 应用的数据逻辑部分，包括定义数据存储单位（即数据库表）的字段属性和行为、与数据库交互以及其他相关联的操作。通常一个模型映射于一个特定的数据库表。 Django 中的模型有以下几个基本属性： 每个模型都是继承自 django.db.models.Model 类的子类 模型类的属性分别对应于与之相关联的数据表中的字段 Django 会自动生成用于访问数据库的 API 一、基本使用项目初始化在开始编写 Web 应用代码之前，需要先使用如下命令初始化一个 Django 项目并创建应用：123$ django-admin startproject myproject$ cd myproject$ python manage.py startapp myapp 最终生成的项目目录结构如下：123456789101112131415myproject ├─manage.py │ ├─myapp │ ├─admin.py │ ├─apps.py │ ├─models.py │ ├─tests.py │ ├─views.py │ └─migrations │ └─myproject ├─settings.py ├─urls.py └─wsgi.py 定义模型用于定义模型的代码通常保存在 myproject/myapp/models.py 文件中。下面的代码即定义了一个简单的 Person 模型：12345from django.db import modelsclass Person(models.Model): first_name = models.CharField(max_length=30) last_name = models.CharField(max_length=30) 其中的 first_name 和 last_name 两个类属性即对应于数据库表的两个字段。Person 模型会以如下的 SQL 语句创建与之关联的数据库表（id 字段默认会自动添加）：12345CREATE TABLE myapp_person ( &quot;id&quot; serial NOT NULL PRIMARY KEY, &quot;first_name&quot; varchar(30) NOT NULL, &quot;last_name&quot; varchar(30) NOT NULL); 为了使模型生效，还需要将 myapp 包含进 settings.py 配置文件中的 INSTALLED_APPS，编辑 myproject/myproject/settings.py 文件，内容如下：12345INSTALLED_APPS = [ #... &apos;myapp&apos;, #...] 之后即可使用 python manage.py makemigrations myapp 创建数据库迁移文件；再运行 python manage.py migrate 命令将模型中定义的表结构迁移至数据库中。 Django Shell 测试完成数据库迁移后，可使用 python manage.py shell 命令进入 Django Shell 交互式命令行，通过 Django 提供的模型 API 进行测试（插入数据）：1234567&gt;&gt;&gt; from myapp.models import Person&gt;&gt;&gt; john = Person(first_name=&apos;John&apos;, last_name=&apos;Smith&apos;)&gt;&gt;&gt; john.save()&gt;&gt;&gt; Person.objects.all()&lt;QuerySet [&lt;Person: Person object (1)&gt;]&gt;&gt;&gt;&gt; john.first_name&apos;John&apos; 访问 sqlite3 数据库查询最终结果，John Smith 已添加至数据表中：1234567&gt;&gt;&gt; import sqlite3&gt;&gt;&gt; conn = sqlite3.connect(&apos;db.sqlite3&apos;)&gt;&gt;&gt; cursor = conn.cursor()&gt;&gt;&gt; cursor.execute(&apos;select * from myapp_person&apos;)&lt;sqlite3.Cursor object at 0x0000022C36ADBD50&gt;&gt;&gt;&gt; print(cursor.fetchone())(1, &apos;John&apos;, &apos;Smith&apos;) 二、字段（Field）模型中最重要的也是唯一必须存在的项目就是字段，它由模型类的属性定义，用来表述与模型相关联的数据表的结构。 字段的类型与选项模型中的每个字段都是 django.db.models.Field 类的实例，对应于数据库表中的列。Django 内置了大量的字段类型，如 CharField，TextField 和 DateTimeField 等。具体可查看 模型字段参考。 每个字段都可以接收特定的字段相关的参数，比如 CharField 需要传入 max_length 用于定义 VARCHAR 类型的字符长度。 此外还有一些通用的可选的字段选项。如： null：如为 True，则 Django 会将空值在数据库中存为 NULL。该选项默认为 False。 blank：如为 True，则该字段允许为空。与 null 选项不同，blank 是与表单验证相关的，而 null 是数据库相关的。 default：用于设置字段的默认值。 primary_key：用于设置模型的主键。如未指定任何字段为主键，则 Django 会自动添加 IntegerField 字段作为主键。 unique：设置字段的值是否允许重复。 PS：默认情况下，Django 会给每个模型添加如下字段id = models.AutoField(primary_key=True)作为为自增的主键。如果想覆盖此默认行为，直接手动指定其他字段为主键（primary_key=True）即可。 关系额，关系型数据库的强大之处即在于各数据库表之间的相互关联。Django 支持定义三种最常见的数据库关系：多对一、多对多和一对一。 可以通过 django.db.models.ForeignKey 创建多对一关系，只需要像定义其他字段那样将它作为类属性引入即可。如：123456789from django.db import modelsclass Manufacturer(models.Model): name = models.CharField(max_length=20) location = models.CharField(max_length=40)class Car(models.Model): manufacturer = models.ForeignKey(Manufacturer, on_delete=models.CASCADE) price = models.IntegerField() 运行 python manage.py makemigrations 命令创建数据库迁移文件：12345$ python manage.py makemigrations myappMigrations for &apos;myapp&apos;: myapp/migrations/0001_initial.py - Create model Manufacturer - Create model Car 使用 python manage.py sqlmigrate myapp 0001 命令查看具体会执行哪些 SQL 语句（基于 sqlite3）：123456789101112$ python manage.py sqlmigrate myapp 0001BEGIN;---- Create model Manufacturer--CREATE TABLE &quot;myapp_manufacturer&quot; (&quot;id&quot; integer NOT NULL PRIMARY KEY AUTOINCREMENT, &quot;name&quot; varchar(20) NOT NULL, &quot;location&quot; varchar(40) NOT NULL);---- Create model Car--CREATE TABLE &quot;myapp_car&quot; (&quot;id&quot; integer NOT NULL PRIMARY KEY AUTOINCREMENT, &quot;price&quot; integer NOT NULL, &quot;manufacturer_id&quot; integer NOT NULL REFERENCES &quot;myapp_manufacturer&quot; (&quot;id&quot;) DEFERRABLE INITIALLY DEFERRED);CREATE INDEX &quot;myapp_car_manufacturer_id_2be676ab&quot; ON &quot;myapp_car&quot; (&quot;manufacturer_id&quot;);COMMIT; 多对多和一对一的数据库关系则分别可以使用 ManyToManyField 和 OneToOneField 定义。 三、模型的属性与方法Meta 选项模型的 Meta 选项在模型类的定义中是可选的，它基本上包含了除字段以外的所有内容。比如数据纪录的顺序（ordering）、关联的数据库表的名称（db_table）和索引（indexes）等。 Django 模型支持的所有 Meta 选项可以参考 Model Meta options 示例代码：12345678from django.db import modelsclass Ox(models.Model): horn_length = models.IntegerField() class Meta: ordering = [&quot;horn_length&quot;] verbose_name_plural = &quot;oxen&quot; 自定义模型方法在模型中创建自定义方法可以为模型对象添加个性化的“底层”功能。参考如下代码：1234567891011from django.db import modelsclass Person(models.Model): first_name = models.CharField(max_length=50) last_name = models.CharField(max_length=50) birth_date = models.DateField() @property def full_name(self): &quot;Returns the person&apos;s full name.&quot; return &apos;%s %s&apos; % (self.first_name, self.last_name) 此时的 Person 模型除了可以从数据库中读取和写入数据等基本功能外，还可以通过它调用自定义的 full_name 方法完成额外的需求（返回全名）。 覆盖默认的模型方法有些情况下，还可以通过修改模型内置的方法，改变模型与数据库的具体交互方式。尤其是 save() （向数据库中存入数据）和 delete() （从数据库中删除纪录）等方法。如：123456789101112131415from django.db import modelsclass Person(models.Model): first_name = models.CharField(max_length=50) last_name = models.CharField(max_length=50) def save(self, *args, **kwargs): self.first_name = self.first_name.capitalize() self.last_name = self.last_name.capitalize() super().save(*args, **kwargs) @property def full_name(self): &quot;Returns the person&apos;s full name.&quot; return &apos;%s %s&apos; % (self.first_name, self.last_name) 重新迁移数据库，进入 Django Shell 测试，结果如下：1234567&gt;&gt;&gt; from myapp.models import Person&gt;&gt;&gt; john = Person(first_name=&apos;john&apos;, last_name=&apos;smith&apos;)&gt;&gt;&gt; john.save()&gt;&gt;&gt; john&lt;Person: Person object (2)&gt;&gt;&gt;&gt; john.full_name&apos;John Smith&apos; 四、数据库操作一旦创建了数据模型，Django 即会自动生成与数据库交互的 API 供用户创建、获取、更新和删除数据对象。 此处先创建如下的模型文件供测试使用：1234567891011121314151617181920212223242526272829from django.db import modelsclass Blog(models.Model): name = models.CharField(max_length=100) tagline = models.TextField() def __str__(self): return self.nameclass Author(models.Model): name = models.CharField(max_length=200) email = models.EmailField() def __str__(self): return self.nameclass Entry(models.Model): blog = models.ForeignKey(Blog, on_delete=models.CASCADE) headline = models.CharField(max_length=255) body_text = models.TextField() pub_date = models.DateField() mod_date = models.DateField() authors = models.ManyToManyField(Author) n_comments = models.IntegerField() n_pingbacks = models.IntegerField() rating = models.IntegerField() def __str__(self): return self.headline Insert可以通过实例化模型类创建一个数据对象，并调用其 save() 方法将对应的记录插入（执行 INSERT SQL 语句）到数据库表中。123456789&gt;&gt;&gt; from myapp.models import Blog&gt;&gt;&gt; b = Blog(name=&apos;Beatles Blog&apos;, tagline=&apos;All the latest Beatles news&apos;)&gt;&gt;&gt; b.save()&gt;&gt;&gt; b.name = &apos;Beatles Blog All&apos;&gt;&gt;&gt; b.save()&gt;&gt;&gt; b&lt;Blog: Beatles Blog All&gt;&gt;&gt;&gt; b.tagline&apos;All the latest Beatles news&apos; 插入 ForeignKey 与 ManyToManyField更新 ForeignKey 与操作普通字段的方式相同，将正确类型的对象赋值给对应字段并调用 save() 方法即可。如：12345&gt;&gt;&gt; from blog.models import Blog, Entry&gt;&gt;&gt; entry = Entry.objects.get(pk=1)&gt;&gt;&gt; cheese_blog = Blog.objects.get(name=&quot;Cheddar Talk&quot;)&gt;&gt;&gt; entry.blog = cheese_blog&gt;&gt;&gt; entry.save() 更新 ManyToManyField 的方式稍有不同，需要使用 add() 方法：123&gt;&gt;&gt; from blog.models import Author&gt;&gt;&gt; joe = Author.objects.create(name=&quot;Joe&quot;)&gt;&gt;&gt; entry.authors.add(joe) 获取数据从数据库中获取数据会生成一个 QuerySet 对象，它代表从数据库中取出的数据对象的集合。QuerySet 等同于数据库中的 SELECT 语句，它可以有零个或者多个 filter 。filter 对应于数据库中的筛选条件如 WHERE 或 LIMIT 等。 获取单个对象&gt;&gt;&gt; one_entry = Entry.objects.get(pk=1) PS：pk 即 primary key 。 获取所有对象&gt;&gt;&gt; all_entries = Entry.objects.all() 应用筛选器&gt;&gt;&gt; entry = Entry.objects.filter(pub_date__year=2006) Limiting&gt;&gt;&gt; entries = Entry.objects.all()[:5] 排序&gt;&gt;&gt; entry = Entry.objects.order_by(&#39;headline&#39;)[0] 字段查询字段查询对应于 SQL 中的 WHERE 语句，可以通过向 QuerySet 对象的方法 filter()、exclude() 和 get() 中传入特定的参数来实现。基本的查询参数语法如下：field__lookuptype=value 。 如：&gt;&gt;&gt; Entry.objects.filter(pub_date__lte=&#39;2006-01-01&#39;)等同于：SELECT * FROM blog_entry WHERE pub_date &lt;= &#39;2006-01-01&#39;; 其中 lte 即 less or equal（小于等于）。其他类似的 lookuptype 还包括 gt（大于）、gte（大于等于）、lt（小于）、exact、iexact（忽略大小写）、startswith、istartswith、endswith、iendswith、contains、range（指定范围）、regex（正则表达式）、iregex 等。 以下为一些常见的使用示例： exact：&gt;&gt;&gt; Entry.objects.get(headline__exact=&quot;Cat bites dog&quot;)等于 SELECT ... WHERE headline = &#39;Cat bites dog&#39;; iexact：&gt;&gt;&gt; Blog.objects.get(name__iexact=&quot;beatles blog&quot;)等于 SELECT ... WHERE name ILIKE &#39;beatles blog&#39;; startswith：&gt;&gt;&gt; Entry.objects.filter(headline__startswith=&#39;Lennon&#39;)等于 SELECT ... WHERE headline LIKE &#39;Lennon%&#39;; contains：&gt;&gt;&gt; Entry.objects.get(headline__contains=&#39;Lennon&#39;)等于 SELECT ... WHERE headline LIKE &#39;%Lennon%&#39;; in：&gt;&gt;&gt; Entry.objects.filter(id__in=[1, 3, 4])等于 SELECT ... WHERE id IN (1, 3, 4); range： 1234import datetimestart_date = datetime.date(2005, 1, 1)end_date = datetime.date(2005, 3, 31)Entry.objects.filter(pub_date__range=(start_date, end_date)) 等于 SELECT ... WHERE pub_date BETWEEN &#39;2005-01-01&#39; and &#39;2005-03-31&#39;; ManagerManager 是提供给 Django 模型，用于做数据库查询操作的接口。Django 项目中的每一个模型都需要至少包含一个 Manager 对象。 默认情况下，Django 会在每一个模型类中添加一个名为 objects 的 Manager 。通过将 models.Manager() 赋值给除 objects 以外的类属性，可以覆盖此默认行为：12345from django.db import modelsclass Person(models.Model): #... people = models.Manager() 此时 Person.objects.all() 查询语句会报出 AttributeError 错误，而 Person.people.all() 则返回所有的 Person 对象。 自定义 Manager自定义的 Manager 方法可以向模型中添加表级别的查询功能。与之对应的纪录级别的功能则需要使用模型方法。 如：123456789101112# First, define the Manager subclass.class DahlBookManager(models.Manager): def get_queryset(self): return super().get_queryset().filter(author=&apos;Roald Dahl&apos;)# Then hook it into the Book model explicitly.class Book(models.Model): title = models.CharField(max_length=100) author = models.CharField(max_length=50) objects = models.Manager() # The default manager. dahl_objects = DahlBookManager() # The Dahl-specific manager. 以上面的模型为例，Book.objects.all() 会返回数据库中所有的书籍信息，而 Book.dahl_objects.all() 则会返回所有作者为 Roald Dahl 的书籍。Django 允许向模型中添加任意数量的 Manager() 实例，因此可以用来为模型定义一些通用的筛选器。如：123456789101112131415class AuthorManager(models.Manager): def get_queryset(self): return super().get_queryset().filter(role=&apos;A&apos;)class EditorManager(models.Manager): def get_queryset(self): return super().get_queryset().filter(role=&apos;E&apos;)class Person(models.Model): first_name = models.CharField(max_length=50) last_name = models.CharField(max_length=50) role = models.CharField(max_length=1, choices=[(&apos;A&apos;, _(&apos;Author&apos;)), (&apos;E&apos;, _(&apos;Editor&apos;))]) people = models.Manager() authors = AuthorManager() editors = EditorManager() 则 Person.people.all()、Person.authors.all() 和 Person.editors.all() 都可以作为从模型中获取数据的接口，且 authors 与 editors 已预先根据 role 对数据进行了筛选。 参考资料Django 2.2 官方文档]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Python</tag>
        <tag>Web</tag>
        <tag>Development</tag>
        <tag>Django</tag>
        <tag>MVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 进阶之并发编程中的多线程]]></title>
    <url>%2F2019%2F09%2F23%2Fpro-python-concurrency-with-multi-threading%2F</url>
    <content type="text"><![CDATA[Two events are concurrent if neither can causally affect the other. 从编程的角度讲，某个问题是可并发的，即代表它可以被完全或部分地分解成多个组件，且这几个组件之间是顺序独立的。换句话说，一个事件被分解成多个相互之间无依赖关系的具体步骤，这些步骤可以独立地被完成，且不管各自完成的顺序如何，都不影响最终的结果。 就像华罗庚先生在《统筹方法》中提到的例子，喝茶需要清洗茶具和烧热水，这是两个相互独立的事件。可以先清洗茶具再烧壶热水，则最终的等待时间是两者独立完成所需的时长之和。更有效率的方法为，先执行比较耗费时间的烧热水动作，并且在等待热水烧开的同时清洗好茶具，效果类似于两个准备步骤同时执行而不是按顺序依次执行。 在程序的世界中，类似的需求同样屡见不鲜。比如用户点击链接下载一个大的文件，通常会把文件下载任务放在后台执行，使得用户可以继续浏览网页，不需要等待下载任务完成。 多线程线程是操作系统能够进行运算调度的最小单位，程序设计者可以将其工作划分成多个可同步运行的线程以应对某些场景和需求。不过在单核系统中，多线程并不会加速程序的运行。而多核或多处理器系统可以将不同的线程分配给多个 CPU 核心同时进行处理，因而能够带来性能上的提升（但 Python 由于 GIL 机制使得这种提升仍有一定的限制）。 在单核系统中，可以通过一种名为时间分片（timeslicing）的机制来实现多线程。即 CPU 可以在多个线程间非常迅速地进行切换，达成一种多个线程“同时”在运行的假象。这种虚拟的并行方式虽然不能带来性能上的提升，但是仍然能够非常好地应对某些特定的需求场景。如： 构建响应式接口：比如将长时间运行的任务放在后台执行，使其等待的过程不会阻塞用户其他的交互动作 任务的分发与委派：对于依赖于第三方资源的进程（比如需要对远程 Web 服务进行大量的请求），多线程可以起到很好的加速效果 构建多用户应用：多用户状态下的多线程类似于独立执行的进程，只不过在某些层面上更加易于管理（共享内存） 示例：多线程请求 Web 数据requests 获取天气信息以下是一个简单的 Web 请求示例，通过 requests 模块访问中国天气网，获取部分城市的天气信息：12345678910111213import requestsdef get_weather(cityid): api_url = &apos;http://www.weather.com.cn/data/sk/&apos; + cityid + &apos;.html&apos; results = requests.get(api_url) results.encoding = &apos;utf-8&apos; weather_info = results.json()[&apos;weatherinfo&apos;] return weather_infoprint(get_weather(&apos;101210101&apos;))# =&gt; &#123;&apos;city&apos;: &apos;杭州&apos;, &apos;cityid&apos;: &apos;101210101&apos;, &apos;temp&apos;: &apos;24.8&apos;, &apos;WD&apos;: &apos;东北风&apos;, &apos;WS&apos;: &apos;小于3级&apos;, &apos;SD&apos;:# &apos;81%&apos;, &apos;AP&apos;: &apos;1000.3hPa&apos;, &apos;njd&apos;: &apos;暂无实况&apos;, &apos;WSE&apos;: &apos;&lt;3&apos;, &apos;time&apos;: &apos;17:50&apos;, &apos;sm&apos;: &apos;2.1&apos;, &apos;isRadar&apos;: &apos;1&apos;, &apos;Radar&apos;: &apos;JC_RADAR_AZ9571_JB&apos;&#125; 获取多个城市天气12345678910111213141516171819202122232425262728293031323334353637import requestsimport timedef get_weather(cityid): api_url = &apos;http://www.weather.com.cn/data/sk/&apos; + cityid + &apos;.html&apos; results = requests.get(api_url) results.encoding = &apos;utf-8&apos; weather_info = results.json()[&apos;weatherinfo&apos;] print(&quot;%s (tmp/humi): %s/%s&quot; % ( weather_info[&apos;city&apos;], weather_info[&apos;temp&apos;], weather_info[&apos;SD&apos;] ))cityids = ( &apos;101210101&apos;, &apos;101010100&apos;, &apos;101090201&apos;, &apos;101020100&apos;, &apos;101280101&apos;, &apos;101230201&apos;)def main(): for id in cityids: get_weather(id)if __name__ == &apos;__main__&apos;: started = time.time() main() elapsed = time.time() - started print(&quot;Time elapsed: &#123;:.2f&#125;s&quot;.format(elapsed))# =&gt; 杭州 (tmp/humi): 24.8/81%# =&gt; 北京 (tmp/humi): 27.9/28%# =&gt; 保定 (tmp/humi): 27.5/43%# =&gt; 上海 (tmp/humi): 23.5/80%# =&gt; 广州 (tmp/humi): 26.6/83%# =&gt; 厦门 (tmp/humi): 26.8/87%# =&gt; Time elapsed: 0.16s 多线程获取多个城市的天气完整代码如下，主要修改了 main 函数：1234567891011121314151617181920212223242526272829303132333435363738394041424344from threading import Threadimport requestsimport timedef get_weather(cityid): api_url = &apos;http://www.weather.com.cn/data/sk/&apos; + cityid + &apos;.html&apos; results = requests.get(api_url) results.encoding = &apos;utf-8&apos; weather_info = results.json()[&apos;weatherinfo&apos;] print(&quot;%s (tmp/humi): %s/%s&quot; % ( weather_info[&apos;city&apos;], weather_info[&apos;temp&apos;], weather_info[&apos;SD&apos;] ))cityids = ( &apos;101210101&apos;, &apos;101010100&apos;, &apos;101090201&apos;, &apos;101020100&apos;, &apos;101280101&apos;, &apos;101230201&apos;)def main(): threads = [] for id in cityids: thread = Thread(target=get_weather, args=[id]) thread.start() threads.append(thread) while threads: threads.pop().join()if __name__ == &apos;__main__&apos;: started = time.time() main() elapsed = time.time() - started print(&quot;Time elapsed: &#123;:.2f&#125;s&quot;.format(elapsed))# =&gt; 保定 (tmp/humi): 27.5/43%# =&gt; 广州 (tmp/humi): 26.6/83%# =&gt; 杭州 (tmp/humi): 24.8/81%# =&gt; 上海 (tmp/humi): 23.5/80%# =&gt; 北京 (tmp/humi): 27.9/28%# =&gt; 厦门 (tmp/humi): 26.8/87%# =&gt; Time elapsed: 0.08s 与前一个版本（在单个线程中顺序地依次请求多个城市的天气信息）相比，此版本通过不同的线程同时请求多个城市的天气信息，每个线程负责一个城市。虽然多线程在系统资源上增加了一定程度的消耗，但是相对于网络资源响应以及 IO 传输产生的延迟和等待，仍然在效率上有了一定程度的提升。 同时也可以从对输出结果的比较中看出，多线程方案获取到的天气信息并不是按顺序返回的。即表明在请求某个数据时，程序并没有等待上一个请求完全解决，而是在结果返回之前又发起了新的请求。从而在一定程度上减弱了网络延迟对整个程序的阻塞效果。 线程池一个程序所能运行的线程数量并不是毫无限制的，很多时候需要构建一个固定大小的线程池来处理所有带并行需求的工作任务。这些并行任务可以先存储在一种名为队列（queue）的数据结构中，以先进先出（FIFO）的原则分配给线程池中固定数量的线程去处理。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364from queue import Queue, Emptyfrom threading import Threadimport requestsimport timeTHREAD_POOL_SIZE = 4cityids = ( &apos;101210101&apos;, &apos;101010100&apos;, &apos;101090201&apos;, &apos;101020100&apos;, &apos;101280101&apos;, &apos;101230201&apos;)def worker(work_queue): while not work_queue.empty(): try: item = work_queue.get(block=False) except Empty: break else: get_weather(item) work_queue.task_done()def get_weather(cityid): api_url = &apos;http://www.weather.com.cn/data/sk/&apos; + cityid + &apos;.html&apos; results = requests.get(api_url) results.encoding = &apos;utf-8&apos; weather_info = results.json()[&apos;weatherinfo&apos;] print(&quot;%s (tmp/humi): %s/%s&quot; % ( weather_info[&apos;city&apos;], weather_info[&apos;temp&apos;], weather_info[&apos;SD&apos;] ))def main(): work_queue = Queue() for id in cityids: work_queue.put(id) threads = [ Thread(target=worker, args=(work_queue,)) for _ in range(THREAD_POOL_SIZE) ] for thread in threads: thread.start() work_queue.join() while threads: threads.pop().join()if __name__ == &apos;__main__&apos;: started = time.time() main() elapsed = time.time() - started print(&quot;Time elapsed: &#123;:.2f&#125;s&quot;.format(elapsed))# =&gt; 保定 (tmp/humi): 27.5/43%# =&gt; 杭州 (tmp/humi): 24.8/81%# =&gt; 北京 (tmp/humi): 27.9/28%# =&gt; 上海 (tmp/humi): 23.5/80%# =&gt; 广州 (tmp/humi): 26.6/83%# =&gt; 厦门 (tmp/humi): 26.8/87%# =&gt; Time elapsed: 0.08s 其中 get_weather 函数可以通过 id 值获取对应城市的天气信息，所有需要请求的 id 参数保存在 main 中定义的队列 work_queue 里； worker 函数是与线程相关联的工作代码，它可以逐个获取队列中存储的 id 参数并传递给 get_weather 函数；main 函数中的 threads 列表则初始化了固定数量（THREAD_POOL_SIZE）的线程对象，所有的请求任务最终都由这些线程去处理。队列中的任何一个 id 参数交由任何一个线程处理时都会立即从队列中弹出，因而保证了各线程间的相互独立（同一个任务不会被多个线程获取）。 简单来说，固定数量的线程完成了队列中大量任务的并行处理。可以适当修改线程数量以达到系统资源和执行效率的平衡。 双向队列123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172import timefrom queue import Queue, Emptyfrom threading import Threadimport requestsTHREAD_POOL_SIZE = 4cityids = ( &apos;101210101&apos;, &apos;101010100&apos;, &apos;101090201&apos;, &apos;101020100&apos;, &apos;101280101&apos;, &apos;101230201&apos;)def get_weather(cityid): api_url = &apos;http://www.weather.com.cn/data/sk/&apos; + cityid + &apos;.html&apos; results = requests.get(api_url) results.encoding = &apos;utf-8&apos; weather_info = results.json()[&apos;weatherinfo&apos;] return weather_infodef present_result(weather_info): print(&quot;%s (tmp/humi): %s/%s&quot; % ( weather_info[&apos;city&apos;], weather_info[&apos;temp&apos;], weather_info[&apos;SD&apos;] ))def worker(work_queue, results_queue): while not work_queue.empty(): try: item = work_queue.get(block=False) except Empty: break else: results_queue.put( get_weather(item) ) work_queue.task_done()def main(): work_queue = Queue() results_queue = Queue() for id in cityids: work_queue.put(id) threads = [ Thread(target=worker, args=(work_queue, results_queue)) for _ in range(THREAD_POOL_SIZE) ] for thread in threads: thread.start() work_queue.join() while threads: threads.pop().join() while not results_queue.empty(): present_result(results_queue.get())if __name__ == &apos;__main__&apos;: started = time.time() main() elapsed = time.time() - started print(&quot;Time elapsed: &#123;:.2f&#125;s&quot;.format(elapsed))# =&gt; 杭州 (tmp/humi): 24.8/81%# =&gt; 北京 (tmp/humi): 27.9/28%# =&gt; 保定 (tmp/humi): 27.5/43%# =&gt; 上海 (tmp/humi): 23.5/80%# =&gt; 广州 (tmp/humi): 26.6/83%# =&gt; 厦门 (tmp/humi): 26.8/87%# =&gt; Time elapsed: 0.08s 与上一个版本的方案不同，此处的程序除了创建包含请求信息的 work_queue 队列外，还创建了一个用于保存返回结果的 results_queue 队列。即工作线程只用于对远程 API 发起请求并获取结果，而最终结果的整理及打印输出等则交由主线程来处理。此举可以减弱某些无关的操作可能对工作线程产生的不利影响。 错误处理为了应对请求数据的过程中可能出现的错误，可以在之前代码的基础上添加异常捕获功能。即在 worker 函数中添加 try...except 语句，当执行成功时将返回的结果保存至 results_queue 队列；如有异常发生，则将异常对象保存至 results_queue 队列。然后在 main 函数中对 results_queue 中的内容进行判断，是直接输出结果还是抛出异常对象。最终代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980import timefrom queue import Queue, Emptyfrom threading import Threadimport requestsTHREAD_POOL_SIZE = 4cityids = ( &apos;101210101&apos;, &apos;101010100&apos;, &apos;101090201&apos;, &apos;101020100&apos;, &apos;101280101&apos;, &apos;101230201&apos;)def get_weather(cityid): api_url = &apos;http://www.weather.com.cn/data/sk/&apos; + cityid + &apos;.html&apos; results = requests.get(api_url) results.encoding = &apos;utf-8&apos; weather_info = results.json()[&apos;weatherinfo&apos;] return weather_infodef present_result(weather_info): print(&quot;%s (tmp/humi): %s/%s&quot; % ( weather_info[&apos;city&apos;], weather_info[&apos;temp&apos;], weather_info[&apos;SD&apos;] ))def worker(work_queue, results_queue): while not work_queue.empty(): try: item = work_queue.get(block=False) except Empty: break else: try: result = get_weather(item) except Exception as err: results_queue.put(err) else: results_queue.put(result) finally: work_queue.task_done()def main(): work_queue = Queue() results_queue = Queue() for id in cityids: work_queue.put(id) threads = [ Thread(target=worker, args=(work_queue, results_queue)) for _ in range(THREAD_POOL_SIZE) ] for thread in threads: thread.start() work_queue.join() while threads: threads.pop().join() while not results_queue.empty(): result = results_queue.get() if isinstance(result, Exception): raise result present_result(result)if __name__ == &apos;__main__&apos;: started = time.time() main() elapsed = time.time() - started print(&quot;Time elapsed: &#123;:.2f&#125;s&quot;.format(elapsed))# =&gt; 杭州 (tmp/humi): 24.8/81%# =&gt; 北京 (tmp/humi): 27.9/28%# =&gt; 保定 (tmp/humi): 27.5/43%# =&gt; 上海 (tmp/humi): 23.5/80%# =&gt; 广州 (tmp/humi): 26.6/83%# =&gt; 厦门 (tmp/humi): 26.8/87%# =&gt; Time elapsed: 0.07s 参考资料Expert Python Programming - Second Edition]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Python</tag>
        <tag>Concurrency</tag>
        <tag>Threading</tag>
        <tag>Performance</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 进阶之 Logging 模块]]></title>
    <url>%2F2019%2F09%2F23%2Fpro-python-logging-module%2F</url>
    <content type="text"><![CDATA[日志可以用于记录软件运行时触发的一系列事件，帮助开发者实时地跟踪和了解程序代码运行的状态。由日志记录的事件消息通常会从属于特定的重要性等级（称为 level 或 severity），该等级由低到高一般包括 DEBUG、INFO、WARNING、ERROR、CRITICAL 等。 一、Level以下为一段简单的 Logging 代码：123456789import logginglogging.warning(&apos;Watch out!&apos;) # will print a message to the consolelogging.error(&apos;Error happend&apos;) # will print a message to the consolelogging.info(&apos;I told you so&apos;) # will not print anythinglogging.debug(&apos;debug information&apos;) # will not print anything# =&gt; WARNING:root:Watch out!# =&gt; ERROR:root:Error happend logging 模块默认的安全等级为 WARNING，只有属于或者高于此等级的日志消息才会被跟踪并进一步处理（比如输出到终端）。因此上面代码中 warning 和 error 记录的信息会输出到终端窗口中，而 info 和 debug 由于所属的安全等级较低，其信息不会输出到终端界面。 logging 模块可以通过 basicConfig 方法中的 level 参数自定义安全等级。示例代码如下：1234567891011import logginglogging.basicConfig(level=logging.INFO)logging.warning(&apos;Watch out!&apos;) # will print a message to the consolelogging.error(&apos;Error happend&apos;) # will print a message to the consolelogging.info(&apos;I told you so&apos;) # will not print anythinglogging.debug(&apos;debug information&apos;) # will not print anything# =&gt; WARNING:root:Watch out!# =&gt; ERROR:root:Error happend# =&gt; INFO:root:I told you so 二、记录日志到文件中参考以下代码：12345import logginglogging.basicConfig(filename=&apos;example.log&apos;,level=logging.DEBUG)logging.debug(&apos;This message should go to the log file&apos;)logging.info(&apos;So should this&apos;)logging.warning(&apos;And this, too&apos;) 上面的代码运行后会在当前目录下生成 example.log 日志文件，其内容如下：123DEBUG:root:This message should go to the log fileINFO:root:So should thisWARNING:root:And this, too 三、更改信息格式记录变量类似于 print 语句，logging 也支持将变量的值嵌入到输出的信息中：1234import logginglogging.warning(&apos; %s before you %s&apos;, &apos;Look&apos;, &apos;Leap!&apos;)# =&gt; WARNING:root: Look before you Leap! 更改输出信息的格式可以通过 basicConfig 方法中的 format 参数定义日志消息的格式，比如具体需要输出哪些内容以及这些信息如何展现给用户等：12345678910import logginglogging.basicConfig(format=&apos;%(levelname)s:%(message)s&apos;, level=logging.DEBUG)logging.debug(&apos;This message should appear on the console&apos;)logging.info(&apos;So should this&apos;)logging.warning(&apos;And this, too&apos;)# =&gt; DEBUG:This message should appear on the console# =&gt; INFO:So should this# =&gt; WARNING:And this, too PS：默认的输出格式为 severity:logger name:message。 显示时间信息123456import logginglogging.basicConfig(format=&apos;%(asctime)s %(message)s&apos;, datefmt=&apos;%m/%d/%Y %I%M%S %p&apos;)logging.warning(&apos;is when this event was logged.&apos;)# =&gt; 09/06/2019 091722 AM is when this event was logged. 其中 datefmt 参数支持的格式定义与 time.strftime() 相同。 四、配置 Logginglogging 库可以通过模块化的方式向外部提供以下几种组件： Loggers：提供可被应用直接调用的接口 Handlers：将 loggers 创建的日志记录发送到指定位置 Filters：提供过滤功能，决定哪些日志记录可以被输出显示 Formatters：决定日志最终显示时的布局格式 对日志的各类操作实际上是通过调用 Logger 实例中包含的方法来实现的。可以使用如下语句创建一个 Logger 类的实例对象并对其命名：logger = logging.getLogger(__name__)同时这种命名方式可以很方便地显示出产生日志信息的模块具体是哪一个。 以下是几种常见的 logging 配置： （1）手动配置：1234567891011121314151617181920212223242526272829303132import loggingimport logging.config# create loggerlogger = logging.getLogger(&apos;simple_example&apos;)logger.setLevel(logging.DEBUG)# create console handler and set level to debugch = logging.StreamHandler()ch.setLevel(logging.DEBUG)# create formatterformatter = logging.Formatter(&apos;%(asctime)s - %(name)s - %(levelname)s - %(message)s&apos;)# add formatter to chch.setFormatter(formatter)# add ch to loggerlogger.addHandler(ch)# &apos;application&apos; codelogger.debug(&apos;debug message&apos;)logger.info(&apos;info message&apos;)logger.warning(&apos;warn message&apos;)logger.error(&apos;error message&apos;)logger.critical(&apos;critical message&apos;)# =&gt; 2019-09-06 09:54:53,574 - simple_example - DEBUG - debug message# =&gt; 2019-09-06 09:54:53,576 - simple_example - INFO - info message# =&gt; 2019-09-06 09:54:53,577 - simple_example - WARNING - warn message# =&gt; 2019-09-06 09:54:53,578 - simple_example - ERROR - error message# =&gt; 2019-09-06 09:54:53,580 - simple_example - CRITICAL - critical message （2）配置多个 handler1234567891011121314151617181920212223242526import logginglogger = logging.getLogger(&apos;simple_example&apos;)logger.setLevel(logging.DEBUG)# create file handler which logs even debug messagesfh = logging.FileHandler(&apos;E:\\spam.log&apos;)fh.setLevel(logging.DEBUG)# create console handler with a higher log levelch = logging.StreamHandler()ch.setLevel(logging.ERROR)# create formatter and add it to the handlersformatter = logging.Formatter(&apos;%(asctime)s - %(name)s - %(levelname)s - %(message)s&apos;)ch.setFormatter(formatter)fh.setFormatter(formatter)# add the handlers to loggerlogger.addHandler(ch)logger.addHandler(fh)# &apos;application&apos; codelogger.debug(&apos;debug message&apos;)logger.info(&apos;info message&apos;)logger.warning(&apos;warn message&apos;)logger.error(&apos;error message&apos;)logger.critical(&apos;critical message&apos;)# =&gt; 2019-09-23 09:20:01,361 - simple_example - ERROR - error message# =&gt; 2019-09-23 09:20:01,377 - simple_example - CRITICAL - critical message 上述代码除了配置 StreamHandler 用于在终端输出日志消息外，还配置了 FileHandler 用于创建 E:\spam.log 日志文件。且日志文件中包含了相对更丰富的信息（因为 Level 级别设置的更低）：123452019-09-23 09:26:58,050 - simple_example - DEBUG - debug message2019-09-23 09:26:58,051 - simple_example - INFO - info message2019-09-23 09:26:58,052 - simple_example - WARNING - warn message2019-09-23 09:26:58,052 - simple_example - ERROR - error message2019-09-23 09:26:58,055 - simple_example - CRITICAL - critical message （3）dictConfig 配置 Logging：1234567891011121314151617181920212223242526272829303132333435import loggingfrom logging.config import dictConfiglogging_config = dict( version=1, formatters=&#123; &apos;f&apos;: &#123;&apos;format&apos;: &apos;%(asctime)s %(name)-12s %(levelname)-8s %(message)s&apos;&#125; &#125;, handlers=&#123; &apos;h&apos;: &#123;&apos;class&apos;: &apos;logging.StreamHandler&apos;, &apos;formatter&apos;: &apos;f&apos;, &apos;level&apos;: logging.DEBUG&#125; &#125;, root=&#123; &apos;handlers&apos;: [&apos;h&apos;], &apos;level&apos;: logging.DEBUG, &#125;,)dictConfig(logging_config)logger = logging.getLogger(&apos;simple_example&apos;)# &apos;application&apos; codelogger.debug(&apos;debug message&apos;)logger.info(&apos;info message&apos;)logger.warning(&apos;warn message&apos;)logger.error(&apos;error message&apos;)logger.critical(&apos;critical message&apos;)# =&gt; 2019-09-09 10:15:47,932 simple_example DEBUG debug message# =&gt; 2019-09-09 10:15:47,934 simple_example INFO info message# =&gt; 2019-09-09 10:15:47,935 simple_example WARNING warn message# =&gt; 2019-09-09 10:15:47,936 simple_example ERROR error message# =&gt; 2019-09-09 10:15:47,938 simple_example CRITICAL critical message （4）YAML 格式的配置文件：12345678910111213141516171819202122# logging.pyimport loggingimport logging.configimport yamlwith open(&apos;E:\\Program\\python\\logging.yml&apos;, &apos;r&apos;) as f: config = yaml.safe_load(f.read()) logging.config.dictConfig(config)logger = logging.getLogger(__file__)# &apos;application&apos; codelogger.debug(&apos;debug message&apos;)logger.info(&apos;info message&apos;)logger.warning(&apos;warn message&apos;)logger.error(&apos;error message&apos;)logger.critical(&apos;critical message&apos;)# =&gt; 2019-09-09 11:18:07,167 - e:\Program\python\logging.py - DEBUG - debug message# =&gt; 2019-09-09 11:18:07,169 - e:\Program\python\logging.py - INFO - info message# =&gt; 2019-09-09 11:18:07,170 - e:\Program\python\logging.py - WARNING - warn message# =&gt; 2019-09-09 11:18:07,171 - e:\Program\python\logging.py - ERROR - error message# =&gt; 2019-09-09 11:18:07,172 - e:\Program\python\logging.py - CRITICAL - critical message 12345678910111213141516171819# logging.ymlversion: 1formatters: simple: format: &apos;%(asctime)s - %(name)s - %(levelname)s - %(message)s&apos;handlers: console: class: logging.StreamHandler level: DEBUG formatter: simple stream: ext://sys.stdoutloggers: sampleLogger: level: DEBUG handlers: [console] propagate: noroot: level: DEBUG handlers: [console] 参考资料Python 3.7.4 documentation]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Advanced</tag>
        <tag>Python</tag>
        <tag>Logging</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django REST framework 教程（1）—— 快速开始]]></title>
    <url>%2F2019%2F09%2F23%2Fdjango-rest-framework-1-quick-start%2F</url>
    <content type="text"><![CDATA[本文参考自 Django REST framework 官方文档 ，创建了一个简单的 API 供 admin 用户查询与修改系统中的用户和用户组信息。 一、创建项目安装依赖库：$ pip install django$ pip install djangorestframework 项目初始化：123$ django-admin startproject tutorial$ cd tutorial$ django-admin startapp quickstart 上述命令执行后，自动生成的 tutorial 项目的目录结构如下：12345678910111213141516tutorial├── manage.py├── quickstart│ ├── __init__.py│ ├── admin.py│ ├── apps.py│ ├── migrations│ │ └── __init__.py│ ├── models.py│ ├── tests.py│ └── views.py└── tutorial ├── __init__.py ├── settings.py ├── urls.py └── wsgi.py 执行以下命令迁移数据库并创建管理员用户：$ python manage.py migrate$ python manage.py createsuperuser 二、序列化创建 tutorial/quickstart/serializers.py 文件并输入以下内容：1234567891011121314from django.contrib.auth.models import User, Groupfrom rest_framework import serializersclass UserSerializer(serializers.HyperlinkedModelSerializer): class Meta: model = User fields = [&apos;url&apos;, &apos;username&apos;, &apos;email&apos;, &apos;groups&apos;]class GroupSerializer(serializers.HyperlinkedModelSerializer): class Meta: model = Group fields = [&apos;url&apos;, &apos;name&apos;] 三、视图修改 tutorial/quickstart/views.py 视图文件：123456789101112131415161718192021from django.contrib.auth.models import User, Groupfrom rest_framework import viewsets, permissionsfrom quickstart.serializers import UserSerializer, GroupSerializerclass UserViewSet(viewsets.ModelViewSet): &quot;&quot;&quot; API endpoint that allows users to be viewed or edited. &quot;&quot;&quot; queryset = User.objects.all().order_by(&apos;-date_joined&apos;) serializer_class = UserSerializer permission_classes = [permissions.IsAuthenticatedOrReadOnly]class GroupViewSet(viewsets.ModelViewSet): &quot;&quot;&quot; API endpoint that allows groups to be viewed or edited. &quot;&quot;&quot; queryset = Group.objects.all() serializer_class = GroupSerializer permission_classes = [permissions.IsAuthenticatedOrReadOnly] 四、URLs 和设置编辑 tutorial/tutorial/urls.py 路由配置文件：12345678910111213141516from django.contrib import adminfrom django.urls import include, pathfrom rest_framework import routersfrom quickstart import viewsrouter = routers.DefaultRouter()router.register(r&apos;users&apos;, views.UserViewSet)router.register(r&apos;groups&apos;, views.GroupViewSet)# Wire up our API using automatic URL routing.# Additionally, we include login URLs for the browsable API.urlpatterns = [ path(&apos;&apos;, include(router.urls)), path(&apos;api-auth/&apos;, include(&apos;rest_framework.urls&apos;, namespace=&apos;rest_framework&apos;)), path(&apos;admin/&apos;, admin.site.urls),] 编辑 tutorial/tutorial/settings.py 文件，在 INSTALLED_APPS 配置中添加上 rest_framework 项目：1234INSTALLED_APPS = [ ... &apos;rest_framework&apos;,] 五、测试运行 $ python manage.py runserver 命令启动测试服务；使用 http 命令对 API 进行访问测试（如未安装 http 工具，运行以下命令安装 $ pip install httpie）。 获取 API 列表：12345$ http -b 127.0.0.1:8000&#123; &quot;groups&quot;: &quot;http://172.20.19.76:8000/groups/&quot;, &quot;users&quot;: &quot;http://172.20.19.76:8000/users/&quot;&#125; GET 方法获取用户组信息：1234567891011$ http -b 127.0.0.1:8000/groups/[ &#123; &quot;name&quot;: &quot;admin&quot;, &quot;url&quot;: &quot;http://172.20.19.76:8000/groups/1/&quot; &#125;, &#123; &quot;name&quot;: &quot;staff&quot;, &quot;url&quot;: &quot;http://172.20.19.76:8000/groups/2/&quot; &#125;] GET 方法获取用户信息：12345678910111213141516171819$ http -b 127.0.0.1:8000/users/[ &#123; &quot;email&quot;: &quot;starky@test.com&quot;, &quot;groups&quot;: [ &quot;http://172.20.19.76:8000/groups/2/&quot; ], &quot;url&quot;: &quot;http://172.20.19.76:8000/users/2/&quot;, &quot;username&quot;: &quot;starky&quot; &#125;, &#123; &quot;email&quot;: &quot;admin@test.com&quot;, &quot;groups&quot;: [ &quot;http://172.20.19.76:8000/groups/1/&quot; ], &quot;url&quot;: &quot;http://172.20.19.76:8000/users/1/&quot;, &quot;username&quot;: &quot;admin&quot; &#125;] POST 方法添加新的用户组（未授权）：1234$ http -b POST 172.20.19.76127.0.0.1:8000/groups/ name=superuser&#123; &quot;detail&quot;: &quot;Authentication credentials were not provided.&quot;&#125; POST 方法添加新的用户组（提供 Admin 账户信息用于验证）12345$ http -b -a admin:123456 POST 127.0.0.1:8000/groups/ name=superuser&#123; &quot;name&quot;: &quot;superuser&quot;, &quot;url&quot;: &quot;http://172.20.19.76:8000/groups/3/&quot;&#125; 六、Web 界面访问 http://127.0.0.1:8000，截图如下： 登录后支持 POST 操作，截图如下：]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Python</tag>
        <tag>WebDev</tag>
        <tag>Django</tag>
        <tag>Restful</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 进阶之类与面向对象编程]]></title>
    <url>%2F2019%2F09%2F23%2Fpro-python-class-and-oop%2F</url>
    <content type="text"><![CDATA[一、类的定义Python 语言中的类实际上是一种数据类型，同时 Python 中所有内置的数据类型也都是由类定义的。123456&gt;&gt;&gt; type(10)&lt;class &apos;int&apos;&gt;&gt;&gt;&gt; type(&apos;10&apos;)&lt;class &apos;str&apos;&gt;&gt;&gt;&gt; type([10,11,12])&lt;class &apos;list&apos;&gt; 可以使用 class 关键字定义一个类，格式如下：12class MyClass: pass 使用赋值的形式实例化某个类，格式如下：instance = MyClass()即创建一个以 MyClass 类为数据类型的新对象 instance 。 实例变量Python 中的类实例可以作为类似于 struct 的数据类型存储数据或记录，且不同于 C 或 Java 语言中的类似结构，关联于类实例的数据不需要提前声明。12345678class Circle: passmy_circle = Circle()my_circle.radius = 4print(2 * 3.14 * my_circle.radius)# =&gt; 25.12 可以通过在类的定义代码中添加 __init__ 方法来初始化实例中的某些数据。每当新的类实例创建时，__init__ 方法都会自动被调用一次，类似于 Java 中的构造器。其第一个参数 self 用来指代新的类实例本身。12345678class Circle: def __init__(self): self.radius = 1my_circle = Circle()print(2 * 3.14 * my_circle.radius)# =&gt; 6.28 上面代码中的 radius 即为 Circle 类的实例变量，每一个由 Circle 类生成的实例对象（如上面代码中的 my_circle）都包含一份独有的 radius 变量。创建实例变量的语法如下：instance.variable = value 类变量类变量是关联于某个类的变量（而不是某个类实例），可以被所有的类实例访问，因此常用来追踪某些类级别的信息。类变量可以通过类结构体中的赋值语句进行创建（而类的实例变量需要在 __init__ 方法中定义）。123456789101112class Circle: pi = 3.14159 def __init__(self, radius): self.radius = radius def area(self): return self.radius * self.radius * Circle.piprint(Circle.pi) # =&gt; 3.14159Circle.pi = 4c = Circle(3)print(c.area()) # =&gt; 36 二、方法方法是指与特定的类对象相关联的函数，比如前面的 __init__ 方法。参考如下代码：123456789101112class Circle: def __init__(self): self.radius = 1 def area(self): return self.radius * self.radius * 3.14159c = Circle()c.radius = 3print(c.area())# =&gt; 28.27431 上面代码中的 area 方法的第一个参数仍为 self，它类似于很多语言中的 this 关键字，用于指代由类生成的实例对象本身。 类的方法定义中可以添加除 self 以外的其他参数，比如可以为 __init__ 方法关联一个 radius 参数，在实例化类的同时直接初始化一个 radius 变量，而不必在类实例创建以后手动进行额外的赋值操作。1234567891011class Circle: def __init__(self, radius=1): self.radius = radius def area(self): return self.radius * self.radius * 3.14159c = Circle(3)print(c.area())# =&gt; 28.27431 三、静态方法与类方法静态方法Python 语言可以通过 @staticmethod 装饰器创建类中的静态方法。静态方法不带 self 参数，即调用时不需要先对类进行实例化，不通过类的实例对象进行调用。它可以没有任何参数，可直接通过类名调用。1234567891011121314151617181920class Circle: all_circles = [] pi = 3.14159 def __init__(self, r=1): self.radius = r self.__class__.all_circles.append(self) def area(self): return self.__class__.pi * self.radius * self.radius @staticmethod def total_area(): total = 0 for c in Circle.all_circles: total = total + c.area() return totalc1 = Circle(1)c2 = Circle(2)print(Circle.total_area())# =&gt; 15.70795 类方法可以使用 @classmethod 装饰器创建 Python 类中的类方法。类方法默认有个 cls 参数（表示类本身），可以被类和实例调用。123456789101112131415161718192021class Circle: all_circles = [] pi = 3.14159 def __init__(self, r=1): self.radius = r self.__class__.all_circles.append(self) def area(self): return self.__class__.pi * self.radius * self.radius @classmethod def total_area(cls): total = 0 for c in cls.all_circles: total = total + c.area() return totalc1 = Circle(1)c2 = Circle(2)print(Circle.total_area())# =&gt; 15.70795 PS：关于实例方法、类方法与静态方法的简要对比 实例方法 定义：第一个参数必须是实例对象，一般约定为 self，通过它来传递实例的属性和方法（也可以传类的属性和方法） 调用：只能由实例对象调用 类方法 定义：使用装饰器 @classmethod。第一个参数必须是当前类对象，一般约定为 cls，通过它来传递类的属性和方法（不能传实例的属性和方法） 调用：实例对象和类对象都可以调用 静态方法 定义：使用装饰器 @staticmethod。参数随意，没有 self 和 cls 参数，方法体中不能使用类或实例的任何属性和方法 调用：实例对象和类对象都可以调用 四、继承12345678910111213141516171819202122class Shape: def __init__(self, x, y): self.x = x self.y = y def move(self, delta_x, delta_y): self.x = self.x + delta_x self.y = self.y + delta_yclass Square(Shape): def __init__(self, side=1, x=0, y=0): super().__init__(x, y) self.side = sideclass Circle(Shape): def __init__(self, r=1, x=0, y=0): super().__init__(x, y) self.radius = rc = Circle(1)c.move(3, 4)print(c.x) # =&gt; 3print(c.y) # =&gt; 4 其中 super 函数用于在子类中调用父类定义的方法。父类 Shape 中定义的 move 方法可以直接被子类实例化后的对象使用。从传统的 OOP 概念来看，即 Python 中所有的方法都是虚拟的，如某个被调用的方法在当前的类中不存在，则 Python 会尝试从它的父类中寻找同名的方法，最终使用第一个找到的结果。 五、私有变量私有变量和私有方法是指在类中定义且在类外不可见的对象。在 Python 语言中，名称前面带双下划线（__）的变量或方法即为私有。 1234567891011class Mine: def __init__(self): self.x = 2 self.__y = 3 def print_y(self): print(self.__y)m = Mine()print(m.x) # =&gt; 2m.print_y() # =&gt; 3print(m.__y) # =&gt; AttributeError: &apos;Mine&apos; object has no attribute &apos;__y&apos; 上面代码中的 __y 变量即为私有变量，因此当直接从类外部访问 __y 时会报出 AttributeError 错误，但是可以通过类内部定义的 print_y 方法（非私有方法）操作 __y 变量。 @propertyPython 允许用户直接访问实例变量，而不需要类似于 Java 或其他面向对象语言中的 getter 或 setter 机制。Python 可以使用 property 机制完成类似的需求。12345678910111213141516171819class Temperature: def __init__(self): self._temp_fahr = 0 @property def temp(self): return (self._temp_fahr - 32) * 5 / 9 @temp.setter def temp(self, new_temp): self._temp_fahr = new_temp * 9 / 5 + 32t = Temperature()print(t._temp_fahr) # =&gt; 0print(t.temp) # =&gt; -17.77777777777778t.temp = 34print(t._temp_fahr) # =&gt; 93.2print(t.temp) # =&gt; 34.0 The Quick Python Book 3rd EditionPython 实例方法、类方法、静态方法的区别与作用]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Advanced</tag>
        <tag>Python</tag>
        <tag>Class</tag>
        <tag>OOP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 进阶之错误捕获与异常处理]]></title>
    <url>%2F2019%2F09%2F17%2Fpro-python-exception-capturing-and-error-handling%2F</url>
    <content type="text"><![CDATA[一、异常介绍Python 中的异常是一种由 raise 语句自动创建的对象。在异常对象生成之后，Python 程序不会再继续执行 raise 后面紧跟的语句或者操作异常对象本身，而是“搜索”用于处理该异常的某个特定的 handler 。如果该 handler 被 Python 程序找到，则它可以关联并访问异常对象获取更多的信息；如果没有找到与异常对应的 handler，则程序终止并输出错误信息。 PS: LBYL 与 EAFP从理念上讲，Python 倾向于在错误发生之后通过捕获异常来处理程序错误。称为 easier to ask forgiveness than permission (EAFP) 。另外一种错误处理的方式则是尽可能地在错误发生之前检查所有可能发生的情况，这种模式称为 look before you leap (LBYL) 。 Python 提供多种不同类型的异常用以反映错误产生的原因和场景等。每种类型的异常实际上都是一个 Python 类，且其中大多数都继承于 Exception 。对于用户自定义的异常类，也最好作为 Exception 的子类来实现。 Python 异常触发时通常会输出以下内容：12345&gt;&gt;&gt; alist = [1,2,3]&gt;&gt;&gt; alist[7]Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;IndexError: list index out of range 上面代码中的 alist[7] 在请求列表中的项目时超出了列表原本的长度，因此触发了 IndexError 异常。该异常被 Python 交互解释器获取并处理，最终输出错误信息。 如果需要，其实也可以在代码中通过 raise 语句手动触发异常：1234&gt;&gt;&gt; raise IndexError(&quot;Just kidding&quot;)Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;IndexError: Just kidding 二、异常捕获能够终止程序的运行并输出错误信息并不是异常机制的关键所在。异常机制的特殊性在于，通过定义合适的用于处理特定异常的 handler，可以确保一般的异常情况能够被 handler 捕捉，而不会直接导致程序运行失败。handler 可以输出错误信息给用户，或者尝试修复问题，但是重点在于它不会终止程序。 捕获异常的基本语法如下：12345678910111213try: bodyexcept exception_type1 as var1: exception_code1except exception_type2 as var2: exception_code2...except: default_exception_codeelse: else_bodyfinally: finally 其具体的执行流程如下： try 语句首先被执行，如果执行成功（没有抛出异常），则继续执行 else 语句（如果有），try 语句此时结束。最后执行 finally 语句（如果有）。 如果 try 语句执行时抛出异常，则 except 语句根据异常类型进行匹配。如某个 except 语句最终匹配抛出的异常类型，则抛出的异常赋值给其后的变量 var（如果有），对应的 exception_code 被执行。 如果 try 抛出的异常没有任何 except 语句进行匹配，则该异常继续传递看是否有内嵌的 try 语句对其进行处理。 上面格式中最后的 except 语句没有跟任何异常类型，则表示它将匹配关联所有的异常类型。这种方式在调试和创建程序原型时较常用，但并不推荐（因为隐藏了异常包含的细节）。 try 语句中的 else 是可选的且并不常用，它只有在 try 语句执行后未抛出任何异常的情况下才会执行。 finally 语句同样是可选的，它在任何情况下最终都会执行。即便 try 语句抛出异常且没有任何 except 语句进行捕获和处理，该异常也是在 finally 语句执行后抛出给用户。因此 finally 语句多用于一些“清理”任务，比如读写硬盘后的关闭文件等。如：12345try: infile = open(filename) data = infile.read()finally: infile.close() 三、assert 语句assert 语句是 raise 语句的一种特殊形式，其语法格式如下：assert expression, argument 其含义为，如果 expression 表达式的执行结果为 False 且系统变量 __debug__ 的值为 True，则抛出 AssertionError 异常和 argument变量（可选）。 系统变量 __debug__ 的值默认为 True，可以在 Python 运行时添加 -O 或 -OO 选项将该值改为 False。因此可以在开发程序时加入 assert 语句进行调试，而程序发布时将其保留在代码中也不会产生任何影响（只需保证 __debug__ 为 False）。12345&gt;&gt;&gt; x = (1, 2, 3)&gt;&gt;&gt; assert len(x) &gt; 5, &quot;len(x) not &gt; 5&quot;Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;AssertionError: len(x) not &gt; 5 四、代码示例不捕获异常1234while True: x = int(input(&apos;Enter the first number: &apos;)) y = int(input(&apos;Enter the second number: &apos;)) print(x / y) 运行效果（出错后程序退出）：1234567891011$ python exceptions.pyEnter the first number: 5Enter the second number: 41.25Enter the first number: 4Enter the second number: 0Traceback (most recent call last): File &quot;exception.py&quot;, line 4, in &lt;module&gt; print(x / y)ZeroDivisionError: division by zero$ 捕获除数不为零异常1234567while True: try: x = int(input(&apos;Enter the first number: &apos;)) y = int(input(&apos;Enter the second number: &apos;)) print(x / y) except ZeroDivisionError: print(&apos;Division by zero is illegal&apos;) 运行效果（出错后异常被捕获，程序不退出）：12345678$ python exceptions.pyEnter the first number: 4Enter the second number: 0Division by zero is illegalEnter the first number: 5Enter the second number: 41.25Enter the first number: 捕获多个异常123456789while True: try: x = int(input(&apos;Enter the first number: &apos;)) y = int(input(&apos;Enter the second number: &apos;)) print(x / y) except ZeroDivisionError: print(&apos;Division by zero is illegal&apos;) except ValueError: print(&quot;That wasn&apos;t a number, was it?&quot;) 运行效果：1234567891011$ python exceptions.pyEnter the first number: 4Enter the second number: 0Division by zero is illegalEnter the first number: 4Enter the second number: helloThat wasn&apos;t a number, was it?Enter the first number: 5Enter the second number: 41.25Enter the first number: 捕获所有异常（不推荐，隐藏了异常的细节）1234567while True: try: x = int(input(&apos;Enter the first number: &apos;)) y = int(input(&apos;Enter the second number: &apos;)) print(x / y) except: print(&apos;Something wrong happened ...&apos;) 运行效果：12345678$ python exceptions.pyEnter the first number: 4Enter the second number: 0Something wrong happened ...Enter the first number: 4Enter the second number: helloSomething wrong happened ...Enter the first number: 稍好一点的版本（输出异常信息）：1234567while True: try: x = int(input(&apos;Enter the first number: &apos;)) y = int(input(&apos;Enter the second number: &apos;)) print(x / y) except Exception as e: print(&apos;Invalid input:&apos;, e) 运行效果：1234567Enter the first number: 4Enter the second number: 0Invalid input: division by zeroEnter the first number: 4Enter the second number: helloInvalid input: invalid literal for int() with base 10: &apos;hello&apos;Enter the first number: 参考资料Beginning Python 3rdThe Quick Python Book 3rd Edition]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Tools</tag>
        <tag>Tricks</tag>
        <tag>Program</tag>
        <tag>Advanced</tag>
        <tag>Python</tag>
        <tag>Technique</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 进阶之 Decorators（装饰器）浅析]]></title>
    <url>%2F2019%2F09%2F05%2Fpro-python-decorators-intro%2F</url>
    <content type="text"><![CDATA[Decorators（装饰器）可以在不更改函数或对象的行为的前提下，动态地向其添加额外的效果。 假设当前的项目中有多个函数需要添加日志功能，即函数执行时向终端或者日志文件中输出特定的内容。 有一种办法就是在每一个函数中添加上若干行记录日志的代码，但这种方式耗费时间的同时，也容易出现意想不到的错误，毕竟会对原本的代码做出相当大的改动。而另一办法就是在每一个函数或类前面添加装饰器，通过装饰器向被装饰函数添加额外的行为（记录日志），这样在提升效率的同时，也不会导致现有的代码中引入了新的 bug 。 比较常见的一种装饰器，比如下面的一段最简单的 flask 应用代码：123456789from flask import Flaskapp = Flask(__name__)@app.route(&quot;/&quot;)def hello(): return &quot;Hello World&quot;if __name__ == &apos;__main__&apos;: app.run() 上面的代码通过 route 装饰器向 hello 函数添加了某些效果，在不变更原 hello 函数内部代码的前提下，将其变成了某个新函数作为 Web 应用中的 API 接受调用 。 一、初级示例函数作为参数下面是一段简单的函数代码，可以用来将某个字符串转换为大写：123456789def to_uppercase(text): if not isinstance(text, str): raise TypeError(&quot;Not a string&quot;) return text.upper()text = &quot;Hello World&quot;upper_text = to_uppercase(text)print(upper_text)# =&gt; HELLO WORLD 这里对 to_uppercase 函数做一点微小的改动：12345678910111213def to_uppercase(func): text = func() if not isinstance(text, str): raise TypeError(&quot;Not a string&quot;) return text.upper()def hello(): return &quot;Hello World&quot;hello = to_uppercase(hello)print(hello)# =&gt; HELLO WORLD 与之前版本的 to_uppercase 不同，此版本的 to_uppercase 函数并不直接使用字符串作为输入，而是接收某个函数作为参数，将该函数执行后返回的字符串转换为大写。 to_uppercase 函数并没有改变 hello 函数原本的行为（输出字符串），而是在其基础上添加了额外的效果（将输出字符串转换为大写），因而起到了装饰器的作用。 上面的代码也可以写成如下的形式（两者效果相同）：12345678910111213def to_uppercase(func): text = func() if not isinstance(text, str): raise TypeError(&quot;Not a string&quot;) return text.upper()@to_uppercasedef hello(): return &quot;Hello World&quot;print(hello)# =&gt; HELLO WORLD @decorator 是 Python 中的语法糖，123@decoratordef func(): ... 等同于123def func(): ...func = decorator(func) 函数作为返回值以下代码为 to_uppercase 装饰器的最终形式：1234567891011121314151617181920def to_uppercase(func): def wrapper(): text = func() if not isinstance(text, str): raise TypeError(&quot;Not a string type&quot;) return text.upper() return wrapper@to_uppercasedef hello(): return &quot;Hello World&quot;&apos;&apos;&apos;等同于def hello(): return &quot;Hello World&quot;hello = to_uppercase(hello)&apos;&apos;&apos;print(hello())# =&gt; HELLO WORLD 之前的 to_uppercase 函数接收另一个函数作为参数，获取其返回值并作出修改，最后返回修改后的结果。而此处的 to_uppercase 函数在代码中内嵌了一个 wrapper 函数并将其作为返回值，wrapper 函数中包含了对被装饰的函数做出的改动。即 to_uppercase 装饰器接收被装饰的函数作为参数，通过内嵌函数对其进行改动，最终返回一个新的函数替代被装饰的原函数。 回到代码中，hello 函数用于返回 Hello World 字符串，而装饰器 to_uppercase 接收 hello 作为参数，通过 wrapper 对其添加新的行为（将返回的字符串转为大写）并替换掉原来的 hello 函数。因此在不改变原 hello 函数内部代码的情况下，通过装饰器生成了新的 hello 函数，最终改变了原函数的行为。 二、使用多个装饰器代码如下：12345678910111213141516171819202122def add_prefix(func): def wrapper(): text = func() result = &quot; &quot;.join([text, &quot;Larry Page!&quot;]) return result return wrapperdef to_uppercase(func): def wrapper(): text = func() if not isinstance(text, str): raise TypeError(&quot;Not a string&quot;) return text.upper() return wrapper()@to_uppercase@add_prefixdef say(): return &quot;welcome&quot;print(say)# =&gt; WELCOME LARRY PAGE! 三、带参数的装饰器示例代码如下：1234567891011121314def to_uppercase(func): def wrapper(*args, **kwargs): text = func(*args, **kwargs) if not isinstance(text, str): raise TypeError(&quot;Not a string&quot;) return text.upper() return wrapper@to_uppercasedef say(greet): return greetprint(say(&quot;hello, how are you&quot;))# =&gt; HELLO, HOW ARE YOU 四、functools.wraps运行如下装饰器代码：1234567891011121314151617def logging(func): def logs(*args, **kwargs): print(func.__name__ + &quot; was called&quot;) return func(*args, **kwargs) return logs@loggingdef foo(x): &quot;&quot;&quot;Calling function for logging&quot;&quot;&quot; return x * xfo = foo(10)# =&gt; foo was calledprint(foo.__name__)# =&gt; logsprint(foo.__doc__)# =&gt; None 从运行结果中可以看出，print(foo.__name__) 并没有输出 foo ，而是打印了装饰器的内嵌函数 logs 的名字。即被装饰的函数 foo 由新函数替代后，其 __name__ 和 __doc__ 等属性也丢失了。 为了避免这种情况，可以使用 functool.wrap ，代码如下：12345678910111213141516171819from functools import wrapsdef logging(func): @wraps(func) def logs(*args, **kwargs): print(func.__name__ + &quot; was called&quot;) return func(*args, **kwargs) return logs@loggingdef foo(x): &quot;&quot;&quot;does some math&quot;&quot;&quot; return x * xfo = foo(10)# =&gt; foo was calledprint(foo.__name__)# =&gt; fooprint(foo.__doc__)# =&gt; does some math 五、场景：基于装饰器的授权很多 Web API 都需要用户携带认证信息才能访问，当然可以在每一段 API 的代码中加入检查授权状态的片段，更便捷的方式则是使用装饰器。如：12345678910from functools import wraps def requires_auth(func): @wraps(func) def wrapper(*args, **kwargs): auth = request.authorization if not auth or not check_auth(auth.username, auth.password): authenticate() return func(*args, **kwargs) return wrapper 则每一个被 require_auth 装饰的函数执行前，都会先获取授权信息并验证。 参考资料Clean PythonPython 函数装饰器]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Function</tag>
        <tag>Python</tag>
        <tag>Programming</tag>
        <tag>Language</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 进阶之生成器与迭代器]]></title>
    <url>%2F2019%2F09%2F05%2Fpro-python-iterators-and-generators%2F</url>
    <content type="text"><![CDATA[迭代器（Iterators）和生成器（Generators）是 Python 语言中用处很大的工具，在某些情况下通过它们可以写出更加精简、清晰和高效的代码。 迭代器迭代器是一种包含 __next__ 方法、用于处理数据流的对象。当使用 for 循环之类的方式遍历迭代器中的每一项数据时，__next__ 方法即被重复性地调用进而完成特定的动作。 以下代码即为一个不完整的迭代器类：1234567891011121314class MultiplyByTwo: def __init__(self, number): self.number = number self.counter = 0 def __next__(self): self.counter += 1 return self.number * self.countermul = MultiplyByTwo(5)print(next(mul)) # =&gt; 5print(next(mul)) # =&gt; 10print(next(mul)) # =&gt; 15print(next(mul)) # =&gt; 20 通过 next() 函数手动调用 MultiplyByTwo 类的 __next__ 方法，可以依次得到 number 变量与递增的 counter 变量的乘积。但是作为一个可被遍历的迭代器类，理论上也应该可以通过 for 语句直接以循环的方式逐次取出 __next__ 返回的乘积。 此时运行如下代码对 MultiplyByTwo 类进行迭代操作：12for num in MultiplyByTwo(5): print(num) 则会报出 TypeError: &#39;MultiplyByTwo&#39; object is not iterable 错误。即此时的“迭代器”对象还不支持遍历操作。 需要在 MultiplyByTwo 类中添加 __iter__ 方法表明其“可被遍历”，代码如下：12345678910111213141516171819class MultiplyByTwo: def __init__(self, number): self.number = number self.counter = 0 def __iter__(self): return self def __next__(self): self.counter += 1 return self.number * self.counterfor num in MultiplyByTwo(5): print(num)# =&gt; 5# =&gt; 10# =&gt; 15# =&gt; 20# =&gt; ... 此时则可以使用 for 语句循环地调用 __next__ 方法获取 number 和递增的 counter 变量的乘积。比较尴尬的是，以上面的方式遍历 MultiplyByTwo 迭代器，for 循环会一直运行下去。 可以通过以下代码为前面的迭代器添加终止点：12345678910111213141516171819202122232425class MultiplyByTwo: def __init__(self, number, limit): self.number = number self.limit = limit self.counter = 0 def __iter__(self): return self def __next__(self): self.counter += 1 value = self.number * self.counter if value &gt; self.limit: raise StopIteration else: return valuefor num in MultiplyByTwo(5, 20): print(num)# =&gt; 5# =&gt; 10# =&gt; 15# =&gt; 20 所以一个实现了 __next__ 方法（用以不断返回下一个数据）、可进行迭代操作的对象即为迭代器。 对于前面实现的 MultiplyByTwo 迭代器类，在用 for 循环进行遍历操作时，for num in MultiplyByTwo(5, 20): 的最终结果等同于 for 语句对以下列表的遍历：for num in [5 * 1, 5 * 2, 5 * 3, 5 *4]: 。 实际上，迭代器对象表示的是一个数据流，其可以被 next() 函数调用并不断返回下一个数据，直到没有数据时抛出 StopIteration 异常。但这个“数据流”不是原本就完整地存在的，只能通过 next() 函数逐次地计算下一个值。即迭代器的计算是惰性的，只有在需要返回下一个数据时才会被动地进行计算。 生成器生成器可以理解为一种实现了迭代器协议的数据结构。前面提到迭代器是“懒惰”的，一次只计算一个数据。对于项目体量非常庞大的数据集合（比如全体自然数？没有任何一个列表能装下）或文件，生成器相比于其他数据结构，能够更加高效地使用内存资源。 生成器代码示例：123456789101112131415def multiple_generator(num, limit): counter = 1 value = num * counter while value &lt;= limit: yield value counter += 1 value = num * counterfor num in multiple_generator(5, 20): print(num)# =&gt; 5# =&gt; 10# =&gt; 15# =&gt; 20 不同于前面的 MultiplyByTwo 类，此次的 multiple_generator 生成器函数并不需要实现 __next__ 和 __iter__ 方法，也不用检查内部状态确认是否发起异常。而是使用了 yield 关键字。yield 关键字类似于 return，只不过它并不会终止函数的运行。而是暂时中断函数的执行，直到下一个数据被请求（就继续返回下一个值）。因此生成器相对于一般的迭代器更加易读和高效。 以下是一个经典的生成器在现实中的应用，通过生成器以数据块的方式读取文件：1234567891011def read_in_chunks(file_handler, chunk_size=1024): &quot;&quot;&quot; Lazy function (generator) to read a file piece by piece.&quot;&quot;&quot; while True: data = file_handler.read(chunk_size) if not data: break yield dataf = open(&apos;large_number_of_data.dat&apos;)for piece in read_in_chunks(f): print(piece) 通过生成器每次只读取 1k 大小的数据块，循环遍历直到整个文件被处理。而不是将所有文件数据一次性地读入到内存中。当需要读取的文件非常大时，此种方式相对于常规手段更加节省内存的使用。 yield fromyield from 关键字可以用来从其他生成器中获取数据。参考如下代码：12345678910def flat_list(iter_values): &quot;&quot;&quot;flatten a multi list or something&quot;&quot;&quot; for item in iter_values: if hasattr(item, &apos;__iter__&apos;): yield from flat_list(item) else: yield itemprint(list(flat_list([1, 2, [3, 4, [5]], 6])))# =&gt; [1, 2, 3, 4, 5, 6] 上面的短短 6 行代码可以将包含任意层次的可迭代对象（如列表等）转换成单层的列表结构。个人感觉，这代码非常漂亮，有点层层递进、环环相扣的感觉了。值得好好观赏。 PS：可以对比下阶乘的实现代码：12345def factorial(n): if n != 1: return n * factorial(n-1) else: return 1 参考资料Clean Python]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Functional</tag>
        <tag>Python</tag>
        <tag>Programming</tag>
        <tag>Language</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python Tricks —— 使用 asciinema 录制命令行操作]]></title>
    <url>%2F2019%2F08%2F25%2Fusing-asciinema-to-record-Linux-terminal-sessions%2F</url>
    <content type="text"><![CDATA[asciinema 是一个由 Python 语言编写的开源的终端会话录制工具。它可以将命令行的输出内容根据时间保存在 JSON 格式的文件中，以供后续播放时使用。同时该录制文件也可以通过 Web 浏览器进行播放（需要使用由 asciinema-player 提供的 Javascript 和 CSS 文件），或者直接上传到 asciinema.org 网站分享给其他互联网用户。 一、script 命令script 命令是 Linux 系统自带一个的终端录制工具，功能与 asciinema 类似，可以将终端交互内容保存在本地的文本文件中，再使用 scriptreplay 命令进行播放。 录制：script -t 2&gt;time.file -a output.file 其中 time.file 用于保存时间信息，output.file 则用于记录终端输出的内容及光标的移动等。录制完成时使用 exit 命令或者 Ctrl+D 终止录制。 播放：scriptreplay time.file output.file 二、asciinema 本地录制asciinema 安装比较简单，直接使用 pip 命令即可：$ pip install asciinema 可使用如下命令将终端内容录制到本地文件中：$ asciinema rec demo.cast完成后使用 exit 或 Ctrl+D 结束录制。 使用如下命令播放前面录制的内容：$ asciinema play demo.cast播放时可使用 -s &lt;n&gt; 选项控制回放的速度，其中 n 为表示倍率的数字，数值越大播放速度越快。 其他选项的使用方法可通过 asciinema rec -h 或 asciinema play -h 命令查看帮助信息。 三、浏览器播放浏览器播放录制文件需要借助 asciinema-player 项目提供的两个库文件 asciinema-player.css 和 asciinema-player.js 。这两个文件可以从该 Github 项目的 release 中下载，也可以直接通过 CDN 链接引入。 示例 HTML 代码（注意新增的 asciinema-player 标签）如下：123456789&lt;html&gt;&lt;head&gt; &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;asciinema-player.css&quot; /&gt;&lt;/head&gt;&lt;body&gt; &lt;asciinema-player src=&quot;demo.cast&quot;&gt;&lt;/asciinema-player&gt; &lt;script src=&quot;asciinema-player.js&quot;&gt;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 播放效果如下： 四、上传至 asciinema.org首先访问 asciinema.org 创建一个新账户。再使用 asciinema auth 命令生成自己电脑独有的 ID ：123456$ asciinema authOpen the following URL in a web browser to link your install ID with your asciinema.org user account:https://asciinema.org/connect/636713f1-db74-41c5-bb45-97fc213f3c94This will associate all recordings uploaded from this machine (past and future ones) to your account, and allow you to manage them (change title/theme, delete) at asciinema.org. 通过浏览器访问上面生成的链接完成绑定，则此台设备上使用 asciinema rec 录制的内容都将自动上传至之前创建的账户中。 录制：asciinema rec停止录制后按下回车键自动上传至云端并返回播放链接。123456asciinema: recording finishedasciinema: press &lt;enter&gt; to upload to asciinema.org, &lt;ctrl-c&gt; to save locallyView the recording at: https://asciinema.org/a/9WlhbT4qnTr5cFWQQZNS0auIY 播放：asciinema play &lt;link&gt; 个人账户界面如下： 如不方便将录制内容放置于外部的公网服务器上，也可以自行搭建类似的私人服务器。参考 asciinema-server 项目，可使用 docker 快速进行部署，不再做详细说明。 注意部署成功后修改 ~/.config/asciinema/config 配置文件，添加如下内容：12[api]url = https://your.asciinema.host 参考资料asciinema Docs]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Admin</tag>
        <tag>Tools</tag>
        <tag>Tricks</tag>
        <tag>Terminal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python Tricks —— 使用 Supervisor 控制 Linux 进程]]></title>
    <url>%2F2019%2F08%2F24%2Fusing-supervisor-to-control-Linux-processes%2F</url>
    <content type="text"><![CDATA[Supervisor 是一个 C/S 架构的进程控制系统，完全由 Python 语言编写。它允许用户监视和控制类 Unix 系统上的一个或多个进程。 在 Linux 系统中，一般可以使用 service &lt;service-name&gt; start|stop|restart 或者 systemctl start|stop|restart &lt;service-name&gt; 等命令启动或停止某个服务的进程实例。实际上，service 和 systemctl 命令都是通过调用 /etc/init.d/ 目录下的启动脚本对服务进行控制。 相对而言，这类启动脚本在编写和维护上都需要耗费比较大的精力。而 Supervisor 只通过一个简单的 INI 格式的配置文件即能完成对一个或多个进程的集中管理，且能够控制进程在崩溃后自动重启。同时，Supervisor 还支持对进程进行分组，并为组中的进程分配不同的优先级，使得它们可以按预先定义的顺序进行启动。 一、软件安装Supervisor 支持 Linux、MacOS、Solaris 和 FreeBSD 等操作系统，直接使用对应的包管理命令安装即可。如 Ubuntu 系统：$ sudo apt-get install supervisor Supervisor 完全由 Python 语言编写，因此可以使用 pip 命令安装，也支持安装到由 virtualenv 等工具构建的虚拟环境中。$ pip install supervisor 组件介绍supervisordsupervisord 是 Supervisor 的服务端组件，负责控制子进程的生命周期、响应客户端组件的命令请求、重启崩溃的进程以及日志记录等工作。supervisord 使用 Windows-INI 格式的配置文件。 supervisorctlsupervisorctl 是一个借助命令行进行交互式操作的客户端组件，它可以通过类似 Shell 的接口访问 supervisord 提供的功能。 Web Server如 Supervisor 配置文件中的 [inet_http_server] 项被启用，则可以通过访问 http://localhost:9001 进入一个功能类似 supervisorctl 的 Web 交互界面。 XML-RPC 接口Supervisor 的 HTTP 服务还提供了 XML-RPC 接口，参考 XML-RPC API Documentation 二、配置文件Supervisor 的配置文件一般命名为 supervisord.conf。它可以同时被 supervisord 和 supervisorctl 使用（通过 -c 选项指定）。如执行上述两个命令时并未手动指定配置文件，则依次在以下位置查找名为 supervisord.conf 的配置文件： $CWD/supervisord.conf $CWD/etc/supervisord.conf /etc/supervisord.conf /etc/supervisor/supervisord.conf ../etc/supervisord.conf ../supervisord.conf Section Settings配置文件中的 [inet_http_server] 用于配置可供远程访问的 HTTP 服务，示例如下：1234[inet_http_server]port = 127.0.0.1:9001username = userpassword = 123 [supervisord] 用于配置 supervisord 进程的一些全局选项，示例如下：1234567891011121314151617[supervisord]logfile = /tmp/supervisord.loglogfile_maxbytes = 50MBlogfile_backups=10loglevel = infopidfile = /tmp/supervisord.pidnodaemon = falseminfds = 1024minprocs = 200umask = 022user = chrismidentifier = supervisordirectory = /tmpnocleanup = truechildlogdir = /tmpstrip_ansi = falseenvironment = KEY1=&quot;value1&quot;,KEY2=&quot;value2&quot; [supervisorctl] 用于控制交互式 Shell supervisorctl 的行为，示例如下：12345[supervisorctl]serverurl = unix:///tmp/supervisor.sockusername = chrispassword = 123prompt = mysupervisor [program:x]配置文件中需要至少包含一个 [program:x] 项用于指定某个由 Supervisor 控制的进程。示例如下：123456789101112131415161718192021222324252627282930[program:cat]command=/bin/catprocess_name=%(program_name)snumprocs=1directory=/tmpumask=022priority=999autostart=trueautorestart=unexpectedstartsecs=10startretries=3exitcodes=0stopsignal=TERMstopwaitsecs=10stopasgroup=falsekillasgroup=falseuser=chrismredirect_stderr=falsestdout_logfile=/a/pathstdout_logfile_maxbytes=1MBstdout_logfile_backups=10stdout_capture_maxbytes=1MBstdout_events_enabled=falsestderr_logfile=/a/pathstderr_logfile_maxbytes=1MBstderr_logfile_backups=10stderr_capture_maxbytes=1MBstderr_events_enabled=falseenvironment=A=&quot;1&quot;,B=&quot;2&quot;serverurl=AUTO [include] 可以用来引入其他位置的配置文件。示例如下：12[include]files = /an/absolute/filename.conf /an/absolute/*.conf foo.conf config??.conf 三、实例演示对于一个初始的 Django 项目，可以通过在项目目录下执行 python manage.py runserver 命令启动 Web 服务。这里使用 Supervisor 控制服务进程。 首先在项目目录下创建 supervisord.conf 配置文件。该文件不需要手动创建，可以直接通过 echo_supervisord_conf 命令获取示例配置并定向到 supervisord.conf 文件中，命令如下：$ echo_supervisord_conf &gt; supervisord.conf 该示例配置中并不包含任何 [program:x] 项，需要自行添加。这里在文件末尾添加如下两行内容：12[include]files = ./django_server.ini 即为了清晰起见，这里不把 Supervisor 控制的进程包含在主配置文件中，而是放置在当前目录下的 django_server.ini 文件中，再通过主配置文件中的 [include] 将其导入。django_server.ini 文件内容如下：12345678910111213[program:django_server]command=python manage.py runserver 0000:8000 ;程序启动命令process_name=%(program_name)s ;进程名称directory=/home/starky/project/django/test_project ;启动目录autostart=true ;自动启动autorestart=unexpected ;异常退出后自动重启startsecs=10 ;程序启动 10 秒后未异常退出，则正常启动startretries=3 ;自动重启尝试次数user=starky ;启动该进程的用户redirect_stderr=true ;stderr 重定向至 stdout 。默认 falsestdout_logfile_maxbytes=20MB ;stdout 日志大小，默认 50MBstdout_log_backups=10 ;stdout 日志文件备份数量stdout_logfile=./logs/django_server.log ;stdout 日志路径。目录不存在时需手动创建 配置完成后，运行以下命令启动 supervisord 程序：$ supervisord -c supervisord.conf 运行 supervisorctl 命令进入交互式 Shell ，可以看到 django_server.ini 中配置的 django_server 程序已经启动成功：123$ supervisorctldjango_server RUNNING pid 6210, uptime 0:00:15supervisor&gt; Web Server出于安全上的考虑，Supervisor 提供的 Web Server 默认是关闭的，可以通过修改主配置文件 supervisord.conf 进行启用。删除以下内容前的注释即可：1234[inet_http_server] ; inet (TCP) server disabled by defaultport=0.0.0.0:9001 ; ip_address:port specifier, *:port for all ifaceusername=user ; default is no username (open server)password=123 ; default is no password (open server) 配置完成后，首先使用 pkill -9 supervisord 命令退出 supervisord 程序，再使用 supervisord -c supervisord.conf 命令重新启动。此时通过浏览器访问 http://127.0.0.1:9001/，输入用户名密码后即可进入 Web 控制台界面： supervisorctlsupervisorctl 是一个交互式的 Shell ，可以通过它访问 supervisord 提供的部分功能（如启动和停止某个进程、查看日志等）。它支持的基本命令如下：12345678$ supervisorctldjango_server RUNNING pid 8661, uptime 0:14:11supervisor&gt; helpdefault commands (type help &lt;topic&gt;):=====================================add exit open reload restart start tailavail fg pid remove shutdown status updateclear maintail quit reread signal stop version 输入 help &lt;topic&gt; 可以查看对应命令的帮助信息。 常用命令的使用方法如下： help : Print a list of available actions help &lt;action&gt; : Print help for add &lt;name&gt; [...] : Activates any updates in config for process/group remove &lt;name&gt; [...] : Removes process/group from active config update : Reload config and add/remove as necessary, and will restart affected programs update all : Reload config and add/remove as necessary, and will restart affected programs update &lt;gname&gt; [...] : Update specific groups, and will restart affected programs clear &lt;name&gt; : Clear a process’ log files. clear &lt;name&gt; &lt;name&gt; : Clear multiple process’ log files clear all : Clear all process’ log files fg &lt;process&gt; : Connect to a process in foreground mode Press Ctrl+C to exit foreground pid : Get the PID of supervisord. pid &lt;name&gt; : Get the PID of a single child process by name. pid all : Get the PID of every child process, one per line. reload : Restarts the remote supervisord reread : Reload the daemon’s configuration files, without add/remove (no restarts) start | stop | restart &lt;name&gt; : Start / Stop / Restart a process start | stop | restart &lt;gname&gt;:* : Start / Stop / Restart all processes in a group. start | stop | restart &lt;name&gt; &lt;name&gt; : Start / Stop / Restart multiple processes or groups start | stop | restart all : Start / Stop / Restart all processes. Note: restart does not reread config files. status : Get all process status info. status &lt;name&gt; : Get status on a single process by name. status &lt;name&gt; &lt;name&gt; : Get status on multiple named processes. tail &lt;name&gt; [stdout|stderr] (default stdout) : Output the last part of process logs tail -f &lt;name&gt; : Continuous tail of named process stdout Ctrl-C to exit tail -100 &lt;name&gt; : last 100 bytes of process stdout 参考资料Supervisord Docs]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Server</tag>
        <tag>Admin</tag>
        <tag>System</tag>
        <tag>Tools</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 磁盘设备和 LVM 管理命令详解]]></title>
    <url>%2F2019%2F08%2F11%2FLinux-disk-and-lvm-management%2F</url>
    <content type="text"><![CDATA[一、设备文件在 Linux 操作系统中，设备文件是一种特殊类型的文件。这些文件绝大多数位于 /dev 目录下，用来表示 Linux 主机检测到的某个具体的硬件设备。比如 /dev/sda 文件通常用来指代系统中的第一块硬盘。Linux 操作系统及其应用与服务则通过这些设备文件与对应的硬件设备进行交互。 对于常见的磁盘（ATA、SATA、SCSI、SAS、SSD 等）和优盘等块存储设备，其设备文件主要以 sd* 的形式命名。如 sda 表示第一块硬盘，sdb2 表示第二块硬盘的第二个分区，以此类推。因此，可直接使用 ls -l /dev/sd* 命令查看系统中的磁盘设备：123$ ls -l /dev/sd*brw-rw---- 1 root disk 8, 0 8月 7 00:47 /dev/sdabrw-rw---- 1 root disk 8, 1 8月 7 00:47 /dev/sda1 即当前系统中只连接了一块硬盘（/dev/sda），且该硬盘只有一个分区（/dev/sda1）。 二、分区分区可以理解为将一整块硬盘划分为一个或多个相互独立的存储区域。 比如可以将系统的第一块硬盘划分为 3 个分区，分别为 sda1、sda2、sda3 。sda1 用于挂载根目录（/），sda2 挂载 /var ，sda3 挂载 /home 目录。则即使 /var 目录下的日志文件等占用了 sda2 全部的存储空间，也不会影响其他两个分区的使用。 可以使用 fdisk -l 命令查看系统中的磁盘和分区信息：1234567891011$ sudo fdisk -lDisk /dev/sda: 10 GiB, 10737418240 bytes, 20971520 sectorsDisk model: VBOX HARDDISKUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisklabel type: dosDisk identifier: 0x20985120Device Boot Start End Sectors Size Id Type/dev/sda1 2048 20964824 20962777 10G 83 Linux 创建磁盘分区fdisk 命令还可以用来对硬盘进行分区操作，包括创建新分区、删除已有的分区、创建分区表等。我这里通过 VirtualBox 软件为虚拟机中的 Linux 系统添加了一块空白的虚拟硬盘。使用 fdisk -l 命令查看系统检测到的硬盘设备：123456789101112131415161718$ sudo fdisk -lDisk /dev/sda: 10 GiB, 10737418240 bytes, 20971520 sectorsDisk model: VBOX HARDDISKUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisklabel type: dosDisk identifier: 0x20985120Device Boot Start End Sectors Size Id Type/dev/sda1 2048 20964824 20962777 10G 83 LinuxDisk /dev/sdb: 5 GiB, 5368709120 bytes, 10485760 sectorsDisk model: VBOX HARDDISKUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytes 此时系统中多了一块不包含任何分区的新硬盘 /dev/sdb 。 使用 fdisk /dev/sdb 命令对新硬盘进行分区操作：12345678910111213141516171819202122232425262728293031323334353637383940414243444546$ sudo fdisk /dev/sdbWelcome to fdisk (util-linux 2.33.1).Changes will remain in memory only, until you decide to write them.Be careful before using the write command.Device does not contain a recognized partition table.Created a new DOS disklabel with disk identifier 0xce119026.Command (m for help): mHelp: DOS (MBR) a toggle a bootable flag b edit nested BSD disklabel c toggle the dos compatibility flag Generic d delete a partition F list free unpartitioned space l list known partition types n add a new partition p print the partition table t change a partition type v verify the partition table i print information about a partition Misc m print this menu u change display/entry units x extra functionality (experts only) Script I load disk layout from sfdisk script file O dump disk layout to sfdisk script file Save &amp; Exit w write table to disk and exit q quit without saving changes Create a new label g create a new empty GPT partition table G create a new empty SGI (IRIX) partition table o create a new empty DOS partition table s create a new empty Sun partition table 进入 fdisk 程序界面之后，按下 m 键并回车，即可打印帮助信息，获取该界面下支持的交互式命令。比如输入 p 可以用来输出当前硬盘的分区信息，输入 n 创建新的分区，输入 d 删除已有的分区。在对分区进行任何操作之后，最后都需要使用 w 将之前的所有更改写入硬盘。 这里先按下 n 开始新分区的创建，根据提示选择分区类型（p 表示主分区，e 表示扩展分区），进一步选择分区编号和第一个扇区的位置（一般默认即可），最后输入新分区中最后一个扇区的位置（也可以直接指定分区大小），格式为 +/-sectors 或 +/-size 。如输入 +3G 则表示创建大小为 3 GB 的新分区。具体步骤如下：123456789101112131415161718192021Command (m for help): nPartition type p primary (0 primary, 0 extended, 4 free) e extended (container for logical partitions)Select (default p): pPartition number (1-4, default 1):First sector (2048-10485759, default 2048):Last sector, +/-sectors or +/-size&#123;K,M,G,T,P&#125; (2048-10485759, default 10485759): +3GCreated a new partition 1 of type &apos;Linux&apos; and of size 3 GiB.Command (m for help): nPartition type p primary (1 primary, 0 extended, 3 free) e extended (container for logical partitions)Select (default p): pPartition number (2-4, default 2):First sector (6293504-10485759, default 6293504):Last sector, +/-sectors or +/-size&#123;K,M,G,T,P&#125; (6293504-10485759, default 10485759):Created a new partition 2 of type &apos;Linux&apos; and of size 2 GiB. 再用同样的步骤将磁盘的剩余空间划分为另一个分区。此时查看分区信息，原本空白的 5GB 新硬盘 sdb 已经被划分为两个分区 sdb1 和 sdb2 ：123456789101112Command (m for help): pDisk /dev/sdb: 5 GiB, 5368709120 bytes, 10485760 sectorsDisk model: VBOX HARDDISKUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisklabel type: dosDisk identifier: 0xce119026Device Boot Start End Sectors Size Id Type/dev/sdb1 2048 6293503 6291456 3G 83 Linux/dev/sdb2 6293504 10485759 4192256 2G 83 Linux 需要注意的是，如果此时按下 q 按键直接退出 fdisk 程序，则之前所做的全部操作都不会被保存。如确认前面对硬盘的操作没有问题，应使用 w 命令将新的分区信息写入到磁盘中。类似于编辑文件时的保存并退出。 三、文件系统可以将磁盘等存储设备看作一个小型的图书馆，存放在其中的书籍即硬盘中的数据，而分区的作用类似于对书籍分门类存放的书架，形成相对独立的区域。但是书架上的书籍并不是随意放置的，每本书都需要根据一定的规则和顺序有规律地摆放，有时还要记录下摆放的具体位置。这些书籍的摆放规则即对应于分区上的文件系统。 文件系统是对存储设备的空间进行组织和分配，负责文件存取并对存入的文件进行保护和检索的系统。对操作系统而言，文件的读写不会直接作用于硬盘扇区，而是通过文件系统以特定的规则处理和组织文件数据。常见的文件系统如 Windows 中的 NTFS 和 Linux 系统中 Ext4 等。 在 Windows 系统中，通常所说的“分区”操作即包含了创建分区并建立文件系统的过程。而在 Linux 系统中，这两步操作则需要两个独立的命令完成。 可以使用 mkfs.ext4 /dev/sdb1 命令，在之前新加硬盘的第一个分区上创建 Ext4 格式的文件系统。1234567891011$ sudo mkfs.ext4 /dev/sdb1mke2fs 1.44.6 (5-Mar-2019)Creating filesystem with 786432 4k blocks and 196608 inodesFilesystem UUID: d5e21599-12e9-44da-ae51-124d89fe5edaSuperblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912Allocating group tables: doneWriting inode tables: doneCreating journal (16384 blocks): doneWriting superblocks and filesystem accounting information: done 交换分区Linux 系统中的 swap 分区可以看作位于硬盘上的“内存设备”。Linux 会将内存中一部分不需要立即使用的数据临时交换至硬盘上的 swap 分区，以缓解内存不足等情况。 我的 Linux 虚拟机安装时并没有分配 swap 分区，这里通过 mkswap 命令将 2G 大小的 sdb2 分区划分为 swap 空间：123$ sudo mkswap /dev/sdb2Setting up swapspace version 1, size = 2 GiB (2146430976 bytes)no label, UUID=47006330-810c-4321-8d73-d52a5f70bc88 然后使用 swapon 命令立即启用前面创建的 swap 分区：12345$ sudo swapon /dev/sdb2$ free -h total used free shared buff/cache availableMem: 983Mi 223Mi 168Mi 4.0Mi 590Mi 597MiSwap: 2.0Gi 0B 2.0Gi 分区挂载在 Windows 系统中，一般插入一个已经分好区的硬盘或优盘之后，会自动为添加的一个或多个分区分配盘符（如 D:、E:、F: 等），之后就可以直接通过盘符在新分区上读取或写入文件了。 Linux 系统中没有盘符的概念，它的文件层次是一个从根目录（/）开始的树状结构（目录），一直向下延申，每一个分支都是一条具体的路径，指向某个特定的文件。比如 /usr、/root、/var、/var/log 等。 目录可以说是独立于硬件存储设备的抽象的逻辑结构，用于指定文件系统层次中的某个具体位置。而磁盘分区与目录结构的对应关系，则需要通过挂载来指定。 一般在安装系统时，可以将 sda1 分区挂载到根目录下，则该目录下的所有文件之后都将保存在 sda1 上。如果后面又添加了一块新的数据盘 sdb，该硬盘只有一个分区 sdb1。为了将某些文件保存在 sdb1 分区上，可以在目录树中新建一个空白分支（比如 /mnt/data）并将 sdb1 挂载在该分支下。之后 /mnt/data 目录下创建的任何子目录和文件等数据都会保存在 sdb1 上。具体命令如下：12$ sudo mkdir -p /mnt/data$ sudo mount /dev/sdb1 /mnt/data 使用 df -h 命令查看文件系统占用的磁盘空间的具体情况：1234567891011$ df -hFilesystem Size Used Avail Use% Mounted onudev 456M 0 456M 0% /devtmpfs 99M 1.1M 98M 2% /run/dev/sda1 9.8G 5.2G 4.2G 56% /tmpfs 492M 0 492M 0% /dev/shmtmpfs 5.0M 4.0K 5.0M 1% /run/locktmpfs 492M 0 492M 0% /sys/fs/cgrouptmpfs 99M 0 99M 0% /run/user/117tmpfs 99M 0 99M 0% /run/user/1000/dev/sdb1 2.9G 9.0M 2.8G 1% /mnt/data 可以看到新添加的分区 /dev/sdb1 已经挂载到 /mnt/data 目录下了。 或者也可以使用 lsblk 命令查看块存储设备（即磁盘和分区）的容量和挂载点：12345678$ lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsda 8:0 0 10G 0 disk└─sda1 8:1 0 10G 0 part /sdb 8:16 0 5G 0 disk├─sdb1 8:17 0 3G 0 part /mnt/data└─sdb2 8:18 0 2G 0 part [SWAP]sr0 11:0 1 1024M 0 rom 需要注意的是，手动挂载的分区在系统重启以后会自动卸载。如果想像根目录那样，每次系统启动时自动挂载分区，可以修改 /etc/fstab 配置文件，示例内容如下：1234# &lt;file system&gt; &lt;mount point&gt; &lt;type&gt; &lt;options&gt; &lt;dump&gt; &lt;pass&gt;UUID=f3435713-b2cd-4196-b07b-2ffb116a028d / ext4 defaults 0 1/dev/sdb1 /mnt/data ext4 defaults 0 1/dev/sdb2 none swap sw 0 0 PS：相对于 /dev/sda1 这种形式，使用 UUID 挂载分区往往更保险一点，可以通过 blkid 命令查看磁盘分区的 UUID：1234$ sudo blkid/dev/sda1: UUID=&quot;f3435713-b2cd-4196-b07b-2ffb116a028d&quot; TYPE=&quot;ext4&quot; PARTUUID=&quot;20985120-01&quot;/dev/sdb1: UUID=&quot;d5e21599-12e9-44da-ae51-124d89fe5eda&quot; TYPE=&quot;ext4&quot; PARTUUID=&quot;ce119026-01&quot;/dev/sdb2: UUID=&quot;47006330-810c-4321-8d73-d52a5f70bc88&quot; TYPE=&quot;swap&quot; PARTUUID=&quot;ce119026-02&quot; 四、LVM（逻辑卷管理）对于不包含逻辑卷管理（LVM）的磁盘分区方案，分区的位置、大小和数量一般都是固定的，从而导致扩展当前分区和添加新分区等操作变得困难。此时若添加额外的硬盘和分区，则需要在目录树中创建新的分支作为挂载点，文件数据分散到多个复杂的位置上，不便于合并、备份和管理数据。 LVM 允许将单个或多个分区合并为一个逻辑卷组，且其中包含的逻辑卷可以动态地添加、改变大小或删除。LVM 系统最底层为物理卷（pv），即磁盘、分区和 RAID 阵列等。物理卷可以用来创建逻辑卷组（vg），而逻辑卷组又可以包含任意数量的逻辑卷（lv），逻辑卷从功能上即对应于物理磁盘上的分区。 创建卷组和逻辑卷可以使用 pvcreate 命令将某个存储设备（磁盘或分区等）标记为物理卷。这里我通过 VirtualBox 添加了另一块大小为 5G 的空白的虚拟硬盘，系统检测到该设备为 /dev/sdc ：123456789$ lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsda 8:0 0 10G 0 disk└─sda1 8:1 0 10G 0 part /sdb 8:16 0 5G 0 disk├─sdb1 8:17 0 3G 0 part /mnt/data└─sdb2 8:18 0 2G 0 part [SWAP]sdc 8:32 0 5G 0 disksr0 11:0 1 1024M 0 rom 创建物理卷：12$ sudo pvcreate /dev/sdc Physical volume &quot;/dev/sdc&quot; successfully created. 通过 pvs 命令列出所有的物理卷：123$ sudo pvs PV VG Fmt Attr PSize PFree /dev/sdc lvm2 --- 5.00g 5.00g 通过 vgcreate 命令在物理卷的基础上创建逻辑卷组：12$ sudo vgcreate data-volume /dev/sdc Volume group &quot;data-volume&quot; successfully created 使用 vgs 命令列出当前所有的逻辑卷组：123$ sudo vgs VG #PV #LV #SN Attr VSize VFree data-volume 1 0 0 wz--n- &lt;5.00g &lt;5.00g 使用 lvcreate 命令在卷组中创建逻辑卷：12$ sudo lvcreate --name data --size 2G data-volume Logical volume &quot;data&quot; created. 访问逻辑卷可以通过 /dev/mapper/&lt;vgname&gt;-&lt;lvname&gt; 或者 /dev/&lt;vgname&gt;/&lt;lvname&gt; 形式的路径，即刚刚创建的 data 逻辑卷可以通过 /dev/data-volume/data 指定。在该逻辑卷上创建 Ext4 文件系统：1234567891011$ sudo mkfs.ext4 /dev/data-volume/datamke2fs 1.44.6 (5-Mar-2019)Creating filesystem with 524288 4k blocks and 131072 inodesFilesystem UUID: 0f24cdd8-62e0-42fd-bc38-aa3bce91e099Superblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912Allocating group tables: doneWriting inode tables: doneCreating journal (16384 blocks): doneWriting superblocks and filesystem accounting information: done 此时该逻辑卷即可挂载到某个目录分支下像普通物理分区一样正常使用了。 操作卷组和逻辑卷可以使用 lvextend 命令动态地扩展逻辑卷的存储空间：12345678$ sudo lvextend --size +2G --resizefs /dev/data-volume/datafsck from util-linux 2.33.1/dev/mapper/data--volume-data: clean, 11/131072 files, 26156/524288 blocks Size of logical volume data-volume/data changed from 2.00 GiB (512 extents) to 4.00 GiB (1024 extents). Logical volume data-volume/data successfully resized.resize2fs 1.44.6 (5-Mar-2019)Resizing the filesystem on /dev/mapper/data--volume-data to 1048576 (4k) blocks.The filesystem on /dev/mapper/data--volume-data is now 1048576 (4k) blocks long. 其中 --size +2G 用于指定增加 2G 空间，--resizefs 指定在扩展逻辑卷大小的同时扩充文件系统的大小（文件系统默认不会随逻辑卷的空间变化而自动扩展）。 或者也可以直接指定扩展后的大小，如：$ sudo lvextend --size 4G --resizefs /dev/data-volume/data 其他常用的命令比如通过 lvresize 命令扩展逻辑卷，使其占用当前卷组中剩余的全部空间：123$ sudo lvresize -l +100%free /dev/data-volume/data Size of logical volume data-volume/data changed from &lt;3.00 GiB (767 extents) to &lt;5.00 GiB (1279 extents). Logical volume data-volume/data successfully resized. 因为上面的命令没有加上 --resizefs 或者 -r 选项，因此文件系统不会随着逻辑卷自动扩展大小，可以通过 resize2fs 命令手动扩展文件系统：$ sudo resize2fs /dev/data-volume/data 假设一段时间以后，逻辑卷 /dev/data-volume/data 的空间即将被数据填满，可以尝试添加另一块硬盘 sdd：1234567891011$ lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsda 8:0 0 10G 0 disk└─sda1 8:1 0 10G 0 part /sdb 8:16 0 5G 0 disk├─sdb1 8:17 0 3G 0 part /mnt/data└─sdb2 8:18 0 2G 0 part [SWAP]sdc 8:32 0 5G 0 disk└─data--volume-data 253:0 0 5G 0 lvmsdd 8:48 0 5G 0 disksr0 11:0 1 1024M 0 rom 使用 pvcreate 命令创建物理卷：1234$ sudo pvs PV VG Fmt Attr PSize PFree /dev/sdc data-volume lvm2 a-- &lt;5.00g 0 /dev/sdd lvm2 --- 5.00g 5.00g 使用 vgextend 命令将该物理卷添加到之前创建的卷组 data-volume 中：12345$ sudo vgextend data-volume /dev/sdd Volume group &quot;data-volume&quot; successfully extended$ sudo vgs VG #PV #LV #SN Attr VSize VFree data-volume 2 1 0 wz--n- 9.99g &lt;5.00g 此时的 data-volume 卷组包含了两个物理卷（/dev/sdc 和 /dev/sdd）和一个逻辑卷（/dev/data-volume/data），总大小变为 10G，闲置空间为 5G（即刚刚添加的物理卷）。 最后使用 lvresize 命令扩展逻辑卷大小，使其占据两个物理卷的全部存储空间：12345678$ sudo lvresize -l +100%free -r /dev/data-volume/datafsck from util-linux 2.33.1/dev/mapper/data--volume-data: clean, 11/196608 files, 30268/785408 blocks Size of logical volume data-volume/data changed from &lt;5.00 GiB (1279 extents) to 9.99 GiB (2558 extents). Logical volume data-volume/data successfully resized.resize2fs 1.44.6 (5-Mar-2019)Resizing the filesystem on /dev/mapper/data--volume-data to 2619392 (4k) blocks.The filesystem on /dev/mapper/data--volume-data is now 2619392 (4k) blocks long. 此时逻辑卷 /dev/data-volume/data 的大小扩展为 10G，即占用了整个卷组 data-volume（包含两个 5G 的物理卷）的全部空间。 总结：LVM 卷组（vg）的作用类似于物理磁盘，用于承载逻辑卷（lv）。卷组可以由多个物理卷（磁盘或分区等）构成，空间不够时也可以随时添加新的物理卷进行扩展。而卷组上的逻辑卷（lv）类似于磁盘分区，可以挂载到目录作为存储空间。但是物理分区的位置和大小固定，而逻辑卷则可以在卷组的基础上动态的改变大小，甚至跨越多个物理磁盘和分区，使得管理起来更加方便和灵活。 常用 LVM 命令列表： Command Used For pvcreate Labeling devices for use with LVM pvremove Removing the LVM label from a physical volume pvdisplay / pvs Displaying information on the specified device or all physical volumes on the system vgcreate Creating a new volume group vgremove Removing (deleting) a volume group vgextend Adding physical volumes to a volume group vgreduce Removing physical volumes from a volume group vgdisplay / vgs Displaying information about the specified group or all volume groups on the system lvcreate Creating a new logical volume lvremove Removing (deleting) a logical volume lvextend Increasing the size of a logical volume lvreduce Decreasing the size of a logical volume lvdisplay / lvs Displaying all logical volumes on the system or in a specified volume group 参考资料Pro Linux System Administration]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Admin</tag>
        <tag>Tools</tag>
        <tag>Disk</tag>
        <tag>Storage</tag>
        <tag>LVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nagios4 系统监控工具安装及配置简介（Ubuntu 19.04）]]></title>
    <url>%2F2019%2F08%2F01%2Fmonitor-system-nagios4-installation-and-usage%2F</url>
    <content type="text"><![CDATA[Nagios 是一款开源的系统监控工具。它主要负责对网络环境中的硬件设备及软件服务进行持续的检查，确保这些设备或服务处于正常运行的状态。一旦发现任何错误，Nagios 会在尽可能短的时间内向工作人员发出警报，同时也会在一定程度上尝试自动修复故障（比如重启设备或服务）。 一、简介Nagios 监控的对象主要可分为两类： Hosts 表示网络中的物理（或虚拟化的）设备，如服务器、工作站、路由器和打印机等 Services 表示网络中某些设施提供的特定功能的集合，如 CPU、内存、磁盘空间等。其他如 sshd 服务等也可被定义为 Service 接受 Nagios 的监控 此外，多台主机还可以被划分到不同的主机组中以方便管理和维护。 pluginsNagios 提供的所有的监控操作全部都由插件来完成。插件是一些用来传递监控信息的附加组件，Nagios 通过它们执行具体的监控和检查任务，同时对收集到的结果进行统计与整理。 Nagios 默认提供了一些基础的插件，几乎可以满足所有常见的监控任务。此外，如果有特殊的监控需求，也可以自行编写 Nagios 插件。一般标准插件的默认安装路径为 /usr/lib/nagios/plugins ，插件名称绝大多数以 check_ 开头：1234567$ ls /usr/lib/nagios/pluginscheck_apt check_file_age check_imap check_nagios check_pop check_ssmtpcheck_breeze check_flexlm check_ircd check_nntp check_procs check_swapcheck_by_ssh check_fping check_jabber check_nntps check_radius check_tcpcheck_clamd check_ftp check_ldap check_nt check_real check_timecheck_cluster check_game check_ldaps check_ntp check_rpc check_udp... 二、安装 Nagios我用的是 Ubuntu 19.04 系统，呃，没有尝试过其他的安装方式。就是直接用包管理器（apt-get）安装的，命令（就一条，，，）如下：$ sudo apt-get install nagios4 该命令会同时安装一些标准的 Nagios 插件以及一个简单的 Web 监控平台（需要 Apache2 服务器和 PHP 语言支持）。用 apt-get 命令安装完 Nagios4 之后，Web 监控平台的 Apache2 配置文件会自动添加到 /etc/apache2/conf_enabled 目录下并直接启用。 只不过我这里重启 Apache2 服务时报错，原因是还需要启用额外两个 Apache 的模块，命令如下：12$ sudo a2enmod auth_digest$ sudo a2enmod authz_groupfile 重启 Apache2 后访问 http://127.0.0.1/nagios4 链接，即可进入 Web 监控平台，截图如下： 三、配置文件介绍Nagios 的配置文件一般位于 /etc/nagios 或者 /usr/local/etc/nagios 目录下，最主要的配置文件为 nagios.cfg 。nagios.cfg 像是一个统领性的大纲文件，它除了定义一些全局范围内的基本配置外，还用于指定其他（更细节的）配置文件的位置或者组织方式，类似于书籍中的目录。 如文件中的 cfg_dir 和 cfg_file 两个配置项：12345678910111213...cfg_dir=/etc/nagios-plugins/configcfg_dir=/etc/nagios4/conf.d# You can specify individual object config files as shown below:cfg_file=/etc/nagios4/objects/commands.cfgcfg_file=/etc/nagios4/objects/contacts.cfgcfg_file=/etc/nagios4/objects/timeperiods.cfgcfg_file=/etc/nagios4/objects/templates.cfg# Definitions for monitoring the local (Linux) hostcfg_file=/etc/nagios4/objects/localhost.cfg... 即关于监控对象的详细配置，一般保存在由 cfg_file 指定的配置文件中。或者也可以将包含配置信息的文件放置在由 cfg_dir 指定的目录（及其子目录）下。 比如默认启用的 /etc/nagios4/objects/localhost.cfg 配置文件，其中包含了关联到本地主机的多个监控对象的信息，从中也可以看出 Nagios 在配置监控对象时所遵循的基本语法：123456789101112131415161718192021222324252627282930313233343536# Define a host for the local machinedefine host&#123; use linux-server ; Name of host template to use host_name localhost alias localhost address 127.0.0.1 &#125;# Define a service to check the disk space of the root partitio on the local machine. Warning if &lt; 20% free, critical if &lt; 10% free space on partition.define service&#123; use local-service ; Name of service template to use host_name localhost service_description Root Partition check_command check_local_disk!20%!10%!/ &#125;# Define a service to check the number of currently running procs on the local machine. Warning if &gt; 250 processes, critical if &gt; 400 processes.define service&#123; use local-service ; Name of service template to use host_name localhost service_description Total Processes check_command check_local_procs!250!400!RSZDT &#125;# Define a service to check HTTP on the local machine. Disable notifications for this service by default, as not all users may have HTTP enabled.define service&#123; use local-service ; Name of service template to use host_name localhost service_description HTTP check_command check_http notifications_enabled 0 &#125; 至于 /etc/nagios4/objects 目录下默认启用的几个配置文件，则包含了一些自定义命令（commands.cfg）、联系人信息（contacts.cfg）、时间段配置（timeperiods.cfg）以及主机和服务的模板（templates.cfg）等。 比如 localhost.cfg 中的 use linux-server 配置项，即使用了由 templates.cfg 文件定义的名为 linux-server 的模板：1234567891011121314151617$ cat /etc/nagios4/objects/templates.cfg...define host&#123; name linux-server ; The name of this host template use generic-host ; This template inherits other values from the generic-host template check_period 24x7 ; By default, Linux hosts are checked round the clock check_interval 5 ; Actively check the host every 5 minutes retry_interval 1 ; Schedule host check retries at 1 minute intervals max_check_attempts 10 ; Check each Linux host 10 times (max) check_command check-host-alive ; Default command to check Linux hosts notification_period workhours ; Linux admins hate to be woken up, so we only notify during the day notification_interval 120 ; Resend notifications every 2 hours notification_options d,u,r ; Only send notifications for specific host states contact_groups admins ; Notifications get sent to the admins by default register 0 ; DONT REGISTER THIS DEFINITION - ITS NOT A REAL HOST, JUST A TEMPLATE! &#125;... 其他由 Nagios 默认提供的主机或服务模板、联系人模板等也都保存在该文件中。 总的来说，在创建自定义配置时，objects 目录下的配置文件可以作为很有价值的参考示例，同时其中定义的命令、联系人和模板等也可在需要时直接通过名称调用，减少相关代码的编写。 对于设备数量庞大且种类较复杂的场景，建议将 Nagios 配置文件的组织架构设计成便于管理的形式。比如：1234567891011$ tree /etc/nagios4/conf.d/etc/nagios4/conf.d├── commands├── contactgroups├── contacts├── hostgroups├── hosts│ └── server2.cfg├── servicegroups├── services└── timeperiods 四、定义监控对象宏指令能够通过宏指令来简化配置，是 Nagios 的关键特性之一。宏的运用在很大程度上提高了定义对象和命令的灵活性。如下面的配置示例：1234567891011define host&#123; use linux-server host_name server2 address 192.168.1.102 check_command check-host-ssh&#125;define command&#123; command_name check-host-ssh command_line $USER1$/check_ssh -H $HOSTADDRESS$&#125; 其中的 $USER1$ 和 $HOSTADDRESS$ 即是预先定义的两个宏。$USER1$ 是在资源配置文件（/etc/nagios4/resource.cfg）中指定的 Nagios 插件的安装路径。$HOSTADDRESS$ 则表示 host 定义中的 address 项的内容，即主机的 IP 地址。 定义主机简单的示例代码如下：123456789101112131415define host&#123; host_name server1 hostgroups linux-servers alias Ubuntu 19.04 address 192.168.1.101 check_command check-host-alive check_interval 10 retry_interval 1 max_check_attempts 5 check_period 24x7 contact_groups admins notification_interval 30 notification_period 24x7 notification_options d,u,r&#125; 关于 notification_options： d : the host DOWN state u : the host UNREACHABLE state r : host recovery (UP state) f : the host starts and stops flapping s : notify when scheduled downtime starts or ends 定义主机组示例代码如下：1234567891011121314151617define hostgroup&#123; hostgroup_name linux-servers alias Linux servers members server1,server2&#125;define hostgroup&#123; hostgroup_name aix-servers alias AIX servers members aixbox1,aixbox2&#125;define hostgroup&#123; hostgroup_name unix-servers alias UNIX servers hostgroup_members linux-servers,aix-servers&#125; 其中定义了两个分别包含两台主机的主机组（linux-servers、aix-servers），同时还定义了包含这两个主机组的“大”主机组（unix-servers）。即主机组的定义支持嵌套。 定义服务示例代码如下：12345678910111213define service&#123; host_name server2 service_description www check_command check_http check_interval 10 check_period 24x7 retry_interval 3 max_check_attempts 3 notification_interval 30 notification_period 24x7 notification_options w,c,u,r contact_groups admins&#125; 关于 notification_options： w : the service WARNING state u : the service UNKNOWN state c : the service CRITICAL state r : the service recovery (back to OK) state f : the host starts and stops flapping s : notify when the scheduled downtime starts or ends 定义时间段示例代码如下：12345678910111213141516define timeperiod&#123; timeperiod_name workinghours alias Working Hours, excluding lunch break monday 09:00-13:00,14:00-17:00 tuesday 09:00-13:00,14:00-17:00 wednesday 09:00-13:00,14:00-17:00 thursday 09:00-13:00,14:00-17:00 friday 09:00-13:00,14:00-17:00&#125;define timeperiod&#123; timeperiod_name weekends alias Weekends all day long saturday 00:00-24:00 sunday 00:00-24:00&#125; 定义联系人示例代码如下：123456789101112define contact&#123; contact_name jdoe alias John Doe email john.doe@gmail.com contactgroups admins host_notification_period workinghours service_notification_period workinghours host_notification_options d,u,r service_notification_options w,u,c,r host_notification_commands notify-host-by-email service_notification_commands notify-service-by-email&#125; 参考资料Learning Nagios - Third Edition]]></content>
      <categories>
        <category>Server</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Server</tag>
        <tag>Admin</tag>
        <tag>Tools</tag>
        <tag>DevOps</tag>
        <tag>Monitoring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息队列中间件 RabbitMQ 详细介绍——安装与基本应用（Python）]]></title>
    <url>%2F2019%2F07%2F28%2Fmessage-broker-RabbitMQ-intro%2F</url>
    <content type="text"><![CDATA[RabbitMQ 是当前最流行的消息中间件（Message Broker）之一，支持多种消息协议（如 AMQP、MQTT）。同时它也是一个轻量级的非常易于部署的开源软件，可以运行在当前大多数操作系统及云端环境中，也能够部署在分布式的集群环境里以达到高可用、可伸缩的需求。此外，RabbitMQ 还为目前主流的编程语言提供了丰富的开发工具。 一、软件安装可以进入 官方下载界面 阅读针对自己操作系统版本的安装手册，根据需求选择适合的安装方式。Windows 系统可以直接在该页面中获取二进制安装包（还需要安装 Erlang 环境），Linux 系统也可以根据发行版的不同添加特定的软件镜像源。 我这里是 Ubuntu 19.04，没有特别的需求，所以直接从系统默认的软件镜像源里下载安装，命令如下：$ sudo apt-get install rabbitmq-server 安装完成以后，运行 systemctl status rabbitmq-server 命令查看 RabbitMQ 服务的运行状态：123456789101112131415161718$ systemctl status rabbitmq-server● rabbitmq-server.service - RabbitMQ Messaging Server Loaded: loaded (/lib/systemd/system/rabbitmq-server.service; enabled; vendor preset: enabled) Active: active (running) since Fri 2019-07-26 01:03:27 CST; 2min 55s ago Main PID: 770 (beam.smp) Status: &quot;Initialized&quot; Tasks: 85 (limit: 2302) Memory: 85.8M CGroup: /system.slice/rabbitmq-server.service ├─ 741 /bin/sh /usr/sbin/rabbitmq-server ├─ 770 /usr/lib/erlang/erts-10.2.4/bin/beam.smp -W w -A 64 -MBas ageffcbf -MHas ageffcbf -MBlmbcs 512 -MHlmbcs 512 -MMmcs 30 -P 1048576 -t 5000000 -stbt db -zdbbl 128000 -K true -- -root /usr/lib/erlang -progname erl -- -home /var/lib/rabbitmq -- -pa /usr/lib/rabbitmq/lib/rabbitmq_server-3.7.8/ebin -noshell -noinput -s rabbit boot -sname rabbit@server1 -boot start_sasl -kernel inet_default_connect_options [&#123;nodelay,true&#125;] -sasl errlog_type error -sasl sasl_error_logger false -rabbit lager_log_root &quot;/var/log/rabbitmq&quot; -rabbit lager_default_file &quot;/var/log/rabbitmq/rabbit@server1.log&quot; -rabbit lager_upgrade_file &quot;/var/log/rabbitmq/rabbit@server1_upgrade.log&quot; -rabbit enabled_plugins_file &quot;/etc/rabbitmq/enabled_plugins&quot; -rabbit plugins_dir &quot;/usr/lib/rabbitmq/plugins:/usr/lib/rabbitmq/lib/rabbitmq_server-3.7.8/plugins&quot; -rabbit plugins_expand_dir &quot;/var/lib/rabbitmq/mnesia/rabbit@server1-plugins-expand&quot; -os_mon start_cpu_sup false -os_mon start_disksup false -os_mon start_memsup false -mnesia dir &quot;/var/lib/rabbitmq/mnesia/rabbit@server1&quot; -kernel inet_dist_listen_min 25672 -kernel inet_dist_listen_max 25672 ├─1243 erl_child_setup 65536 ├─1286 inet_gethost 4 └─1287 inet_gethost 47月 26 01:02:44 server1 systemd[1]: Starting RabbitMQ Messaging Server...7月 26 01:03:27 server1 systemd[1]: rabbitmq-server.service: Supervising process 770 which is not our child. We&apos;ll most likely not notice when it exits.7月 26 01:03:27 server1 systemd[1]: Started RabbitMQ Messaging Server. Web AdminRabbitMQ 还提供了可以远程访问的 Web 管理与监控工具，默认以插件的形式安装到系统中，需要使用 rabbitmq-plugins 命令开启。具体命令如下：$ sudo rabbitmq-plugins enable rabbitmq_management RabbitMQ 默认创建了一个用户名密码分别为 guest/guest 的用户，只是该用户只允许本地登录。（我这里是远程。。。）如果需要远程访问 Web 控制台，可以通过 rabbitmqctl 命令创建一个新的管理账户：$ sudo rabbitmqctl add_user &lt;username&gt; &lt;password&gt; 此时新创建的账户仍无法登录，还需要为其分配用户角色以及对 vhost 的管理权限，命令如下：12$ sudo rabbitmqctl set_user_tags &lt;username&gt; administrator$ sudo rabbitmqctl set_permissions -p / &lt;username&gt; &quot;.*&quot; &quot;.*&quot; &quot;.*&quot; 权限设置完毕后，即可用之前指定的用户名密码远程登录 Web 管理系统，界面如下图： Web 形式的后台界面为管理工作与监控需求提供了便捷的接口，同时大部分管理操作也可直接通过 rabbitmqctl 命令完成，具体可参考该命令的帮助信息：1234567891011121314$ sudo rabbitmqctlUsage:rabbitmqctl [-n &lt;node&gt;] [-l] [-q] &lt;command&gt; [&lt;command options&gt;]...Commands: add_user &lt;username&gt; &lt;password&gt; add_vhost &lt;vhost&gt; authenticate_user &lt;username&gt; &lt;password&gt; await_online_nodes &lt;count&gt; [-t &lt;timeout&gt;] cancel_sync_queue [-p &lt;vhost&gt;] queue change_cluster_node_type &lt;disc|ram&gt; change_password &lt;username&gt; &lt;password&gt;... 二、架构解析RabbitMQ 是一种高性能、稳定、可伸缩（集群部署）的消息中间件，由 Erlang 语言编写。 Erlang 是一种函数式编程语言，专注于分布式、高容错的软件类实时系统等应用场景。它通过轻量级的进程设计以及进程之间的消息通信，提供了一个高层次的不需要共享状态的并发模型。RabbitMQ 集群通过 Erlang VM 原生的 IPC (inter-process communication) 机制完成跨节点的消息通信。 松耦合架构对于传统的应用架构，比如一个 Web 应用的登录程序，往往需要对后端的数据库表格进行多项实时的写入操作。而当用户的访问量大增时，此时的表格更新操作很容易成为瓶颈并影响到整体的响应速度。 相对于登录程序直接更新表格数据的紧耦合架构，可以将前端的请求数据推送到基于消息的中间件或者某个中心化的消息队列应用，再通过中间件分发消息到多个消费者（Consumer）应用，由消费者独立、异步地完成最终的数据库更新操作。基于消息的中间件对于创建数据导向的灵活的应用架构有非常大的优势。RabbitMQ 支持的松耦合设计可以使应用不再受类似于数据库写操作的性能限制。同时这种架构也非常易于横向扩展，可以在添加作用于相同数据的应用实例时不影响现有的核心功能。 三、消息应用示例代码下文中将使用 Python 语言及其 RabbitMQ 客户端 Pika 创建 5 个基本的消息应用，结构由简单到复杂，源代码均参考自官网 RabbitMQ Tutorials 。安装 pika 库：pip install pika Hello World该应用的结构示意图如下： 由 P (Producer) 发送一条消息到队列（Queue），再由队列转发消息到 C (Consumer) 。 发送端代码 send.py 如下：123456789101112131415#!/usr/bin/env pythonimport pika# 初始化与 RabbitMQ 服务器的连接connection = pika.BlockingConnection( pika.ConnectionParameters(host=&apos;localhost&apos;))channel = connection.channel()# 队列声明channel.queue_declare(queue=&apos;hello&apos;)# 发送消息channel.basic_publish(exchange=&apos;&apos;, routing_key=&apos;hello&apos;, body=&apos;Hello World!&apos;)print(&quot; [x] Sent &apos;Hello World!&apos;&quot;)connection.close() 接收端 reveive.py 代码如下：123456789101112131415161718#!/usr/bin/env pythonimport pikaconnection = pika.BlockingConnection( pika.ConnectionParameters(host=&apos;localhost&apos;))channel = connection.channel()channel.queue_declare(queue=&apos;hello&apos;)# 接收到消息后触发的回调函数def callback(ch, method, properties, body): print(&quot; [x] Received %r&quot; % body)# 消费者声明与消息监听channel.basic_consume( queue=&apos;hello&apos;, on_message_callback=callback, auto_ack=True)print(&apos; [*] Waiting for messages. To exit press CTRL+C&apos;)channel.start_consuming() 测试首先运行 4 次发送程序：12345678$ python send.py [x] Sent &apos;Hello World&apos;$ python send.py [x] Sent &apos;Hello World&apos;$ python send.py [x] Sent &apos;Hello World&apos;$ python send.py [x] Sent &apos;Hello World&apos; 从 Web 管理界面中可以看到，此时队列中缓存了 4 条消息。运行接收端程序：123456$ python receive.py [x] Waiting for messages. To exit press CTRL+C [x] Received b&apos;Hello World&apos; [x] Received b&apos;Hello World&apos; [x] Received b&apos;Hello World&apos; [x] Received b&apos;Hello World&apos; 发送端连续 4 次发送的消息被接收端收取，队列中缓存的消息被清空。同时接收端保持运行状态等待新的消息被转发给自己。消息队列一直处于等待生产者发送消息和将收到或缓存的消息转发给消费者的状态。如未有消费者及时接收和处理被转发的消息，则这部分消息缓存在队列中等待进一步操作。 Work Queue结构示意图：本例中将创建一个 Work Queue 用来将消耗时间长的任务以轮询的方式分发给多个消费者处理。 生产者源代码 new_task.py ：1234567891011121314151617181920#!/usr/bin/env pythonimport pikaimport sysconnection = pika.BlockingConnection( pika.ConnectionParameters(host=&apos;localhost&apos;))channel = connection.channel()channel.queue_declare(queue=&apos;task_queue&apos;, durable=True)message = &apos; &apos;.join(sys.argv[1:]) or &quot;Hello World!&quot;channel.basic_publish( exchange=&apos;&apos;, routing_key=&apos;task_queue&apos;, body=message, properties=pika.BasicProperties( delivery_mode=2, # make message persistent ))print(&quot; [x] Sent %r&quot; % message)connection.close() 消费者源代码 worker.py ：1234567891011121314151617181920212223#!/usr/bin/env pythonimport pikaimport timeconnection = pika.BlockingConnection( pika.ConnectionParameters(host=&apos;localhost&apos;))channel = connection.channel()channel.queue_declare(queue=&apos;task_queue&apos;, durable=True)print(&apos; [*] Waiting for messages. To exit press CTRL+C&apos;)def callback(ch, method, properties, body): print(&quot; [x] Received %r&quot; % body) time.sleep(body.count(b&apos;.&apos;)) print(&quot; [x] Done&quot;) ch.basic_ack(delivery_tag=method.delivery_tag) # Message acknowledgmentchannel.basic_qos(prefetch_count=1)channel.basic_consume(queue=&apos;task_queue&apos;, on_message_callback=callback)channel.start_consuming() Message acknowledgment消费者在处理接收到的任务或消息时有可能会消耗比较多的时间，在此过程中，如消费者端出现软硬件故障，则会出现消息丢失的情况。 RabbitMQ 支持 Message acknowledgment 。即消费者在接收和处理完一个特定的消息后会向 RabbitMQ 返回一个应答（ack），说明该消息可以从队列中移除。如果消费者在返回应答之前丢失与队列的连接，则 RabbitMQ 判定对应的消息未由消费者完全处理，会将该消息保留在队列中并重新分发给其他在线的消费者。 Message durability消息应答的机制可以确保即使消费者宕机的情况下任务仍不会丢失。但是当 RabbitMQ 服务本身出现故障时，队列以及队列中缓存的消息仍旧会被清理掉。 为了保证 RabbitMQ 中队列以及消息的持久化，首先需要在生产者和消费者代码中同时声明队列为 durable ：channel.queue_declare(queue=&#39;task_queue&#39;, durable=True) 此外还需要将生产者代码中的 delivery_mode 属性设置为 2 确保消息的持久化：properties=pika.BasicProperties(delivery_mode=2,) 测试打开两个命令行终端，分别运行 worker.py 程序：123# Shell 1$ python worker.py [x] Waiting for messages. To exit press CTRL+C 123# Shell 2$ python worker.py [x] Waiting for messages. To exit press CTRL+C 打开另一个终端窗口运行 new_task.py 程序发送 4 条消息：123456789# Shell 3$ python new_task.py First Message [x] Sent &apos;First Message&apos;$ python new_task.py Second Message [x] Sent &apos;Second Message&apos;$ python new_task.py Third Message [x] Sent &apos;Third Message&apos;$ python new_task.py Forth Message [x] Sent &apos;Forth Message&apos; 最终两个消费者分别接收到队列分发的两条消息：1234567# Shell 1$ python worker.py [x] Waiting for messages. To exit press CTRL+C [x] Received b&apos;First Message&apos; [x] Done [x] Received b&apos;Third Message&apos; [x] Done 1234567# Shell 2$ python worker.py [x] Waiting for messages. To exit press CTRL+C [x] Received b&apos;Second Message&apos; [x] Done [x] Received b&apos;Forth Message&apos; [x] Done Fair dispatch当 RabbitMQ 以轮询的方式（即平均分配）将队列中的消息转发给多个消费者时，如果这些消费者接收到的任务繁重程度差异很大，则会导致某些消费者端任务的积压。为了避免这种情况发生，可以使用 basic_qos 方法设置 prefetch 的值，如 worker.py 程序中的以下代码：channel.basic_qos(prefetch_count=1) 。 该行代码可以确保同一个消费者在任意时间点最多只接受 1 个任务分配给自己。即如果某个消费者当前有未处理完的消息，则不再接收新的消息直到当前的任务处理完。 Publish/Subscribe结构示意图： Exchange在之前的示例中，用到了消息队列模型中的以下几个组件： producer ：生产者，即发送消息的应用 queue ：队列，即存储消息的缓存 consumer ：消费者，即接收消息的应用 实际上在 RabbitMQ 的消息模型中，生产者从来不会将消息直接发送到队列中，而是将消息发送给一个名为 exchange 的组件。exchange 的一端用来接收生产者发送的消息，一端用来将消息推送到队列中。它通过 exchange type 中的定义判断特定的消息是该推送给某个对应的队列，还是将其广播给多个队列，又或者直接丢弃。 RabbitMQ 主要提供了 4 种 exchange 类型：direct、topic、headers 和 fanout。本例中使用 fanout，即 exchange 会将接收到的消息以广播的形式发送给所有关联的队列，再由队列传递给消费者处理。 源代码（emit_log.py）如下：1234567891011121314#!/usr/bin/env pythonimport pikaimport sysconnection = pika.BlockingConnection( pika.ConnectionParameters(host=&apos;localhost&apos;))channel = connection.channel()channel.exchange_declare(exchange=&apos;logs&apos;, exchange_type=&apos;fanout&apos;)message = &apos; &apos;.join(sys.argv[1:]) or &quot;info: Hello World!&quot;channel.basic_publish(exchange=&apos;logs&apos;, routing_key=&apos;&apos;, body=message)print(&quot; [x] Sent %r&quot; % message)connection.close() receive_logs.py：1234567891011121314151617181920212223#!/usr/bin/env pythonimport pikaconnection = pika.BlockingConnection( pika.ConnectionParameters(host=&apos;localhost&apos;))channel = connection.channel()channel.exchange_declare(exchange=&apos;logs&apos;, exchange_type=&apos;fanout&apos;)result = channel.queue_declare(queue=&apos;&apos;, exclusive=True)queue_name = result.method.queuechannel.queue_bind(exchange=&apos;logs&apos;, queue=queue_name)print(&apos; [*] Waiting for logs. To exit press CTRL+C&apos;)def callback(ch, method, properties, body): print(&quot; [x] %r&quot; % body)channel.basic_consume( queue=queue_name, on_message_callback=callback, auto_ack=True)channel.start_consuming() receive_logs.py 文件中有一行 result = channel.queue_declare(queue=&#39;&#39;, exclusive=True) 代码，用来声明一个临时队列（ queue=&#39;&#39; 没有指定名称，因此会由 RabbitMQ 设置随机的名称），同时 exclusive=True 设置该队列在消费者断开连接后自行删除。 测试同时打开两个命令行窗口分别运行 receive_logs.py 文件：123# Shell 1$ python receive_logs.py [*] Waiting for logs. To exit press CTRL+C 123# Shell 2$ python receive_logs.py [*] Waiting for logs. To exit press CTRL+C 再打开第三个终端执行 emit_log.py 命令 4 次：123456789# Shell 3$ python emit_log.py [x] Sent &apos;info: Hello World!&apos;$ python emit_log.py [x] Sent &apos;info: Hello World!&apos;$ python emit_log.py [x] Sent &apos;info: Hello World!&apos;$ python emit_log.py [x] Sent &apos;info: Hello World!&apos; 此时之前运行的两个 receive 程序同时收到发送的 4 条消息：123456$ python receive_logs.py [*] Waiting for logs. To exit press CTRL+C [x] b&apos;info: Hello World!&apos; [x] b&apos;info: Hello World!&apos; [x] b&apos;info: Hello World!&apos; [x] b&apos;info: Hello World!&apos; 123456$ python receive_logs.py [*] Waiting for logs. To exit press CTRL+C [x] b&apos;info: Hello World!&apos; [x] b&apos;info: Hello World!&apos; [x] b&apos;info: Hello World!&apos; [x] b&apos;info: Hello World!&apos; Routing结构示意图：与上一个例子中以广播的形式转发消息不同，本例中允许消费者通过队列有选择地订阅生产者发送的部分消息。 Binding 和 Direct exchange在 RabbitMQ 中，binding 代表 exchange 与队列的对应关系，即队列会根据 binding 的设置对 exchange 转发的消息有选择性地接收。因此 binding 的最终效果也依赖于 exchange 的类型。比如之前用到的 fanout 类型，由于是广播的形式（转发给所有关联的队列）并不需要选择的动作，则 binding 的值被忽略。 但是对于 direct 类型的 exchange ，则可以通过 binding 对消息进行筛选。在 direct exchange 下，只有当队列的 binding_key 与消息的 routing_key 一致时，队列才会收到 exchange 转发的消息。 emit_log_direct.py：12345678910111213141516#!/usr/bin/env pythonimport pikaimport sysconnection = pika.BlockingConnection( pika.ConnectionParameters(host=&apos;localhost&apos;))channel = connection.channel()channel.exchange_declare(exchange=&apos;direct_logs&apos;, exchange_type=&apos;direct&apos;)severity = sys.argv[1] if len(sys.argv) &gt; 1 else &apos;info&apos;message = &apos; &apos;.join(sys.argv[2:]) or &apos;Hello World!&apos;channel.basic_publish( exchange=&apos;direct_logs&apos;, routing_key=severity, body=message)print(&quot; [x] Sent %r:%r&quot; % (severity, message))connection.close() receive_logs_direct.py：123456789101112131415161718192021222324252627282930313233#!/usr/bin/env pythonimport pikaimport sysconnection = pika.BlockingConnection( pika.ConnectionParameters(host=&apos;localhost&apos;))channel = connection.channel()channel.exchange_declare(exchange=&apos;direct_logs&apos;, exchange_type=&apos;direct&apos;)result = channel.queue_declare(queue=&apos;&apos;, exclusive=True)queue_name = result.method.queueseverities = sys.argv[1:]if not severities: sys.stderr.write(&quot;Usage: %s [info] [warning] [error]\n&quot; % sys.argv[0]) sys.exit(1)for severity in severities: channel.queue_bind( exchange=&apos;direct_logs&apos;, queue=queue_name, routing_key=severity)print(&apos; [*] Waiting for logs. To exit press CTRL+C&apos;)def callback(ch, method, properties, body): print(&quot; [x] %r:%r&quot; % (method.routing_key, body))channel.basic_consume( queue=queue_name, on_message_callback=callback, auto_ack=True)channel.start_consuming() 测试首先运行 receive_logs_direct.py 程序并指定参数为 error（即只接收标记为“error”的消息）：123# Shell 1$ python receive_logs_direct.py error [*] Waiting for logs. To exit press CTRL+C 打开另一终端同样运行 receive_logs_direct.py 程序并指定参数为 info warning（即接收标记为 info 或 warning 的消息）：123# Shell 2$ python receive_logs_direct.py info warning [*] Waiting for logs. To exit press CTRL+C 打开第三个终端并运行 emit_log_direct.py 程序发送 4 条日志消息：123456789# Shell 3$ python emit_log_direct.py error &quot;This is an error&quot; [x] Sent &apos;error&apos;:&apos;This is an error&apos;$ python emit_log_direct.py info &quot;Hi, I am an info&quot; [x] Sent &apos;info&apos;:&apos;Hi, I am an info&apos;$ python emit_log_direct.py warning &quot;Yeah, it&apos;s a warning&quot; [x] Sent &apos;warning&apos;:&quot;Yeah, it&apos;s a warning&quot;$ python emit_log_direct.py error &quot;Hi, it&apos;s an error again&quot; [x] Sent &apos;error&apos;:&quot;Hi, it&apos;s an error again&quot; 此时 Shell 1 中只接收到了标记为 error 的消息：1234$ python receive_logs_direct.py error [*] Waiting for logs. To exit press CTRL+C [x] &apos;error&apos;:b&apos;This is an error&apos; [x] &apos;error&apos;:b&quot;Hi, it&apos;s an error again&quot; 而 Shell 2 中接收到了标记为 info 和 warning 的消息：1234$ python receive_logs_direct.py info warning [*] Waiting for logs. To exit press CTRL+C [x] &apos;info&apos;:b&apos;Hi, I am an info&apos; [x] &apos;warning&apos;:b&quot;Yeah, it&apos;s a warning&quot; Topics结构示意图： direct 类型的 exchange 虽然可以根据消息的 routing_key 以及队列的 binding_key 有选择性的推送消息到队列，但是并不适合更复杂的场景。而 topic 类型的 exchange 与 direct 类型逻辑上大致相同，只是 topic 类型的 exchange 并没有一个明确的 routing_key，而是由几个点号（.）分隔的单词（如 lazy.orange.cat）进行定义。与之对应的 binding_key 也需要遵循同样的形式，只不过 binding_key 额外支持两个特殊含义的字符： 星号（*)可以表示某一个任意的单词 井号（#）可以表示任意 0 个或多个单词 因此对于上图（Topics）中的情形，routing_key 为 quick.orange.rabbit 的消息会被转发给 Q1 和 Q2 队列，quick.orange.fox 则只会转发给 Q1 队列，lazy.orange.male.rabbit 被转发给 Q2 队列。 emit_log_topic：12345678910111213141516#!/usr/bin/env pythonimport pikaimport sysconnection = pika.BlockingConnection( pika.ConnectionParameters(host=&apos;localhost&apos;))channel = connection.channel()channel.exchange_declare(exchange=&apos;topic_logs&apos;, exchange_type=&apos;topic&apos;)routing_key = sys.argv[1] if len(sys.argv) &gt; 2 else &apos;anonymous.info&apos;message = &apos; &apos;.join(sys.argv[2:]) or &apos;Hello World!&apos;channel.basic_publish( exchange=&apos;topic_logs&apos;, routing_key=routing_key, body=message)print(&quot; [x] Sent %r:%r&quot; % (routing_key, message))connection.close() receive_logs_topic.py：123456789101112131415161718192021222324252627282930313233#!/usr/bin/env pythonimport pikaimport sysconnection = pika.BlockingConnection( pika.ConnectionParameters(host=&apos;localhost&apos;))channel = connection.channel()channel.exchange_declare(exchange=&apos;topic_logs&apos;, exchange_type=&apos;topic&apos;)result = channel.queue_declare(&apos;&apos;, exclusive=True)queue_name = result.method.queuebinding_keys = sys.argv[1:]if not binding_keys: sys.stderr.write(&quot;Usage: %s [binding_key]...\n&quot; % sys.argv[0]) sys.exit(1)for binding_key in binding_keys: channel.queue_bind( exchange=&apos;topic_logs&apos;, queue=queue_name, routing_key=binding_key)print(&apos; [*] Waiting for logs. To exit press CTRL+C&apos;)def callback(ch, method, properties, body): print(&quot; [x] %r:%r&quot; % (method.routing_key, body))channel.basic_consume( queue=queue_name, on_message_callback=callback, auto_ack=True)channel.start_consuming() 测试先运行接收端程序（Shell 1 和 Shell 2），再运行发送端（Shell 3），效果如下：1234567# Shell 3$ python emit_log_topic.py &quot;kern.warning&quot; &quot;A kernel warning message&quot; [x] Sent &apos;kern.warning&apos;:&apos;A kernel warning message&apos;$ python emit_log_topic.py &quot;network.critical&quot; &quot;A critical network error&quot; [x] Sent &apos;network.critical&apos;:&apos;A critical network error&apos;$ python emit_log_topic.py &quot;kern.critical&quot; &quot;A critical kernel error&quot; [x] Sent &apos;kern.critical&apos;:&apos;A critical kernel error&apos; 12345# Shell 1$ python receive_logs_topic.py &quot;kern.*&quot; [*] Waiting for logs. To exit press CTRL+C [x] &apos;kern.warning&apos;:b&apos;A kernel warning message&apos; [x] &apos;kern.critical&apos;:b&apos;A critical kernel error&apos; 12345# Shell 2$ python receive_logs_topic.py &quot;*.critical&quot; [*] Waiting for logs. To exit press CTRL+C [x] &apos;network.critical&apos;:b&apos;A critical network error&apos; [x] &apos;kern.critical&apos;:b&apos;A critical kernel error&apos; 参考资料RabbitMQ TutorialsRabbitMQ in Depth]]></content>
      <categories>
        <category>Server</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Server</tag>
        <tag>Admin</tag>
        <tag>DevOps</tag>
        <tag>Development</tag>
        <tag>Message</tag>
        <tag>Deployment</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu 系统 dpkg 命令使用详解]]></title>
    <url>%2F2019%2F07%2F21%2Fdpkg-package-manager-manual%2F</url>
    <content type="text"><![CDATA[dpkg 即 package manager for Debian ，是 Debian 和基于 Debian 的系统中一个主要的包管理工具，可以用来安装、构建、卸载、管理 deb 格式的软件包。 安装软件使用 dpkg 命令安装软件时，可以使用 -i 选项并指定 deb 安装包的路径。和 Ubuntu 下的另一个包管理工具 apt-get（Advanced Package Tool）有所不同。apt-get 命令并不直接操作 deb 安装包文件，而是从 /etc/apt/sources.list 配置文件中定义的软件镜像源里下载软件包并安装，使用时也只需指定软件的名称（或者也可以附加上版本号）。 apt-get 命令安装软件：$ apt-get install &lt;package_name[=version]&gt; dpkg 命令安装软件：$ dpkg -i &lt;package_file_path&gt; 因此，dpkg 主要是用来安装已经下载到本地的 deb 软件包，或者对已经安装好的软件进行管理。而 apt-get 可以直接从远程的软件仓库里下载安装软件。 12345678910111213141516$ sudo apt-get install emacs正在读取软件包列表... 完成正在分析软件包的依赖关系树正在读取状态信息... 完成将会同时安装下列软件： emacs-bin-common emacs-common emacs-el emacs-gtk libm17n-0 libotf0 m17n-db建议安装： mailutils emacs-common-non-dfsg m17n-docs gawk下列【新】软件包将被安装： emacs emacs-bin-common emacs-common emacs-el emacs-gtk libm17n-0 libotf0 m17n-db升级了 0 个软件包，新安装了 8 个软件包，要卸载 0 个软件包，有 115 个软件包未被升级。需要下载 34.4 MB 的归档。解压缩后会消耗 137 MB 的额外空间。您希望继续执行吗？ [Y/n] 123456$ sudo dpkg -i fping_4.2-1_amd64.deb(正在读取数据库 ... 系统当前共安装有 252654 个文件和目录。)准备解压 fping_4.2-1_amd64.deb ...正在解压 fping (4.2-1) 并覆盖 (4.2-1) ...正在设置 fping (4.2-1) ...正在处理用于 man-db (2.8.5-2) 的触发器 ... 列出已安装的软件可以使用 dpkg -l 命令列出当前系统中已经安装的软件以及软件包的状态。如：12345678910111213141516$ dpkg -l期望状态=未知(u)/安装(i)/删除(r)/清除(p)/保持(h)| 状态=未安装(n)/已安装(i)/仅存配置(c)/仅解压缩(U)/配置失败(F)/不完全安装(H)/触发器等待(W)/触发器未决(T)|/ 错误?=(无)/须重装(R) (状态，错误：大写=故障)||/ 名称 版本 体系结构 描述+++-=============================================-===================================-============-===============================================================================ii 2048-qt 0.1.6-1build1 amd64 mathematics based puzzle gameii accountsservice 0.6.50-0ubuntu1 amd64 query and manipulate user account informationii acl 2.2.53-4 amd64 access control list - utilitiesii acpi-support 0.143 amd64 scripts for handling many ACPI eventsii acpid 1:2.0.31-1ubuntu2 amd64 Advanced Configuration and Power Interface event daemonii adduser 3.118ubuntu1 all add and remove users and groupsii adwaita-icon-theme 3.32.0-1ubuntu1 all default icon theme of GNOME (small subset)ii alsa-base 1.0.25+dfsg-0ubuntu5 all ALSA driver configuration filesii alsa-utils 1.1.8-1ubuntu1 amd64 Utilities for configuring and using ALSA... 该命令每行输出中的第一列 ii 表示软件包的安装和配置状态，其格式如下：期望状态|当前状态|错误其中期望状态有以下几种 u：即 unknown，软件包未安装且用户未请求安装 i：即 install，用户请求安装该软件包 r：即 remove，用户请求卸载该软件包 p：即 purge，用户请求卸载该软件包并清理配置文件 h：即 hold，用户请求保持续当前软件包版本 当前状态 有以下几种： n：即 not-installed，软件包未安装 i：即 installed，软件包已安装并完成配置 c：即 config-files，软件包已经被卸载，但是其配置文件未清理 u：即 unpacked，软件包已经被解压缩，但还未配置 f：即 half-configured，配置软件包时出现错误 w：即 triggers-awaited，触发器等待 t：即 triggers-pending，触发器未决 错误状态 有以下几种： h：软件包被强制保持 r：即 reinstall-required，需要卸载并重新安装 x：软件包被破坏 因此 ii 表示该软件需要安装且已经安装，没有出现错误；iu 表示已经安装该软件，但未正确配置；rc 表示该软件已经被删除，但配置文件未清理。 查看处于 rc 状态的软件包：123456$ dpkg -l | grep ^rcrc libmhash2:amd64 0.9.9.9-7 amd64 Library for cryptographic hashing and message authenticationrc linux-image-5.0.0-13-generic 5.0.0-13.14 amd64 Signed kernel image genericrc linux-modules-5.0.0-13-generic 5.0.0-13.14 amd64 Linux kernel extra modules for version 5.0.0 on 64 bit x86 SMPrc linux-modules-extra-5.0.0-13-generic 5.0.0-13.14 amd64 Linux kernel extra modules for version 5.0.0 on 64 bit x86 SMPrc zabbix-proxy-mysql 1:4.0.4+dfsg-1 amd64 network monitoring solution - proxy (using MySQL) 此外，还可以使用 dpkg -l &lt;package_name_pattern&gt; 命令筛选出名称中包含指定模式的软件包。12345678910111213$ dpkg -l &quot;nginx*&quot;期望状态=未知(u)/安装(i)/删除(r)/清除(p)/保持(h)| 状态=未安装(n)/已安装(i)/仅存配置(c)/仅解压缩(U)/配置失败(F)/不完全安装(H)/触发器等待(W)/触发器未决(T)|/ 错误?=(无)/须重装(R) (状态，错误：大写=故障)||/ 名称 版本 体系结构 描述+++-==============-===============-============-=========================================================ii nginx 1.15.9-0ubuntu1 all small, powerful, scalable web/proxy serverii nginx-common 1.15.9-0ubuntu1 all small, powerful, scalable web/proxy server - common filesii nginx-core 1.15.9-0ubuntu1 amd64 nginx web/proxy server (standard version)un nginx-doc &lt;无&gt; &lt;无&gt; (无描述)un nginx-extras &lt;无&gt; &lt;无&gt; (无描述)un nginx-full &lt;无&gt; &lt;无&gt; (无描述)un nginx-light &lt;无&gt; &lt;无&gt; (无描述) 卸载软件dpkg 命令的 -r 选项可以用来卸载已安装的软件包，此时只需要指定软件的名称即可。1234567$ sudo dpkg -r vim(正在读取数据库 ... 系统当前共安装有 252653 个文件和目录。)正在卸载 vim (2:8.1.0320-1ubuntu3.1) ...update-alternatives: 使用 /usr/bin/vim.tiny 来在自动模式中提供 /usr/bin/vi (vi)update-alternatives: 使用 /usr/bin/vim.tiny 来在自动模式中提供 /usr/bin/view (view)update-alternatives: 使用 /usr/bin/vim.tiny 来在自动模式中提供 /usr/bin/ex (ex)update-alternatives: 使用 /usr/bin/vim.tiny 来在自动模式中提供 /usr/bin/rview (rview) 需要注意的是，-r 选项只会移除指定的软件包而不对其配置文件产生影响，可以使用 -P 选项在删除软件包的同时清理配置文件。sudo dpkg -P &lt;package&gt; 其他包管理操作查看软件包的内容dpkg -c &lt;package_file_path&gt;123456789101112131415161718192021$ dpkg -c fping_4.2-1_amd64.debdrwxr-xr-x root/root 0 2019-02-20 06:27 ./drwxr-xr-x root/root 0 2019-02-20 06:27 ./usr/drwxr-xr-x root/root 0 2019-02-20 06:27 ./usr/bin/-rwxr-xr-x root/root 52128 2019-02-20 06:27 ./usr/bin/fpingdrwxr-xr-x root/root 0 2019-02-20 06:27 ./usr/share/drwxr-xr-x root/root 0 2019-02-20 06:27 ./usr/share/bug/-rwxr-xr-x root/root 118 2017-06-19 05:19 ./usr/share/bug/fpingdrwxr-xr-x root/root 0 2019-02-20 06:27 ./usr/share/doc/drwxr-xr-x root/root 0 2019-02-20 06:27 ./usr/share/doc/fping/-rw-r--r-- root/root 495 2017-09-06 08:00 ./usr/share/doc/fping/NEWS.Debian.gz-rw-r--r-- root/root 1615 2019-02-20 06:27 ./usr/share/doc/fping/changelog.Debian.gz-rw-r--r-- root/root 3445 2017-12-07 04:09 ./usr/share/doc/fping/copyrightdrwxr-xr-x root/root 0 2019-02-20 06:27 ./usr/share/lintian/drwxr-xr-x root/root 0 2019-02-20 06:27 ./usr/share/lintian/overrides/-rw-r--r-- root/root 41 2017-06-19 05:19 ./usr/share/lintian/overrides/fpingdrwxr-xr-x root/root 0 2019-02-20 06:27 ./usr/share/man/drwxr-xr-x root/root 0 2019-02-20 06:27 ./usr/share/man/man8/-rw-r--r-- root/root 5733 2019-02-20 06:27 ./usr/share/man/man8/fping.8.gz-rw-r--r-- root/root 1512 2019-02-20 06:27 ./usr/share/man/man8/fping6.8.gzlrwxrwxrwx root/root 0 2019-02-20 06:27 ./usr/bin/fping6 -&gt; fping 查看软件包（已安装）的详细信息dpkg -s &lt;package&gt; 或 dpkg --status &lt;package&gt;1234567891011121314151617181920$ dpkg -s fpingPackage: fpingStatus: deinstall ok installedPriority: optionalSection: netInstalled-Size: 87Maintainer: Ubuntu Developers &lt;ubuntu-devel-discuss@lists.ubuntu.com&gt;Architecture: amd64Version: 4.2-1Depends: libcap2-bin, netbase, libc6 (&gt;= 2.15)Enhances: netdata (&gt;= 1.5)Description: sends ICMP ECHO_REQUEST packets to network hosts fping is a ping like program which uses the Internet Control Message Protocol (ICMP) echo request to determine if a target host is responding. fping differs from ping in that you can specify any number of targets on the command line, or specify a file containing the lists of targets to ping. Instead of sending to one target until it times out or replies, fping will send out a ping packet and move on to the next target in a round-robin fashion.Original-Maintainer: Axel Beckert &lt;abe@debian.org&gt;Homepage: https://www.fping.org/ 查看软件包的安装位置dpkg -L &lt;package&gt; 或 dpkg --list-files &lt;package&gt;123456789101112131415161718192021$ dpkg -L fping/./usr/usr/bin/usr/bin/fping/usr/share/usr/share/bug/usr/share/bug/fping/usr/share/doc/usr/share/doc/fping/usr/share/doc/fping/NEWS.Debian.gz/usr/share/doc/fping/changelog.Debian.gz/usr/share/doc/fping/copyright/usr/share/lintian/usr/share/lintian/overrides/usr/share/lintian/overrides/fping/usr/share/man/usr/share/man/man8/usr/share/man/man8/fping.8.gz/usr/share/man/man8/fping6.8.gz/usr/bin/fping6 筛选出包含指定文件（模式）的软件包dpkg -S &lt;filename_pattern&gt; 或 dpkg --search &lt;filename_pattern&gt;123456$ dpkg -S sites-availableapache2: /etc/apache2/sites-available/default-ssl.confapache2: /etc/apache2/sites-available/000-default.confnginx-common: /etc/nginx/sites-availablenginx-common: /etc/nginx/sites-available/defaultapache2: /etc/apache2/sites-available 参考资料15 Practical Examples of “dpkg commands” for Debian Based DistrosLinux软件安装管理之——dpkg与apt-*详解]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Admin</tag>
        <tag>Tools</tag>
        <tag>Package</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Paramiko 代码示例]]></title>
    <url>%2F2019%2F07%2F20%2Fparamiko-examples%2F</url>
    <content type="text"><![CDATA[Paramiko 是由 Python 语言编写的一个扩展模块，提供了基于 SSHv2 协议（包括客户端和服务端）的多种功能实现。通常被用来远程控制类 UNIX 系统。 Paramiko 可以直接使用 pip 命令安装：$ pip install paramiko 此处不作过多介绍，参考后文中的代码示例。 远程执行 Linux 命令代码如下：12345678910111213141516import paramiko# 初始化 SSH 客户端，通过用户名密码连接至远程服务器client = paramiko.SSHClient()client.set_missing_host_key_policy(paramiko.AutoAddPolicy)client.connect(hostname=&apos;remoteserver_ip&apos;, username=&apos;username&apos;, password=&apos;password&apos;)# 通过 RSA 秘钥验证的方式连接至远程 SSH 服务# private_key = paramiko.RSAKey.from_private_key_file(&apos;~/.ssh/id_rsa&apos;)# client.connect(hostname=&quot;remoteserver_ip&quot;, username=&quot;username&quot;, pkey=private_key)# 远程执行 df -h 命令并打印输出stdin, stdout, stderr = client.exec_command(&apos;df -h&apos;)print(stdout.read().decode(&apos;utf-8&apos;))client.close() 运行效果如下： SFTP 文件传输示例代码如下：12345678910111213141516171819import paramikotransport = paramiko.Transport((&apos;hostname_or_ip&apos;, port))# 通过用户名密码完成验证建立连接transport.connect(username=&apos;username&apos;, password=&apos;password&apos;)# 通过 RSA 私钥文件完成验证建立连接# private_key = paramiko.RSAKey.from_private_key_file(&apos;/path/to/private_key_file&apos;)# transport.connect(username=&apos;username&apos;, pkey=private_key)sftp = paramiko.SFTPClient.from_transport(transport)localpath = &quot;localfile&quot;remotepath = &quot;remotefile_fullpath&quot;sftp.put(localpath, remotepath)print(&quot;Successfully uploaded&quot;)transport.close() 综合示例代码如下（文件名 ssh_connection.py）：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374import paramikoimport getpassimport osclass SSHConnection(): def __init__(self, user, host, port=22, password=&apos;&apos;): self.username = user self.host = host self.port = port self.password = password self.keyfile = self.get_keyfile() def get_keyfile(self, path=os.getcwd()): default_keyfile = os.path.join( os.environ[&apos;HOME&apos;], &apos;.ssh&apos;, &apos;id_rsa&apos;) if &apos;id_rsa&apos; in os.listdir(path): keyfile = os.path.join(path, &apos;id_rsa&apos;) elif os.path.isfile(default_keyfile): keyfile = default_keyfile else: keyfile = &apos;&apos; return keyfile def connect(self): transport = paramiko.Transport((self.host, self.port)) if self.password: transport.connect(username=self.username, password=self.password) elif self.keyfile: transport.connect( username=self.username, pkey=paramiko.RSAKey.from_private_key_file(self.keyfile)) else: password = getpass.getpass( &quot;Password for %s@%s: &quot; % (self.username, self.host)) transport.connect(username=self.username, password=password) self._transport = transport print(&quot;Connected to %s as %s&quot; % (self.host, self.username)) def close(self): self._transport.close() def run_cmd(self, command): ssh = paramiko.SSHClient() ssh._transport = self._transport stdin, stdout, stderr = ssh.exec_command(command) res = stdout.read().decode(&apos;utf-8&apos;) error = stderr.read().decode(&apos;utf-8&apos;) if error.strip(): return error else: return res def trans_file(self, localpath, remotepath, method=&apos;&apos;): sftp = paramiko.SFTPClient.from_transport(self._transport) if method == &apos;put&apos;: sftp.put(localpath, remotepath) print(&quot;File %s has uploaded to %s&quot; % (localpath, remotepath)) elif method == &apos;get&apos;: sftp.get(remotepath, localpath) print(&quot;File %s has saved as %s&quot; % (remotepath, localpath)) else: print(&apos;usage: trans_file(localpath, remotepath, method=&quot;get/put&quot;&apos;) def __del__(self): self.close() 测试结果如下：1234567891011121314(python3) D:\Program\python\devops&gt;pythonPython 3.7.2 (default, Jan 2 2019, 17:07:39) [MSC v.1915 64 bit (AMD64)] :: Anaconda, Inc. on win32Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; from ssh_connection import SSHConnection&gt;&gt;&gt; client = SSHConnection(&apos;starky&apos;,&apos;127.0.0.1&apos;)&gt;&gt;&gt; client.connect()Connected to 127.0.0.1 as starky&gt;&gt;&gt; client.run_cmd(&apos;uname -a&apos;)&apos;Linux server1 5.0.0-20-generic #21-Ubuntu SMP Mon Jun 24 09:32:09 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux\n&apos;&gt;&gt;&gt; client.trans_file(&apos;id_rsa.pub&apos;, &apos;/home/starky/id_rsa.pub&apos;, method=&apos;put&apos;)File id_rsa.pub has uploaded to /home/starky/id_rsa.pub&gt;&gt;&gt; client.run_cmd(&apos;ls -l /home/starky/id_rsa.pub&apos;)&apos;-rw-rw-r-- 1 starky starky 410 7月 20 15:01 /home/starky/id_rsa.pub\n&apos;&gt;&gt;&gt; exit() 参考资料Github 项目主页API 手册]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Admin</tag>
        <tag>DevOps</tag>
        <tag>Program</tag>
        <tag>Python</tag>
        <tag>Development</tag>
        <tag>SSH</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vimdiff 命令使用介绍]]></title>
    <url>%2F2019%2F07%2F20%2Fvimdiff-manual%2F</url>
    <content type="text"><![CDATA[vimdiff 等同于 vim -d 命令，即 Vim 编辑器的 diff 模式。该命令后面通常会接两个或多个文件名作为参数，这些文件会同时在 Vim 编辑器的分割窗口中打开，并高亮显示文件中内容有差异的部分。同时该模式下还提供部分快捷按键用于完成文件内容的合并等操作。 启动 vimdiffvimdiff 命令常用于编辑同一文件的不同历史版本，对各文件的内容进行比对与调整。如下面两个文件：123456789$ cat file1Line oneLine 2Line threeLine 4Line 5Line 6 123456789$ cat file2Line 1Line 2Line 3Line 4Line 5Line 6Line 7Line 8 可以使用 vim -O2 file1 file2 命令，在左右排列的两个窗口中同时打开 file1 和 file2 两个文件，如下图所示： 而 vimdiff file1 file2 命令会以同样的形式打开这两个文件，并且用不同的背景色高亮显示彼此间有差别的内容，如下图： 从上面的两幅截图中可以得出 vimdiff 标记差别内容时的几个规则： 只在某一个文件中存在的行背景色设置为蓝色，而另一文件中的对应位置则被标记为绿色。（或者说，相对于另一个文件，当前文件中“多余”的行标记为蓝色，“缺少”的行则标记为绿色） 两个文件中同时存在但是内容有差异的行，都标记为粉色，而引起差异的文字标记为红色 除了 vimdiff FILE_LEFT FILE_RIGHT 或者 vim -d FILE_LEFT FILE_RIGHT 的形式外，也可以通过在 Vim 中输入命令进入 diff 模式。 比如先进入 Vim 编辑 FILE_LEFT 文件（vim FILE_LEFT），再输入以下命令进入 diff 模式：:vertical diffsplit FILE_RIGHT 光标移动可以使用下列两种快捷键，在文件的各个差异点之间前后移动： ], c：跳转到下个差异点 [, c：跳转到上个差异点 至于光标在两个窗口之前的切换，可以使用如下按键： Ctrl-w, l：光标切换到右侧的窗口 Ctrl-w, h：光标切换到左侧的窗口 Ctrl-w, w：光标在两个窗口间彼此切换 内容合并可以使用 d, p （即 diff put）命令，将当前差异点中的内容覆盖到另一文件中的对应位置。如当光标位于左侧文件（file1）中的第一行时，依次按下 d、p 键，则 file1 中的 Line one 被推送到右侧，并替换掉 file2 中对应位置上的 Line 1 。截图如下：可与上一幅截图对比查看效果。 而 d, o （即 diff obtain）命令可以将另一窗口中差异点处的内容拉取到当前位置并进行替换操作。截图如下： 即在 file1 的第一行执行 d o 命令后，file2 中的第一行内容 Line 1 被拉取到 file1 中并替换掉原来位置上的 Line one。 同时操作两个文件vimdiff 实际上是 Vim 编辑器的 diff 模式，因此适用于 Vim 编辑器的命令和快捷键也同样可以在该模式下使用。常用的几个命令如下： :qa：退出所有文件 :wa：保存所有文件 :wqa：保存并退出所有文件 qa!：强制退出（不保存）所有文件 z o：查看被折叠的内容 z c：重新折叠 其他常用的命令与快捷键可参考 Vim 速查手册]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Tools</tag>
        <tag>Tricks</tag>
        <tag>Vim</tag>
        <tag>Efficiency</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IT 自动化工具 Ansible 入门指南]]></title>
    <url>%2F2019%2F07%2F09%2Fansible-automate-tools-quickstart%2F</url>
    <content type="text"><![CDATA[Ansible 是一个非常简单的 IT 自动化引擎，可以完成诸如云端资源调配、配置管理、应用部署、服务协调等众多 IT 自动化任务。它不需要在受控端安装配置额外的 agent 软件，因此部署流程非常简单。Ansible 的运行机制也并不复杂，它通过 SSH 协议向远程节点推送特定的“小程序”（Ansible modules）并运行，一旦运行完成则将其移除。同时 Ansible 提供了一种非常简单易懂的语言（YAML）用于编写自动化代码。 一、简介Ansible 通常会被描述为一个配置管理工具，类似于 Chef、Puppet 和 Salt 等。通过配置管理工具，我们可以确保服务器主机处于某种期望的状态，比如指定的软件包已安装，配置文件中包含正确的值，运行着特定的服务等。与其他配置管理工具一样，Ansible 也加入了自己的 DSL（领域专用语言）用来描述服务器的状态，即后面会介绍到的用于编写 Playbook 的 YAML 语言。 Ansible 也可以用于部署任务，比如通过源代码生成可执行程序或静态资源并发布到服务器，然后开启远程主机上的对应服务。类似的开源部署工具如 Fabric 等。 还有一种需求叫做流程编排，通常会涉及到多个远程服务器，用于确保各类型的任务以特定顺序执行。比如在开启 Web 服务器之前确保数据库服务处于已经运行的状态。Ansible 从设计之初即关注多个服务器状态下任务的执行，它有一个非常简单的模块用于控制动作的顺序。 此外，Ansible 还提供众多的模块用来与常见的云服务进行交互，包括 Amazon EC2、Azure、Digital Ocean、Linode 以及任何支持 OpenStack API 的云端服务。 一个简单的 Ansible 运行实例如下图： 二、Ansible 安装绝大部分 Linux 发行版的软件镜像中都默认包含了 Ansible 的安装包， 可以直接通过对应的包管理器进行安装。如 Ubuntu 系统：$ sudo apt-get install ansible Ansible 是基于 Python 语言开发的，因此也可以通过 Python 的包管理器进行安装，命令如下：$ pip install ansible 我用 VirtualBox 软件搭建了两台 Ubuntu 19.04 虚拟机，配置了内部网络（Internal）的联网方式。server1 IP 地址为 192.168.1.101，用于安装 Ansible 环境。server2 IP 地址为 192.168.1.102，作为远程主机进行测试。两者可以相互 ping 通。 SSH 的密钥认证为了使得每次运行 Ansible 任务时，不需要重复输入远程主机的认证信息，这里先配置好 SSH 连接的无密码认证（即 RSA 密钥认证）。命令如下：1234$ # 生成 SSH 密钥文件$ ssh-keygen$ # 复制公钥文件到远程主机（需要输入密码）$ ssh-copy-id remoteuser@remoteserver 运行成功后，使用 $ ssh remoteuser@remoteserver 命令进行测试，如可以自动登录，则配置完成。 PS：被控制的远程主机不需要安装任何客户端软件，但是必须确保已安装 Python 且 sshd 服务处于运行状态。如两者未正确安装，可运行以下命令：12$ sudo apt-get install python$ sudo apt-get install openssh-server 主机清单（Inventory）Ansible 通过一个主机清单文件（hosts）存放被管理的服务器的列表。创建 playbooks 目录作为存放 ansible 脚本和配置文件的项目文件夹，进入该目录并编辑如下 hosts 文件：1server2 ansible_ssh_host=192.168.1.102 ansible_ssh_user=skitar ansible_ssh_private_key_file=~/.ssh/id_rsa 通过 hosts 中定义的服务器别名和连接信息访问远程主机并执行 ping 模块：$ ansible server2 -i hosts -m ping 输出内容如下：1234567server2 | SUCCESS =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/bin/python3&quot; &#125;, &quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot;&#125; 如看到类似上面的输出则 Ansible 环境配置完成。 PS：Ansible 主机清单的配置文件默认为 /etc/ansible/hosts。如需使用其他位置的主机清单文件，可以通过 -i 选项手动指定，或者修改 ansible.cfg 配置文件的 inventory 项。 ansible.cfgansible.cfg 文件中包含了 Ansible 工具的一些默认配置，该文件通常位于以下位置： 当前目录（./ansible.cfg） Home 目录（~/.ansible.cfg） /etc/ansible/ansible.cfg 在当前目录下创建 ansible.cfg 文件并输入以下内容：12345[defaults]inventory = hostsremote_user = skitarprivate_key_file = ~/.ssh/id_rsahost_key_checking = False 由于部分默认选项已配置，此时的 hosts 文件则可以省略用户名和密钥文件等信息，简化为如下形式：1server2 ansible_ssh_host=192.168.1.102 使用 ansible 命令时也无需再通过 -i hosts 选项手动指定主机清单文件。即之前的 ping 模块可以这样调用：$ ansible server2 -m ping Ad-Hoc 命令即通过命令行的形式直接调用 Ansible 模块。Ansible 有着功能丰富的内置模块，可以通过 ansible-doc -l 命令显示所有的内置模块，通过 ansible-doc &lt;module&gt; 命令查看指定模块的介绍以及使用案例。 Ansible 内置的 command 模块可以用来在远程主机上执行 Linux 命令。如执行 uptime 命令：123$ ansible server2 -m command -a uptimeserver2 | CHANGED | rc=0 &gt;&gt; 17:45:12 up 5:13, 1 user, load average: 0.12, 0.08, 0.02 其中 -m 用于指定调用的模块，-a 用于指定传递给该模块的选项，此处即某个具体的命令。由于 command 模块很常用，它其实是不指定任何模块情况下的默认模块。所以上面的命令也可以使用如下形式：$ ansible server2 -a uptime 当远程主机上执行的命令中包含空格时，需要用引号括起来，示例如下：123456789101112$ ansible server2 -a &quot;tail /var/log/syslog&quot;server2 | CHANGED | rc=0 &gt;&gt;Jul 8 18:18:18 server2 systemd[6250]: Reached target Paths.Jul 8 18:18:18 server2 systemd[6250]: Listening on GnuPG cryptographic agent and passphrase cache (access for web browsers).Jul 8 18:18:18 server2 systemd[6250]: Listening on D-Bus User Message Bus Socket.Jul 8 18:18:18 server2 systemd[6250]: Reached target Sockets.Jul 8 18:18:18 server2 systemd[6250]: Reached target Basic System.Jul 8 18:18:18 server2 systemd[1]: Started User Manager for UID 1000.Jul 8 18:18:18 server2 systemd[1]: Started Session 47 of user skitar.Jul 8 18:18:18 server2 systemd[6250]: Reached target Default.Jul 8 18:18:18 server2 systemd[6250]: Startup finished in 75ms.Jul 8 18:18:19 server2 python3[6304]: ansible-command Invoked with _raw_params=tail /var/log/syslog warn=True _uses_shell=False stdin_add_newline=True strip_empty_ends=True argv=None chdir=None executable=None creates=None removes=None stdin=None 对于某些需要 root 权限才能执行的操作，则需要加上 --become --ask-become-pass 或者 -b -K 选项通过 sudo 执行。如使用 service 模块重启远程主机上的 nginx 服务：12345678910111213141516$ ansible server2 -b -K -m service -a &quot;name=nginx state=restarted&quot;BECOME password:server2 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/bin/python3&quot; &#125;, &quot;changed&quot;: true, &quot;name&quot;: &quot;nginx&quot;, &quot;state&quot;: &quot;started&quot;, &quot;status&quot;: &#123; &quot;ActiveEnterTimestamp&quot;: &quot;Mon 2019-07-08 18:16:58 CST&quot;, &quot;ActiveEnterTimestampMonotonic&quot;: &quot;20685653757&quot;, &quot;ActiveExitTimestamp&quot;: &quot;Mon 2019-07-08 18:16:57 CST&quot;, &quot;ActiveExitTimestampMonotonic&quot;: &quot;20685035019&quot;, &quot;ActiveState&quot;: &quot;active&quot;,... 其他常用的内置模块还有 apt、copy、user 等。 如通过 apt 模块管理远程主机上的软件包：123456789101112$ ansible server2 --b -K -m apt -a &quot;name=nginx state=latest&quot;BECOME password: [WARNING]: Could not find aptitude. Using apt-get insteadserver2 | SUCCESS =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/bin/python3&quot; &#125;, &quot;cache_update_time&quot;: 1562598780, &quot;cache_updated&quot;: false, &quot;changed&quot;: false&#125; 通过 copy 模块复制本地文件到远程主机：1234567891011121314151617$ ansible server2 -m copy -a &quot;src=ansible.cfg dest=/home/skitar/ansible.cfg owner=skitar mode=644&quot;server2 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/bin/python3&quot; &#125;, &quot;changed&quot;: true, &quot;checksum&quot;: &quot;2f4f9975ef1875adcc2a299d3962f70630f49965&quot;, &quot;dest&quot;: &quot;/home/skitar/ansible.cfg&quot;, &quot;gid&quot;: 1001, &quot;group&quot;: &quot;skitar&quot;, &quot;mode&quot;: &quot;0644&quot;, &quot;owner&quot;: &quot;skitar&quot;, &quot;path&quot;: &quot;/home/skitar/ansible.cfg&quot;, &quot;size&quot;: 109, &quot;state&quot;: &quot;file&quot;, &quot;uid&quot;: 1000&#125; 通过 user 模块管理远程主机上的用户（需要先通过 openssl 命令生成密码，因为 user 模块的 password 参数只接受加密后的值）：1234567891011121314151617181920$ echo ansible | openssl passwd -1 -stdin$1$ZyNqkbXH$i.4R0EDQZV.zu8akyJAu10$ ansible server2 -b -K -m user -a &apos;name=starky password=&quot;$1$ZyNqkbXH$i.4R0EDQZV.zu8akyJAu10&quot; shell=/bin/bash&apos;BECOME password:server2 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/bin/python3&quot; &#125;, &quot;append&quot;: false, &quot;changed&quot;: true, &quot;comment&quot;: &quot;&quot;, &quot;group&quot;: 1002, &quot;home&quot;: &quot;/home/starky&quot;, &quot;move_home&quot;: false, &quot;name&quot;: &quot;starky&quot;, &quot;password&quot;: &quot;NOT_LOGGING_PASSWORD&quot;, &quot;shell&quot;: &quot;/bin/bash&quot;, &quot;state&quot;: &quot;present&quot;, &quot;uid&quot;: 1001&#125; 三、PlaybooksPlaybooks 即 Ansible 用于执行自动化配置的脚本文件。它使用非常简单的 YAML 语言描述期望达到的状态，YAML 之于 JSON 类似于 Markdown 之于 HTML 。 一个简单的用于配置 nginx 站点的 playbook 示例（web-notls.yml）如下：123456789101112131415161718192021- name: Configure webserver with nginx hosts: webservers become: True tasks: - name: install nginx apt: name=nginx update_cache=yes - name: copy nginx config file copy: src=files/nginx.conf dest=/etc/nginx/sites-available/default - name: enable configuration file: &gt; dest=/etc/nginx/sites-enabled/default src=/etc/nginx/sites-available/default state=link - name: copy index.html template: src=templates/index.html.j2 dest=/var/www/html/index.html mode=0644 - name: restart nginx service: name=nginx state=restarted 编辑 nginx 配置文件，即 playbook 中 copy 模块的 src 选项指定的文件（files/nginx.conf），内容如下：123456789101112server &#123; listen 80 default_server; root /var/www/html; index index.html; server_name 192.168.1.102; location / &#123; try_files $uri $uri/ =404; &#125;&#125; 编辑 nginx 站点的主页文件，即 playbook 中 template 模块的src 选项指定的文件（templates/index.html.j2），内容如下：12345678910&lt;html&gt; &lt;head&gt; &lt;title&gt;Welcome to ansible&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;nginx, configured by Ansible&lt;/h1&gt; &lt;p&gt;If you see this, Ansible successfuly installed nginx.&lt;/p&gt; &lt;p&gt;Current time is &#123;&#123; now() &#125;&#125;&lt;/p&gt; &lt;/body&gt;&lt;/html&gt; 编辑 Inventory （主机清单）即hosts 文件，创建 webservers 主机组：12[webservers]server2 ansible_ssh_host=192.168.1.102 主机组中可以包含一个或多个远程主机，便于同时管理多个远程节点。 上述配置完成后，通过 ansible-playbook web-nolts.yml -K 命令运行 playbook，输出如下：123456789101112131415161718192021222324252627$ ansible-playbook web-notls.yml -KBECOME password:PLAY [Configure webserver with nginx] **********************************************************TASK [Gathering Facts] *************************************************************************ok: [server2]TASK [install nginx] *************************************************************************** [WARNING]: Could not find aptitude. Using apt-get insteadok: [server2]TASK [copy nginx config file] ******************************************************************changed: [server2]TASK [enable configuration] ********************************************************************ok: [server2]TASK [copy index.html] *************************************************************************changed: [server2]TASK [restart nginx] ***************************************************************************changed: [server2]PLAY RECAP *************************************************************************************server2 : ok=6 changed=3 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 注意 ansibe-playbook 命令的 -K 选项（即 --ask-become-pass），由于 playbook 中的部分任务需要 root 权限执行，加上 -K 选项后，执行 playbook 时会出现 BECOME password: 提示用于输入 sudo 密码。否则会报错。 playbook 执行成功后，使用 curl 192.168.1.102 命令访问 server2 上刚刚配置的 nginx 站点，输出如下：1234567891011$ curl 192.168.1.102&lt;html&gt; &lt;head&gt; &lt;title&gt;Welcome to ansible&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;nginx, configured by Ansible&lt;/h1&gt; &lt;p&gt;If you see this, Ansible successfuly installed nginx.&lt;/p&gt; &lt;p&gt;Current time is 2019-07-09 00:28:46.484053&lt;/p&gt; &lt;/body&gt;&lt;/html&gt; 参考资料Ansible: Up and Running, 2nd Edition]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Server</tag>
        <tag>Admin</tag>
        <tag>Ansible</tag>
        <tag>DevOps</tag>
        <tag>Automate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Arduino（配合舵机、超声波传感器）和 Processing 制作“声呐”探测系统]]></title>
    <url>%2F2019%2F07%2F09%2Farduino-radar-with-servo-and-ultrasound-sensor%2F</url>
    <content type="text"><![CDATA[参考自 Github 项目 ArduinoRadar 。原项目中 Processing 部分代码测试有疏漏，已修改并完成验证。主要是通过超声波传感器测量目标距离，并借助舵机完成扫描巡视动作，最后通过 Processing 收集测量数据，并完成类似声纳显示器的图形绘制。 项目实物图如下： Processing 绘制的类似监视器界面的动态图形如下： 一、准备材料软件： Arduino IDE：编写 C 语言源代码并编译上传至 Ardunio 开发板。 Processing：通过串口与 Arduino 开发板通信，获取实时数据并绘制类似监视器画面的动态图形。 硬件： Arduino Uno 或与之兼容的开发版：控制中心。 超声波传感器：测量目标距离。 舵机：承载超声波传感器，完成扫描动作。 二、连线示意图线路连接示意图如下： 三、源代码arduino C 程序源代码 radar.ino：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#include &lt;Servo.h&gt;. const int trigPin = 7;const int echoPin = 8;long duration;int distance;Servo myServo; void setup() &#123; pinMode(trigPin, OUTPUT); pinMode(echoPin, INPUT); Serial.begin(9600); myServo.attach(9); &#125;void loop() &#123; for(int i=15;i&lt;=165;i++)&#123; myServo.write(i); delay(30); distance = calculateDistance(); Serial.print(i); Serial.print(&quot;,&quot;); Serial.print(distance); Serial.print(&quot;.&quot;); &#125; for(int i=165;i&gt;15;i--)&#123; myServo.write(i); delay(30); distance = calculateDistance(); Serial.print(i); Serial.print(&quot;,&quot;); Serial.print(distance); Serial.print(&quot;.&quot;); &#125;&#125;int calculateDistance() &#123; digitalWrite(trigPin, LOW); delayMicroseconds(2); digitalWrite(trigPin, HIGH); delayMicroseconds(10); digitalWrite(trigPin, LOW); duration = pulseIn(echoPin, HIGH); distance= duration*0.034/2; return distance;&#125; Processing 源代码 radar.pde：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144import processing.serial.*; // imports library for serial communicationimport java.awt.event.KeyEvent; // imports library for reading the data from the serial portimport java.io.IOException;String Port = &quot;COM3&quot;; //Arduino portSerial myPort; String angle=&quot;&quot;;String distance=&quot;&quot;;String data=&quot;&quot;;String noObject;float pixsDistance;int iAngle, iDistance;int index1=0;int index2=0;PFont orcFont;void setup() &#123; size (1250, 650); //resolution smooth(); myPort = new Serial(this, Port, 9600); myPort.bufferUntil(&apos;.&apos;);&#125;void draw() &#123; fill(98,245,31); noStroke(); fill(0,4); rect(0, 0, width, height-height*0.065); fill(98,245,31); drawRadar(); drawLine(); drawObject(); drawText();&#125;void serialEvent (Serial myPort) &#123; data = myPort.readStringUntil(&apos;.&apos;); data = data.substring(0,data.length()-1); index1 = data.indexOf(&quot;,&quot;); angle= data.substring(0, index1); distance= data.substring(index1+1, data.length()); iAngle = int(angle); iDistance = int(distance);&#125;void drawRadar() &#123; pushMatrix(); translate(width/2,height-height*0.074); noFill(); strokeWeight(2); stroke(98,245,31); arc(0,0,(width-width*0.0625),(width-width*0.0625),PI,TWO_PI); arc(0,0,(width-width*0.27),(width-width*0.27),PI,TWO_PI); arc(0,0,(width-width*0.479),(width-width*0.479),PI,TWO_PI); arc(0,0,(width-width*0.687),(width-width*0.687),PI,TWO_PI); line(-width/2,0,width/2,0); line(0,0,(-width/2)*cos(radians(30)),(-width/2)*sin(radians(30))); line(0,0,(-width/2)*cos(radians(60)),(-width/2)*sin(radians(60))); line(0,0,(-width/2)*cos(radians(90)),(-width/2)*sin(radians(90))); line(0,0,(-width/2)*cos(radians(120)),(-width/2)*sin(radians(120))); line(0,0,(-width/2)*cos(radians(150)),(-width/2)*sin(radians(150))); line((-width/2)*cos(radians(30)),0,width/2,0); popMatrix();&#125;void drawObject() &#123; pushMatrix(); translate(width/2,height-height*0.074); strokeWeight(9); stroke(255,10,10); pixsDistance = iDistance*((height-height*0.1666)*0.025); if(iDistance&lt;40)&#123; //range limit line(pixsDistance*cos(radians(iAngle)),-pixsDistance*sin(radians(iAngle)),(width-width*0.505)*cos(radians(iAngle)),-(width-width*0.505)*sin(radians(iAngle))); &#125; popMatrix();&#125;void drawLine() &#123; pushMatrix(); strokeWeight(9); stroke(30,250,60); translate(width/2,height-height*0.074); line(0,0,(height-height*0.12)*cos(radians(iAngle)),-(height-height*0.12)*sin(radians(iAngle))); popMatrix();&#125;void drawText() &#123; pushMatrix(); fill(0,0,0); noStroke(); rect(0, height-height*0.0648, width, height); fill(98,245,31); textSize(15); text(&quot;10cm&quot;,width-width*0.3854,height-height*0.0833); text(&quot;20cm&quot;,width-width*0.281,height-height*0.0833); text(&quot;30cm&quot;,width-width*0.177,height-height*0.0833); text(&quot;40cm&quot;,width-width*0.0729,height-height*0.0833); textSize(30); text(&quot;Angle: &quot; + iAngle +&quot; °&quot;, width-width*0.48, height-height*0.0277); text(&quot;Distance: &quot;, width-width*0.26, height-height*0.0277); if(iDistance&lt;40) &#123; text(&quot; &quot; + iDistance +&quot; cm&quot;, width-width*0.225, height-height*0.0277); &#125; textSize(25); fill(98,245,60); translate((width-width*0.4994)+width/2*cos(radians(30)),(height-height*0.0907)-width/2*sin(radians(30))); rotate(-radians(-60)); text(&quot;30°&quot;,0,0); resetMatrix(); translate((width-width*0.503)+width/2*cos(radians(60)),(height-height*0.0888)-width/2*sin(radians(60))); rotate(-radians(-30)); text(&quot;60°&quot;,0,0); resetMatrix(); translate((width-width*0.507)+width/2*cos(radians(90)),(height-height*0.0833)-width/2*sin(radians(90))); rotate(radians(0)); text(&quot;90°&quot;,0,0); resetMatrix(); translate(width-width*0.513+width/2*cos(radians(120)),(height-height*0.07129)-width/2*sin(radians(120))); rotate(radians(-30)); text(&quot;120°&quot;,0,0); resetMatrix(); translate((width-width*0.5104)+width/2*cos(radians(150)),(height-height*0.0574)-width/2*sin(radians(150))); rotate(radians(-60)); text(&quot;150°&quot;,0,0); popMatrix();&#125; 注意 radar.pde 文件开头的 String Port = &quot;COM3&quot;; 行代码，将 Port 变量的值 COM3 改为 Ardunio 开发板实际连接的串口号。 四、运行效果演示视频]]></content>
      <categories>
        <category>IOT</category>
      </categories>
      <tags>
        <tag>IOT</tag>
        <tag>DIY</tag>
        <tag>Electronics</tag>
        <tag>Hardware</tag>
        <tag>Ardunio</tag>
        <tag>Maker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu 19.04 配置 Zabbix 监控系统]]></title>
    <url>%2F2019%2F07%2F06%2Fzabbix-moniter-system-for-ubuntu%2F</url>
    <content type="text"><![CDATA[Zabbix 是一个用于监控 IT 设施的企业级解决方案，支持实时监控数千台服务器，虚拟机和网络设备，采集百万级监控指标。Zabbix 完全开源免费。 一、特性与架构特性Zabbix 监控系统的主要特性如下： 一个中心化的简单易用的 Web 管理界面，内置丰富的图形化和可视化组件 Zabbix Server 可以运行在绝大多数 UNIX-like 操作系统上，提供原生的客户端（agent）程序（支持绝大多数 UNIX-like 系统和 Windows 系统） 可以直接监控 SNMP (SNMPv1, SNMPv2, SNMPv3) 和 IPMI 设备 通过 JMX 可以直接监控 Java 应用，通过 VMware API 可以直接监控 vCenter 或 vSphere 实例 灵活的配置，包括丰富的模板系统。方便与其他系统集成的通知系统 系统架构一个简单的 Zabbix 监控系统的示例架构如下图： Zabbix 由以下几个主要的功能组件组成： Server：Zabbix 软件的核心组件，agent 向其报告可用性、系统完整性和其他统计信息 数据库：用于存储所有配置信息以及 Zabbix 采集到的数据 Web 界面：属于 Zabbix Server 的一部分，便于从任何地方、任何设备访问和配置 Zabbix Proxy：可以替代 Zabbix Server 进行数据的采集操作，在 Zabbix 的部署中是可选部分，但是可以很好地分担单个 Server 的负载 agent：Zabbix agents 部署在被监控目标上，用于主动监控本地资源和应用程序，并将数据发送给 Zabbix Server 二、安装获取 Zabbix 主要有以下三种方式： 从发行包安装 下载最新版源码包并编译 通过容器安装部署 这里选择第一种安装方式。Zabbix 官方的软件仓库有提供 RPM 和 DEB 格式的二进制包，本文并没有使用。使用的是 Ubuntu 19.04 默认软件仓库中提供的安装包，具体操作大同小异，详情可参考 Zabbix 4.0 产品手册 使用 apt-get 命令安装 Zabbix 系列软件：12$ sudo apt-get update$ sudo apt-get install zabbix-server-mysql zabbix-frontend-php zabbix-agent 其中 zabbix-server-mysql 是以 MySQL 数据库为后端的 Zabbix Server 软件。zabbix-frontend-php 则是由 PHP 语言编写的 Web 控制台界面。 导入初始数据首先确保已经安装了 MySQL 数据库，使用 root 用户登录进 MySQL 的命令行界面，输入以下命令创建数据库并授权：12345mysql&gt; CREATE DATABASE zabbix CHARACTER SET utf8 COLLATE utf8_bin;Query OK, 1 row affected (0.00 sec)mysql&gt; GRANT ALL ON zabbix.* TO zabbix@localhost IDENTIFIED BY &apos;password&apos;;Query OK, 0 rows affected, 1 warning (0.11 sec) 以上命令创建了一个名为 zabbix 的数据库，并授予用户 zabbix （密码为 password）对它的访问权限。zabbix 数据库用于存储 Zabbix Server 的配置信息和采集到的数据，在正式启用前还需要创建数据表并导入初始数据。 Zabbix 软件包中已经包含了用于创建这些数据表的 SQL 语句，一般保存在 /usr/share/doc/zabbix-server-mysql/ 或者 /usr/share/zabbix-server-mysql/ 目录下的一个或多个数据库备份文件中，直接导入即可。 我这里使用如下命令进行导入：$ zcat /usr/share/zabbix-server-mysql/{schema,images,data}.sql.gz | mysql -u zabbix -p zabbix按照提示输入密码后即可完成导入。 配置数据库连接信息修改 Zabbix Server 的配置文件 /etc/zabbix/zabbix_server.conf，将其中对应的项目改为如下内容：1234DBHost=localhostDBName=zabbixDBUser=zabbixDBPassword=password 重启 zabbix-server 服务：$ sudo systemctl restart zabbix-server Web 前端配置首先确保已经安装了 Apache2 Web 服务器和 PHP 语言支持。并且还需要安装以下几个 PHP 模块： gd mysqli bcmath mbstring gettext 前面安装完 zabbix-frontend-php 软件后，会自动在 /etc/apache2/conf-available/ 目录下创建 zabbix-frontend-php.conf 文件，作为 Zabbix Server 网页后台的配置文件。 该文件的默认配置可直接使用，只需要启用该配置即可，命令如下：$ sudo a2enconf zabbix-frontend-php或者 $sudo ln -s /etc/apache2/conf-available/zabbix-frontend-php.conf /etc/apache2/conf-enabled/ 此外，在正式访问 Web 页面安装之前，需要先修改时区配置。编辑 /etc/apache2/conf-enabled/zabbix-frontend-php.conf 文件，将时区配置改为如下内容：php_value date.timezone Asia/Shanghai Web 安装程序以上步骤完成后，重启 Apache2 服务。进入浏览器访问 http://localhost/zabbix ,根据提示进行操作，部分截图如下： 操作完成后，会自动生成 zabbix.conf.php 文件，内容大致如下：12345678910111213141516171819&lt;?php// Zabbix GUI configuration file.global $DB;$DB[&apos;TYPE&apos;] = &apos;MYSQL&apos;;$DB[&apos;SERVER&apos;] = &apos;localhost&apos;;$DB[&apos;PORT&apos;] = &apos;3306&apos;;$DB[&apos;DATABASE&apos;] = &apos;zabbix&apos;;$DB[&apos;USER&apos;] = &apos;admin&apos;;$DB[&apos;PASSWORD&apos;] = &apos;password&apos;;// Schema name. Used for IBM DB2 and PostgreSQL.$DB[&apos;SCHEMA&apos;] = &apos;&apos;;$ZBX_SERVER = &apos;your_ip_address&apos;;$ZBX_SERVER_PORT = &apos;10051&apos;;$ZBX_SERVER_NAME = &apos;server1&apos;;$IMAGE_FORMAT_DEFAULT = IMAGE_FORMAT_PNG; 如该文件未自动在 /etc/zabbix/ 目录下生成，可将该文件下载后移动到对应位置。 此时访问 http://localhost/zabbix ，即可进入安装配置完成的 Zabbix 监控系统控制台。默认登录用户名为 Admin，密码为 zabbix。截图如下： 三、主机与监控项本文主要介绍 Zabbix 监控系统的安装配置流程，对于主机及其关联的监控项的配置，限于篇幅不作过多介绍。建议参考官方文档。 实际上完成安装之后，Zabbix 已经默认关联了一个名为 Zabbix server 的主机（即安装 Zabbix Server 的 Linux 服务器本身），其中默认配置了众多监控项、触发器、图形和自动发现规则等。可以查看它们的具体配置信息作为参考。部分截图如下： 参考资料Zabbix 产品手册Zabbix Network Monitoring, Second Edition]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Server</tag>
        <tag>Admin</tag>
        <tag>Zabbix</tag>
        <tag>Monitor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 系统 nginx 服务器安装及负载均衡配置详解]]></title>
    <url>%2F2019%2F07%2F02%2Fconfigure-nginx-for-load-banlance%2F</url>
    <content type="text"><![CDATA[nginx(engine x) 是一个高性能的 HTTP 和反向代理服务器、邮件代理服务器以及通用的 TCP/UDP 代理服务器。其特点为轻量级（占用系统资源少）、稳定性好、可扩展性（模块化结构）、并发能力强、配置简单等。本文主要介绍在测试环境中通过 nginx 实现基本的负载均衡功能。 nginx 可以提供 HTTP 服务，包括处理静态文件，支持 SSL 和 TLS SNI、GZIP 网页压缩、虚拟主机、URL 重写等功能，可以搭配 FastCGI、uwsgi 等程序处理动态请求。 此外，nginx 还可以用于代理、反向代理、负载均衡、缓存等服务器功能，在集群环境中改善网络负载、提高可用性。 一、搭建测试环境这里的测试环境为通过 VirtualBox 安装的两台 Lubuntu 19.04 虚拟机，Linux 系统安装方法不作赘述。为了保证两台 Linux 虚拟机之间的相互访问，虚拟机的网络配置除了默认的 NAT 方式外，还使用了 VirtualBox 软件提供的 内部网络（Internal） 联网方式。此外，还需要将两台虚拟机中与“内部网络”相关联的网卡，绑定上同一网段的静态 IP 地址，则两台主机形成局域网络，相互之间可以直接访问。 网络配置打开 VirtualBox 软件，分别进入两台虚拟机的设置界面，为其添加连接方式为内部网络的网络连接，截图如下（两台虚拟机作同样的配置）： 登录进虚拟机系统，使用 ip addr 命令查看当前的网络连接信息：123456789101112$ ip addr...2: enp0s3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether 08:00:27:38:65:a8 brd ff:ff:ff:ff:ff:ff inet 10.0.2.15/24 brd 10.0.2.255 scope global dynamic noprefixroute enp0s3 valid_lft 86390sec preferred_lft 86390sec inet6 fe80::9a49:54d3:2ea6:1b50/64 scope link noprefixroute valid_lft forever preferred_lft forever3: enp0s8: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether 08:00:27:0d:0b:de brd ff:ff:ff:ff:ff:ff inet6 fe80::2329:85bd:937e:c484/64 scope link noprefixroute valid_lft forever preferred_lft forever 可以看到，此时的 enp0s8 网卡还没有绑定 IPv4 地址，需要为其手动指定静态 IP。需要注意的是，从 Ubuntu 17.10 版本开始，一个新的名为 netplan 的工具被引入，原来的网络配置文件 /etc/network/interfaces 不再生效。 所以为网卡设置静态 IP 时需要修改 /etc/netplan/01-network-manager-all.yaml 配置文件，示例如下：1234567891011network: version: 2 renderer: NetworkManager ethernets: enp0s8: dhcp4: no dhcp6: no addresses: [192.168.1.101/24]# gateway4: 192.168.1.101# nameservers:# addresses: [192.168.1.101, 8.8.8.8] 由于两台主机处于同一子网，网关和 DNS 服务器未配置的情况下仍可以互相访问。对应的配置项暂时先注释掉（后续可以尝试自行搭建 DNS 服务器）。 编辑完成后运行 sudo netplan apply 命令，前面配置的静态 IP 即可生效。12345678$ ip addr...3: enp0s8: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether 08:00:27:0d:0b:de brd ff:ff:ff:ff:ff:ff inet 192.168.1.101/24 brd 192.168.1.255 scope global noprefixroute enp0s8 valid_lft forever preferred_lft forever inet6 fe80::a00:27ff:fe0d:bde/64 scope link valid_lft forever preferred_lft forever 登录进另一台虚拟机中，执行同样的操作（注意配置文件中的 addresses 项改为 [192.168.1.102/24]）。两台虚拟机的网络即配置完成。 此时有 Linux 虚拟机 server1，IP 地址为 192.168.1.101；Linux 虚拟机 server2，IP 地址为 192.168.1.102。两台主机可相互访问。测试如下：12345678starky@server1:~$ ping 192.168.1.102 -c 2PING 192.168.1.102 (192.168.1.102) 56(84) bytes of data.64 bytes from 192.168.1.102: icmp_seq=1 ttl=64 time=0.951 ms64 bytes from 192.168.1.102: icmp_seq=2 ttl=64 time=0.330 ms--- 192.168.1.102 ping statistics ---2 packets transmitted, 2 received, 0% packet loss, time 2msrtt min/avg/max/mdev = 0.330/0.640/0.951/0.311 ms 12345678skitar@server2:~$ ping 192.168.1.101 -c 2PING 192.168.1.101 (192.168.1.101) 56(84) bytes of data.64 bytes from 192.168.1.101: icmp_seq=1 ttl=64 time=0.223 ms64 bytes from 192.168.1.101: icmp_seq=2 ttl=64 time=0.249 ms--- 192.168.1.101 ping statistics ---2 packets transmitted, 2 received, 0% packet loss, time 29msrtt min/avg/max/mdev = 0.223/0.236/0.249/0.013 ms 二、安装 nginx 服务器nginx 的安装方式主要有两种： 预编译的二进制程序。这是最简单和最快速的安装方式，各主流操作系统都可以通过包管理器（如 Ubuntu 的 apt-get）安装。此种方式会安装几乎所有的官方模块或插件。 从源代码编译安装。这种方式相对于前者更加灵活，可以自行选择需要安装的模块或第三方插件。 本示例并没有特殊的需求，所以直接选择第一种安装方式。命令如下：12$ sudo apt-get update$ sudo apt-get install nginx 安装成功后，通过 systemctl status nginx 命令查看 nginx 服务的运行状态：1234567891011$ systemctl status nginx● nginx.service - A high performance web server and a reverse proxy server Loaded: loaded (/lib/systemd/system/nginx.service; enabled; vendor preset: en Active: active (running) since Tue 2019-07-02 01:22:07 CST; 26s ago Docs: man:nginx(8) Main PID: 3748 (nginx) Tasks: 2 (limit: 1092) Memory: 4.9M CGroup: /system.slice/nginx.service ├─3748 nginx: master process /usr/sbin/nginx -g daemon on; master_pro └─3749 nginx: worker process 通过 curl -I 127.0.0.1 命令验证 Web 服务器是否可以正常访问：1234$ curl -I 127.0.0.1HTTP/1.1 200 OKServer: nginx/1.15.9 (Ubuntu)... 三、负载均衡配置负载均衡（load-balancing）即按照一定的规则将负载分摊到多个操作单元上执行，从而提高服务的可用性和响应速度。简单的示例图如下： 如某网站应用部署在多台主机构成的服务器集群上，负载均衡服务器位于终端用户和服务器集群之间，负责接收终端用户的访问流量，并根据一定的规则将用户访问分发给后端的服务器主机，从而提高在高并发状态下的响应速度。 负载均衡服务器nginx 可以通过 upstream 选项配置负载均衡。这里使用虚拟机 server1 作为负载均衡服务器。修改 serve1 上默认站点的配置文件（sudo vim /etc/nginx/sites-available/default），改为如下内容：123456789101112upstream backend &#123; server 192.168.1.102:8000; server 192.168.1.102;&#125;server &#123; listen 80; location / &#123; proxy_pass http://backend; &#125;&#125; 基于测试的目的，当前只有两台虚拟机。server1（192.168.1.101）已经作为负载均衡服务器，所以使用 server2（192.168.1.102）作为应用服务器。这里借助 nginx 的虚拟主机功能，分别将 192.168.1.102 和 192.168.1.102:8000 “模拟”为两台不同的应用服务器。 应用服务器修改 server2 上默认站点的配置文件（sudo vim /etc/nginx/sites-available/default），改为如下内容：12345678910111213server &#123; listen 80; root /var/www/html; index index.html index.htm index.nginx-debian.html; server_name 192.168.1.102; location / &#123; try_files $uri $uri/ =404; &#125;&#125; 在 /var/www/html 目录下创建 index.html 文件，作为 default 站点的 index 页面，内容如下：12345678&lt;html&gt; &lt;head&gt; &lt;title&gt;Index Page From Server1&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;This is Server1, Address 192.168.1.102.&lt;/h1&gt; &lt;/body&gt;&lt;/html&gt; 运行 sudo systemctl restart nginx 命令重启 nginx 服务，此时访问 http://192.168.1.102 即可获取刚刚创建的 index.html 页面：123456789$ curl 192.168.1.102&lt;html&gt; &lt;head&gt; &lt;title&gt;Index Page From Server1&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;This is Server1, Address 192.168.1.102.&lt;/h1&gt; &lt;/body&gt;&lt;/html&gt; 配置“另一台主机”上的站点，在 server2 上创建 /etc/nginx/sites-available/server2 配置文件，内容如下：12345678910111213server &#123; listen 8000; root /var/www/html; index index2.html index.htm index.nginx-debian.html; server_name 192.168.1.102; location / &#123; try_files $uri $uri/ =404; &#125;&#125; 注意监听端口和 index 页面的配置变化。在 /var/www/html 目录下创建 index2.html 文件，作为 server2 站点的 index 页面，内容如下：12345678&lt;html&gt; &lt;head&gt; &lt;title&gt;Index Page From Server2&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;This is Server2, Address 192.168.1.102:8000.&lt;/h1&gt; &lt;/body&gt;&lt;/html&gt; PS：为了测试目的，default 站点和 server2 站点配置在同一个主机 server2 上，且页面稍有不同。实际环境中通常将这两个站点配置在不同的主机上，且内容一致。 运行 sudo ln -s /etc/nginx/sites-available/server2 /etc/nginx/sites-enabled/ 命令启用刚刚创建的 server2 站点。重启 nginx 服务，此时访问 http://192.168.1.102:8000 即可获取刚刚创建的 index2.html 页面：123456789$ curl 192.168.1.102:8000&lt;html&gt; &lt;head&gt; &lt;title&gt;Index Page From Server2&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;This is Server2, Address 192.168.1.102:8000.&lt;/h1&gt; &lt;/body&gt;&lt;/html&gt; 负载均衡测试回到负载均衡服务器即虚拟机 server1 上，其配置文件中设置的反向代理 URL 为 http://backend 。由于未曾配置域名解析服务，无法将 URL http://backend 定位到正确的位置。 可以修改 server1 上的 /etc/hosts 文件，添加如下一条记录：127.0.0.1 backend即可将该域名解析到本地 IP ，完成对负载均衡服务器的访问。 重启 nginx 服务，在 server1 上访问 http://backend ，效果如下：123456789101112131415161718192021222324252627282930313233343536$ curl http://backend&lt;html&gt; &lt;head&gt; &lt;title&gt;Index Page From Server1&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;This is Server1, Address 192.168.1.102.&lt;/h1&gt; &lt;/body&gt;&lt;/html&gt;$ curl http://backend&lt;html&gt; &lt;head&gt; &lt;title&gt;Index Page From Server2&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;This is Server2, Address 192.168.1.102:8000.&lt;/h1&gt; &lt;/body&gt;&lt;/html&gt;$ curl http://backend&lt;html&gt; &lt;head&gt; &lt;title&gt;Index Page From Server1&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;This is Server1, Address 192.168.1.102.&lt;/h1&gt; &lt;/body&gt;&lt;/html&gt;$ curl http://backend&lt;html&gt; &lt;head&gt; &lt;title&gt;Index Page From Server2&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;This is Server2, Address 192.168.1.102:8000.&lt;/h1&gt; &lt;/body&gt;&lt;/html&gt; 从输出中可以看出，server1 对负载均衡服务器 http://backend 的访问，完成了对应用服务器 server2 上两个 Web 站点的轮询，起到负载均衡的作用。 四、负载均衡方法nginx 开源版本提供四种负载均衡的实现方式，简单介绍如下。 1. Round Robin用户请求均匀地分配给后端服务器集群（可以通过 weight 选项设置轮询的权重），这是 nginx 默认使用的负载均衡方式：1234upstream backend &#123; server backend1.example.com weight=5; server backend2.example.com;&#125; 2. Least Connections用户请求会优先转发给集群中当前活跃连接数最少的服务器。同样支持 weight 选项。12345upstream backend &#123; least_conn; server backend1.example.com; server backend2.example.com;&#125; 3. IP Hash用户请求会根据客户端 IP 地址进行转发。即该方式意图保证某个特定的客户端最终会访问同一个服务器主机。12345upstream backend &#123; ip_hash; server backend1.example.com; server backend2.example.com;&#125; 4. Generic Hash用户请求会根据一个自定义键值确定最终转发的目的地，该键值可以是字符串、变量或者组合（如源 IP 和端口号）。12345upstream backend &#123; hash $request_uri consistent; server backend1.example.com; server backend2.example.com;&#125; 权重参考下面的示例配置：12345upstream backend &#123; server backend1.example.com weight=5; server backend2.example.com; server 192.0.0.1 backup;&#125; 默认权重（weight）为 1 。backup 服务器只有在所有其他服务器全部宕机的情况下才会接收请求。如上面的示例，每 6 个请求会有 5 个转发给 backend1.example.com，1 个转发给 backend2.example.com。只有当 backend1 和 backend2 全部宕机时，192.0.0.1 才会接收并处理请求。 参考资料HTTP Load Balancing]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Server</tag>
        <tag>Admin</tag>
        <tag>Nginx</tag>
        <tag>WebDev</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django 学习笔记（四）—— 第一个自定义应用 下篇]]></title>
    <url>%2F2019%2F06%2F29%2Fdjango-manual-4-admin%2F</url>
    <content type="text"><![CDATA[本文接上篇 Django 学习笔记（三）—— 第一个自定义应用 中篇，涉及到代码重构（基于通用视图）和 Django 后台管理系统的定制。 一、通用视图前面编写的 index()、detail() 和 results() 视图都很简单且存在一定的冗余问题。它们都遵循 Web 开发中一种常见的模式，即根据 URL 中的参数从数据库中获取数据、载入模板文件然后返回渲染后的页面。而通用视图可以将这种常见的模式抽象化，使得在编写应用时能够减少大量不必要的代码。 修改视图定义文件（polls/views.py），借助通用视图改为如下版本：1234567891011121314151617181920212223242526272829303132333435363738from django.http import HttpResponseRedirectfrom django.shortcuts import render, get_object_or_404from django.urls import reversefrom django.views import genericfrom .models import Question, Choiceclass IndexView(generic.ListView): template_name = &apos;polls/index.html&apos; context_object_name = &apos;latest_question_list&apos; def get_queryset(self): return Question.objects.order_by(&apos;-pub_date&apos;)[:5]class DetailView(generic.DetailView): model = Question template_name = &apos;polls/detail.html&apos;class ResultsView(generic.DetailView): model = Question template_name = &apos;polls/results.html&apos;def vote(request, question_id): question = get_object_or_404(Question, pk=question_id) try: selected_choice = question.choice_set.get(pk=request.POST[&apos;choice&apos;]) except (KeyError, Choice.DoesNotExist): return render(request, &apos;polls/detail.html&apos;, &#123; &apos;question&apos;: question, &apos;error_message&apos;: &quot;You didn&apos;t select a choice.&quot;, &#125;) else: selected_choice.votes += 1 selected_choice.save() return HttpResponseRedirect(reverse(&apos;polls:results&apos;, args=(question.id,))) ListView 和 DetailView 分别表示显示若干对象的列表和显示一个特定类型对象的详细信息两种视图模板。其中每个通用视图都可以用 model 属性指定其作用于哪个模型。此外，DetailView 期望从 URL 中捕获名为 “pk” 的主键值，因此需要修改 polls/urls.py 中的具体定义。 视图对应的路由定义修改为如下形式（polls/urls.py）：12345678910from django.urls import pathfrom . import viewsapp_name = &apos;polls&apos;urlpatterns = [ path(&apos;&apos;,views.IndexView.as_view(), name=&apos;index&apos;), path(&apos;&lt;int:pk&gt;/&apos;, views.DetailView.as_view(), name=&apos;detail&apos;), path(&apos;&lt;int:pk&gt;/results/&apos;, views.ResultsView.as_view(), name=&apos;results&apos;), path(&apos;&lt;int:question_id&gt;/vote/&apos;, views.vote, name=&apos;vote&apos;),] 二、自定义管理后台自定义后台表单当前的 Django 后台管理界面如下： 对于投票问题（Questions）和选项（Choices）对象的编辑需要进入两个不同的页面分别进行修改，使用的友好性上有待提升。 可以使用如下方法，为 Questions 对象添加关联的 Choices 对象，即在投票问题的后台页面中添加上修改投票选项的接口，使得这两个页面合并为同一个。 编辑后台定义文件（polls/admin.py）：123456789101112131415from django.contrib import adminfrom .models import Question, Choiceclass ChoiceInline(admin.StackedInline): model = Choice extra = 3class QuestionAdmin(admin.ModelAdmin): fieldsets = [ (None, &#123;&apos;fields&apos;: [&apos;question_text&apos;]&#125;), (&apos;Date information&apos;, &#123;&apos;fields&apos;: [&apos;pub_date&apos;], &apos;classes&apos;: [&apos;collapse&apos;]&#125;), ] inlines = [ChoiceInline]admin.site.register(Question, QuestionAdmin) 此时后台界面如下： 不过仍有点小问题，即修改对象时的后台页面占据了大量的屏幕区域用来显示 Choice 对象的字段。Django 提供了一种表格的形式用来显示关联对象，只需作如下修改（polls/admin.py）：123...class ChoiceInline(admin.TabularInline):... 效果如下： 自定义后台对象页面当前后台管理系统中的对象主页（如 Question 对象的主页）布局如下： 从该页面中无法直接看到除 question_text 之外的任何信息。下面将对该页面如下定制： 显示更多的字段信息（如 pub_date） 添加一个用来筛选数据的过滤器（基于日期） 添加搜索功能（基于 question_text） 修改 polls/admin.py 文件，添加如下 3 行代码：123456...class QuestionAdmin(admin.ModelAdmin): list_display = (&apos;question_text&apos;, &apos;pub_date&apos;) list_filter = [&apos;pub_date&apos;] search_fields = [&apos;question_text&apos;]... 效果如下： 参考资料 Django 2.2 官方文档]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Python</tag>
        <tag>WebDev</tag>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django 学习笔记（二）—— 第一个自定义应用 上篇]]></title>
    <url>%2F2019%2F06%2F24%2Fdjango-manual-2-models%2F</url>
    <content type="text"><![CDATA[本文接上篇 Django 学习笔记（一）—— 快速建站，前提是已经完成了 Django 开发环境的搭建和 MySQL 数据库的关联。本教程将创建一个基本的投票应用程序，包含供人们参与投票的公共站点和一个可操作后台数据的管理平台。主要参考自 Django 2.2 官方文档。 一、创建项目$ django-admin startproject mysite 该命令会在当前目录下创建一个 mysite 目录，并且该框架中已经包含了一个初始 Django 项目必需的所有组件。其目录结构如下：1234567mysite├── manage.py└── mysite ├── __init__.py ├── settings.py ├── urls.py └── wsgi.py 进入 manage.py 所在的目录下，运行 python manage.py runserver 0000:8000 即可运行一个用于开发的简易服务器：12345678910$ python manage.py runserver 0.0.0.0:8000Watching for file changes with StatReloaderPerforming system checks...System check identified no issues (0 silenced).June 22, 2019 - 07:47:04Django version 2.2.2, using settings &apos;mysite.settings&apos;Starting development server at http://0.0.0.0:8000/Quit the server with CONTROL-C. 访问效果如下： 二、创建投票应用 PS：“应用”是一个专门用于做某件事的应用程序，比如博客或者简单的投票程序，“项目”则是一个网站所包含的配置和应用的合集。一个项目可以包含多个应用，一个应用也可以被多个项目使用。 Django 中的每个应用都是一个 Python 包，可以通过 manage.py 创建应用的基础目录结构：$ python manage.py startapp polls 当前目录结构如下：12345678910111213141516mysite├── manage.py├── mysite│ ├── __init__.py│ ├── settings.py│ ├── urls.py│ └── wsgi.py└── polls ├── admin.py ├── apps.py ├── __init__.py ├── migrations │ └── __init__.py ├── models.py ├── tests.py └── views.py 编辑视图（View）编辑 polls/views.py 文件，代码如下：1234from django.http import HttpResponsedef index(request): return HttpResponse(&quot;Hello Wrold. This is the index page.&quot;) 创建 URL 映射在 polls 目录下创建 urls.py 文件，编辑输入如下内容以完成到 index 页面的 URL 映射：123456from django.urls import pathfrom . import viewsurlpatterns = [ path(&apos;&apos;,views.index, name=&apos;index&apos;),] 在根 URLconf 文件中（即 mysite/urls.py）引入刚刚创建的 polls.urls 模块（即 polls/urls.py）：1234567from django.contrib import adminfrom django.urls import path, includeurlpatterns = [ path(&apos;polls/&apos;, include(&apos;polls.urls&apos;)), path(&apos;admin/&apos;, admin.site.urls),] 运行测试服务器，访问 http://127.0.0.1:8000/polls ，最终效果如下： 三、创建模型（Model）在 Django 中，对于一个数据驱动的 Web 应用，定义模型（即数据库的结构设计）是非常必要的一个操作。 本应用中需要创建两个模型： 问题 Question 模型：包含问题描述和发布时间 选项 Choice 模型：包含选项描述和当前票数 编辑 polls/models.py 文件，具体结构定义如下：12345678910from django.db import modelsclass Question(models.Model): question_text = models.CharField(max_length=200) pub_date = models.DateTimeField(&apos;date published&apos;)class Choice(model.Model): question = models.ForeignKey(Question, on_delete=models.CASCADE) choice_text = models.CharField(max_length=200) votes = models.IntegerField(default=0) 上述模型代码可以被 Django 用来创建本应用的数据库 schema（生成 CREATE TABLE 语句）。不过需要先在 mysite/settings.py 配置文件中修改 INSTALLED_APPS 变量，Django 需要依据该变量中对应用的指定进行数据库迁移操作。 123456789INSTALLED_APPS = [ &apos;polls.apps.PollsConfig&apos;, &apos;django.contrib.admin&apos;, &apos;django.contrib.auth&apos;, &apos;django.contrib.contenttypes&apos;, &apos;django.contrib.sessions&apos;, &apos;django.contrib.messages&apos;, &apos;django.contrib.staticfiles&apos;,] 运行 python manage.py makemigrations polls 命令创建数据库迁移文件：12345$ python manage.py makemigrations pollsMigrations for &apos;polls&apos;: polls/migrations/0001_initial.py - Create model Question - Create model Choice 运行 python manage.py migrate 命令完成数据库迁移操作：123456$ python manage.py migrateOperations to perform: Apply all migrations: admin, auth, contenttypes, polls, sessionsRunning migrations: Applying polls.0001_initial... OK... PS：在运行 migrate 命令之前，可以使用 python manage.py sqlmigrate polls 0001 查看该次迁移操作具体会执行哪些 SQL 语句：123456789101112 python manage.py sqlmigrate polls 0001BEGIN;---- Create model Question--CREATE TABLE &quot;polls_question&quot; (&quot;id&quot; integer NOT NULL PRIMARY KEY AUTOINCREMENT, &quot;question_text&quot; varchar(200) NOT NULL, &quot;pub_date&quot; datetime NOT NULL);---- Create model Choice--CREATE TABLE &quot;polls_choice&quot; (&quot;id&quot; integer NOT NULL PRIMARY KEY AUTOINCREMENT, &quot;choice_text&quot; varchar(200) NOT NULL, &quot;votes&quot; integer NOT NULL, &quot;question_id&quot; integer NOT NULL REFERENCES &quot;polls_question&quot; (&quot;id&quot;) DEFERRABLE INITIALLY DEFERRED);CREATE INDEX &quot;polls_choice_question_id_c5b4b260&quot; ON &quot;polls_choice&quot; (&quot;question_id&quot;);COMMIT; 四、数据库 API可以通过运行 python manage.py shell 进入 Python 交互式命令行，尝试 Django 提供的各种数据库 API 。示例如下：12345678910111213141516171819202122$ python manage.py shellPython 3.7.3 (default, Apr 3 2019, 05:39:12)[GCC 8.3.0] on linuxType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.(InteractiveConsole)&gt;&gt;&gt; from polls.models import Choice, Question&gt;&gt;&gt; Question.objects.all()&lt;QuerySet []&gt;&gt;&gt;&gt; from django.utils import timezone&gt;&gt;&gt; q = Question(question_text=&quot;What&apos;s new?&quot;, pub_date=timezone.now())&gt;&gt;&gt; q.save()&gt;&gt;&gt; q.id1&gt;&gt;&gt; q.question_text&quot;What&apos;s new?&quot;&gt;&gt;&gt; q.pub_datedatetime.datetime(2019, 6, 24, 15, 34, 47, 614267, tzinfo=&lt;UTC&gt;)&gt;&gt;&gt; q.question_text = &quot;What&apos;s up&quot;&gt;&gt;&gt; q.save()&gt;&gt;&gt; Question.objects.all()&lt;QuerySet [&lt;Question: Question object (1)&gt;]&gt;&gt;&gt;&gt; 上面的示例中，&lt;Question: Question object (1)&gt; 类型的输出不便于了解对象的细节，可以通过修改 Question 模型的代码来改变 Question.objects.all() 函数的行为。将 polls/models.py 内容改为如下形式：12345678910111213141516from django.db import modelsclass Question(models.Model): question_text = models.CharField(max_length=200) pub_date = models.DateTimeField(&apos;date published&apos;) def __str__(self): return self.question_textclass Choice(models.Model): question = models.ForeignKey(Question, on_delete=models.CASCADE) choice_text = models.CharField(max_length=200) votes = models.IntegerField(default=0) def __str__(self): return self.choice_text 此时再次尝试使用数据库 API ：123456789$ python manage.py shellPython 3.7.3 (default, Apr 3 2019, 05:39:12)[GCC 8.3.0] on linuxType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.(InteractiveConsole)&gt;&gt;&gt; from polls.models import Choice, Question&gt;&gt;&gt; Question.objects.all()&lt;QuerySet [&lt;Question: What&apos;s up&gt;]&gt;&gt;&gt;&gt; 给模型增加 __str__() 方法只是其中一种形式，实际上可以添加任意需要的函数以供后期调用。 五、后台管理系统（Django admin）Django admin 是任何一个初始的 Django 项目（完成数据库同步之后）默认开启的应用，用于对项目关联的数据库表进行基本的增删改查操作。 首先需要创建用于登录后台系统的管理员账户：123456$ python manage.py createsuperuserUsername (leave blank to use &apos;starky&apos;):Email address:Password:Password (again):Superuser created successfully. 开启测试服务器（python manage.py runserver 0000:8000），访问 http://127.0.0.1:8000/admin/，使用刚刚创建的管理员账户登录，效果如下： 将 poll 应用添加至后台修改 polls/admin.py 文件，将 Question 对象添加至后台面板：1234from django.contrib import adminfrom .models import Questionadmin.site.register(Question) 启动测试服务器，访问后台页面效果如下： PS：中文界面可以修改配置文件 mysite/settings.py，将 LANGUAGE_CODE 项改为如下形式：LANGUAGE_CODE = &#39;zh-Hans&#39; 之后便可以在后台页面直接对之前 MySQL 中创建的 polls_question 数据表进行编辑操作： 参考资料 Django 2.2 官方文档]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Python</tag>
        <tag>WebDev</tag>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django 学习笔记（三）—— 第一个自定义应用 中篇]]></title>
    <url>%2F2019%2F06%2F24%2Fdjango-manual-3-views%2F</url>
    <content type="text"><![CDATA[本文接上篇 Django 学习笔记（二）—— 第一个自定义应用 上篇，前提是已经完成了 Django 项目的初始化以及数据模型的创建。本篇主要讲视图（View）的创建，视图即一类具有相同功能和模板的网页的集合。 本应用中需要用到一下几个视图： 问题索引页：展示最近几个问题的列表 问题详情页：展示某个需要投票的问题及其选项 问题结果页：展示某个投票的结果 投票处理器：响应用户为某个问题的特定选项投票的操作 一、模板理论上讲，视图可以从数据库读取记录，可以使用模板引擎（Django 自带的或者第三方模板），可以输出 XML，创建压缩文件，可以使用任何想用的 Python 库。 必须的要求只是返回一个 HttpResponse 对象，或者抛出一个异常。 借助 Django 提供的数据库 API，修改视图（polls/views.py 文件）中的 index() 函数，使得应用首页可以展示数据库中以发布时间排序的最近 5 个问题：123456789from django.http import HttpResponsefrom .models import Questiondef index(request): latest_question_list = Question.objects.order_by(&apos;-pub_date&apos;)[:5] output = &apos;/n&apos;.join([q.question_text for q in latest_question_list]) if output: output = &apos;Em...there is no questions. Please add some.&apos; return HttpResponse(output) 开启测试服务器，进入 Django 后台管理系统（http://127.0.0.1:8000/admin），添加测试问题： 访问 index 视图（http://127.0.0.1:8000/polls）效果如下： 在当前的代码中，页面的布局定义是固定在视图函数中的，页面设计变更时则需要对 Python 代码进行改动。此时可以通过使用 Django 的模板系统，将页面设计从业务代码中分离出来。 在 polls 目录下创建 templates 目录，Django 会自动在该目录下寻找模板文件。在 polls/templates 目录下创建 polls 目录，并在该目录下创建 index.html 文件（即最终的模板文件为 polls/templates/polls/index.html）。 具体代码如下：123456789&#123;% if latest_question_list %&#125; &lt;ul&gt; &#123;% for question in latest_question_list %&#125; &lt;li&gt;&lt;a href=&quot;/polls/&#123;&#123; question.id &#125;&#125;/&quot;&gt;&#123;&#123; question.question_text &#125;&#125;&lt;/a&gt;&lt;/li&gt; &#123;% endfor %&#125; &lt;/ul&gt;&#123;% else %&#125; &lt;p&gt;No polls are available.&lt;/p&gt;&#123;% endif %&#125; 修改视图函数（polls/view.py）已使用刚刚创建的模板：1234567from django.shortcuts import renderfrom .models import Questiondef index(request): latest_question_list = Question.objects.order_by(&apos;-pub_date&apos;)[:5] context = &#123;&apos;latest_question_list&apos;: latest_question_list&#125; return render(request, &apos;polls/index.html&apos;, context) render() 函数用于加载模块并填充上下文，然后返回生成的 HttpResponse 对象。 效果如下： 404 错误此时访问问题详情页面（即点击 index 页面中的 test quesion 链接），会提示 Page not found 错误，原因是模板（index.html）中指定的 polls// 还没有创建对应的路由及其绑定的页面。 这里需要创建一个问题详情页的视图，用于显示指定问题的详细信息。同时当访问的问题不存在时，该视图会抛出 Http404 异常。视图代码（polls/views.py）如下：123456789101112131415from django.http import Http404from django.shortcuts import renderfrom .models import Questiondef index(request): latest_question_list = Question.objects.order_by(&apos;-pub_date&apos;)[:5] context = &#123;&apos;latest_question_list&apos;: latest_question_list&#125; return render(request, &apos;polls/index.html&apos;, context)def detail(request, question_id): try: question = Question.objects.get(pk=question_id) except Question.DoesNotExist: raise Http404(&quot;Question does not exist&quot;) return render(request, &apos;polls/detail.html&apos;, &#123;&apos;question&apos;: question&#125;) 创建对应 detail 视图的模板文件（polls/templates/polls/detail.html）：123456&lt;h1&gt;&#123;&#123; question.question_text &#125;&#125;&lt;/h1&gt;&lt;ul&gt;&#123;% for choice in question.choice_set.all %&#125; &lt;li&gt;&#123;&#123; choice.choice_text &#125;&#125;&lt;/li&gt;&#123;% endfor %&#125;&lt;/ul&gt; 其中 choice 模型还没有关联至后台页面并添加数据，不过暂时不影响页面显示。 修改路由配置文件（polls/urls.py），添加关联 detail 页面的路由，内容如下：12345678from django.urls import pathfrom . import viewsapp_name = &apos;polls&apos;urlpatterns = [ path(&apos;&apos;,views.index, name=&apos;index&apos;), path(&apos;&lt;int:question_id&gt;/&apos;, views.detail, name=&apos;detail&apos;),] 运行效果如下： 去除硬编码 URLpolls/index.html 模板中的问题详情页链接当前是如下形式：&lt;li&gt;&lt;a href=&quot;/polls//&quot;&gt;&lt;/a&gt;&lt;/li&gt; 这种硬编码形式的链接在包含多个应用的项目中，相对而言并不方便修改。因为之前在路由配置文件 polls/urls.py 的 url() 函数中通过 name 参数对 URL 进行了命名（path(&#39;&lt;int:question_id&gt;/&#39;, views.detail, name=&#39;detail&#39;),），所以之前模板文件中的硬编码链接可以修改为如下形式的链接：1&lt;li&gt;&lt;a href=&quot;&#123;% url &apos;detail&apos; question.id %&#125;&quot;&gt;&#123;&#123; question.question_text &#125;&#125;&lt;/a&gt;&lt;/li&gt; 同时，对于包含多个应用的项目，为了避免 URL 重名的情况出现，可以为 URL 名称添加命名空间。即 polls/urls.py 文件中的如下代码行：app_name = &#39;polls&#39; 此时模板文件（polls/templates/polls/index.html）中的链接即改为如下形式：1&lt;li&gt;&lt;a href=&quot;&#123;% url &apos;polls:detail&apos; question.id %&#125;&quot;&gt;&#123;&#123; question.question_text &#125;&#125;&lt;/a&gt;&lt;/li&gt; 完整 index.html 代码如下：123456789&#123;% if latest_question_list %&#125; &lt;ul&gt; &#123;% for question in latest_question_list %&#125; &lt;li&gt;&lt;a href=&quot;&#123;% url &apos;polls:detail&apos; question.id %&#125;&quot;&gt;&#123;&#123; question.question_text &#125;&#125;&lt;/a&gt;&lt;/li&gt; &#123;% endfor %&#125; &lt;/ul&gt;&#123;% else %&#125; &lt;p&gt;No polls are available.&lt;/p&gt;&#123;% endif %&#125; 二、表单修改问题详情页的模板文件（polls/templates/polls/detail.html），添加 &lt;form&gt; 表单：1234567891011&lt;h1&gt;&#123;&#123; question.question_text &#125;&#125;&lt;/h1&gt;&#123;% if error_message %&#125;&lt;p&gt;&lt;strong&gt;&#123;&#123; error_message &#125;&#125;&lt;/strong&gt;&lt;/p&gt;&#123;% endif %&#125;&lt;form action=&quot;&#123;% url &apos;polls:vote&apos; question.id %&#125;&quot; method=&quot;post&quot;&gt;&#123;% csrf_token %&#125;&#123;% for choice in question.choice_set.all %&#125; &lt;input type=&quot;radio&quot; name=&quot;choice&quot; id=&quot;choice&#123;&#123; forloop.counter &#125;&#125;&quot; value=&quot;&#123;&#123; choice.id &#125;&#125;&quot;&gt; &lt;label for=&quot;choice&#123;&#123; forloop.counter &#125;&#125;&quot;&gt;&#123;&#123; choice.choice_text &#125;&#125;&lt;/label&gt;&lt;br&gt;&#123;% endfor %&#125;&lt;input type=&quot;submit&quot; value=&quot;Vote&quot;&gt;&lt;/form&gt; 上面的模板在 Question 中的每个 Choice 前添加一个单选按钮，其 value 为 “choice.id” ，即每次选择并提交表单后，它将发送一个 POST 数据 choice=#choice_id 。 表单的 action 为 url &#39;polls:vote&#39; question_id，且 action 方法为 POST。forloop.counter 用于指示 for 标签当前循环的次数。 csrf_token 用于防御跨站点请求伪造。 接下来需要在视图文件（polls/views.py）中添加定义 vote 视图的函数：1234567891011121314151617181920212223242526272829303132from django.http import HttpResponse, HttpResponseRedirectfrom django.shortcuts import render, get_object_or_404from django.urls import reversefrom .models import Question, Choicedef index(request): latest_question_list = Question.objects.order_by(&apos;-pub_date&apos;)[:5] context = &#123;&apos;latest_question_list&apos;: latest_question_list&#125; return render(request, &apos;polls/index.html&apos;, context)def detail(request, question_id): question = get_object_or_404(Question, pk=question_id) return render(request, &apos;polls/detail.html&apos;, &#123;&apos;question&apos;: question&#125;)def vote(request, question_id): question = get_object_or_404(Question, pk=question_id) try: selected_choice = question.choice_set.get(pk=request.POST[&apos;choice&apos;]) except (KeyError, Choice.DoesNotExist): return render(request, &apos;polls/detail.html&apos;, &#123; &apos;question&apos;: question, &apos;error_message&apos;: &quot;You didn&apos;t select a choice.&quot;, &#125;) else: selected_choice.votes += 1 selected_choice.save() return HttpResponseRedirect(reverse(&apos;polls:results&apos;, args=(question.id,)))def results(request, question_id): question = get_object_or_404(Question, pk=question_id) return render(request, &apos;polls/results.html&apos;, &#123;&apos;question&apos;: question&#125;) 其中 get_object_or_404() 是一个用于获取对象或者抛出 Http404 异常的快捷函数。HttpResponseRedirect 用于将用户重定向至指定页面（投票结果 results 页）。 所以还需要创建一个 polls/templates/polls/results.html 模板文件：123456789&lt;h1&gt;&#123;&#123; question.question_text &#125;&#125;&lt;/h1&gt;&lt;ul&gt;&#123;% for choice in question.choice_set.all %&#125; &lt;li&gt;&#123;&#123; choice.choice_text &#125;&#125; -- &#123;&#123; choice.votes &#125;&#125; vote&#123;&#123; choice.votes|pluralize &#125;&#125;&lt;/li&gt;&#123;% endfor %&#125;&lt;/ul&gt;&lt;a href=&quot;&#123;% url &apos;polls:detail&apos; question.id %&#125;&quot;&gt;Vote again?&lt;/a&gt; 修改 polls/urls.py 文件，添加上 vote 和 results 的路由配置：12345678910from django.urls import pathfrom . import viewsapp_name = &apos;polls&apos;urlpatterns = [ path(&apos;&apos;,views.index, name=&apos;index&apos;), path(&apos;&lt;int:question_id&gt;/&apos;, views.detail, name=&apos;detail&apos;), path(&apos;&lt;int:question_id&gt;/results/&apos;, views.results, name=&apos;results&apos;), path(&apos;&lt;int:question_id&gt;/vote/&apos;, views.vote, name=&apos;vote&apos;),] 项目进行到这里算是基本告一段落了。为了可以在 Django 后台系统中操作 Choice 模型关联的数据库，还需要将 polls/admin.py 文件改为如下形式：12345from django.contrib import adminfrom .models import Question, Choiceadmin.site.register(Question)admin.site.register(Choice) 此时运行测试服务器，最终效果如下： 参考资料 Django 2.2 官方文档]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Python</tag>
        <tag>WebDev</tag>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django 学习笔记（一）—— 快速建站]]></title>
    <url>%2F2019%2F06%2F20%2Fdjango-manual-1-simple-site%2F</url>
    <content type="text"><![CDATA[Django 是一个基于 MVC（Model-View-Controller）模式的服务器端的 Web 框架，由 Python 语言编写。其创建之初主要是用来与关系型数据库进行交互，随着技术的不断革新，Django 也逐渐融合了众多更现代的 Web 开发趋势。作为一个成熟的 Web 开发框架，Django 有着众多企业级的应用，如 Instagram、Pinterest、National Geographic 等。 Django 设计原则 Don’t Repeat Yourself (DRY) Explicit Is Better Than Implicit Loosely Coupled Architecture 一、环境搭建Ubuntu 系统。为了保证多个 Python 运行环境之间彼此不受影响，这里通过 virtualenv 创建独立的虚拟开发环境。 使用 apt-get 命令安装 virtualenv ：$ sudo apt-get install python3-virtualenv 或者使用 Python 的包管理器（pip 命令）安装：$ python3 -m pip install virtualenv 使用 virtualenv 命令创建独立的虚拟运行环境：$ virtualenv --python=python3 mydjango 激活刚刚创建的虚拟环境：$ source activate mydjango/bin/activate 安装 Django 框架：$ pip install django 二、创建初始项目Django 框架安装成功以后，会提供 django-admin 命令用于常见的管理操作。如 django-admin startproject 命令用于创建一个初始项目的骨架：$ django-admin startproject testproject 该命令会在当前目录下创建 testproject 文件夹，结构如下：1234567testproject├── manage.py└── testproject ├── __init__.py ├── settings.py ├── urls.py └── wsgi.py 其中各文件的作用如下： manage.py：类似于 django-admin 命令，用于执行一些项目相关的任务 settings.py：Django 项目的配置设置 urls.py：Django 项目的 URL 模式 wsgi.py：Django 项目的 WSGI 配置。WSGI 是 Django 应用部署在生产环境中的推荐方式 运行测试服务进入项目目录，运行 python manage.py runserver &lt;IP:Port&gt; 命令开启测试服务，一个可供访问的最简单的 Web 站点即搭建成功：12345678910$ python manage.py runserver 0.0.0.0:8000Watching for file changes with StatReloaderPerforming system checks...System check identified no issues (0 silenced).June 20, 2019 - 09:03:29Django version 2.2.2, using settings &apos;testproject.settings&apos;Starting development server at http://0.0.0.0:8000/Quit the server with CONTROL-C. 效果如下： 三、数据库配置创建数据库 django 并授予用户 admin 访问权限：12345678mysql&gt; CREATE DATABASE django;Query OK, 1 row affected (0.00 sec)mysql&gt; GRANT ALL ON django.* TO admin IDENTIFIED BY &apos;password&apos;;Query OK, 0 rows affected, 1 warning (0.07 sec)mysql&gt; FLUSH PRIVILEGES;Query OK, 0 rows affected (0.00 sec) Django 使用 SQLite3 作为默认的数据库引擎，相关配置位于 settings.py 配置文件中：1234567...DATABASES = &#123; &apos;default&apos;: &#123; &apos;ENGINE&apos;: &apos;django.db.backends.sqlite3&apos;, &apos;NAME&apos;: os.path.join(BASE_DIR, &apos;db.sqlite3&apos;), &#125;... 如需使用 MySQL 数据库，将 settings.py 文件中的对应部分改为如下内容：12345678910DATABASES = &#123; &apos;default&apos;: &#123; &apos;ENGINE&apos;: &apos;django.db.backends.mysql&apos;, &apos;HOST&apos;: &apos;127.0.0.1&apos;, &apos;NAME&apos;: &apos;django&apos;, &apos;PASSWORD&apos;: &apos;password&apos;, &apos;PORT&apos;: &apos;3306&apos;, &apos;USER&apos;: &apos;admin&apos;, &#125;&#125; 安装 Python 操作 MySQL 的依赖库：12$ sudo apt-get install python3-dev libmysqlclient-dev$ pip install mysqlclient 使用 python manage.py migrate 命令完成数据库迁移操作：123456789101112131415161718192021$ python manage.py migrateOperations to perform: Apply all migrations: admin, auth, contenttypes, sessionsRunning migrations: Applying contenttypes.0001_initial... OK Applying auth.0001_initial... OK Applying admin.0001_initial... OK Applying admin.0002_logentry_remove_auto_add... OK Applying admin.0003_logentry_add_action_flag_choices... OK Applying contenttypes.0002_remove_content_type_name... OK Applying auth.0002_alter_permission_name_max_length... OK Applying auth.0003_alter_user_email_max_length... OK Applying auth.0004_alter_user_username_opts... OK Applying auth.0005_alter_user_last_login_null... OK Applying auth.0006_require_contenttypes_0002... OK Applying auth.0007_alter_validators_add_error_messages... OK Applying auth.0008_alter_user_username_max_length... OK Applying auth.0009_alter_user_last_name_max_length... OK Applying auth.0010_alter_group_name_max_length... OK Applying auth.0011_update_proxy_permissions... OK Applying sessions.0001_initial... OK 四、Django 管理后台为了方便管理，Django 将项目主要的业务逻辑和功能以模块化的方式（Django App）进行组织，一般用户自定义的应用位于项目目录下某个单独的文件夹中。这些 App 可以在 settings.py 文件中进行启用或禁用：12345678INSTALLED_APPS = [ &apos;django.contrib.admin&apos;, &apos;django.contrib.auth&apos;, &apos;django.contrib.contenttypes&apos;, &apos;django.contrib.sessions&apos;, &apos;django.contrib.messages&apos;, &apos;django.contrib.staticfiles&apos;,] 从上面的代码中可以看到，任何一个初始的 Django 项目默认已经开启了一个基本的“后台管理系统”（django.contrib.admin），可以对项目关联的数据库进行基本的增删改查操作。 该 admin 应用的路由定义在 urls.py 文件中：123456from django.contrib import adminfrom django.urls import pathurlpatterns = [ path(&apos;admin/&apos;, admin.site.urls),] 数据库迁移操作完成后，启动测试服务，即可访问 http://127.0.0.1:8000/admin 进入后台管理系统： 此时用于登录的后台管理员还未创建，可以使用 python manage.py createsuperuser 命令生成管理员账户：123456$ python manage.py createsuperuser用户名 (leave blank to use &apos;starky&apos;):电子邮件地址:Password:Password (again):Superuser created successfully. 登录成功后效果如下： 即无需编写任何业务代码，只搭建 Django 环境即可生成一个基本的“后台管理系统”。 参考资料Beginning Django]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Python</tag>
        <tag>WebDev</tag>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 laravel-admin 配置后台管理系统]]></title>
    <url>%2F2019%2F06%2F08%2Fbuild-management-console-with-laravel-admin%2F</url>
    <content type="text"><![CDATA[内容有点多，就不说别的了。。需要一个简单的后台管理系统，对接数据库中的用户信息表，完成基本的增删改查操作。最好支持权限管理；有便捷的接口可供调用（不需要深度定制）；前端界面和交互美观简洁，足够“现代化”；架构明晰，配置简单，可快速成型等等。几经查找，感觉 laravel-admin 这个框架还不错。虽说文档算不上完善，小踩几坑，没怎么太费事就构建好了。值得记录一下。 一、安装 Laravel 环境laravel-admin 需要 PHP 7+ 和 Lavavel 5.5+ ，我当前使用的是 VirtualBox 虚拟机里的 Ubuntu 19.04 系统，配置起来还是比较方便的。Laravel 官方的定义是 The PHP Framework For Web Artisans ，优雅和快速成型。依赖于 PHP &gt;= 7.1.3 和一些 PHP 扩展组件。可以使用 Linux 系统自带的包管理器进行安装，命令如下：$ sudo apt-get install php7.2 php7.2-bcmath php7.2-json php7.2-mbstring php7.2-mysql php7.2-xml php7.2-zip php7.2-common 安装 composer 并配置国内镜像Composer 是 PHP 语言的依赖管理工具，类似于 Node.js 下的 npm 。后面需要用到的 Laravel 、laravel-admin 及其相关的依赖项都可以通过 composer 命令安装。$ sudo apt-get install composer 为了提高访问速度，可以把 composer 的镜像源改为国内版本，命令如下（全局配置）：$ composer config -g repo.packagist composer https://packagist.laravel-china.org 安装 Laravel 并初始化项目使用 composer 命令安装 Laravel ：composer global require laravel/installer 将 Laravel 安装路径添加到 PATH 环境变量：$ echo export PATH=&quot;$PATH:~/.config/composer/vendor/bin&quot; &gt;&gt; ~/.zshrc &amp;&amp; source ~/.zshrc 初始化 Laravel 项目：$ laravel new admin 以上步骤完成后，进入 admin 项目目录，运行 $ php artisan serve 命令即可开启一个最基本的 Laravel 站点。 配置数据库安装 mysql 数据库：$ sudo apt-get install mysql-server 创建数据库 admin 并授权给测试账户（用户名 test_user ，密码 test_password）：12345678mysql&gt; CREATE DATABASE admin;Query OK, 1 row affected (0.00 sec)mysql&gt; GRANT ALL ON admin.* to test_user IDENTIFIED BY &apos;test_password&apos;;Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; FLUSH PRIVILEGES;Query OK, 0 rows affected (0.00 sec) 修改数据库配置文件编辑 config/database.php 文件（已经默认使用 mysql 数据库），修改 mysql 配置部分，将 url 改为如下形式：&#39;url&#39; =&gt; env(&#39;DATABASE_URL&#39;, &#39;mysql://test_user:test_password@127.0.0.1/admin&#39;),（数据库 URL 的格式为 mysql://用户名:密码@IP地址/数据库名） 二、安装 laravel-admin数据库配置完成后，即可按照以下步骤安装配置 laravel-admin 。 在 admin 目录下，使用 composer 命令安装 laravel-admin ：$ composer require encore/laravel-admin 发布资源：$ php artisan vendor:publish --provider=&quot;Encore\Admin\AdminServiceProvider&quot; 使用以下命令完成安装：$ php artisan admin:install 运行服务查看效果：$ php artisan serve 访问 http://127.0.0.1:8000/admin ，使用用户名 admin 和密码 admin 登录，效果如下： 安装完成后，laravel-admin 所有的配置都在 config/admin.php 文件中（如站点名称、logo、登录界面的背景等），而项目文件的安装目录为 app/Admin ，目录结构如下：123456app/Admin├── Controllers│ ├── ExampleController.php│ └── HomeController.php├── bootstrap.php└── routes.php 其中 app/Admin/routes.php 文件用来配置后台路由；app/Admin/bootstrap.php 是 laravel-admin 的启动文件；app/Admin/Controllers 目录用来存放后台控制器文件，该目录下的HomeController.php 文件是后台首页的显示控制器。 三、一些必要的配置项目进行到这里，已经具备了一个后台管理系统的所有基本要素，只是在添加或者修改用户时，会报出下图所示的 Config error ，需要添加一个 Disk 配置： 编辑 config/filesystems.php 文件，在 &#39;disks&#39; 配置下添加如下内容：123456&apos;admin&apos; =&gt; [ &apos;driver&apos; =&gt; &apos;local&apos;, &apos;root&apos; =&gt; public_path(&apos;upload&apos;), &apos;visibility&apos; =&gt; &apos;public&apos;, &apos;url&apos; =&gt; env(&apos;APP_URL&apos;).&apos;/public/puload/&apos;, ], 中文配置配置界面语言为中文可以修改 config/app.php 文件，将其中的 locale =&gt; en 改为 locale =&gt; zh-CN 即可。 其他常用的配置如站点名称、页面布局等可以编辑 config/admin.php 文件，文件中的注释信息非常详细，根据需求直接修改即可。 四、绑定自己的数据库前面生成的算是演示用的示例页面，如果需要绑定和管理自己的数据库表格，操作也是比较简单的。 创建数据库表格在之前创建的 admin 数据库中添加名为 employee 的表格：12345678mysql&gt; CREATE TABLE employee ( -&gt; id int(6) unsigned AUTO_INCREMENT PRIMARY KEY, -&gt; number int(6) unsigned NOT NULL UNIQUE, -&gt; name varchar(10) NOT NULL, -&gt; mail varchar(60) UNIQUE, -&gt; password varchar(30), -&gt; department varchar(40) NOT NULL DEFAULT &apos;&apos; -&gt; ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci; 创建模型文件$ php artisan make:model Employee 上述命令会创建 app/Employee.php 模型文件，将该文件改为如下内容：1234567891011&lt;?phpnamespace App;use Illuminate\Database\Eloquent\Model;class Employee extends Model&#123; protected $table = &apos;employee&apos;; public $timestamps = false;&#125; PS：关于模型的使用可以参考 Laravel 官方文档 添加控制器通过以下命令创建一个对接 app/employee 模型的控制器：12$ php artisan admin:make EmployeeController --model=App\\EmployeeApp\Admin\Controllers\EmployeeController created successfully. 添加路由编辑路由配置文件 app/Admin/routers.php ，在根 URL 的路由下添加如下一行内容：$router-&gt;resource(&#39;employee&#39;, EmployeeController::class); 添加网页菜单访问 http://127.0.0.1:8000/admin/auth/menu ，添加页面左侧的菜单项，用于指向前面创建的后台数据。 上述步骤完成后，访问 http://127.0.0.1:8000/admin/employee ，最终效果如下： 五、优化筛选和密码显示上面完成的项目中，筛选按钮只支持通过 ID 搜索，密码也是直接显示。这些和表格相关的行为都可以通过修改 app/Admin/Controllers/EmployeeController.php 文件进行控制。 修改 EmployeeController.php 文件中对表格相关行为的定义：123456789101112131415161718192021222324252627protected function grid()&#123; $grid = new Grid(new Employee); // 不显示 ID 列 //$grid-&gt;id(&apos;ID&apos;);^M $grid-&gt;number(&apos;工号&apos;);^M $grid-&gt;name(&apos;姓名&apos;);^M $grid-&gt;mail(&apos;邮箱&apos;);^M // 隐藏密码列 //$grid-&gt;password(&apos;Password&apos;);^M $grid-&gt;department(&apos;部门&apos;); $grid-&gt;filter(function($filter)&#123; // 去掉默认的 id 过滤器 $filter-&gt;disableIdFilter(); // 添加新的字段过滤器（通过工号过滤） $filter-&gt;like(&apos;number&apos;, &apos;工号&apos;); &#125;); return $grid;&#125; 实际效果如下： 六、nginx 服务器配置首先需要终止默认安装的 Apache2 服务并安装 nginx 和 php-fpm：123$ sudo systemctl stop apache2$ sudo systemctl disable apache2$ sudo apt-get install nginx php7.2-fpm 创建新的站点配置文件（/etc/nginx/sites-available/admin.conf）并写入以下内容：123456789101112131415161718192021222324252627282930313233server &#123; listen 80; server_name 127.0.0.1; root &lt;your-project-path&gt;/public; add_header X-Frame-Options &quot;SAMEORIGIN&quot;; add_header X-XSS-Protection &quot;1; mode=block&quot;; add_header X-Content-Type-Options &quot;nosniff&quot;; index index.html index.htm index.php; charset utf-8; location / &#123; try_files $uri $uri/ /index.php?$query_string; &#125; location = /favicon.ico &#123; access_log off; log_not_found off; &#125; location = /robots.txt &#123; access_log off; log_not_found off; &#125; error_page 404 /index.php; location ~ \.php$ &#123; fastcgi_pass unix:/var/run/php/php7.2-fpm.sock; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $realpath_root$fastcgi_script_name; include fastcgi_params; &#125; location ~ /\.(?!well-known).* &#123; deny all; &#125;&#125; 使用以下命令启用新的站点配置并重启 nginx 服务：12$ sudo ln -s /etc/nginx/sites-available/admin.conf /etc/nginx/sites-enabled/$ sudo systemctl restart nginx 需要注意的是，app/storage 目录的属主应该与运行 nginx 服务的用户（默认为 www-data）一致，可通过以下命令修改：$ sudo chown -R www-data storage 参考资料laravel-admin 官方文档Laravel 官网]]></content>
      <categories>
        <category>Program</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>Program</tag>
        <tag>Laravel</tag>
        <tag>laravel-admin</tag>
        <tag>Web</tag>
        <tag>PHP</tag>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[树莓派使用 snowboy 配置语音唤醒]]></title>
    <url>%2F2019%2F05%2F17%2Fpython-snowboy-voice-arousal%2F</url>
    <content type="text"><![CDATA[语音唤醒算是语音识别领域里最基础的应用，具体的场景如 Android 手机里的 “OK, Google” 或者苹果设备里的 “Hey, Siri”。简单来说就是在后台静默地运行着一个占用较少系统资源的服务（语音识别组件），该组件一直处于监视麦克风输入的状态，如果有检测到特定的语音输入（即唤醒词或“热词”），则激活与之绑定的某个程序“开关”。相当于一个简化版的语音助手吧，只对某一个特定的词汇进行响应，识别后也只完成某一件指定的任务。如果说同语音助手的交互是一段持续的交流，那么语音唤醒即可作为这种连续交流的入口（打招呼）。 snowboy 是一个开源的、轻量级语音唤醒引擎，可以通过它很轻松地创建属于自己的类似“hey, Siri” 的唤醒词。它的主要特性如下： 高度可定制性。可自由创建和训练属于自己的唤醒词 始终倾听。可离线使用，无需联网，保护隐私。精确度高，低延迟 轻量可嵌入。耗费资源非常低（单核 700MHz 树莓派只占用 10% CPU） 开源跨平台。开放源代码，支持多种操作系统和硬件平台，可绑定多种编程语言 详细看了官网提供的安装配置教程（已经很久没更新，有点过于繁琐了），几番尝试之后，感觉下面的介绍算是最新也相对最简单的方法了吧。 PS：只针对 Linux 系统（包含树莓派），其他平台可参考 Github 一、获取源代码并编译安装依赖树莓派原生的音频设备是不支持语音输入的（无法录音），需要在网上购买一支免驱动的USB音频驱动（便携式的和 U 盘差不多），一般插上即可直接使用。建议安装下 pulseaudio 软件，减少音频配置的步骤：$ sudo apt-get install pulseaudio 安装 sox 软件测试录音与播放功能：$ sudo apt-get install sox 安装完成后运行 sox -d -d 命令，对着麦克风说话，确认可以听到自己的声音。 安装其他软件依赖： 安装 PyAudio：$ sudo apt-get install python3-pyaudio 安装 SWIG（&gt;3.0.10)：$ sudo apt-get install swig 安装 ATLS：$ sudo apt-get install libatls-base-dev 编译源代码获取源代码：$ git clone https://github.com/Kitt-AI/snowboy.git编译 Python3 绑定：$ cd snowboy/swig/Python3 &amp;&amp; make 测试：进入官方示例目录 snowboy/examples/Python3 并运行以下命令：$ python3 demo.py resources/models/snowboy.umdl（ 命令中的 snowboy.umdl 文件即语音识别模型） 然后对着麦克风清晰地讲出“snowboy”，如果可以听到“滴”的声音，则安装配置成功。命令行输出如下： PS：官方源代码使用 Python3 测试有报错，经测试需修改 snowboy/examples/Python3 目录下的 snowboydecoder.py 文件。将第 5 行代码 from * import snowboydetect 改为 import snowboydetect 即可直接运行。 二、设置自己的唤醒词可将包含自定义唤醒词的音频文件上传至 snowboy 官网（需要登录），以训练生成自己喜欢的语音模型。需要上传的音频文件数量为 3 个，wav 格式。我试过直接在线录制，貌似有 Bug 。。。（也可能是我浏览器的问题） 训练完成并测试通过后，即可下载 PMDL 后缀的模型文件了。 #####测试将以下文件复制到自己的项目目录下： 上一步中下载好的 model.pmdl 模型文件 之前 snowboy/swig/Python3 目录下编译好的 _snowboydetect.so 库 snowboy/examples/Python3 目录下的 demo.py、snowboydecoder.py、snowboydetect.py 文件以及 resources 目录 在项目目录下执行 $ python3 demo.py model.pmdl 并使用自己的唤醒词进行测试 三、自定义响应官方提供的示例 demo.py 文件的源代码如下：123456789101112131415161718192021222324252627282930313233import snowboydecoderimport sysimport signalinterrupted = Falsedef signal_handler(signal, frame): global interrupted interrupted = Truedef interrupt_callback(): global interrupted return interruptedif len(sys.argv) == 1: print(&quot;Error: need to specify model name&quot;) print(&quot;Usage: python demo.py your.model&quot;) sys.exit(-1)model = sys.argv[1]# capture SIGINT signal, e.g., Ctrl+Csignal.signal(signal.SIGINT, signal_handler)detector = snowboydecoder.HotwordDetector(model, sensitivity=0.5)print(&apos;Listening... Press Ctrl+C to exit&apos;)# main loopdetector.start(detected_callback=snowboydecoder.play_audio_file, interrupt_check=interrupt_callback, sleep_time=0.03)detector.terminate() 通过阅读代码，可以看出唤醒词识别成功以后，程序响应的具体内容由程序末尾 detector.start() 函数的 detected_callback 参数指定。即重新绑定 detected_callback 对应的函数，可改变程序最终的响应。如：123456789101112131415161718192021222324252627282930313233343536import snowboydecoderimport sysimport signalinterrupted = Falsedef signal_handler(signal, frame): global interrupted interrupted = Truedef interrupt_callback(): global interrupted return interrupteddef detected(): print(&quot;Great! I have recognized your words.\n&quot;)if len(sys.argv) == 1: print(&quot;Error: need to specify model name&quot;) print(&quot;Usage: python demo.py your.model&quot;) sys.exit(-1)model = sys.argv[1]# capture SIGINT signal, e.g., Ctrl+Csignal.signal(signal.SIGINT, signal_handler)detector = snowboydecoder.HotwordDetector(model, sensitivity=0.5)print(&apos;Listening... Press Ctrl+C to exit&apos;)# main loopdetector.start(detected_callback=detected, interrupt_check=interrupt_callback, sleep_time=0.03)detector.terminate() 注意添加的 detected 函数。 效果如下： 更复杂的应用形式（如控制 LED 小灯等）也是基本上一样的思路，具体示例代码可参考官方文档。 参考资料snowboy Githubsnowboy 官网snowboy 官方文档]]></content>
      <categories>
        <category>Program</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Python</tag>
        <tag>Voice</tag>
        <tag>Intelligence</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Termux 详解—— Android 平台上完美移植的 Linux 工具集]]></title>
    <url>%2F2019%2F05%2F15%2FTermux-app-details%2F</url>
    <content type="text"><![CDATA[最近换了新手机，系统是基于 Android Pie（即 Android 9）定制的 MIUI 10 。Android 相对而言算得上是比较开放的平台，如此说来，不趁此机会乱搞一下难免有些说不过去。。。额，新手机，刷机Root来一套有点舍不得，好在有 Termux 这个应用。来，耍一耍看上去能够彰显“硬核”范儿的东西。 一、简介Termux 是 Android 平台上的一个终端模拟器，它将众多 Linux 上运行的软件和工具近乎完美的移植到了手机端。无需任何复杂的安装和配置过程，软件装好以后即会自动配置一个基本的运行环境，用以执行一些常见的 Linux 命令。最为关键的是，它还内置了功能健全的包管理工具，可以使用类似于 Ubuntu 系统的 apt （或 pkg）命令安装额外的软件包。 之所以称它为“模拟器”而非“虚拟机”，是因为它并非像 PC 端的 VirtualBox 等虚拟机软件那样，在宿主机中虚拟出一个完全独立且完整的系统环境，而是类似于 Mingw 等软件，只是提供一个接口，以安装和运行面向新环境交叉编译后的程序。 也可以将此时的手机看作是安装了 Linux 系统的树莓派，可以像 PC 端系统那样运行各种类型的软件，只不过这些软件都是针对特定的 CPU 架构和硬件设备编译过的（交叉编译或者在树莓派系统中本地编译）。需要注意的是，由于移动端和 PC 端硬件设备的巨大差异，加上 Android 内核和操作系统的限制，能够直接运行的程序毕竟是少数。不过我刚刚算了一下，实际上可直接安装运行的软件足足有 910 个！ 二、软件包前面提到的可供安装的近一千个（算上为数众多的基础工具、库文件和开发版软件包）程序和软件，数量虽然远不及桌面系统，面对日常使用、学习任务甚至很多高阶应用也已经算得上绰绰有余了。举个例子来说，Termux 是可以直接安装配置 Python 编程环境的。想想 Python 社区里浩如烟海的第三方库，甚至还可以根据特定的需求自行编写程序源代码。这里面包含着无限的可能性。 当然这也只是 Python 罢了，那么 Perl、Ruby、Nodejs、Lua、C/C++、Golang、Rust……我不会拿它去对标电脑上完备的系统环境，单说这种似乎无限的可能性，就已经很值得玩味了。 这里简单的列举下我所熟悉的部分软件： 基础工具：apt、bash、busybox、dpkg、git、htop、make、zsh …… 编程语言：binutils、clang、dart、erlang、golang、lua、nodejs、perl、php、python、ruby、rust …… 服务器软件：apache2、lighttpd、nginx、openssh …… 数据库软件：mariadb、memcached、mosquitto、postgresql、redis、sqlite …… 文本工具和编辑器：emacs、gawk、nano、sed、vim …… 媒体工具：ffmpeg、imagemagick、mpv、sox …… 网络工具：curl、httping、nmap、wget …… 游戏和娱乐：bastet、cmatrix、cowsay、fortune、moon-buggy、nsnake、sl …… 三、有趣的 Terminal 小命令就先不说具体的环境搭建的步骤了，包含的东西很多，实际上跟电脑端的操作并没有太大的区别。就简单列举一些我个人非常喜欢的好玩儿的小命令吧。 fortune：输出一段格言警句、名著节选或者小笑话等 cowsay：将输出的文字内容包含在由 ASCII 字符组成的动物形象的气泡内 lolcat：将苍白的输出文字变成绚丽的彩虹色 安装方法： fortune：$ apt install fortune cowsay：$ apt install cowsay 或者 $ gem install cowsay lolcat：$ gem install lolcat 其中 apt 版本的 cowsay 依赖 Perl ，安装包整个算起来有点大。所以我比较倾向于使用 gem 命令安装，即作为 Ruby 的第三方库。当然为了使用 gem 命令是要先安装好 Ruby 的：$ apt install ruby 效果截图： 虽然名字叫 cowsay ，但它所包含的动物形象事实上不只“牛”这一种。可以使用 cowsay -l 命令列出所有可供选择的动物形象，并通过 cowsay -f animal_name 手动指定另一种动物。 另外，其实 cowsay 的每个动物形象都是由对应的 cow 文件（基本就是 ASCII Art 形式的文本文件）定义的，可以自己扩充，篇幅有限不赘述。类似的小玩意儿还有 sl（突突的小火车）、cmatrix（全屏滚动乱码），试试就知道了。 配置 ssh 服务前面的截图，估计已经暴露了。。。我是在电脑上截的图，但程序确实是在手机上运行的。只是在手机端 Termux 上安装了 SSH 服务，远程登录而已。步骤也非常简单： 软件安装：$ apt install openssh 设置远程登录密码：$ passwd 电脑端登录：$ ssh phone_ip -p 8022 电脑上的 ssh 客户端可自行选择，尤其要注意，这里 SSH 服务监听的端口是 8022 。呃，差点忘记了。远程连接之前，先在手机端运行下 sshd 命令启动 SSH 服务。。。 四、高端的命令行游戏moon-buggymoon-buggy 是一个非常“酷炫”的命令行版本的跑酷游戏。虽说游戏界面完全由 ASCII 字符构成，它仍然具备了一个跑酷游戏必需的所有的基本要素。玩下就懂了，蛮神奇的。 玩儿到后面貌似还有迎面飞来的障碍物，还可以发射武器弹药？记不太清楚了。。。 nsnake嗯，不多说了，看名字就知道，贪吃蛇。。。初始的移动速度有点慢，建议在游戏选项里面改一下。 bastet就是大名鼎鼎的俄罗斯方块啦。看图： 五、oh-my-zsh手机端输入命令总觉得有点别扭，可能还是不习惯吧。这时候有个 oh-my-zsh 就显得很有必要了。反正我个人觉得挺好用的，尤其搭配上 zsh-completions、zsh-autosuggestions、zsh-syntax-highlighting 等插件。可以对命令行中输入的命令进行语法高亮、自动补全等，极大地提高了输入效率。 软件安装 oh-my-zsh 12$ apt install zsh curl$ sh -c &quot;$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&quot; zsh-autosuggestions$ git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions zsh-completions$ git clone https://github.com/zsh-users/zsh-completions ~/.oh-my-zsh/custom/plugins/zsh-completions zsh-syntax-highlighting$ git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting 软件配置：编辑 ~/.zshrc 文件，将上述插件添加到 plugins 项后面： PS：Termux 貌似是没有默认 SHELL 的配置的，所以安装好 oh-my-zsh 以后，打开软件还是直接进入 Bash 界面。我没有特别去找配置文件的位置，而是用了另外一种方案，，，手动输入 zsh 命令进入，或者，在 ~/.bashrc 文件中加入 zsh 一行内容。。。 六、访问手机文件及 Termux-Api根据默认的 Android 系统的权限设定，Termux 是无法访问手机存储的。当然可以使用命令进行修改。只需要输入 termux-setup-storage 命令，即会弹出授权窗口，允许即可。该命令会在用户主目录下生成 storage 文件夹，里面即包含了到系统主要资源（如手机内存、外置存储卡、Downloads 文件夹、照片等）的链接。 Termux-Api 是 Termux 软件的一个插件，需要安装额外的 APK 包。并且命令行中也需要使用 $ apt install termux-api 命令安装具体的工具。它提供了一种以 API 的形式直接访问 Android 系统硬件和资源（如相机、电池、WiFi、短信、通讯录、指纹、GPS等）的途径。 如获取电池状态和 WiFi 连接信息： 这个感觉可以深挖，用好了可以达到曾经的安卓神器 Tasker 的效果。 今天也不早了，，，就先这样吧。熬，附个软件链接吧。。Termux and Termux-Api 提取码：i37yBy the way，录了段蛮简陋的视频演示，额，第一次剪。。。 参考资料Termux Wiki]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Admin</tag>
        <tag>Tools</tag>
        <tag>Android</tag>
        <tag>Software</tag>
        <tag>Fun</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python Tricks —— 使用 keyboard 录制键盘事件]]></title>
    <url>%2F2019%2F05%2F11%2Fpython-capture-keyboard-events%2F</url>
    <content type="text"><![CDATA[之前在某本书上看到一个程序，可以通过 Python 记录下全局范围内的键盘事件，使用的是 ctypes 库。后来几经尝试，始终不能成功运行。原来它只支持 Python2 和 32 位的 Windows 系统。。。Excuse me？于是在网上查找可行的替代方案，比如 pyHook 。呃，不合胃口。安装比较繁琐（有依赖库且不能通过 pip 命令安装），只支持 Windows 系统，况且又是十年前就没再更新的项目。。。看了下函数调用也算不上简洁直观。 后来又多番搜索，终于找到了一个名为 keyboard 的 Python 库，可以绑定全局事件、录制及模拟键盘输入、设置热键等。尤其是安装和使用足够简单，比较合我的心意（毕竟 Github 上将近 1.5K 的小星星）。 一、特性 全局范围内的键盘事件绑定。即程序可以后台运行，捕捉其他软件下的按键动作。 跨平台，支持 Windows 、Linux 以及 MacOS 系统。支持 Python2 和 Python3 。 纯 Python 代码，无需编译 C 语言模块。无依赖库，安装简单（只是复制文件就可以）。 通过独立的线程捕捉事件，不阻塞主程序的运行。 很详细的文档，参见项目主页的 README 。 其实我真的有点感觉，这才是我心目中比较“现代”的工具。 二、录制及模拟按键动作就像前面提到的，安装 keyboard 的流程非常简单，无需考虑任何兼容性或者依赖问题，只需要一条简短的命令：$ pip install keyboard 可以使用下面的代码录制 10 秒钟的键盘事件，并将其回放一遍（即重复按下之前操作的按键）：1234567import keyboardimport timekeyboard.start_recording()time.sleep(10)events = keyboard.stop_recording()keyboard.replay(events) 可以使用如下代码制作一个简单的“键盘录制器”（打印输出全局范围内的按键动作，并将按键顺序保存在文本文件中）：1234567891011import keyboarddef print_pressed_keys(e): line = &apos;, &apos;.join(str(code) for code in keyboard._pressed_events) print(line) with open(&apos;keylogger.txt&apos;, &apos;a+&apos;) as f: f.write(line + &apos;\n&apos;)keyboard.hook(print_pressed_keys)keyboard.wait() PS：上述代码中的 code 并不是对应按键的 ASCII 码，而是根据键盘布局为按键指定的数值（如 a 键为 30，b 键为 42 等等），可以通过自行测试确认具体的对应关系。如同时按下两个或多个按键，则上述程序会以 code, code... 的形式输出。 三、热键捕获及绑定可以使用如下代码录制热键并为该热键绑定上特定的触发事件：1234567891011import keyboardprint(&apos;Press and release your desired hotkey: &apos;)hotkey = keyboard.read_hotkey()print(&apos;Hotkey selected: &apos;, hotkey)def on_triggered(): print(&quot;Triggered!&quot;)keyboard.add_hotkey(hotkey, on_triggered)print(&quot;Press ESC to stop.&quot;) 其他的使用方式就不再一一列举了，可以参考 keyboard 项目的 Github 主页。几种常见的使用示例也已经包含在项目代码的 examples 目录下。 参考keyboard]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Admin</tag>
        <tag>Tools</tag>
        <tag>Security</tag>
        <tag>Tricks</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ImageMagick 图片处理常用实例简介]]></title>
    <url>%2F2019%2F04%2F11%2Fexamples-about-processing-images-by-imagemagick%2F</url>
    <content type="text"><![CDATA[ImageMagick 是一整套用于图像处理的跨平台的命令行工具，大部分 Linux 发行版都可以直接通过包管理器安装（如 Ubuntu 系统：sudo apt-get install imagemagick）。其他平台也可以从官网下载对应的编译好的程序。通过命令行，ImageMagick 可以很高效的对图片进行编辑、转换和创作，也支持批量处理多张图片，或者内嵌到 Bash 脚本中。这里简单介绍下 ImageMagick 常见的几种用法。 格式转换ImageMagick 提供了 convert 命令用于接收图片文件并对其进行特定的操作后输出。其中最基本的用法即改变图片的格式。 如将 PNG 格式的图片转为 JPEG 格式：$ convert image.png image.jpg 对于 JPEG 图片，在转换时还可以指定压缩等级，如：$ convert image.png -quality 95 image.jpg 其中压缩等级（-quality）的值为 1-100，默认使用输入图片的压缩等级。如该值为空，则压缩等级默认为 92 。 改变图片大小convert 命令还可以用来改变图片的大小。如下面的命令可以将原图片转成大小为 200x100 像素的图片：$ convert image.png -resize 200x100 out.png 需要注意的是，在上面的命令中，ImageMagick 会优先保持原图片的比例（否则图片会发生一定程度的变形）。这样的结果是，改变后的图片可以正好放进一个 200x100 大小的区域，但图片本身并不一定是精确的 200x100 像素。 如果就是需要将原图片转换为特定大小，而不用考虑形变的影响。可以使用如下命令：$ convert image.png -resize 200x100! out.png 当然更多的时候，指定输出图片的大小时并非一定需要“宽x高”这样的形式，其实只需要指定宽或者高中的一项即可。如指定输出图片的宽度：$ convert image.png -resize 200 out.png 或者指定输出图片的高度：$ convert image.png -resize x100 out.png 旋转与翻转将原图片旋转 90° 后输出：$ convert image.jpg -rotate 90 image-rotated.jpg 指定的角度为正时即顺时针旋转图片，为负时逆时针旋转。 左右翻转：$ convert image.png -flop out.png上下翻转：$ convert image.png -flip out.png PS：包括前面的几种情况在内，如果输出图片的文件名和原图片相同，则改变后的图片会直接覆盖掉原图片。 裁剪与缩放convert 命令支持等比例缩放图片，如将图片缩小为原来的一半：$ convert image.png -scale 50% out.png 同时 convert 也可以对图片进行裁剪，包括自动裁剪（剔除图片周围空白的部分或边框等）和自定义范围的裁剪。 自动裁剪：$ convert image.png -trim out.png 自定义裁剪：$ convert image.jpg -crop 600x600+240+240 out.jpg 其中 -crop 的参数为 宽x高+横坐标偏移量+纵坐标偏移量 的形式，即宽和高用来定义裁剪的矩形区域的范围，横纵偏移量用来指定裁剪区域的相对位置（都为 0 时表示从最左上角开始）。 需要注意的是，当用 -crop 选项裁剪 PNG 和 GIF 格式的图片时（这两种格式的图片包含“虚拟画布”），并不是以画面的实际像素为基准，而是需要参考“画布”的大小和位置，所以有时候并不会达到预期的效果。详细介绍可参考官方文档 Cutting and Bordering 。 shave裁剪图片有时候可以采取相反的思路，即剔除图片中不需要的部分：$ convert image.png -shave 100x50 out.png将输入图片的左右两边剔除 100 像素，上下两边剔除 50 像素，获取剩余的部分并输出。 色彩、亮度与饱和度convert 命令可以通过 -modulate 选项调整图片的色彩、亮度和饱和度。如：$ convert image.png -modulate 150,100,100 out.png 上述命令会将原图片的亮度增大为原来的 150% 。其中 150,100,100 三个数值分别表示亮度、饱和度和色相。100 为基准值，即大于 100 表示增强某种属性，小于 100 表示减弱某种属性。 透明度、色彩与位深度 将透明（alpha）通道替换为纯黑色：$ convert image.png -flatten out.png 将原彩色图片转为灰度模式：$ convert image.png -type Grayscale out.png 降低图片的位深度（bits per pixel）：$ convert image.png -depth 8 out.png 减少图片色彩：$ convert image.png -dither -colors 256 out.png PS：dither 会增加像素点，如需要在减少色彩的同时不应用 dither 效果，将命令中的 -dither 替换为 +dither 。 锐化与虚化锐化$ convert image.png -sharpen 2 out.png 模糊$ convert image.png -blur 1 out.png 添加文字和边框添加水印$ convert image.jpg -fill red -draw &quot;text 20 20 &#39;© 2019 example.com&#39;&quot; out.jpg 可以自行定义添加文字的位置（默认为左上角）和字体类型：$ convert image.jpg -fill red -gravity SouthEast -font arial -draw &quot;text 20 20 &#39;© 2019 example.com&#39;&quot; out.jpg 添加边框$ convert image.png -bordercolor blue -border 50 out.png其中 -bordercolor 用于指定边框颜色，-border 用于指定边框宽度，可以为百分比。 组合叠加组合多张图片（垂直方向）$ convert x1.png x2.png x3.png -append out.png 组合多张图片（水平方向）$ convert x1.png x2.png x3.png +append out.png 叠加图片$ composite -gravity center img1.png img2.png out.png将 img1.png 叠加到 img2.png 上并作为 out.png 输出（方位为正中间) 应用效果ImageMagick 可以对图片应用多种样式的特效。如 “charcoal” 效果：$ convert image.png -charcoal 2 out.png其中 -charcoal 后面的数字 2 用于指定该效果的强度。 “implode” 效果：$ convert image.png -implode 1 out.png 结合多种操作前面提到的多种处理方式实际上可以任意组合使用，使得只用一条命令即可以同时完成多种操作。如：$ convert image.png -resize 400x400 -rotate 180 -charcoal 4 -quality 95 out.jpg 批量处理借助 Bash 脚本（Linux 系统）的强大功能，ImageMagick 可以很方便的批量处理多张图片。如下面的命令可以查找当前目录下所有的 PNG 图片，将它们每一张都旋转 90°，再将原文件名添加 “rotated-” 前缀后保存：$ for file in *.png; do convert $file -rotate 90 rotated-$file; done Windows 系统上是没有原生的 Bash Shell 的，但是可以下载安装某些软件以支持 Bash 环境，比如 Git for Windows。其实使用 Windows 系统自带的 PowerShell 也可以完成同样的批量操作：PS &gt; dir *.png | foreach { convert $_ -rotate 90 rotated-$($_.basename).png } 有兴趣的话，可以多玩几下。 GIF 动图制作可以借助 convert 命令将多张图片组合为一张重复播放的 GIF 动图：$ convert -delay 20 -loop 0 *.png out.gif 其中 -delay 选项用于指定图片切换的时间间隔，单位为毫秒。 参考文章ImageMagick TutorialImageMagick basics 拓展阅读Examples of ImageMagick Usage（很详细）]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Tools</tag>
        <tag>Shell</tag>
        <tag>Tricks</tag>
        <tag>Image</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python Tricks —— 简单的 HTTP 和 FTP 服务]]></title>
    <url>%2F2019%2F04%2F07%2Fpython-simple-http-and-ftp-service%2F</url>
    <content type="text"><![CDATA[之前有位同事，需要在两台电脑间传输一个很大的文件，前提是只开放了 80 端口。我以为他会配个 Apache 之类的 HTTP 服务或者 WebDAV 什么的。他只用了一条命令：python -m http.server 80。后来我想也是，有时候面对问题，一个很简单的且还算完美的方案，即便不是通用的或者完备的，就解决问题而言，未尝不是一个好的选择。 http.serverhttp.server) 是 Python3 的一个内置模块，源代码在 Lib/http/server.py 中，它定义了用来实现 HTTP 服务的类。 其中的 SimpleHTTPRequestHandler 类可以用来在当前目录下创建一个基本的 HTTP 服务：12345678910import http.serverimport socketserverPORT = 8000Handler = http.server.SimpleHTTPRequestHandlerwith socketserver.TCPServer((&quot;&quot;, PORT), Handler) as httpd: print(&quot;serving at port&quot;, PORT) httpd.serve_forever() 运行效果如下：12345$ python test.pyserving at port 8000127.0.0.1 - - [06/Apr/2019 22:55:26] &quot;GET / HTTP/1.1&quot; 200 -127.0.0.1 - - [06/Apr/2019 22:55:41] &quot;GET /pyqt/ HTTP/1.1&quot; 200 -127.0.0.1 - - [06/Apr/2019 22:55:56] &quot;GET /test.py HTTP/1.1&quot; 200 - 因为当前目录下没有 index.html 文件，所以显示的是类似 FTP 站点上的那种文件列表。 当然，http.server 也可以通过 Python 的 -m 选项在命令行中直接调用：$ python -m http.server 默认会在 8000 端口打开 HTTP 服务，也可以手动指定端口：$ python -m http.server 8080 同时，该服务会绑定本机的所有网络接口（0.0.0.0），也可以手动指定：$ python -m http.server 8000 -b 127.0.0.1 其他支持的命令行选项可以参考帮助信息：123456789101112131415$ python -m http.server -husage: server.py [-h] [--cgi] [--bind ADDRESS] [--directory DIRECTORY] [port]positional arguments: port Specify alternate port [default: 8000]optional arguments: -h, --help show this help message and exit --cgi Run as CGI Server --bind ADDRESS, -b ADDRESS Specify alternate bind address [default: all interfaces] --directory DIRECTORY, -d DIRECTORY Specify alternative directory [default:current directory] pyftpdlibpyftpdlib 是一个非常高效的异步的 FTP 库，可以为 Python 编写 FTP 服务提供高级的可移植的编程接口。pyftpdlib 是 Python 的第三方库，需要使用包管理器安装：pip install pyftpdlib 安装成功以后，一个最基本的 FTP 服务器可以通过以下代码实现：12345678910111213141516171819202122232425262728293031323334353637383940import osfrom pyftpdlib.authorizers import DummyAuthorizerfrom pyftpdlib.handlers import FTPHandlerfrom pyftpdlib.servers import FTPServerdef main(): # 初始化验证器 authorizer = DummyAuthorizer() # 创建有读写权限的用户和只读权限的匿名用户 authorizer.add_user(&apos;user&apos;, &apos;12345&apos;, &apos;.&apos;, perm=&apos;elradfmwMT&apos;) authorizer.add_anonymous(os.getcwd()) # 实例化 FTPHandler 类 handler = FTPHandler handler.authorizer = authorizer # 自定义提示信息 handler.banner = &quot;pyftpdlib based ftpd ready.&quot; # Specify a masquerade address and the range of ports to use for # passive connections. Decomment in case you&apos;re behind a NAT. #handler.masquerade_address = &apos;151.25.42.11&apos; #handler.passive_ports = range(60000, 65535) # FTP 服务监听于 0.0.0.0:2121 address = (&apos;&apos;, 2121) server = FTPServer(address, handler) # 连接限制 server.max_cons = 256 server.max_cons_per_ip = 5 # 开启 FTP 服务 server.serve_forever()if __name__ == &apos;__main__&apos;: main() 效果如下：123456789$ python ftp.py[I 2019-04-07 15:08:37] &gt;&gt;&gt; starting FTP server on :::2121, pid=9952 &lt;&lt;&lt;[I 2019-04-07 15:08:37] concurrency model: async[I 2019-04-07 15:08:37] masquerade (NAT) address: None[I 2019-04-07 15:08:37] passive ports: None[I 2019-04-07 15:08:44] ::1:63265-[] FTP session opened (connect)[I 2019-04-07 15:08:44] ::1:63265-[anonymous] USER &apos;anonymous&apos; logged in.[I 2019-04-07 15:08:44] ::1:63265-[anonymous] CWD D:\Program\python 250[I 2019-04-07 15:08:44] ::1:63265-[anonymous] FTP session closed (disconnect). pyftpdlib 从 0.6.0 版本开始是完全支持 FTPS (FTP over TLS/SSL) 的，需要提前安装好 PyOpenSSL 模块：pip install pyopenssl 示例代码如下：12345678910111213141516171819202122232425&quot;&quot;&quot;An RFC-4217 asynchronous FTPS server supporting both SSL and TLS.Requires PyOpenSSL module (http://pypi.python.org/pypi/pyOpenSSL).&quot;&quot;&quot;from pyftpdlib.servers import FTPServerfrom pyftpdlib.authorizers import DummyAuthorizerfrom pyftpdlib.handlers import TLS_FTPHandlerdef main(): authorizer = DummyAuthorizer() authorizer.add_user(&apos;user&apos;, &apos;12345&apos;, &apos;.&apos;, perm=&apos;elradfmwMT&apos;) authorizer.add_anonymous(&apos;.&apos;) handler = TLS_FTPHandler handler.certfile = &apos;keycert.pem&apos; handler.authorizer = authorizer # requires SSL for both control and data channel #handler.tls_control_required = True #handler.tls_data_required = True server = FTPServer((&apos;&apos;, 21), handler) server.serve_forever()if __name__ == &apos;__main__&apos;: main() TLS_FTPHandler 类需要至少一个 certfile 和一个可选的 keyfile。可以参考 Apache FAQs 自行生成证书文件，也可以直接下载 pyftpdlib 提供的示例文件 keycert.pem。 FTP 客户端可以使用 WinSCP，截图如下： 运行效果：12345678$ python ftps.py[I 2019-04-07 17:20:24] &gt;&gt;&gt; starting FTP+SSL server on :::21, pid=5028 &lt;&lt;&lt;[I 2019-04-07 17:20:24] concurrency model: async[I 2019-04-07 17:20:24] masquerade (NAT) address: None[I 2019-04-07 17:20:24] passive ports: None[I 2019-04-07 17:20:36] ::1:64934-[] FTP session opened (connect)[I 2019-04-07 17:20:36] ::1:64934-[user] USER &apos;user&apos; logged in.[I 2019-04-07 17:20:36] ::1:64934-[user] CWD D:\Program\python 250 同 http.server 类似，pyftpdlib 也可以在命令行中通过 python -m 直接调用：12345$ python -m pyftpdlib[I 2019-04-07 17:27:51] &gt;&gt;&gt; starting FTP server on 0.0.0.0:2121, pid=1100 &lt;&lt;&lt;[I 2019-04-07 17:27:51] concurrency model: async[I 2019-04-07 17:27:51] masquerade (NAT) address: None[I 2019-04-07 17:27:51] passive ports: None 匿名用户有写权限：$ python -m pyftpdlib -w 设置特定的监听地址、端口号和 home 目录：$ python -m pyftpdlib -i localhost -p 8021 -d /home/someone 设置登录用户和密码（匿名用户则会被禁用）$ python -m pyftpdlib -u username -P password 获取帮助信息：$ python -m pyftpdlib -h 拓展资料http.server 源码http.server 文档pyftpdlib 文档]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Admin</tag>
        <tag>Tools</tag>
        <tag>Tricks</tag>
        <tag>Python</tag>
        <tag>Programming</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows PowerShell 学习笔记其三（字符串与数组）]]></title>
    <url>%2F2019%2F03%2F10%2Fwindows-powershell-cookbook-3%2F</url>
    <content type="text"><![CDATA[字符串介绍两种类型PowerShell 下的字符串主要有两种类型：非扩展（nonexpanding）和扩展（expanding）型。这里的“扩展”和“非扩展”指的是对字符串中包含的变量和转义符是否进行解析。扩展型字符串需要用双引号括起来，而非扩展型字符串使用单引号。 实际效果如下：123456PS &gt; $username = &quot;starky&quot;PS &gt; echo &quot;hi, my name is $username. `nAnother line&quot;hi, my name is starky.Another linePS &gt; echo &apos;hi, my name is $username. `nwithin the same line&apos;hi, my name is $username. `nwithin the same line 在上面的例子中，双引号包裹的字符串对变量 $username 和转义符 `n（等同于 bash 里的 \n）进行了解析，自动替换为变量和转义符代表的内容。而单引号包裹的字符串则只是将美元符、反引号等符号视为普通的字符，不做任何处理直接打印输出。 PS：PowerShell 里的转义符是反引号 ` 而不是 bash 里的反斜杠 多行格式化文本PowerShell 支持创建 here string，即多行格式化文本，类似 Python 里的三引号。只需要将多行文本包裹在成对的 @&quot; 和 &quot;@ 符号中即可。示例如下：123456789101112PS &gt; $mystring = @&quot;&gt;&gt; This is the first line&gt;&gt; of a very long string. A &quot;here string&quot;&gt;&gt; lets you create blocks of text&gt;&gt; that span several lines.&gt;&gt; &quot;@&gt;&gt;PS &gt; $mystringThis is the first lineof a very long string. A &quot;here string&quot;lets you create blocks of textthat span several lines. 字符串中的动态内容前面有提到过，由双引号包裹的字符串为“扩展”型字符串，可以对其中包含的变量等自动进行替换。其实也可以在字符串中，以 $(expression) 的格式插入表达式或一系列 PowerShell 命令，示例如下：12PS &gt; &quot;1 + 2 equals $(1 + 2)&quot;1 + 2 equals 3 还可以使用 PowerShell 的字符串格式化操作符在字符串中插入动态内容，它遵循和 .NET 一样的字符串格式化规则。示例如下：12345PS &gt; $header = &quot;Report for Today&quot;PS &gt; $mystring = &quot;&#123;0&#125;`n&#123;1&#125;&quot; -f $header,(&apos;-&apos; * $header.Length)PS &gt; $mystringReport for Today---------------- 示例 2：123456PS &gt; $number1 = 10PS &gt; $number2 = 32PS &gt; &quot;$number2 divided by $number1 is $($number2 / $number1)&quot;32 divided by 10 is 3.2PS &gt; &quot;&#123;0&#125; divided by &#123;1&#125; is &#123;2&#125;&quot; -f $number2, $number1, ($number2 / $number1)32 divided by 10 is 3.2 字符串操作检索与替换PowerShell 提供了多种用于字符串搜索和匹配的方法。 -like-like 操作符用于判断字符串是否匹配特定的模式，该模式中可以包含通配符： 12PS &gt; &quot;Hello World&quot; -like &quot;*llo W*&quot;True -match-match 操作符用于判断字符串是否匹配特定的正则表达式： 12PS &gt; &quot;Hello World&quot; -match &apos;.*l[l-z]o W.*$&apos;True Contains()Contains() 方法用于判断一个字符串是否包含了另一个较短的字符串： 12PS &gt; &quot;Hello World&quot;.Contains(&quot;World&quot;)True IndexOf()IndexOf() 方法可以用来获取一个字符串在另一个字符串中的位置索引： 12PS &gt; &quot;Hello World&quot;.IndexOf(&quot;World&quot;)6 Replace()Replace() 方法用于将字符串中的一部分替换为另一个字符串： 12PS &gt; &quot;Hello World&quot;.Replace(&quot;World&quot;, &quot;PowerShell&quot;)Hello PowerShell 另外，使用 PowerShell 的 -replace 操作符搭配上正则表达式，可以完成更加高级的替换任务：12PS &gt; &quot;Hello World&quot; -replace &apos;(.*) (.*)&apos;, &apos;$2 $1&apos;World Hello 分割、合并、修剪 -split-split 操作符可以用来将指定字符串分割成一系列的字符片段： 12345678PS &gt; &quot;a-b-c-d-e-f&quot; -split &quot;-c-&quot;a-bd-e-fPS &gt; &quot;a-b-c-d-e-f&quot; -split &quot;b|[d-e]&quot;a--c---f -join-join 操作符用于将多个字符片段合并为一个完整的字符串 123456PS &gt; $list = &quot;Hello&quot;,&quot;World&quot;PS &gt; $listHelloWorldPS &gt; $list -join &quot;, &quot;Hello, World Trim()Trim() 方法用于去除字符串两边的空白字符： 123PS &gt; $text = &quot; `t Test String`t `t&quot;PS &gt; &quot;|&quot; + $text.Trim() + &quot;|&quot;|Test String| 列表、数组与哈希表创建数组和列表创建和初始化一个数组在 PowerShell 里非常简单，用很常见的赋值语句即可：12345PS &gt; $myArray = 1,2,&quot;HelloWorld&quot;PS &gt; $myArray12HelloWorld 用上述方法创建的数组是没有数据类型限制的，即该数组在初始化时可以包含任何类型的数据。 创建指定长度的数组，可以使用 New-Object 命令：1234567891011121314PS &gt; $myArray = New-Object &quot;int32[]&quot; 4PS &gt; $myArray[3] = 3PS &gt; $myArray0003PS &gt; $myArray[4] = 4索引超出了数组界限。所在位置 行:1 字符: 1+ $myArray[4] = 4+ ~~~~~~~~~~~~~~~ + CategoryInfo : OperationStopped: (:) [], IndexOutOfRangeException + FullyQualifiedErrorId : System.IndexOutOfRangeException 创建指定类型的数组，可以使用 .NET 框架提供的强类型的集合：12345678910PS &gt; $list = New-Object Collections.Generic.list[Int]PS &gt; $list.add(10)PS &gt; $list.add(&quot;Hello&quot;)无法将“Add”的参数“item”(其值为“Hello”)转换为类型“System.Int32”:“无法将值“Hello”转换为类型“System.Int32”。错误:“输入字符串的格式不正确。””所在位置 行:1 字符: 1+ $list.add(&quot;Hello&quot;)+ ~~~~~~~~~~~~~~~~~~ + CategoryInfo : NotSpecified: (:) [], MethodException + FullyQualifiedErrorId : MethodArgumentConversionInvalidCastArgument 多维数组PowerShell 可以使用 @() 形式的语法创建多维数组：12345678PS &gt; $jagged = @(&gt;&gt; (1,2,3,4),&gt;&gt; (5,6,7,8)&gt;&gt; )PS &gt; $jagged[0][0]1PS &gt; $jagged[1][3]8 也可以使用下面的方式：123456789101112PS &gt; $multidimensional = New-Object &quot;int32[,]&quot; 2,4PS &gt; $multidimensional[0,0] = 1PS &gt; $multidimensional[1,3] = 8PS &gt; $multidimensional10000008 操作数组中的元素可以通过位置索引（从 0 开始）获取数组中的某个元素：12345PS &gt; $myArray = 1,2,&quot;Hello World&quot;PS &gt; $myArray[0]1PS &gt; $myArray[2]Hello World 当然也可以对数组进行分片操作，即获取数组中的某“一段”元素：1234567PS &gt; $myArray12Hello WorldPS &gt; $myArray[1..2]2Hello World 在对数组进行分片时，PowerShell 提供了如下的一个小技巧，可以对输出后的元素进行灵活的排序：12345678PS &gt; $myArray = 0,1,2,3,4,5PS &gt; $myArray[3..5 + 2 + 0..1]345201 Foreach-Object如果需要挨个访问数组中的每一个元素，可以使用 Foreach-Object 命令：12345PS &gt; $myArray = 1,2,3PS &gt; $sum = 0PS &gt; $myArray | Foreach-Object &#123; $sum += $_ &#125;PS &gt; $sum6 当然也可以稍微复杂点，通过位置索引和 for 循环访问数组的每一个元素：1234567PS &gt; $myArray = 1,2,3PS &gt; $sum = 0PS &gt; for($i = 0; $i -lt $myArray.Count; $i++) &#123;&gt;&gt; $sum += $myArray[$i]&gt;&gt; &#125;PS &gt; $sum6 排序使用 Sort-Object 命令可以对数组元素进行排序后再输出：123456789101112131415161718192021PS &gt; dir 目录: D:\Program\pythonMode LastWriteTime Length Name---- ------------- ------ ----d----- 2019/2/28 22:43 pyqtd----- 2019/3/3 0:17 speech-a---- 2019/3/6 22:13 26434 test.html-a---- 2019/3/6 22:00 174 test.mdPS &gt; Get-ChildItem | Sort-Object -Descending Length | select Name,LengthName Length---- ------test.html 26434test.md 174pyqtspeech 使用 Get-ChildItem 获取当前目录下所有文件的列表，再把该列表传递给 Sort-Object ，根据文件占用空间的大小（Length）逆序输出 Name 和 Length 项。 在使用 Sort-Object 对元素进行排序时，可以自由选择排序依据的条件。如根据首字母对字符串进行排序：12345PS &gt; &quot;Hello&quot;,&quot;World&quot;,&quot;And&quot;,&quot;Shell&quot; | Sort-ObjectAndHelloShellWorld 根据次字母对字符串进行排序：12345PS &gt; &quot;Hello&quot;,&quot;World&quot;,&quot;And&quot;,&quot;Shell&quot; | Sort-Object &#123; $_.Substring(1,1) &#125;HelloShellAndWorld 数组与运算符确定数组与元素的包含关系确定数组与元素的包含关系，可以使用 -contains 或者 -in 操作符：12345678PS &gt; &quot;Hello&quot;,&quot;World&quot; -contains &quot;Hello&quot;TruePS &gt; &quot;Hello&quot;,&quot;World&quot; -contains &quot;Shell&quot;FalsePS &gt; &quot;Hello&quot; -in &quot;Hello&quot;,&quot;World&quot;TruePS &gt; &quot;Shell&quot; -in &quot;Hello&quot;,&quot;World&quot;False 合并数组可以使用算术运算符 + 对数组进行合并操作：12345678910111213141516PS &gt; $firstArray = &quot;Element 1&quot;,&quot;Element 2&quot;,&quot;Element 3&quot;PS &gt; $secondArray = 1,2,3PS &gt; $firstArray + $secondArrayElement 1Element 2Element 3123PS &gt; $array = 1,2PS &gt; $array += 3,4PS &gt; $array1234 匹配数组中的元素可以使用 -eq、-match、-like 操作符对数组中的元素进行匹配：12345678910PS &gt; $array = &quot;Item 1&quot;,&quot;Item 2&quot;,&quot;Item 3&quot;,&quot;Item 1&quot;,&quot;Item 12&quot;PS &gt; $array -eq &quot;Item 1&quot;Item 1Item 1PS &gt; $array -like &quot;*1*&quot;Item 1Item 1Item 12PS &gt; $array -match &quot;Item ..&quot;Item 12 其中 -eq 表示完全匹配，-like 支持使用通配符，-match 支持正则表达式。 更复杂的匹配条件可以使用 Where-Object ：123PS &gt; $array = &quot;Item 1&quot;,&quot;Item 2&quot;,&quot;Item 3&quot;,&quot;Item 1&quot;,&quot;Item 12&quot;PS &gt; $array | Where-Object &#123; $_.Length -gt 6 &#125;Item 12 移除数组中的元素为了移除数组中符合特殊规则的元素，可以使用 -ne、-notlike、-notmatch 等比较操作符：12345678910111213PS &gt;$array = &quot;Item 1&quot;,&quot;Item 2&quot;,&quot;Item 3&quot;,&quot;Item 1&quot;,&quot;Item 12&quot;PS &gt;$array -ne &quot;Item 1&quot;Item 2Item 3Item 12PS &gt; $array -notlike &quot;*1*&quot;Item 2Item 3PS &gt; $array -notmatch &quot;Item ..&quot;Item 1Item 2Item 3Item 1 获取大于或小于特定值的元素-gt、-ge、-lt、-le 等比较操作符可以用来获取数组中大于或小于某个特定值的元素。 PS：其中 -gt 表示大于（great than），-ge 表示大于等于（great and equal），-lt 表示小于（less than），-le 表示小于等于（less and equal）。1234567PS &gt; $array = &quot;Item 1&quot;,&quot;Item 2&quot;,&quot;Item 3&quot;,&quot;Item 1&quot;,&quot;Item 12&quot;PS &gt; $array -ge &quot;Item 3&quot;Item 3PS &gt; $array -lt &quot;Item 2&quot;Item 1Item 1Item 12 ArrayList通过类似 $array = 1,2,3,4 这种赋值的方式创建的数组，其长度是固定的。可以通过位置索引访问其中的某个值，并对它重新赋值。但是不能直接添加或者删除数组中的元素：12345678910111213141516PS &gt; $array = 0,1,2,3PS &gt; $array[1]1PS &gt; $array[0]=1PS &gt; $array1123PS &gt; $array.Add(4)使用“1”个参数调用“Add”时发生异常:“集合的大小是固定的。”所在位置 行:1 字符: 1+ $array.add(4)+ ~~~~~~~~~~~~~ + CategoryInfo : NotSpecified: (:) [], MethodInvocationException + FullyQualifiedErrorId : NotSupportedException 如果需要在数组中添加或者删除元素，可以使用 +、-ne、-match、-gt 等比较操作符，获取数组中匹配某个条件的元素，并将它们赋值给新的变量，原数组中元素的值则不受影响：12345678910111213141516171819202122PS &gt; $original = 1,2,3,4PS &gt; $new1 = $original + 5PS &gt; $new112345PS &gt; $new2 = $original -ne 4PS &gt; $new2123PS &gt; $new3 = $original -gt 2PS &gt; $new334PS &gt; $original1234 在面对长度很大的数组时，上述的添加、移除、搜索等操作就会稍微显得效率较低。所以 PowerShell 提供了 ArrayList 数据类型，可以直接对数组本身进行添加、删除等操作：123456789101112131415PS &gt; $collection = New-Object System.Collections.ArrayListPS &gt; [void] $collection.Add(&quot;Hello&quot;)PS &gt; [void] $collection.AddRange((&quot;World&quot;,&quot;How&quot;,&quot;Are&quot;,&quot;You&quot;))PS &gt; $collectionHelloWorldHowAreYouPS &gt; $collection.RemoveAt(1)PS &gt; $collectionHelloHowAreYou [void] 可以省略操作执行后返回的状态值。 哈希表可以使用 @{} 形式的语法创建哈希表（或关联数组）。123456789PS &gt; $myHashtable = @&#123; Key1 = &quot;Value1&quot;; &quot;Key 2&quot; = 1,2,3 &#125;PS &gt; $myHashtable[&quot;New Item&quot;] = 5PS &gt; $myHashtableName Value---- -----Key 2 &#123;1, 2, 3&#125;Key1 Value1New Item 5 按哈希表的键或值排序1234567891011121314151617181920212223242526272829303132PS &gt; $myHashtable = @&#123;&#125;PS &gt; $myHashtable[&quot;Hello&quot;] = 3PS &gt; $myHashtable[&quot;Ali&quot;] = 2PS &gt; $myHashtable[&quot;Alien&quot;] = 4PS &gt; $myHashtable[&quot;Duck&quot;] = 1PS &gt; $myHashtableName Value---- -----Hello 3Duck 1Alien 4Ali 2PS &gt; $myHashtable.GetEnumerator() | Sort NameName Value---- -----Ali 2Alien 4Duck 1Hello 3PS &gt; $myHashtable.GetEnumerator() | Sort ValueName Value---- -----Duck 1Ali 2Hello 3Alien 4 参考书籍Windows PowerShell Cookbook, 3rd Edition]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>Admin</tag>
        <tag>Tools</tag>
        <tag>Shell</tag>
        <tag>Windows</tag>
        <tag>Program</tag>
        <tag>Script</tag>
        <tag>PowerShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[视频处理工具 FFmpeg 常用实例详解]]></title>
    <url>%2F2019%2F03%2F10%2Fffmpeg-user-manual-and-practical-examples%2F</url>
    <content type="text"><![CDATA[FFmpeg 是一个专业的多媒体框架，能够解码、编码、转码、复用、解复用、流式传输、过滤和播放几乎所有格式的媒体文件。其核心就是 FFmpeg 程序本身，是一个基于命令行的视频和音频处理工具，多用于视频转码、基础编辑（修剪和合并）、视频缩放、后期效果制作等场景。这里通过一些示例简单地介绍下 ffmpeg 命令的基本使用。 一、获取详细信息ffmpeg -i &lt;inputfile&gt; -hide_banner其中 -hide_banner 选项用于在输出文件的详细信息时省略 ffmpeg 的版本信息和编译选项等。12345678910111213141516171819202122232425262728$ ffmpeg -i bbb.mp4 -hide_bannerInput #0, mov,mp4,m4a,3gp,3g2,mj2, from &apos;bbb.mp4&apos;: Metadata: major_brand : isom minor_version : 1 compatible_brands: isomavc1 creation_time : 2013-12-17T16:40:26.000000Z title : Big Buck Bunny, Sunflower version artist : Blender Foundation 2008, Janus Bager Kristensen 2013 comment : Creative Commons Attribution 3.0 - http://bbb3d.renderfarming.net genre : Animation composer : Sacha Goedegebure Duration: 00:10:34.53, start: 0.000000, bitrate: 8487 kb/s Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 3840x2160 [SAR 1:1 DAR 16:9], 8002 kb/s, 60 fps, 60 tbr, 60k tbn, 120 tbc (default) Metadata: creation_time : 2013-12-17T16:40:26.000000Z handler_name : GPAC ISO Video Handler Stream #0:1(und): Audio: mp3 (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 160 kb/s (default) Metadata: creation_time : 2013-12-17T16:40:28.000000Z handler_name : GPAC ISO Audio Handler Stream #0:2(und): Audio: ac3 (ac-3 / 0x332D6361), 48000 Hz, 5.1(side), fltp, 320 kb/s (default) Metadata: creation_time : 2013-12-17T16:40:28.000000Z handler_name : GPAC ISO Audio Handler Side data: audio service type: mainAt least one output file must be specified 二、格式转换ffmpeg -i &lt;inputfile&gt; &lt;outputfile&gt; FFmpeg 是一个强大的音频和视频格式转换器，几乎支持当前所有常用的格式，如：$ ffmpeg -i input.avi output.mp4 或者经常需要用到的，将视频文件转为 GIF 动图：$ ffmpeg -i input.mp4 output.gif 如果在格式转换时需要保留源视频的质量，可以添加上 -qscale 0 选项（-qscale 的值越低，输出视频的质量越高）：$ ffmpeg -i input.webm -qscale 0 output.mp4 可以使用 -formats 选项列出 ffmpeg 命令支持的所有格式（很长很长的一个列表。。。）：123456789101112131415161718192021222324252627282930313233$ ffmpeg -formats -hide_bannerFile formats: D. = Demuxing supported .E = Muxing supported -- D 3dostr 3DO STR E 3g2 3GP2 (3GPP2 file format) E 3gp 3GP (3GPP file format) D 4xm 4X Technologies E a64 a64 - video for Commodore 64 D aa Audible AA format files D aac raw ADTS AAC (Advanced Audio Coding) DE ac3 raw AC-3 D acm Interplay ACM D act ACT Voice file format D adf Artworx Data Format D adp ADP D ads Sony PS2 ADS E adts ADTS AAC (Advanced Audio Coding) DE adx CRI ADX D aea MD STUDIO audio D afc AFC DE aiff Audio IFF D aix CRI AIX DE alaw PCM A-law D alias_pix Alias/Wavefront PIX image DE amr 3GPP AMR D amrnb raw AMR-NB D amrwb raw AMR-WB D anm Deluxe Paint Animation D apc CRYO APC D ape Monkey&apos;s Audio... 三、指定编码可以通过 -c 选项手动指定输出文件的编码，如：$ ffmpeg -i input.mp4 -c:v vp9 -c:a libvorbis output.mkv其中 -c:v 用于指定视频编码，-c:a 指定音频编码 PS：视频文件的后缀如 mp4、mkv、avi 等只是表示用来装载媒体流的“容器”类型，而编码时使用的编码方式则另需指定。当然很多时候 ffmpeg 会根据输出文件的后缀自行选择默认的编码方式，无需手动指定。 只改变视频或者音频流的编码可以在指定编码时，只改变视频或者音频编码中的一项，另一项则保持原来的格式：$ ffmpeg -i input.webm -c:v copy -c:a flac output.mkv-c:v copy 表示复制输入文件中的视频流到输出文件，不重新进行编码 只改变文件后缀即输入文件中的视频流和音频流同时复制到输出文件，只改变文件后缀：$ ffmpeg -i input.webm -c:av copy output.mkv 编码列表查看 FFmpeg 支持的所有音视频编码格式（又一个很长的列表。。。）：123456789101112131415161718192021222324252627$ ffmpeg -codecs -hide_bannerCodecs: D..... = Decoding supported .E.... = Encoding supported ..V... = Video codec ..A... = Audio codec ..S... = Subtitle codec ...I.. = Intra frame-only codec ....L. = Lossy compression .....S = Lossless compression ------- ... DEV.L. flv1 FLV / Sorenson Spark / Sorenson H.263 (Flash Video) (decoders: flv ) (encoders: flv ) D.V..S fmvc FM Screen Capture Codec D.VI.S fraps Fraps D.VI.S frwu Forward Uncompressed D.V.L. g2m Go2Meeting D.V.L. gdv Gremlin Digital Video DEV..S gif GIF (Graphics Interchange Format) DEV.L. h261 H.261 DEV.L. h263 H.263 / H.263-1996, H.263+ / H.263-1998 / H.263 version 2 D.V.L. h263i Intel H.263 DEV.L. h263p H.263+ / H.263-1998 / H.263 version 2 DEV.LS h264 H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10 (decoders: h264 h264_qsv h264_cuvid ) (encoders: libx264 libx264rgb h264_amf h264_nvenc h264_qsv nvenc nvenc_h264 ) DEVIL. hap Vidvox Hap DEV.L. hevc H.265 / HEVC (High Efficiency Video Coding) (decoders: hevc hevc_qsv hevc_cuvid ) (encoders: libx265 nvenc_hevc hevc_amf hevc_nvenc hevc_qsv )... 四、视频压缩编码与比特率有些时候，基于磁盘空间和网络传输的考虑，需要对视频文件进行压缩处理。其中一种方法就是改变视频的比特率。在某些情况下，比特率的适当缩减对视频的观看效果并不会产生太大的影响（人眼察觉的范围内）。当然编码的选择也会对输出文件的大小产生一定的影响，示例如下： $ ffmpeg -i input.webm -c:a copy -c:v vp9 -b:v 1M output.mkv-b:v 用于指定视频的比特率。 帧率另一种方式就是改变视频文件的帧率，也就是人们常常提到的FPS。 $ ffmpeg -i input.webm -c:a copy -c:v vp9 -r 30 output.mkv-r 30 选项用于指定输出视频的帧率为 30 FPS。 分辨率视频的分辨率也会影响文件的大小，可以使用 -s 选项指定输出文件的分辨率。当然，视频的画幅大小也会产生相应的变化： $ ffmpeg -i input.mkv -c:a copy -s hd720 output.mkv或$ ffmpeg -i input.mkv -c:a copy -s 1280x720 output.mkv 五、提取音频通过格式转换，FFmpeg 可以直接将视频文件转为音频文件，只需要指定输出文件的格式为 .mp3 或 .ogg 等。如：$ ffmpeg -i input.mp4 output.mp3 同时，也可以在转换时指定音频的格式选项：$ ffmpeg -i input.mp4 -vn -ar 44100 -ac 2 -ab 320 -f mp3 output.mp3 其中：-vn ：指定输出文件中禁用视频-ar ：指定输出文件中音频的采样率-ac：指定音频的通道数-ab：指定音频的比特率-f：指定输出文件的格式 六、常用实用命令集锦调整分辨率将某视频文件的分辨率改为 1280x720：$ ffmpeg -i input.mp4 -filter:v scale=1280:720 output.mp4或者：$ ffmpeg -i input.mp4 -s 1280x720 output.mp4 压缩视频文件$ ffmpeg -i input.mp4 -vf scale=1280:-1 -c:v libx264 -preset veryslow -crf 24 output.mp4 也可以添加如下选项同时对音频流进行压缩：-c:a aac -strict -2 -b:a 128k 移除音频$ ffmpeg -i input.mp4 -an output.mp4-an 选项表示在输出文件中禁用音频 提取图片$ ffmpeg -i input.mp4 -r 1 -f image2 image-%2d.png 其中各选项的含义：-r ：设置帧率，即每秒有多少帧画面被提取到图片中。默认为 25-f ：指定输出的格式。本例中为图片（image2）-image-%2d.png ：指定提取出的图片的命名方式。本例中最终的命名为 image-01.png、image-02.png 等。如使用 image-%3d.png ，则最终的命名为 image-001.png、imag-002.png 等 裁剪视频即截取指定范围内的视频画面，裁切掉多余的部分：$ ffmpeg -i input.mp4 -vf &quot;crop=w:h:x:y&quot; output.mp4 其中 crop=w:h:x:y 用于指定“裁剪框”的大小和位置。w 表示裁剪部分的宽度（默认为源视频的宽度 iw）；h 表示裁剪部分的高度（默认为源视频的高度 ih；x 表示 x 轴上裁剪的起始位置（最左边为 0，默认为源视频的中间位置）；y 表示 y 轴上裁剪的起始位置（最顶部为 0，默认为源视频的中间位置）。 改变视频比例视频比例即视频画幅的长宽比，也就是通常所说的 4:3 和 16:9 等。$ ffmpeg -i input.mp4 -aspect 16:9 output.mp4 设置音频封面即创建以一张静止的图片为画面的视频。 $ ffmpeg -loop 1 -i inputimage.jpg -i inputaudio.wav -c:v libx264 -tune stillimage -c:a aac -b:a 192k -shortest output.mp4其中的选项和参数可以根据需求自行修改和省略。 截取视频片段$ ffmpeg -i input.mp4 -ss 00:00:50 -codec copy -t 60 output.mp4截取视频中从第 50 秒开始，持续时间为一分钟的视频片段。 其中 -ss 用于指定视频片段的开始时间；-t 指定视频片段的持续时间，单位都为秒。 也可以使用如下方式：$ ffmpeg -i audio.mp3 -ss 00:01:54 -to 00:06:53 -c copy output.mp3 以上命令也适用于音频文件。 视频分割$ ffmpeg -i input.mp4 -t 00:00:30 -c copy part1.mp4 -ss 00:00:30 -codec copy part2.mp4将输入的视频文件分割为两段，第一段为从最开始到第 30 秒；第二段为第 30 秒到视频结束。 其中 -t 00:00:30 前面省略了 -ss 00:00:00；-ss 00:00:30 后面省略了 -t 剩余时间。 有点类似于截取多个连续的视频片段。 视频合并首先创建包含各媒体文件路径列表的文本文件 join.txt ：123file &apos;~/myvideos/part1.mp4&apos;file &apos;~/myvideos/part2.mp4&apos;file &apos;~/myvideos/part3.mp4&apos; 使用 -f concat 选项对多个视频进行合并：$ ffmpeg -f concat -i join.txt -c copy output.mp4 添加字幕文件$ ffmpeg -i input.mp4 -i subtitle.srt -map 0 -map 1 -c copy -c:v libx264 -crf 23 -preset veryfast output.mp4 改变视频播放速度（音频不受影响）$ ffmpeg -i input.mp4 -vf &quot;setpts=0.5*PTS&quot; output.mp4 上述命令会加快视频画面的播放速度，音频播放速度不变。 如果想放慢视频画面的切换速度，可以相应地将 setpts=0.5*PTS 中的 0.5 改为大于 1 的数值。 Padding即宽银幕视频中上下的两道“黑边”，可以使用 FFmpeg 命令添加类似的效果：1$ ffmpeg -i input.mp4 -vf &quot;scale=1920:1080:force_original_aspect_ratio=decrease,pad=1920:1080:(ow-iw)/2:(oh-ih)/2:black&quot; output.mp4 该效果由 -vf 选项的 pad 参数指定，可以根据情况自行修改。 从图片创建视频$ ffmpeg -framerate 1 -i img%02d.jpg -c:v libx264 -r 30 -pix_fmt yuv420p output.mp4把当前目录下的多张图片（名字为 img01.jpg、img02.jpg 的形式）组合为一个视频文件，效果类似于自动播放的 PPT。每秒切换一张图片。 $ ffmpeg -framerate 30 -i img%02d.jpg -c:v libx264 -pix_fmt yuv420p output.mp4也是将当前目录下的多张图片组合成一个完整的视频，该视频帧率为 30 FPS。每帧切换一张图片。 参考资料20 FFmpeg Commands For BeginnersHow to create a video from images with FFmpeg?]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Tools</tag>
        <tag>Media</tag>
        <tag>Video</tag>
        <tag>FFmpeg</tag>
        <tag>Audio</tag>
        <tag>Script</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用 Python 实现自己的智能语音助理（百度语音 + 图灵机器人）]]></title>
    <url>%2F2019%2F03%2F03%2Fpython-voice-assistant%2F</url>
    <content type="text"><![CDATA[依稀记得去年生日，对着 Google 说 “Sing me Happy Birthday” 。她真的给我唱了英文版的生日歌，满怀深情地（我感觉……）。最后还加了一串调皮的鼓声。我转头对着公司的前台小姐姐说，看见没有，你的 Siri 不爱我。。。 呃，不瞎扯了。基于以上的渊源，我用 Python 写了一个还算得上智能的语音助理。 截图如下： 演示视频：用 Python 实现的智能语音机器人（一） 源代码 不要慌，用的现成的框架和公共 API，一百来行代码而已，权当游戏。 一、整体结构没有做过多的设计（不懂。。。），整体就是一个简单的线性结构，顺序执行。一次交互完毕后，从头开始重复执行。 SpeechRecognition（录音）--&gt; 百度语音（Speech-to-Text）--&gt; 图灵机器人（语义分析及应答）--&gt; 百度语音（Text-to-Speech）--&gt; PyAudio（音频播放） 二、SpeechRecognitionSpeechRecogintion 是 Python 的一个语音识别框架，已经对接了如谷歌和微软的 STT （语音转文本）服务。 本项目里的语音识别及合成用的是百度的开放服务，所以只是需要 SpeechRecogintion 的录音功能。它可以检测语音中的停顿自动终止录音并保存，比 PyAudio 更人性化（代码写起来也更简单）。 安装依赖库Windows安装 SpeechRecognition 需要提前装好 Python 的 PyAudio 框架。PyAudio 貌似需要编译安装，Windows 系统上估计会有点麻烦。 我用的是 Anaconda 软件，Windows 系统上用它管理 Python 包很方便。嫌这个软件太大的话，也有简化版的 Miniconda 。装好以后直接执行下面的命令即可（当然也可以在 conda 的虚拟环境里安装，不赘述）：conda install pyaudio PyAudio 装好以后，直接使用 Python 的包管理工具 pip 安装 SpeechRecognition 即可：pip install SpeechRecognition LinuxLinux 系统下就显得省事一点了。可以直接使用系统自带的包管理器安装 PyAudio （如 Ubuntu 和 Raspbian 系统的 apt-get）$ sudo apt-get install python3-pyaudio 当然也可以使用 pip 命令安装，不过需要提前装好编译用的依赖库 portaudio19 ：12$ sudo apt-get install portaudio19-dev$ pip install pyaudio 同样的，PyAudio 装好以后，安装 SpeechRecognition ：pip install SpeechRecognition 录音代码123456789101112import speech_recognition as srdef rec(rate=16000): r = sr.Recognizer() with sr.Microphone(sample_rate=rate) as source: print(&quot;please say something&quot;) audio = r.listen(source) with open(&quot;recording.wav&quot;, &quot;wb&quot;) as f: f.write(audio.get_wav_data())rec() 从系统麦克风拾取音频数据，采样率为 16000（貌似百度语音 API 最高就支持到 16k 的采样率）。之后把采集到的音频数据以 wav 格式保存在当前目录下的 recording.wav 文件中，供后面的程序使用。 录音完成后，可以找到录好的音频文件试听一下效果。 三、百度语音（STT）创建应用百度语音是百度云 AI 开放平台提供的支持语音识别和语音合成的服务，注册以后就可以直接访问它的 REST API 了，并且有向普通用户提供免费的调用额度。 注册成功以后，进入语音服务的控制台创建一个新的应用，记下自己的 AppID、API Key 和 Secret Key。 语音识别代码百度 AI 有提供面向 Python 的框架 baidu-aip ，感觉就相当于重新打包以后的 requests 库，用来访问 REST API。这里简单起见，直接使用该框架。安装：pip install baidu-aip 语音识别代码如下（代码中的 Key 替换成自己的）：1234567891011121314151617181920212223from aip import AipSpeechAPP_ID = &apos;Your AppID&apos;API_KEY = &apos;Your API Key&apos;SECRET_KEY = &apos;Your Secret Key&apos;client = AipSpeech(APP_ID, API_KEY, SECRET_KEY)def listen(): with open(&apos;recording.wav&apos;, &apos;rb&apos;) as f: audio_data = f.read() result = client.asr(audio_data, &apos;wav&apos;, 16000, &#123; &apos;dev_pid&apos;: 1536, &#125;) result_text = result[&quot;result&quot;][0] print(&quot;you said: &quot; + result_text) return result_textlisten() 简单来说，将 SpeechRecognition 录制的音频上传至百度语音的服务，返回识别后的文本结果并输出。 四、图灵机器人图灵机器人是一个提供（一定额度内）免费的智能聊天服务的平台，注册以后就可以创建自己的聊天机器人并接入到项目中。 首先进入图灵机器人的控制台并创建一个新的聊天机器人，记下分配到的 apikey。 该平台也提供了开放的 REST API ，但是不像百度那样有打包自己的 SDK 。所以需要使用 Python 的 requests 库访问，代码如下：123456789101112131415161718192021222324252627282930313233343536import requestsimport jsonTURING_KEY = &quot;Your apikey&quot;URL = &quot;http://openapi.tuling123.com/openapi/api/v2&quot;HEADERS = &#123;&apos;Content-Type&apos;: &apos;application/json;charset=UTF-8&apos;&#125;def robot(text=&quot;&quot;): data = &#123; &quot;reqType&quot;: 0, &quot;perception&quot;: &#123; &quot;inputText&quot;: &#123; &quot;text&quot;: &quot;&quot; &#125;, &quot;selfInfo&quot;: &#123; &quot;location&quot;: &#123; &quot;city&quot;: &quot;杭州&quot;, &quot;street&quot;: &quot;网商路&quot; &#125; &#125; &#125;, &quot;userInfo&quot;: &#123; &quot;apiKey&quot;: TURING_KEY, &quot;userId&quot;: &quot;starky&quot; &#125; &#125; data[&quot;perception&quot;][&quot;inputText&quot;][&quot;text&quot;] = text response = requests.request(&quot;post&quot;, URL, json=data, headers=HEADERS) response_dict = json.loads(response.text) result = response_dict[&quot;results&quot;][0][&quot;values&quot;][&quot;text&quot;] print(&quot;the AI said: &quot; + result) return resultrobot(&quot;你好&quot;) 简单来说就是上传一个 json 格式的请求（包含聊天内容和个人信息等），获取到回复。再从收到的对象中提取出回复的文本。 五、百度语音（TTS）其实大部分系统都有内置的 TTS （即文本转语音）引擎，如 MacOS 的 say 命令，只不过其中有很多都显得太“机械”，呃，缺少“人情味儿”。。。 百度的 TTS 引擎语音效果听起来还是很卡哇伊（4 号选手度丫丫）的，比较超出我的预期。 测试代码如下：12345678910111213141516171819from aip import AipSpeechAPP_ID = &apos;Your AppID&apos;API_KEY = &apos;Your API Key&apos;SECRET_KEY = &apos;Your Secret Key&apos;client = AipSpeech(APP_ID, API_KEY, SECRET_KEY)def speak(text=&quot;&quot;): result = client.synthesis(text, &apos;zh&apos;, 1, &#123; &apos;spd&apos;: 4, &apos;vol&apos;: 5, &apos;per&apos;: 4, &#125;) if not isinstance(result, dict): with open(&apos;audio.mp3&apos;, &apos;wb&apos;) as f: f.write(result)speak(&quot;你好啊&quot;) 就是把需要转换成语音的文本内容上传，再将返回的数据保存在本地。貌似只能生成 mp3 格式。 六、PyAudio 播放这个我有点方。。。没找到 Python 播放 MP3 的合适的方法，所以用 os.system 调用系统中的 sox 命令将 MP3 转为 wav 格式，再用 PyAudio 播放。 sox 安装SoX 是一个强大的跨平台的音频处理工具，Linux 系统可以直接使用包管理器安装：$ sudo apt-get install sox libsox-fmt-mp3 Windows 系统安装的默认的 SoX 是不包含 mp3 格式支持的，所以需要自己编译（手动狗头）或者下载已经编译好的 dll 文件（libmad.dll 和 libmp3lame.dll，放置在 SoX 的安装目录下。最后将安装目录添加至系统的 PATH 环境变量即可。 代码如下：1234567891011121314151617181920212223242526272829303132import pyaudioimport waveimport osimport timedef play(): os.system(&apos;sox audio.mp3 audio.wav&apos;) wf = wave.open(&apos;audio.wav&apos;, &apos;rb&apos;) p = pyaudio.PyAudio() def callback(in_data, frame_count, time_info, status): data = wf.readframes(frame_count) return (data, pyaudio.paContinue) stream = p.open(format=p.get_format_from_width(wf.getsampwidth()), channels=wf.getnchannels(), rate=wf.getframerate(), output=True, stream_callback=callback) stream.start_stream() while stream.is_active(): time.sleep(0.1) stream.stop_stream() stream.close() wf.close() p.terminate()play() 七、最终代码及视频演示整合后的最终代码我就不再贴一遍了，100 行左右，已上传至 Github 。第二个视频：用 Python 实现的智能语音机器人（二） 聊天截图： 对了，这个是支持树莓派的。不过需要额外装一个USB音频驱动作为录音设备。参考树莓派3 音频配置及其应用场景（录音、VoIP 电话等） 参考资料SpeechRecognition百度语音图灵机器人PyAudioSoX]]></content>
      <categories>
        <category>Program</category>
      </categories>
      <tags>
        <tag>Program</tag>
        <tag>Python</tag>
        <tag>Audio</tag>
        <tag>AI</tag>
        <tag>chatbot</tag>
        <tag>SpeechRecognition</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows PowerShell 学习笔记其二（变量与控制语句）]]></title>
    <url>%2F2019%2F02%2F28%2Fwindows-powershell-cookbook-2%2F</url>
    <content type="text"><![CDATA[重定向与管道重定向可以借助管道符和 Out-File 命令将某个命令的输出内容重定向至文本文件中。 如：Get-ChildItem | Out-File files.txt通过 Get-ChildItem（即 dir）获取当前目录下的文件列表，再借助管道和 Out-File 将列表保存在 files.txt 文件中。 在使用 Out-File 命令时可以带上 -Encoding 等选项来指定输出文件的编码等属性：Get-Content filename.cs | Out-File -Encoding ASCII file.txtGet-ChildItem | Out-File -Width 120 files.cs 或者也可以使用类似 bash 里的 &gt; 符号：Get-ChildItem &gt; files.txtGet-ChildItem 2&gt; errors.txtGet-ChildItem n&gt; otherStreams.txt 在文件末尾添加内容在使用 Out-File 命令的同时，可以附加上 -Append 选项用来指明在文件末尾添加内容，如：Get-ChildItem | Out-File -Append files.txt 同样也可以使用类似于 bash 中的 &gt;&gt; 符号：Get-ChildItem &gt;&gt; files.txt 管道简单来说，管道可以用来连接多个命令，使得上一个命令的输出作为下一个命令的输入，从而将多个命令以“首尾相接”的方式执行。 Get-Process | Where-Object WorkingSet -gt 100mb | Sort-Object -Descending WS获取系统当前的进程信息，并筛选出内存占用大于 100MB 的进程，再将筛选结果按照占用的内存由大到小排序后输出。12345678910PS C:\Users\starky&gt; Get-Process | Where-Object WorkingSet -gt 100mb | Sort-Object -Descending WSHandles NPM(K) PM(K) WS(K) CPU(s) Id SI ProcessName------- ------ ----- ----- ------ -- -- ----------- 997 75 342180 249576 1,265.59 8516 0 MsMpEng 1598 103 147168 203348 40.02 5992 3 SearchUI 806 29 167004 173960 186.02 5288 3 chrome 1757 182 75120 153712 195.45 13116 3 chrome 2816 134 89428 124596 126.25 1480 3 explorer 367 38 83872 116840 74.64 416 3 chrome 筛选（Where-Object）Where-Object 命令可以对某个列表内容或命令的输出应用各种类型的筛选条件。它的默认别名为 where 和 ?。 Get-Process | Where-Object { $_.Name -like &quot;Baidu*&quot; }获取当前系统中名字以“Baidu”开头的进程及其信息 上面的命令同时也可以这样表述：Get-Process | Where-Object Name -like &quot;Baidu*&quot; 即先通过 Get-Process 命令获取全部进程信息，再将它们传递给 Where-Object 命令。而 Where-Object 又指定每一个进程的 Name 属性（即进程名称）与模式 Baidu* 进行匹配，最后只输出匹配的结果。123456PS C:\Users\starky&gt; gps | where &#123; $_.Name -like &quot;Baidu*&quot; &#125;Handles NPM(K) PM(K) WS(K) CPU(s) Id SI ProcessName------- ------ ----- ----- ------ -- -- ----------- 1030 251 58288 98076 552.59 204 3 BaiduNetdisk 187 14 11952 8628 0.06 4856 3 BaiduNetdiskHost 其他示例如筛选未响应的进程：Get-Process | where { -not $_.Responding } 筛选已经停止的服务：Get-Process | where { $_.Status -eq &quot;Stopped&quot; } 遍历（Foreach-Object）Foreach-Object 命令（默认别名为 foreach 和 %）用于对某个列表中的每一个对象指定特定的操作。如：123456PS C:\Users\starky&gt; 1..5 | Foreach-Object &#123; $_ * 2 &#125;246810 又比如筛选当前目录下所有的文本文件，并去掉它们的只读属性：Get-ChildItem *.txt | Foreach-Object { attrib -r $_ } 其中 $_ 表示传递给 Foreach-Object 的每一个对象。attrib -r $_ 即表示对 Get-ChildItem *.txt 获取到的所有文本文件去除只读属性。 又如：12345PS C:\Users\starky&gt; $myArray = 1,2,3,4,5PS C:\Users\starky&gt; $sum = 0PS C:\Users\starky&gt; $myArray | Foreach-Object &#123; $sum += $_ &#125;PS C:\Users\starky&gt; $sum15 上面的命令也可以使用如下形式：123PS C:\Users\starky&gt; $myArray = 1,2,3,4,5PS C:\Users\starky&gt; $myArray | Foreach-Object &#123; $sum = 0 &#125; &#123; $sum += $_ &#125; &#123; $sum &#125;15 格式化输出PowerShell 中的许多命令默认情况下是以“表格”的形式来格式化输出的，如：123456PS C:\Users\starky&gt; Get-Process PowerShellHandles NPM(K) PM(K) WS(K) VM(M) CPU(s) Id ProcessName------- ------ ----- ----- ----- ------ -- ----------- 410 41 60444 75004 550 3.21 4212 powershell 428 43 60688 56684 561 4.04 5288 powershell 实际上在多数情况下，命令的“真实”输出包含了更加丰富的信息，可以使用 Format-List 命令比较一下效果：123456789101112131415161718192021222324252627PS C:\Users\starky&gt; Get-Process PowerShell | Format-List *__NounName : ProcessName : powershellHandles : 404VM : 575397888WS : 76754944PM : 61808640NPM : 41736Path : C:\WINDOWS\system32\WindowsPowerShell\v1.0\powershell.exeCompany : Microsoft CorporationCPU : 3.2136206FileVersion : 6.3.9600.16406 (winblue_gdr_oob.130926-1103)ProductVersion : 6.3.9600.16406Description : Windows PowerShellProduct : Microsoft® Windows® Operating SystemId : 4212PriorityClass : NormalHandleCount : 404WorkingSet : 76754944PagedMemorySize : 61808640PrivateMemorySize : 61808640VirtualMemorySize : 575397888TotalProcessorTime : 00:00:03.2136206BasePriority : 8... Format-List 是 4 种格式化输出的命令之一，其他还有 Format-Table、Format-Wide、Format-Custom。Format-List 用来接收输入内容并将其以列表的形式输出。 默认情况下，不带任何参数的格式化命令只会输出对象的一小部分属性，如：1234567891011PS C:\Users\starky&gt; Get-Process PowerShell | Format-ListId : 4212Handles : 428CPU : 3.4632222Name : powershellId : 5288Handles : 392CPU : 4.1028263Name : powershell 而 Format-List * 则会显示输入对象的所有属性。 同时，也可以在格式化命令后面手动指定需要显示的属性或参数，如：123456PS C:\Users\starky&gt; Get-Process PowerShell | Format-Table Id,Name,CPU,WS -Auto Id Name CPU WS -- ---- --- --4212 powershell 3.7128238 787046405288 powershell 4.1028263 58068992 变量与对象变量在 PowerShell 中，可以将命令的输出或其他内容先保存在某个变量（以 $ 符号为前缀）中，以供后续使用（甚至可以把变量直接传递给管道符）。 1234567891011PS C:\Users\starky&gt; $result = 2 + 2PS C:\Users\starky&gt; $result4PS C:\Users\starky&gt; $processes = Get-ProcessPS C:\Users\starky&gt; $processes.Count64PS C:\Users\starky&gt; $processes | Where-Object &#123; $_.ID -eq 0 &#125;Handles NPM(K) PM(K) WS(K) VM(M) CPU(s) Id ProcessName------- ------ ----- ----- ----- ------ -- ----------- 0 0 0 24 0 0 Idle 访问环境变量PowerShell 可以很轻松地访问系统中定义的环境变量，如使用 Get-ChildItem env: 命令获取当前系统已定义的所有环境变量的列表：12345678910111213141516PS C:\Users\starky&gt; Get-ChildItem env:Name Value---- -----ALLUSERSPROFILE C:\ProgramDataAPPDATA C:\Users\starky\AppData\RoamingCommonProgramFiles C:\Program Files\Common FilesCommonProgramFiles(x86) C:\Program Files (x86)\Common FilesCommonProgramW6432 C:\Program Files\Common FilesCOMPUTERNAME Starky-LenovoComSpec C:\windows\system32\cmd.exeFP_NO_HOST_CHECK NOHOMEDRIVE C:HOMEPATH \Users\starkyLOCALAPPDATA C:\Users\starky\AppData\Local... 也可以使用 $env:variablename 形式的变量名直接表示系统环境变量。几种形式的示例如下：12345678910111213141516PS C:\Users\starky&gt; Get-ChildItem env:usernameName Value---- -----USERNAME starkyPS C:\Users\starky&gt; Get-ChildItem Environment::usernameName Value---- -----USERNAME starkyPS C:\Users\H19038&gt; $env:usernamestarky 作用域创建一个只在特定范围内生效的变量，使用如下形式的语法：$SCOPE:variable = value 获取特定的作用域里某个变量的值，使用如下形式的语法：$SCOPE:variable 如创建一个在脚本执行完毕后仍旧有效的变量，使用 GLOBAL 作用域：$GLOBAL:variable = value 在某个函数内部更改脚本范围内的变量，需要显式地指定 SCRIPT 作用域：$SCRIPT:variable = value PowerShell 中变量的作用域，就是控制各变量在不同范围内的可见性。比如当进入一个代码块、函数或别名时，当前的作用域成为新的“本地作用域”（子作用域），原来的作用域则成为“父作用域”。子作用域可以访问父作用域中定义的所有变量，但是没有权限直接修改这些变量的值。换句话说，子作用域可以修改在父作用域中定义的变量，但是这种修改不会将新值自动同步到父作用域。 .NET 对象PowerShell 可以直接访问 .NET 对象的方法（包括静态方法和实例）和属性，比如访问某个静态方法：[ClassName]::MethodName(parameter list) 访问某个对象实例绑定的方法：$objectReference.MethodName(parameter list) 访问某个类的静态属性：[ClassName]::PropertyName 访问某个对象实例的属性：$objectReference.PropertyName 下面是一些具体的例子。 静态方法：12345PS C:\Users\starky&gt; [System.Diagnostics.Process]::GetProcessById(0)Handles NPM(K) PM(K) WS(K) VM(M) CPU(s) Id ProcessName------- ------ ----- ----- ----- ------ -- ----------- 0 0 0 24 0 0 Idle 实例方法：123PS C:\Users\starky&gt; $now = Get-DatePS C:\Users\starky&gt; $now.ToString()2019/2/27 15:34:21 静态属性：123PS C:\Users\starky&gt; [System.DateTime]::Now2019年2月27日 15:36:09 实例属性：123PS C:\Users\starky&gt; $today = Get-DatePS C:\Users\starky&gt; $today.DayOfWeekWednesday 创建对象的实例使用 New-Object 命令可以创建某个 .NET 对象的实例。如：123PS C:\Users\starky&gt; $generator = New-Object System.RandomPS C:\Users\starky&gt; $generator.NextDouble()0.697396862179691 也可以在创建实例的同时直接使用它：12345PS C:\Users\starky&gt; (New-Object Net.WebClient).DownloadString(&quot;http://www.baidu.com&quot;)&lt;!DOCTYPE html&gt;&lt;!--STATUS OK--&gt;&lt;html&gt;&lt;head&gt;... 通常的做法是，创建对象实例的同时，还要为其指定某些属性。如：1234567891011PS C:\Users\starky&gt; $startInfo = New-Object Diagnostics.ProcessStartInfo -Property @&#123;&gt;&gt; &apos;Filename&apos; = &quot;powershell.exe&quot;;&gt;&gt; &apos;WorkingDirectory&apos; = $HOMEPATH;&gt;&gt; &apos;Verb&apos; = &quot;RunAs&quot;&gt;&gt; &#125;&gt;&gt;PS C:\Users\starky&gt; [Diagnostics.Process]::Start($startInfo)Handles NPM(K) PM(K) WS(K) VM(M) CPU(s) Id ProcessName------- ------ ----- ----- ----- ------ -- ----------- 4 2 260 1224 6 0.00 6248 powershell 上述命令中创建 Diagnostics.ProcessStartInfo 对象的语句也可以简写为如下形式：12345$startInfo = [Diagnostics.ProcessStartInfo] @&#123; &apos;Filename&apos; = &quot;powershell.exe&quot;; &apos;WorkingDirectory&apos; = $HOMEPATH; &apos;Verb&apos; = &quot;RunAs&quot;&#125; 有时候为了简写 .NET 类的完整名称，可以借助变量赋值，如：12345PS C:\Users\starky&gt; $math = [System.Math]PS C:\Users\starky&gt; $math::Min(1,10)1PS C:\Users\starky&gt; $math::Sin(3.14)0.00159265291648683 循环与流程控制比较与逻辑运算PowerShell 支持的比较运算符：-eq, -ne, -gt, -in, -notin, -lt, -le, -like, -notlike, -match, -notmatch, -contains, -notcontains, -is, -isnot 逻辑运算符：-and, -or, -xor, -not 逻辑与比较运算符可以用来在数据间进行比较，同时也可以测试当前某些特定的条件是否成立。如判断当前目录下的文件个数是否大于等于 4：12PS C:\Users\starky&gt; (dir).Count -ge 4True 某个字符串是否匹配特定的正则表达式：12PS C:\Users\starky&gt; &quot;Hello World&quot; -match &quot;H.*World&quot;True 默认情况下，PowerShell 里的比较运算是区分大小写的，如果想不区分大小写，可以使用如下版本的比较运算符：-ceq, -cne, -cge, -cgt, -cin, -clt, -cle, -clike, -cnotlike, -cmatch, -cnotmatch, -ccontains, -cnotcontains 逻辑运算符可以组合多个值为 true 或 false 的语句，并根据运算符号的不同返回特定的逻辑运算结果。比如判断某个字符串是否匹配特定模式，且字符串长度大于 10：123PS C:\Users\starky&gt; $data = &quot;Hello World&quot;PS C:\Users\starky&gt; ($data -like &quot;*llo W*&quot;) -and ($data.Length -gt 10)True 条件语句PowerShell 中的 if 语句基本用法如下：123456789101112131415161718$temperature = 35if($temperature -le 0)&#123; &quot;Freezing&quot;&#125;elseif($temperature -le 10)&#123; &quot;Cold&quot;&#125;elseif($temperature -le 20)&#123; &quot;Warm&quot;&#125;else&#123; &quot;Hot&quot;&#125; 除了流程控制，条件语句也经常用来对变量进行赋值，形式如下：123456PS C:\Users\starky&gt; $result = if(Get-Process -n notepad) &#123; &quot;Running&quot; &#125; else &#123; &quot;Not running&quot; &#125;Get-Process : 找不到名为“notepad”的进程。请验证该进程名称，然后再次调用 cmdlet。...PS C:\Users\starky&gt; $resultNot running 通常情况下，使用 switch 语句可以替代包含大量 if ... elseif ... else 的语句。PowerShell 的 switch 在对用户输入进行条件判断时，支持多种选项的使用，如通配符、正则表达式甚至简短的代码块，相比于 C 和 C++ 中的 switch 语句更显得强大。 12345678910$temperature = 35switch($temperature)&#123; &#123; $_ -lt 0 &#125; &#123; &quot;Below Freezing&quot;; break &#125; 32 &#123; &quot;Exactly Freezing&quot;; break &#125; &#123; $_ -le 10 &#125; &#123; &quot;Cold&quot;; break &#125; &#123; $_ -le 20 &#125; &#123; &quot;Warm&quot;; break &#125; default &#123; &quot;Hot&quot; &#125;&#125; 循环for 循环：1234for($counter = 1; $counter -le 10; $counter++)&#123; &quot;Loop number $counter&quot;&#125; foreach 循环：1234foreach($file in dir)&#123; &quot;File name: &quot; + $file.Name&#125; 或者：dir | foreach { &quot;File name: &quot; + $_.Name } while 循环：12345$response = &quot;&quot;while($response -ne &quot;QUIT&quot;)&#123; $response = Read-Host &quot;Type something&quot;&#125; do..while 循环：12345$response = &quot;&quot;do&#123; $response = Read-Host &quot;Type something&quot;&#125; while($response -ne &quot;QUIT&quot;) do..until 循环：12345$response = &quot;&quot;do&#123; $response = Read-Host &quot;Type something&quot;&#125; until($response -eq &quot;QUIT&quot;) 参考书籍Windows PowerShell Cookbook, 3rd Edition]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>Admin</tag>
        <tag>Tools</tag>
        <tag>Shell</tag>
        <tag>Windows</tag>
        <tag>Program</tag>
        <tag>Script</tag>
        <tag>PowerShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows PowerShell 学习笔记其一（特性介绍）]]></title>
    <url>%2F2019%2F02%2F26%2Fwindows-powershell-cookbook-1%2F</url>
    <content type="text"><![CDATA[PowerShell 是一个跨平台的自动化和配置工具（框架），在处理结构化数据（如 JSON、CSV、XML 等）、REST API 和对象模型方面做了大量针对性的优化。它是一个基于任务的命令行终端，同时也是一个构建在 .NET 上的脚本语言。对于自动化系统管理任务有极大的帮助。 其基本特性如下： PowerShell 可以与基础的 Windows 命令和应用完美整合 引入了一种新的命令形式（cmdlets），使用 Verb-Noun 形式的语法，对比普通命令有更高的灵活度 PowerShell 能够“理解”对象，可以直接处理结构化的数据对象，区别于普通 Shell 的“纯文本” 可以同多种技术直接整合使用。如 .NET、COM、WMI、XML 和活动目录等 简单化 data store 的管理（使用和管理文件同样的技术） 结构化命令（Cmdlets）PowerShell 引入了一种名为 Cmdlets 的新型命令。所有的 cmdlets 命令都以 Verb-Noun 的形式命名，如 Get-Process、Get-Content、Stop-Process 等。123456789PS C:\Users\starky&gt; Get-Process -Name chromeHandles NPM(K) PM(K) WS(K) VM(M) CPU(s) Id ProcessName------- ------ ----- ----- ----- ------ -- ----------- 285 36 80040 93808 620 104.61 1384 chrome 201 16 9000 7296 121 0.05 3572 chrome 1061 73 57324 99924 550 145.21 4052 chrome 221 17 8864 7952 131 0.08 5832 chrome 260 30 209528 154748 534 118.55 6408 chrome 在交互式的命令行环境下，可以使用 &lt;TAB&gt; 键自动补全命令和参数。如上述命令也可以这样输入：Get-Pr&lt;TAB&gt; -N&lt;TAB&gt; c&lt;TAB&gt; 大部分 Verb-Noun 形式的命令手动输入时仍显得有些长，所以 PowerShell 为所有常用的命令提供了简短的别名。如 Get-Process 的别名即为 gps 。123456789101112131415161718192021222324252627282930313233PS C:\Users\starky&gt; gps -n explorerHandles NPM(K) PM(K) WS(K) VM(M) CPU(s) Id ProcessName------- ------ ----- ----- ----- ------ -- ----------- 841 56 36280 35632 279 6.36 2552 explorerPS C:\Users\starky&gt; Get-AliasCommandType Name ModuleName----------- ---- ----------Alias % -&gt; ForEach-ObjectAlias ? -&gt; Where-ObjectAlias ac -&gt; Add-ContentAlias asnp -&gt; Add-PSSnapinAlias cat -&gt; Get-ContentAlias cd -&gt; Set-LocationAlias chdir -&gt; Set-LocationAlias clc -&gt; Clear-ContentAlias clear -&gt; Clear-HostAlias clhy -&gt; Clear-HistoryAlias cli -&gt; Clear-ItemAlias clp -&gt; Clear-ItemPropertyAlias cls -&gt; Clear-HostAlias clv -&gt; Clear-VariableAlias cnsn -&gt; Connect-PSSessionAlias compare -&gt; Compare-ObjectAlias copy -&gt; Copy-ItemAlias cp -&gt; Copy-ItemAlias cpi -&gt; Copy-ItemAlias cpp -&gt; Copy-ItemPropertyAlias curl -&gt; Invoke-WebRequest... 上述命令中，gps 即 Get-Process 命令的别名，-n 选项等同于 -Name。实际上 -n 选项此处也可以省略（默认即根据名称筛选进程）。 对象的深度整合PowerShell 可以直接处理复杂的结构化数据和功能完整的对象。如以下命令用于创建一个简单的字符串：12PS C:\Users\starky&gt; &quot;Hello World&quot;Hello World 事实上刚刚创建的 “Hello World” 字符串是一个具有完整功能的对象（来源于 .NET 框架），可以通过 . 符号访问其属性：12PS C:\Users\starky&gt; &quot;Hello World&quot;.Length11 所有的 PowerShell 命令都会将其输出内容作为对象，同时该对象可以被赋值给任意一个变量。如 Get-Process cmdlet 会生成一个 System.Diagnostics.Process 对象。12345PS C:\Users\starky&gt; notepadPS C:\Users\starky&gt; $process = Get-Process notepadPS C:\Users\starky&gt; $process.kill()PS C:\Users\starky&gt; Get-Process notepadGet-Process : 找不到名为“notepad”的进程。请验证该进程名称，然后再次调用 cmdlet。 管理员作为“第一等级”用户PowerShell 始终将管理员执行的任务作为关注的焦点，比如在终端中可以直接完成此种类型的计算：12PS C:\Users\starky&gt; 40GB / 650MB63.0153846153846 借助于 .NET 框架提供的支持，PowerShell 还可以作为一个强大的“日历”应用：12PS C:\Users\starky&gt; [DateTime]::IsLeapYear(2008)True 12345678PS C:\Users\starky&gt; [DateTime]::Now2019年2月18日 21:32:03PS C:\Users\starky&gt; $result = [DateTime] &quot;06/21/2019&quot; - [DateTime]::NowPS C:\Users\starky&gt; $result.TotalDays122.102253218295 组合命令可以使用管道符（|）将一个命令的输出重定向至另一个命令作为输入，和 Bash 中管道符的使用一样。如：Get-Item Path1\* | Move-Item -Destination Path2上述命令将 Path1 中的所有文件移动到 Path2 目录下。 更复杂的形式如：123456789101112131415PS C:\Users\starky&gt; Get-Process | Where-Object &#123; $_.Handles -ge 1000 &#125; | Sort-Object Handles | Format-Table Handles,Name,Desciption -AutoHandles Name Description------- ---- ----------- 1023 dwm 桌面窗口管理器 1025 chrome Google Chrome 1096 SkypeApp SkypeApp 1107 Microsoft.Photos Microsoft.Photos.exe 1126 svchost Windows 服务主进程 1236 svchost Windows 服务主进程 1425 SearchUI Search and Cortana application 1437 lsass Local Security Authority Process 1712 chrome Google Chrome 2592 explorer Windows 资源管理器 3410 System 通过 Get-Process 命令获取当前所有进程的信息，使用 Where-Object { $_.Handles -ge 1000 } 命令筛选出 Handles 在 1000 以上的对象，Sort-Object Handles 命令用来通过 Handles 属性排序，Format-Table ... 命令用来对输出结果进行格式化。 通过别名的简化，上述命令也可以使用如下的形式：gps | ? { $_.Handles -ge 1000 } | sort Handles | ft Handles,Name,Description -Auto “发现”命令可以通过 Get-Command cmdlet 进行模糊搜索，查询可能用到的命令，如需要使用“进程”相关的命令：123456789101112131415161718PS C:\Users\starky&gt; Get-Command *process*CommandType Name Version Source----------- ---- ------- ------Function Get-AppvVirtualProcess 1.0.0.0 AppvClientFunction Start-AppvVirtualProcess 1.0.0.0 AppvClientCmdlet ConvertTo-ProcessMitigationPolicy 1.0.11 ProcessMitigationsCmdlet Debug-Process 3.1.0.0 Microsoft.PowerShell.ManagementCmdlet Enter-PSHostProcess 3.0.0.0 Microsoft.PowerShell.CoreCmdlet Exit-PSHostProcess 3.0.0.0 Microsoft.PowerShell.CoreCmdlet Get-Process 3.1.0.0 Microsoft.PowerShell.ManagementCmdlet Get-ProcessMitigation 1.0.11 ProcessMitigationsCmdlet Get-PSHostProcessInfo 3.0.0.0 Microsoft.PowerShell.CoreCmdlet Set-ProcessMitigation 1.0.11 ProcessMitigationsCmdlet Start-Process 3.1.0.0 Microsoft.PowerShell.ManagementCmdlet Stop-Process 3.1.0.0 Microsoft.PowerShell.ManagementCmdlet Wait-Process 3.1.0.0 Microsoft.PowerShell.ManagementApplication qprocess.exe 10.0.17... C:\Windows\system32\qprocess.exe 如需要获取某个命令的具体帮助信息，可以使用 Get-Help cmdlet：12345678910111213141516171819202122232425262728293031323334353637383940PS C:\Users\starky&gt; Get-Help Stop-Process名称 Stop-Process摘要 Stops one or more running processes.语法 Stop-Process [-Id] &lt;Int32[]&gt; [-Confirm] [-Force] [-PassThru] [-WhatIf] [&lt;CommonParameters&gt;] Stop-Process [-InputObject] &lt;Process[]&gt; [-Confirm] [-Force] [-PassThru] [-WhatIf] [&lt;CommonParameters&gt;] Stop-Process [-Confirm] [-Force] -Name &lt;String[]&gt; [-PassThru] [-WhatIf] [&lt;CommonParameters&gt;]说明 The Stop-Process cmdlet stops one or more running processes. You can specify a process by process name or process I D (PID), or pass a process object to Stop-Process . Stop-Process works only on processes running on the local compu ter. On Windows Vista and later versions of the Windows operating system, to stop a process that is not owned by the cur rent user, you must start Windows PowerShell by using the Run as administrator option. Also, you are prompted for c onfirmation unless you specify the Force parameter.相关链接 Online Version: http://go.microsoft.com/fwlink/?LinkId=821642 Debug-Process Get-Process Start-Process Stop-Process Wait-Process备注 若要查看示例，请键入: &quot;get-help Stop-Process -examples&quot;. 有关详细信息，请键入: &quot;get-help Stop-Process -detailed&quot;. 若要获取技术信息，请键入: &quot;get-help Stop-Process -full&quot;. 有关在线帮助，请键入: &quot;get-help Stop-Process -online&quot; PowerShell 可以直接操作从 .NET 框架中引入的数据对象，通过将某个对象传递给 Get-Member cmdlet，可以获取绑定于该对象的属性和方法等：1234567891011121314151617181920212223PS C:\Users\starky&gt; &quot;Hello World&quot; | Get-Member TypeName:System.StringName MemberType Definition---- ---------- ----------...IndexOf Method int IndexOf(char value), int IndexOf(char value, int startIndex), int IndexOf...IndexOfAny Method int IndexOfAny(char[] anyOf), int IndexOfAny(char[] anyOf, int startIndex), i...Insert Method string Insert(int startIndex, string value)IsNormalized Method bool IsNormalized(), bool IsNormalized(System.Text.NormalizationForm normaliz...LastIndexOf Method int LastIndexOf(char value), int LastIndexOf(char value, int startIndex), int...LastIndexOfAny Method int LastIndexOfAny(char[] anyOf), int LastIndexOfAny(char[] anyOf, int startI...Normalize Method string Normalize(), string Normalize(System.Text.NormalizationForm normalizat...PadLeft Method string PadLeft(int totalWidth), string PadLeft(int totalWidth, char paddingChar)PadRight Method string PadRight(int totalWidth), string PadRight(int totalWidth, char padding...Remove Method string Remove(int startIndex, int count), string Remove(int startIndex)Replace Method string Replace(char oldChar, char newChar), string Replace(string oldValue, s...Split Method string[] Split(Params char[] separator), string[] Split(char[] separator, int...StartsWith Method bool StartsWith(string value), bool StartsWith(string value, System.StringCom...Substring Method string Substring(int startIndex), string Substring(int startIndex, int length)... 后台运行PowerShell 可以通过 Start-Job 将指定命令以后台任务的形式运行。如：1234567891011121314151617PS C:\Users\starky&gt; Start-Job &#123; while($true) &#123; Get-Random; Start-Sleep 5 &#125; &#125; -Name SleeperId Name PSJobTypeName State HasMoreData Location Command-- ---- ------------- ----- ----------- -------- -------2 Sleeper BackgroundJob Running True localhost while($true) &#123; Get-Ra...PS C:\Users\starky&gt; Receive-Job Sleeper20136626437901827701345543150PS C:\Users\starky&gt; Stop-Job SleeperPS C:\Users\starky&gt; Get-JobId Name PSJobTypeName State HasMoreData Location Command-- ---- ------------- ----- ----------- -------- -------2 Sleeper BackgroundJob Stopped True localhost while($true) &#123; Get-Ra... 其中 Receive-Job 用于获取后台任务的命令输出，Stop-Job 用于停止任务的运行，Get-Job 用于获取当前会话已绑定的所有任务。此外还有 Remove-Job 用于将活动任务从列表里移除。 除了使用 Start-Job cmdlet 生成后台任务，还可以通过在很多 cmdlets 后面加上 -AsJob 选项将其指定为后台运行。 脚本语言PowerShell 实际上不只是一个简单的交互式终端，同时也是一种强大的脚本语言。所以支持众多的编程特性，如：1234PS C:\Users\starky&gt; $handleCount = 0PS C:\Users\starky&gt; foreach($process in Get-Process) &#123; $handleCount += $process.Handles &#125;PS C:\Users\starky&gt; $handleCount69841 甚至如下的形式：123456789101112131415PS C:\Users\starky&gt; $webClient = New-Object System.Net.WebClientPS C:\Users\starky&gt; $content = $webClient.DownloadString(&quot;http://blogs.msdn.com/PowerShell/rss.aspx&quot;)PS C:\Users\starky&gt; $content.Substring(0,500)&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;rss version=&quot;2.0&quot; xmlns:content=&quot;http://purl.org/rss/1.0/modules/content/&quot; xmlns:wfw=&quot;http://wellformedweb.org/CommentAPI/&quot; xmlns:dc=&quot;http://purl.org/dc/elements/1.1/&quot; xmlns:atom=&quot;http://www.w3.org/2005/Atom&quot; xmlns:sy=&quot;http://purl.org/rss/1.0/modules/syndication/&quot; xmlns:slash=&quot;http://purl.org/rss/1.0/modules/slash/&quot; &gt;&lt;channel&gt; &lt;title&gt;PowerShell Team Blog&lt;/title&gt; &lt;atom:link href=&quot;https://blogs.msdn.microsoft.com/powershell/feed/&quot; rel=&quot;s 整合其他技术PowerShell 也支持操作 WMI（Windows Management Instrumentation）和 CIM 对象：12345678PS C:\Users\starky&gt; Get-CimInstance Win32_BiosSMBIOSBIOSVersion : D5CN31WWManufacturer : LENOVOName : D5CN31WWSerialNumber : PF0F77WRVersion : LENOVO - 1 又如操作 COM 对象：1234567891011121314PS C:\Users\starky&gt; $firewall = New-Object -com HNetCfg.FwMgrPS C:\Users\Administrator&gt; $firewall.LocalPolicy.CurrentProfileType : 1FirewallEnabled : TrueExceptionsNotAllowed : FalseNotificationsDisabled : FalseUnicastResponsesToMulticastBroadcastDisabled : FalseRemoteAdminSettings : System.__ComObjectIcmpSettings : System.__ComObjectGloballyOpenPorts : System.__ComObjectServices : System.__ComObjectAuthorizedApplications : System.__ComObject ProvidersPowerShell 可以通过 Providers 像浏览目录那样浏览系统中的 data store。如浏览注册表的某个分支：1234567891011121314151617181920212223242526272829303132333435363738394041PS C:\Users\starky&gt; Set-Location HKCU:\Software\Microsoft\WindowsPS HKCU:\Software\Microsoft\Windows&gt; Get-ChildItem Hive: HKEY_CURRENT_USER\Software\Microsoft\WindowsName Property---- --------AssignedAccessConfigurationCurrentVersionDWM Composition : 1 ColorizationColor : 3288365271 ColorizationColorBalance : 89 ColorizationAfterglow : 3288365271 ColorizationAfterglowBalance : 10 ColorizationBlurBalance : 1 EnableWindowColorization : 0 ColorizationGlassAttribute : 1 AccentColor : 4292311040 ColorPrevalence : 0 EnableAeroPeek : 1 AlwaysHibernateThumbnails : 0 UseDpiScaling : 0ShellTabletPCWindows Error Reporting LastQueuePesterTime : 131873467252566492WinlogonPS HKCU:\Software\Microsoft\Windows&gt; Set-Location CurrentVersion\RunPS HKCU:\Software\Microsoft\Windows\CurrentVersion\Run&gt; Get-ItemProperty .OneDrive : &quot;C:\Users\Administrator\AppData\Local\Microsoft\OneDrive\OneDrive.exe&quot; /backgroundLantern : &quot;C:\Users\Administrator\AppData\Roaming\Lantern\lantern.exe&quot; -startupPSPath : Microsoft.PowerShell.Core\Registry::HKEY_CURRENT_USER\Software\Microsoft\Windows\CurrentVersion\RunPSParentPath : Microsoft.PowerShell.Core\Registry::HKEY_CURRENT_USER\Software\Microsoft\Windows\CurrentVersionPSChildName : RunPSDrive : HKCUPSProvider : Microsoft.PowerShell.Core\Registry 即使用 Set-Location（或 cd）和 Get-ChildItem（或 dir ）像浏览本地目录一样浏览访问注册表。 同样的方式也适用于系统里的证书库：1234567891011121314PS C:\users\starky&gt; Set-Location cert:\CurrentUser\RootPS Cert:\CurrentUser\Root&gt; Get-ChildItem PSParentPath:Microsoft.PowerShell.Security\Certificate::CurrentUser\RootThumbprint Subject---------- -------CDD4EEAE6000AC7F40C3802C171E30148030C072 CN=Microsoft Root Certificate Authority, DC=microsoft, DC=comBE36A4562FB2EE05DBB3D32323ADF445084ED656 CN=Thawte Timestamping CA, OU=Thawte Certification, O=Thawte, L=Durbanvill...A43489159A520F0D93D032CCAF37E7FE20A8B419 CN=Microsoft Root Authority, OU=Microsoft Corporation, OU=Copyright (c) 19...92B46C76E13054E104F230517E6E504D43AB10B5 CN=Symantec Enterprise Mobile Root for Microsoft, O=Symantec Corporation, ...8F43288AD272F3103B6FB1428485EA3014C0BCFE CN=Microsoft Root Certificate Authority 2011, O=Microsoft Corporation, L=R...... 参考书籍Windows PowerShell Cookbook, 3rd Edition]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>Admin</tag>
        <tag>Tools</tag>
        <tag>Shell</tag>
        <tag>Windows</tag>
        <tag>Program</tag>
        <tag>PowerShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Arduino IDE 搭建 ESP8266 开发环境及项目演示]]></title>
    <url>%2F2019%2F01%2F11%2Fprogramming-esp8266-with-arduino-ide%2F</url>
    <content type="text"><![CDATA[ESP8266 是一款由乐鑫 Espressif 公司制作的低成本的 Wi-Fi 芯片，具有完整的 TCP / IP 协议栈和微控制器功能。它专为移动设备、可穿戴电子产品和物联网应用设计，功耗很低且价格非常低廉。我这里使用的 NodeMcu 开发板即搭载了这款芯片。 Arduino IDE 是由 Arduino 官方提供的支持 C 语言的集成开发环境，主要是针对 Arduino 系列的开发板进行编程。通过简单的配置，可以在原本的编程环境里添加上对 ESP8266 开发板的支持。对于熟悉 Arduino 函数库和开发流程的用户，基本上没有任何使用上的区别。 一、添加 ESP8266 支持首先从 Arduino 官网 下载最新版本的 Arduino IDE 软件并安装。安装完成以后，进入首选项（Preferences），找到附加开发板管理器地址（Additional Board Manager URLs），并在其后添加如下信息：http://arduino.esp8266.com/stable/package_esp8266com_index.json 之后点击工具 - 开发板 - 开发板管理器，进入开发板管理器界面： 找到 esp8266 并安装： 安装完成后，重启 Arduino IDE 软件。在工具 - 开发板选项中即会看到 ESP8266 开发板的选项： 二、测量温湿度本例中使用 DHT11 温湿度传感器测量室内温度和湿度，再把测量所得的结果输出至 Arduino IDE 的串口监视器中。 源代码在 Arduino IDE 中新建项目并写入如下代码：123456789101112131415161718192021222324252627282930313233#include &quot;DHT.h&quot;#define DHTPIN 5#define DHTTYPE DHT11// Initialize DHT sensorDHT dht(DHTPIN, DHTTYPE, 15);void setup() &#123; // Start Serial Serial.begin(115200); // Init DHT dht.begin();&#125;void loop() &#123; // Reading temperature and humidity float h = dht.readHumidity(); float t = dht.readTemperature(); // Display data Serial.print(&quot;Humidity: &quot;); Serial.print(h); Serial.print(&quot; %\t&quot;); Serial.print(&quot;Temperature: &quot;); Serial.print(t); Serial.println(&quot; *C &quot;); // Wait a few seconds between measurements. delay(2000);&#125; 由于源代码中首行引入的 DHT 库并不是 Arduino IDE 内置的库文件，需要先点击项目 - 加载库 - 管理库进入库管理器，搜索安装如下两个依赖库（Adafruit Unified Sensor 和 DHT sensor library）： 线路连接该测试项目只需要连接好 NodeMcu 开发板与 DHT11 温湿度模块（或者单独的 DHT11 元件配合 5kΩ 的上拉电阻），无需额外的传感器模块和电子组件。 线路连接示意图如下： NodeMcu DHT11 3V3 VCC（Pin1） GND GND（Pin4） D1 DATA(Pin2） 3V3 5k 电阻 - DATA（Pin2） 编译运行Arduino IDE 实际上支持非常多的基于 ESP8266 芯片设计的开发板，如 Adafruit Feather HUZZAH ESP8266、LOLIN (WEMOS) D1 mini 等。可以根据自己购买的开发板的具体型号，在编译前选择对应的开发板选项（工具 - 开发板）。 我这里使用的是开源的 NodeMcu v1.0 开发板，编译代码前确保选择正确： 最终的运行效果如下：呃，，南方的冬天，外面在下雨。室内，没开空调。。。（后面温湿度升高是因为，我对着传感器哈气了。。。） 注意事项可以看到，源代码中的 DHTPIN （即传感器 DATA 引脚需要连接的开发板引脚 ）定义为 5 ，但开发板实际连接的是 D1 引脚（而不是 D5）。 ESP8266 芯片有自己的引脚（GPIO）布局，但是基于该芯片设计的众多开发板，对于芯片上 GPIO 的引出方式却有自己的规则。即源代码中的 5 指的并不是开发板的引脚 D5 ，而是 ESP8266 的引脚 GPIO 5 ，对应到开发板上即是 D1 引脚。 相关的引脚布局如下图所示： 三、Wi-Fi 连接ESP8266 最大的特性就是其超低成本的 Wi-Fi 实现。这里简单贴出其连接 Wi-Fi 的示例代码：123456789101112131415161718192021222324252627// Import required libraries#include &lt;ESP8266WiFi.h&gt;// WiFi parametersconst char* ssid = &quot;your_wifi_name&quot;;const char* password = &quot;your_wifi_password&quot;;void setup(void)&#123; // Start Serial Serial.begin(115200); // Connect to WiFi WiFi.begin(ssid, password); while (WiFi.status() != WL_CONNECTED) &#123; delay(500); Serial.print(&quot;.&quot;); &#125; Serial.println(&quot;&quot;); Serial.println(&quot;WiFi connected&quot;); // Print the IP address Serial.println(WiFi.localIP());&#125; void loop() &#123;&#125; 运行结果如下： 四、aRESTaREST 框架可以为一些常见的嵌入式开发板提供 RESTful 接口，支持通过串口、Wi-Fi、以太网、蓝牙等硬件发送命令至开发板，激发特定的操作，并将数据以 JSON 的格式返回给控制端用户。 使用 aREST 框架既可以在本地网络环境中控制联网设备，也可以借助云端平台进行远程操作或监控。 结合之前的温湿度项目，可以将连接 Wi-Fi 后的 NodeMcu 开发板作为一个实现了 REST API 的本地服务器，通过访问其 IP 地址来获取相应的温湿度数据（JSON 格式）。 代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778// Import required libraries#include &quot;ESP8266WiFi.h&quot;#include &lt;aREST.h&gt;#include &quot;DHT.h&quot;// DHT11 sensor pins#define DHTPIN 5#define DHTTYPE DHT11// Create aREST instanceaREST rest = aREST();// Initialize DHT sensorDHT dht(DHTPIN, DHTTYPE, 15);// WiFi parametersconst char* ssid = &quot;wifi-name&quot;;const char* password = &quot;wifi-pass&quot;;// The port to listen for incoming TCP connections #define LISTEN_PORT 80// Create an instance of the serverWiFiServer server(LISTEN_PORT);// Variables to be exposed to the APIfloat temperature;float humidity;void setup(void)&#123; // Start Serial Serial.begin(115200); // Init DHT dht.begin(); // Init variables and expose them to REST API rest.variable(&quot;temperature&quot;,&amp;temperature); rest.variable(&quot;humidity&quot;,&amp;humidity); // Give name and ID to device rest.set_id(&quot;1&quot;); rest.set_name(&quot;esp8266&quot;); // Connect to WiFi WiFi.begin(ssid, password); while (WiFi.status() != WL_CONNECTED) &#123; delay(500); Serial.print(&quot;.&quot;); &#125; Serial.println(&quot;&quot;); Serial.println(&quot;WiFi connected&quot;); // Start the server server.begin(); Serial.println(&quot;Server started&quot;); // Print the IP address Serial.println(WiFi.localIP());&#125;void loop() &#123; // Reading temperature and humidity humidity = dht.readHumidity(); temperature = dht.readTemperature(); // Handle REST calls WiFiClient client = server.available(); if (!client) &#123; return; &#125; while(!client.available())&#123; delay(1); &#125; rest.handle(client);&#125; 运行效果： 以上只是一些基础的使用介绍吧，，，后续比如更加复杂的网络服务、对接公共的物联网云平台及 MQTT 协议等内容，有时间再看看。我去，光着脚，12℃。冻死我了。。。 参考资料Internet of Things with ESP8266 (English Edition)]]></content>
      <categories>
        <category>IoT</category>
      </categories>
      <tags>
        <tag>Programming</tag>
        <tag>Arduino</tag>
        <tag>IoT</tag>
        <tag>ESP8266</tag>
        <tag>NodeMcu</tag>
        <tag>Wi-Fi</tag>
        <tag>Sensor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[树莓派3 音频配置及其应用场景（录音、VoIP 电话等）]]></title>
    <url>%2F2019%2F01%2F06%2Fraspberry-pi-audio-configuration-and-applications%2F</url>
    <content type="text"><![CDATA[从网上看到一本关于树莓派的电子书 Raspberry Pi for Secret Agents，利用树莓派打造“特工装备”。其中有一章讲到音频设备的配置和几个相关的应用场景（比如录音、监听、搭建电话系统等），感觉比较有意思。 一、音频系统简单配置1. ALSAALSA (Advanced Linux Sound Architecture) 是一个承载树莓派上音频系统的底层框架，为树莓派及其外接的播放或录制设备提供内核驱动程序。同时该框架也包含用于制作音频应用的程序代码，和一些方便的命令行实用程序。 在 ALSA 的定义里，系统中的每一个音频设备都称作“声卡”。可以使用如下命令列出所有已连接的音频设备：123$ cat /proc/asound/cards 0 [ALSA ]: bcm2835_alsa - bcm2835 ALSA bcm2835 ALSA 可以看到此时系统中只有树莓派默认的声卡 0 bcm2835 ALSA。 2. 调节音量大小可以使用 alsamixer 命令打开 AlsaMixer 实用程序，对音量等声音系统参数进行调节： 界面中 View 选项后面的 Playback、Capture、All 分别对应播放、录制和全部。可以按键盘上的 TAB 键切换到对应的界面。按下 fn+F6 或 S 键切换声卡设备（此时只有一个声卡） 使用 ↑ ↓ 方向键调节音量，设置完成后按 ESC 键退出 AlsaMixer。 3. 切换音频输出树莓派提供两种音频输出接口：3.5mm 模拟音频接口和 HDMI。可以通过 $sudo raspi-config 命令（选择 Advanced Options - Audio）配置音频输出方向，使音频输出固定使用 3.5mm 接口或 HDMI： 类似的操作也可以直接通过 amixer 命令完成：$ amixer cset numid=3 1 ：指定音频输出接口为 3.5mm 耳机接口$ amixer cset numid=3 2 ：指定音频输出接口为 HDMI1234$ amixer cset numid=3 1numid=3,iface=MIXER,name=&apos;PCM Playback Route&apos; ; type=INTEGER,access=rw------,values=1,min=0,max=2,step=0 : values=1 4. 播放测试可以使用 $ speaker-test -c2 -t wav 命令测试音频播放是否正常。如一切顺利，则会依次从左耳耳机（或音箱）听到 Front Left，从右耳耳机听到 Front Right 的女声语音，直到按下 Ctrl + C 终止测试。 二、音频录制设备1. USB声卡树莓派提供的音频接口是不支持语音输入的。使用 alsamixer 命令进入 AlsaMixer 程序，按下 TAB 键切换到 Caputre 界面，可以看到此设备无音频采集控制的提示： 为了录制音频，需要使用外接的音频输入设备。可以从网上购买一个便携式的 USB 免驱动声卡。插入USB声卡后，通过 $ cat /proc/asound/cards 命令查看当前系统检测到的音频设备：12345$ cat /proc/asound/cards 0 [ALSA ]: bcm2835_alsa - bcm2835 ALSA bcm2835 ALSA 1 [Device ]: USB-Audio - USB Audio Device GeneralPlus USB Audio Device at usb-3f980000.usb-1.3, full speed 此时输出信息中多了一个序号为 1 的声卡设备 USB-Audio。可以使用 $ speaker-test -D plughw:1 -c2 -t wav 测试 USB 声卡的音频播放是否正常（注意命令中的 -D plughw:1）。 使用 alsamixer -c1 命令调节新声卡的具体参数。其中 -c1 选项用于指定编号为 1 的声卡设备，即新插入的 USB 声卡。 按下 fn+F4 或 TAB 键将视图切换到 Capture 界面，确保 Mic 上方有出现 CAPTURE 字样（说明已开启录制功能，可以使用空格键切换开关状态）： 2. 麦克风测试首先安装 SoX 工具及其 mp3 格式支持：$sudo apt-get install sox libsox-fmt-mp3SoX 是 Linux 系统上一个强大的音频处理工具，详细使用方法可以参考这篇文章：SoX — 音频处理工具里的瑞士军刀。 sox 命令的基本格式为 sox &lt;input&gt; &lt;output&gt; 。其中的 &lt;input&gt; 和 &lt;output&gt; 既可以是某个具体的音频文件，也可以是某个特定的音频设备。所以可以简单的理解为，sox 工具就是对音频进行“传导”： 从文件到设备即为播放 sox music.mp3 &lt;device&gt; 从设备到文件即为录制 sox &lt;device&gt; myrec.wav 从文件到文件即为转码 sox input.wav output.mp3 可以使用 $ sox -t alsa plughw:1 -t alsa plughw:1 命令对麦克风进行测试。其中 -t alsa plughw:1 表示 ALSA 声卡设备 1（即USB声卡）。上述命令表示既使用USB声卡（麦克风） 作为音频输入，又用它（耳机）作为音频输出。 如一切正常，此时可以通过耳机听到自己对着麦克风讲话的声音。 3. 切换默认的音频设备可以通过修改配置文件，将树莓派默认用于播放和录制的音频设备（即树莓派内置声卡），改为当前插入的USB声卡。编辑 ~/.asoundrc 文件，改为如下内容：123456789pcm.!default &#123; type hw card 1&#125;ctl.!default &#123; type hw card 1&#125; 其实就是将配置文件中的 card 0 改为 card 1。 此时可直接使用 $ sox -d -d 命令测试USB声卡上连接的麦克风和耳机，无需再通过 -t alsa plughw:1 选项手动指定USB声卡（-d 选项表示默认音频设备，即已配置成默认的USB声卡）。 4. 录制与播放默认音频设备切换为USB声卡后，可以使用以下命令录制一段音频并将其保存在 myrec.mp3 文件中：$ sox -d myrec.mp3 或 $ rec myrec.mp3 播放前面录制的音频文件可使用如下命令：$ sox myrec.mp3 -d 或 $ play myrec.mp3 如未能配置USB声卡为默认音频设备或配置不成功，也可以使用如下命令进行录制与播放：录制：$ sox -t alsa plughw:1 myrec.mp3播放：$ sox myrec.mp3 -t alsa plughw:1 录制固定长度的音频片段（如 30 分钟）并保存在指定文件中：$ sox -t alsa plughw:1 myrec.wav trim 0 00:30:00 持续录制很长时间的音频，保存在几个不同的文件中，每隔一小时保存一次：$ sox -t alsa plughw:1 myrec.wav trim 0 01:00:00 : newfile : restart 三、远程监听可以通过树莓派的 SSH 服务，在另一台电脑上远程收听树莓派通过USB声卡收集到的音频数据。也就是说，用树莓派的麦克风录制周围环境的声音，同时在远程的另一台电脑上实时地（有短暂延迟）收听录制的内容，达到监听的效果。 在电脑端（也需要安装 sox 程序）执行如下命令即可：$ ssh pi@[IP address] sox -t alsa plughw:1 -t sox - | sox -q -t sox - -d 对于 Windows 系统，除安装 SoX 工具外，还需要先下载完整版 PuTTY 工具，并确保这两个工具的安装路径都已添加至 PATH 环境变量。 则可以使用如下命令通过树莓派进行远程监听：plink pi@[IP address] -pw [password] sox -t alsa plughw:1 -t sox - | sox -q -t sox - -t waveaudio default 可以使用如下命令，将远程树莓派收集到的音频数据直接保存在本地文件中：$ ssh pi@[IP address] sox -t alsa plughw:1 -t mp3 - &gt; ~/Desktop/myrec.mp3或 plink pi@[IP address] sox -t alsa plughw:1 -t mp3 - &gt; D:\myrec.mp3 （Windows 系统） 使用如下命令，让本地电脑作为音频输入源，将其麦克风收集到的音频数据，通过 SSH 发送到远程树莓派上进行播放。也就是将自己对着本地电脑讲的话通过树莓派进行远程广播：$ sox -d -t sox - | ssh pi@[IP address] sox -q -t sox - -d或 sox -t waveaudio default -t sox - | plink pi@[IP address] -pw [password] sox -q -t sox - -d （Windows 系统） 同样的原理，也可以将本地磁盘上的音频文件直接发送到远程的树莓派上进行播放：$ cat ~/Desktop/media/audios/Faded.wav | ssh pi@[IP address] sox -t wav - -d或 type D:\myrec.mp3 | plink pi@[IP address] -pw [password] sox -t mp3 - -d （Windows 系统） 四、蓝牙耳机树莓派 3 代 B+ 自带了 WIFI 和蓝牙功能，可以直接通过蓝牙连接音频设备。 1. 使用 hciconfig 命令获取蓝牙模块的相关信息：1234567891011121314151617$ hciconfig -ahci0: Type: Primary Bus: UART BD Address: B8:27:EB:C3:38:31 ACL MTU: 1021:8 SCO MTU: 64:1 UP RUNNING RX bytes:4181 acl:136 sco:0 events:135 errors:0 TX bytes:5065 acl:128 sco:0 commands:60 errors:0 Features: 0xbf 0xfe 0xcf 0xfe 0xdb 0xff 0x7b 0x87 Packet type: DM1 DM3 DM5 DH1 DH3 DH5 HV1 HV2 HV3 Link policy: RSWITCH SNIFF Link mode: SLAVE ACCEPT Name: &apos;raspberrypi&apos; Class: 0x480000 Service Classes: Capturing, Telephony Device Class: Miscellaneous, HCI Version: 4.2 (0x8) Revision: 0xfc LMP Version: 4.2 (0x8) Subversion: 0x6119 Manufacturer: Broadcom Corporation (15) 2. 使用 hcitool scan 命令扫描附近可供连接的蓝牙设备，并记下蓝牙耳机对应的 MAC 地址1234$ hcitool scanScanning ... FC:58:FA:F4:67:33 A2 50:8F:4C:0D:31:3A Starky 3. 通过 MAC 地址与蓝牙耳机进行配对使用 bluetoothctl 命令进入蓝牙控制台，依次通过 power on 、agent on 、scan on 、pair 、trust 、connect 等命令连接蓝牙设备。 注意此处连接蓝牙使用的是蓝牙设备的 MAC 地址。123456789101112131415161718192021$ bluetoothctl[NEW] Controller B8:27:EB:C3:38:31 raspberrypi [default][NEW] Device 50:8F:4C:0D:31:3A Starky...[bluetooth]# power onChanging power on succeeded[bluetooth]# agent onAgent registered[bluetooth]# scan onDiscovery started[bluetooth]# pair FC:58:FA:F4:67:33Attempting to pair with FC:58:FA:F4:67:33Pairing successful[bluetooth]# trust FC:58:FA:F4:67:33[CHG] Device FC:58:FA:F4:67:33 Trusted: yesChanging FC:58:FA:F4:67:33 trust succeeded[bluetooth]# connect FC:58:FA:F4:67:33Attempting to connect to FC:58:FA:F4:67:33[CHG] Device FC:58:FA:F4:67:33 Connected: yesConnection successful[A2]# 退出蓝牙控制台，使用 hcitool con 命令查看当前已连接的蓝牙设备，确认连接成功：123$ hcitool conConnections: &gt; ACL FC:58:FA:F4:67:33 handle 11 state 1 lm SLAVE AUTH ENCRYPT 4. 将音频输出设备切换为蓝牙耳机首先安装 PulseAudio 软件包：$ sudo apt-get install pulseaudio pulseaudio-module-bluetooth 启动 PulseAudio 守护进程：$ pulseaudio --start 列出 PulseAudio 检测到的音频设备名称：1234$ pacmd list-sinks short | grep -e &apos;name:&apos; name: &lt;alsa_output.platform-soc_audio.analog-mono&gt; name: &lt;bluez_sink.FC_58_FA_F4_67_33.headset_head_unit&gt; 使用 pactl 命令将蓝牙耳机作为默认的音频设备：$ pactl set-default-sink bluez_sink.FC_58_FA_F4_67_33.headset_head_unit 此时，即可直接使用 play 命令通过蓝牙耳机播放音频文件： 如果需要将音频输出切换回系统默认，运行如下命令即可：$ pactl set-default-sink alsa_output.platform-soc_audio.analog-mono 或者自己对当前的音频配置有点混乱了。。。可以使用如下命令重置：$ sudo /etc/init.d/alsa-utils reset 5. 注意事项经过测试，发现蓝牙耳机连接后音质相差太大，播放速度明显放缓，未确定是哪里的问题。 同时我的蓝牙耳机开启后会自动连接至树莓派，如无法自动连接或者连接以后并没有被 PulseAudio 检测到，可以先使用 bluetoothctl 命令进入蓝牙控制台：依次输入 power off、power on 命令重启蓝牙，使用 connect &lt;MAC address&gt; 命令重新连接蓝牙耳机（无需再配对和信任，直接连接）。 蓝牙耳机为默认音频设备后，之前配置 USB 声卡为默认的操作不再生效（除非断开蓝牙或关闭蓝牙耳机）。可以在播放或录制时通过 -t alsa plughw:1 选项手动指定 USB 声卡。如 $ sox -t alsa plughw:1 -d ：使用 USB 声卡作为音频输入源，再将采集到的音频输出到默认设备（蓝牙耳机） 这一章的蓝牙介绍只供参考，推荐使用 USB 声卡进行音频的录制和播放。 五、配置 VoIP 服务器VoIP 即 Voice over Internet Protocol ，就是将声音信号经过压缩与封包之后，以数据封包的形式在IP网络间进行传输。通俗地说也就是互联网电话或IP电话。 这里使用 Linux 平台上的 SIP Witch 软件作为 VoIP 系统的服务端。 1. 安装 SIP Witch$ sudo apt-get install sipwitch 2. 编辑配置文件/etc/default/sipwtich ：找到 PLUGINS 选项，删除该行前面的注释 /etc/sipwitch.conf ：编辑文件内容，在 &lt;provision&gt; 标签下添加用户注册信息：12345678910&lt;user id=&quot;phone1&quot;&gt; &lt;extension&gt;201&lt;/extension&gt; &lt;secret&gt;SecretSauce201&lt;/secret&gt; &lt;display&gt;Agent 201&lt;/display&gt;&lt;/user&gt;&lt;user id=&quot;phone2&quot;&gt; &lt;extension&gt;202&lt;/extension&gt; &lt;secret&gt;SecretSauce202&lt;/secret&gt; &lt;display&gt;Agent 202&lt;/display&gt;&lt;/user&gt; 其中的 id 表示注册用户登录时需要输入的用户名，&lt;secret&gt; 表示登录时使用的密码。 找到 &lt;stack&gt; 标签，并在其后添加如下一行配置，用于指定 VoIP 服务器的IP地址：&lt;localnames&gt;[Your Pi&#39;s IP address]&lt;/localnames&gt; 编辑完成后，重启 sipwitch 服务：$ sudo systemctl restart sipwitch 3. 客户端配置Windows 系统“软电话”可使用 MicroSIP 软件，Android 客户端可使用 CSipSimple，Mac 客户端有 Telephone。 使用 /etc/sipwitch.conf 文件中定义的用户ID、密码以及服务器地址完成用户注册，各客户端之间即可直接拨打语音电话。 参考资料Raspberry Pi for Secret Agents - Third Edition]]></content>
      <categories>
        <category>IoT</category>
      </categories>
      <tags>
        <tag>Media</tag>
        <tag>Audio</tag>
        <tag>Raspberrypi</tag>
        <tag>SecretAgent</tag>
        <tag>sox</tag>
        <tag>VoIP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NodeMCU 开发板刷入 MicroPython 固件并通过 Atom 进行编程]]></title>
    <url>%2F2018%2F12%2F28%2Fprogramming-esp8266-with-micropython%2F</url>
    <content type="text"><![CDATA[MicroPython 是对 Python 3 语言的一种精简的实现，主要是为了在微控制器这种硬件资源受限的环境中可以高效地运行，因此做了很多针对性的优化。它类似于一个小型的 Python 操作系统，可以通过串口与内置的 Python 解释器直接交互，也可以上传程序文件在开机上电后自动运行。MicroPython 支持多种开发板，包括价格很实惠的基于 ESP8266 芯片的 NodeMCU。 一、刷入固件我这里使用的开发板是从网上购买的 NodeMCU ，出厂时预先刷好了基于 Lua 语言编程的固件。为了使用 MicroPython ，需要先对该开发板重新刷写固件。 1. 准备工作首先进入 MicroPython 官方的下载页面，下载最新版的针对 ESP8266 硬件的固件包。我这里使用的是 esp8266-20180511-v1.9.4.bin 。 刷写软件可以使用支持多种操作系统的命令行工具 esptool。对于已经装好 Python 环境的电脑，直接使用 pip 命令安装即可：pip install esptool 2. 刷入固件首先将 NodeMCU 开发板连接至电脑，Mac 系统可以使用 ls /dev/tty.usbserial* 命令查看当前系统已经检测到的 USB 串口：12$ ls /dev/tty.usbserial*/dev/tty.usbserial-14110 使用 esptool.py -p &lt;SerialPort&gt; flash_id 命令确认该串口是否能成功检测到 ESP8266 设备：123456789101112131415$ esptool.py -p /dev/tty.usbserial-14110 flash_idesptool.py v2.5.1Serial port /dev/tty.usbserial-14110Connecting....Detecting chip type... ESP8266Chip is ESP8266EXFeatures: WiFiMAC: 2c:3a:e8:06:aa:7eUploading stub...Running stub...Stub running...Manufacturer: c8Device: 4016Detected flash size: 4MBHard resetting via RTS pin... 使用 esptool.py -p &lt;SerialPort&gt; erase_flash 命令对开发板进行擦除操作（以防万一）：1234567891011121314$ esptool.py -p /dev/tty.usbserial-14110 erase_flashesptool.py v2.5.1Serial port /dev/tty.usbserial-14110Connecting....Detecting chip type... ESP8266Chip is ESP8266EXFeatures: WiFiMAC: 2c:3a:e8:06:aa:7eUploading stub...Running stub...Stub running...Erasing flash (this may take a while)...Chip erase completed successfully in 2.5sHard resetting via RTS pin... 擦除完成后即可使用 esptool 工具的 write_flash 命令将 MicroPython 固件刷入开发板。（完整命令为：esptool.py -p &lt;SerialPort&gt; --baud 460800 write_flash --flash_size=detect -fm dio 0 &lt;FirmwareFile&gt;）12345678910111213141516171819202122$ esptool.py -p /dev/tty.usbserial-14110 --baud 460800 write_flash --flash_size=detect -fm dio 0 ~/Downloads/esp8266-20180511-v1.9.4.binesptool.py v2.5.1Serial port /dev/tty.usbserial-14110Connecting....Detecting chip type... ESP8266Chip is ESP8266EXFeatures: WiFiMAC: 2c:3a:e8:06:aa:7eUploading stub...Running stub...Stub running...Changing baud rate to 460800Changed.Configuring flash size...Auto-detected Flash size: 4MBFlash params set to 0x0240Compressed 604872 bytes to 394893...Wrote 604872 bytes (394893 compressed) at 0x00000000 in 9.9 seconds (effective 490.0 kbit/s)...Hash of data verified.Leaving...Hard resetting via RTS pin... 二、固件测试刷写固件的操作完成后，可以使用 Mac 系统自带的串口调试工具 cu 连接 USB 串口，对刚刷好的开发版进行测试：sudo cu -l &lt;SerialPort&gt; -s &lt;BaudRateSpeed&gt;效果如下：12$ sudo cu -l /dev/tty.usbserial-14110 -s 115200Connected. 终端窗口提示 Connected 之后，按下 NodeMCU 板子上的 RST (Reset) 按钮。如固件刷写成功，则终端在输出部分乱码后会立即进入 Python 解释器界面：123MicroPython v1.9.4-8-ga9a3caad0 on 2018-05-11; ESP module with ESP8266Type &quot;help()&quot; for more information.&gt;&gt;&gt; 在解释器界面下，输入 help() 命令获取基本的帮助信息：12345678910111213141516171819202122232425262728MicroPython v1.9.4-8-ga9a3caad0 on 2018-05-11; ESP module with ESP8266Type &quot;help()&quot; for more information.&gt;&gt;&gt; help()Welcome to MicroPython!For online docs please visit http://docs.micropython.org/en/latest/esp8266/ .For diagnostic information to include in bug reports execute &apos;import port_diag&apos;.Basic WiFi configuration:import networksta_if = network.WLAN(network.STA_IF); sta_if.active(True)sta_if.scan() # Scan for available access pointssta_if.connect(&quot;&lt;AP_name&gt;&quot;, &quot;&lt;password&gt;&quot;) # Connect to an APsta_if.isconnected() # Check for successful connection# Change name/password of ESP8266&apos;s AP:ap_if = network.WLAN(network.AP_IF)ap_if.config(essid=&quot;&lt;AP_NAME&gt;&quot;, authmode=network.AUTH_WPA_WPA2_PSK, password=&quot;&lt;password&gt;&quot;)Control commands: CTRL-A -- on a blank line, enter raw REPL mode CTRL-B -- on a blank line, enter normal REPL mode CTRL-C -- interrupt a running program CTRL-D -- on a blank line, do a soft reset of the board CTRL-E -- on a blank line, enter paste modeFor further help on a specific object, type help(obj)&gt;&gt;&gt; 更多的交互命令和详细的指导手册可以参考官方文档 使用如下的命令，能够让 GPIO2 上连接的 LED（即 ESP8266 模块内置的蓝色 LED）以 1s 的频率闪烁：1234567891011&gt;&gt;&gt; from machine import Pin&gt;&gt;&gt; import time&gt;&gt;&gt; p=Pin(2,Pin.OUT)&gt;&gt;&gt; while True:... p.on()... time.sleep(1)... p.off()... time.sleep(1)......... 三、配置 Atom 编程环境当前可以使用多种软件作为简单的 IDE 对 MicroPython 开发板进行编程。主要是提供连接串口的终端，可以交互地执行 Python 命令，以及程序文件的上传和下载。 我个人比较喜欢 Atom 编辑器搭配上 pymakr-atom 插件。 Atom 的配置较简单，主要步骤如下： 从 Atom 官网下载对应系统版本的安装程序并安装 通过 Atom 内置的插件管理器搜索安装 pymakr 插件，安装完成后重启编辑器 编辑器重启后底部自动出现 pymakr 的终端窗口，点击终端右上角设置 - 全局设置，找到设备地址并改为开发板连接的端口号 直接点击终端顶部的连接按钮即可完成串口连接 此时的 Atom 编辑器，可以通过底部的终端窗口直接输入 Python 命令。也可以在编辑器中新建项目目录，并创建 main.py 源文件。编辑好 Python 代码后，点击执行按钮即可直接运行，或者点击上传按钮将代码文件上传至开发板。 参考资料MicroPython documentation]]></content>
      <categories>
        <category>IoT</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Programming</tag>
        <tag>IoT</tag>
        <tag>ESP8266</tag>
        <tag>Microcontroller</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SoX — 音频处理工具里的瑞士军刀]]></title>
    <url>%2F2018%2F12%2F18%2Fprocessing-audio-with-sox%2F</url>
    <content type="text"><![CDATA[SoX（即 Sound eXchange）是一个跨平台（Windows，Linux，MacOS 等）的命令行实用程序，可以将各种格式的音频文件转换为需要的其他格式。SoX 还可以对输入的音频文件应用各种效果，也支持在大多数平台上播放和录制音频文件。 一、简介SoX 可以读取和写入常见格式的音频文件，并在此过程中选择性的加入一些声音效果。它可以组合多个输入源及合成音效，在许多系统上也可以作为音频播放器或多轨录音机使用。SoX 工具在大部分 Linux 系统上都可以直接通过软件包管理器安装（如 sudo apt-get install sox），Mac 系统上则可以使用 brew install sox 命令。 SoX 处理音频的基本流程如下：Input(s) -&gt; Combiner -&gt; Effects -&gt; Output(s) SoX 工具的所有功能都可以通过一个简单的 sox 命令及相应的选项实现。但它同时提供了 play 命令用于播放音频文件，rec 命令用于录制音频，以及 soxi 命令用于获取音频的文件头中包含的信息。 上述几个命令的基本格式如下：12345678910111213SYNOPSIS sox [global-options] [format-options] infile1 [[format-options] infile2] ... [format-options] outfile [effect [effect-options]] ... play [global-options] [format-options] infile1 [[format-options] infile2] ... [format-options] [effect [effect-options]] ... rec [global-options] [format-options] outfile [effect [effect-options]] ... soxi [-V[level]] [-T] [-t|-r|-c|-s|-d|-D|-b|-B|-p|-e|-a] infile1 ... 二、基本使用1. 获取音频文件的元数据soxi 或 sox --i 命令可以通过分析音频文件的文件头，获取其元数据（如通道数、采样率、编码等）。12345678910$ soxi Faded.wavInput File : &apos;Faded.wav&apos;Channels : 2Sample Rate : 44100Precision : 16-bitDuration : 00:03:32.63 = 9376836 samples = 15947 CDDA sectorsFile Size : 37.5MBit Rate : 1.41MSample Encoding: 16-bit Signed Integer PCM soxi 命令跟上某个特定的选项可以只获取该选项对应的信息，如只显示某音频文件 Faded.wav 的比特率（Bit Rate）：12$ soxi -B Faded.wav1.41M soxi 命令支持的所有选项及其含义如下：1234567891011121314151617$ soxiUsage: soxi [-V[level]] [-T] [-t|-r|-c|-s|-d|-D|-b|-B|-p|-e|-a] infile1 ...-t Show detected file-type-r Show sample-rate-c Show number of channels-s Show number of samples (0 if unavailable)-d Show duration in hours, minutes and seconds (0 if unavailable)-D Show duration in seconds (0 if unavailable)-b Show number of bits per sample (0 if not applicable)-B Show the bitrate averaged over the whole file (0 if unavailable)-p Show estimated sample precision in bits-e Show the name of the audio encoding-a Show file comments (annotations) if availableWith no options, as much information as is available is shown foreach given file. 2. 获取音频的统计信息可以使用 sox &lt;inputfile&gt; -n stat 命令获取某音频文件的统计信息。示例如下：12345678910111213141516$ sox Faded.wav -n statSamples read: 18753672Length (seconds): 212.626667Scaled by: 2147483647.0Maximum amplitude: 0.977417Minimum amplitude: -0.977478Midline amplitude: -0.000031Mean norm: 0.229415Mean amplitude: -0.000006RMS amplitude: 0.302594Maximum delta: 1.765564Minimum delta: 0.000000Mean delta: 0.202369RMS delta: 0.273320Rough frequency: 6339Volume adjustment: 1.023 3. 播放与录制play 和 rec 命令提供了最基本的播放和录制功能。播放：$ play existing-file.wav录制：$ rec new-file.wav 上述命令等同于 sox 命令的如下形式：$ sox existing-file.wav −d（播放）和 sox −d new-file.wav（录制）其中 -d 选项用于指定播放或录制时使用的音频设备，不指定时则表示使用默认设备。 可以这样理解： sox existing-file.wav -d 就是从 existing-file.wav 文件中读取其包含的音频数据，再输出到 -d （默认音频设备，扬声器）进行播放； sox -d new-file.wav 就是从 -d （默认音频设备，麦克风）中读取音频数据，再输出（录制）到 new-file.wav 文件中。 其实都遵循了一个基本的格式，即 sox &lt;input&gt; &lt;output&gt; 。而其中的 &lt;input&gt; 和 &lt;output&gt; 根据需要既可以为某个具体的音频文件，也可以是某个具体的音频设备。 播放或录制的同时，也可以对音频文件应用指定的编辑操作或效果选项，因此在对音频数据应用某效果前，可以先使用 play 命令进行“预览”。 如 trim 效果可以从音频文件中裁剪提取指定的片段到输出文件。play 命令通过该效果可以直接播放指定片段：$ play foo.wav trim 10.0 5.0 或 $ play foo.wav trim 10.0 =15.0播放 foo.wav 文件中 10-15s 之间的音频片段 使用 echo 效果播放 Faded.wav 文件：123456789101112$ play Faded.wav echo 0.8 0.88 200.0 0.4Faded.wav: File Size: 37.5M Bit Rate: 1.41M Encoding: Signed PCM Channels: 2 @ 16-bitSamplerate: 44100HzReplaygain: off Duration: 00:03:32.63In:12.1% 00:00:25.82 [00:03:06.81] Out:1.14M [-=====|=====-] Hd:2.7 Clip:0 4. 音频格式转换文件格式类型对于音频数据格式的描述，主要通过以下 4 种属性： 采样率（sample rate）：指声音由模拟信号转换成数字信号的过程中，每秒从连续信号中提取的用于组成离散信号的样本个数。音频CD所用的采样率为 44100 Hz，数字音频磁带和许多计算机系统使用 48000 Hz，专业级音频系统通常使用 96000 Hz。 采样大小（sample size 或 Precision）：音频采样时用于存储每个样本的数据位数（bits）。如今 16 bit 的采样大小已被广泛使用，24 bit 主要用于专业音频领域。 编码格式（data encoding）：即每个音频样本的表示（即“编码”）方式。常用的编码类型包括 floating-point、μ-law、ADPCM、singed-integer PCM、MP3 和 FLAC 等。 通道（channel）：即文件中包含的音频通道的数量。其中单声道（mono）和双声道（stereo）是最常见的两种，“环绕声”音频（Surround sound）通常包含六个或更多声道。 此外，音频文件还使用比特率（Bit Rate）表示一个单位时间内编码音频信号占用的存储空间大小， 它的数值一般取决于所有的上述四个参数。MP3 编码的立体声音乐通常具有 128-196kbps 的比特率， FLAC 编码的立体声音乐通常具有 550-760kbps 的比特率。 我个人是这样想的，，，可以将一段音频数据看成很长很长的一排苹果树，从头走到尾，每隔一段距离停下，摘下满满一筐苹果。。。筐的大小就是采样大小，停下来采摘的次数就是采样频率，比特率就是把一定数量的苹果“榨成汁”（以特定的格式对音频编码）以后的重量，当然有些榨汁方法会造成一定的损失。 格式转换形式最简单的 sox 命令即使用两个文件名作为参数，如：$ sox Faded.wav Faded.mp3 ：将 Faded.wav 文件的格式由 wav 转为 mp3 上述命令执行时，SoX 会先从 Faded.wav 文件中读取音频数据，再将其输出到 Faded.mp3 文件中。而 SoX 程序会根据参数中文件名的后缀推断出相应的格式，并在复制音频数据的过程中自动进行转码。 SoX 可以处理 self-describing 和 raw 格式的音频文件。self-describing 格式（如 WAV、FLAC、MP3）的文件包含一个用于描述信号和编码属性的文件头，而 raw 或 headless 格式的音频则不包含这些信息。 所以当 raw 格式的音频作为输入文件时，需要在 sox 命令的格式选项里指定其信号和编码属性。 常用的音频格式选项： 选项 描述 b 每个编码样本占用的数据位数 c 音频文件包含的通道数 e 音频文件的编码类型 r 音频文件的采样率 t 音频文件的文件类型 上述选项适用于输入或输出文件，主要用于说明 raw（或 headless）文件作为输入时的格式信息，或格式转换时指定输出文件的具体参数。 $ sox −r 48k −e float −b 32 −c 2 input.raw output.wav将某个特定的 raw 格式的音频文件转换为 wav 格式 $ sox Faded.wav Faded.raw将音频文件 Faded.wav 转为 raw 格式 $ play -r 44800 -b 16 -e signed-integer -c 2 Faded.raw播放 raw 格式的音频文件 $ sox Faded.wav -c 1 Faded-mono.wav将 Faded.wav 文件转换成单声道（-c 1）后输出 三、音频效果SoX 工具可以在音频处理的过程中，对输入的音频数据应用众多的效果。可以使用如下命令查看所有效果的帮助信息：1234567891011121314151617181920212223$ sox --help-effect all | lesssox: SoX vEffect usage:allpass frequency width[h|k|q|o]band [-n] center [width[h|k|q|o]]bandpass [-c] frequency width[h|k|q|o]bandreject frequency width[h|k|q|o]bass gain [frequency(100) [width[s|h|k|q|o]](0.5s)]bend [-f frame-rate(25)] [-o over-sample(16)] &#123;start,cents,end&#125;: 也可以直接查看具体某个音频效果的使用方法：123456$ sox --help-effect echosox: SoX vEffect usage:echo gain-in gain-out delay decay [ delay decay ... ] 以下是一些简单的应用场景。 1. 更改声道数sox 命令可以更改音频文件中声道的数目，如将单声道音频转换成双声道：$ sox foo.wav foostereo.wav channels 2 或 $ sox foo.wav -c 2 foostereo.wav 但是上述命令并没有创建一个“真实”的双声道音频，而是将单声道音频复制成完全一致的两个声道再合并到输出文件中。 可以通过 sox 命令的 -M 选项将左右两个声道的单声道音频合并成一个双声道文件：$ sox -M left.wav right.wav stereo.wav 当然，也可以通过对双声道文件中两个声道的均一化处理，将其输出为单声道音频：$ sox original.wav mono.wav channels 1 或 $ sox original.wav -c 1 mono.wav remix通过 sox 命令的 remix 效果也可以完成对声道数据的提取或融合。 提取双声道音频文件中单个声道的数据并作为单声道音频输出：$ sox stereo.wav left.wav remix 1 （提取左声道音频）$ sox stereo.wav right.wav remix 2 （提取右声道音频） 融合双声道文件中两个声道的音频数据并作为单声道音频输出：$ sox stereo.wav mono.wav remix 1,2 或$ sox stereo.wav mono.wav remix 1-2 此外，remix 还可以将输入文件中的多个声道数据分别进行融合。如使用 -M 选项将两个双声道音频合并，再通过 remix 将合并得到的四个声道两两融合，生成一个只包含两个声道的输出文件。$ sox -M stereo1.wav stereo2.wav output.wav remix 1,3 2,4 2. 改变音量sox 命令的 -v 选项可以用来（成倍地）改变音量的大小：$ sox -v 0.5 foo.wav bar.wav上述命令将 foo.wav 音频放大 0.5 倍音量后输出至 bar.wav 文件 可以将音量放大功能与 stat 效果结合。以 sox foo.wav -n stat -v 命令返回的数字作为放大倍数，将最大化 foo.wav 的音量而不至于出现削波：12$ sox foo.wav -n stat -v 2&gt; vc$ sox -v `cat vc` foo.wav foo-maxed.wav 此外，还有一个选项 --norm 用来归一化音频响度。为了最大化音频的声音强度，可以在处理输入音频时将该选项设置为 -1：sox --norm=-1 &lt;inputfile&gt; &lt;outputfile&gt; 3. 提取文件的某个部分sox 命令的 trim 效果可以将输入音频的某一段裁剪出来并提取到输出文件中。 trim 接收两个参数，一个作为裁剪片段的起始位置，另一个作为该片段持续的时间。可以使用整数+s格式的参数以样本个数作为计量单位，也可以直接使用 ((hh:)mm:)ss(.fs) 形式的时间参数。当参数为纯整数时，单位为秒。 $ sox Input.wav Half1.wav trim 0 30:00 截取输入文件中前 30 分钟的音频$ sox Input.wav Half2.wav trim 30:00 30:00 截取输入文件中从第 30 分钟开始到第 60 分钟的音频 4. 拼接文件与前面裁剪提取的操作相反，sox 命令还可以实现对两个或多个音频文件的拼接。 $ sox Half1.wav Half2.wav Full.wav将 Half1.wav 和 Half2.wav 合并至 Full.wav 文件。注意合并前的音频文件需保持一致的类型和采样率等。 5. 合成音频sox 命令可以通过 synth 效果合成许多标准波形和噪声类型。 $ sox -n sine.wav synth 1.0 sine 1000.0合成频率为 1000 Hz 长度为 1 秒的正弦波，保存至 sine.wav 文件中。 synth 支持合成的声音类型包括 sine、square、triangle、sawtooth、trapetz (trapezoidal)、exp (exponential)、whitenoise、pinknoise 和 brownnoise。 6. 静音效果sox 命令可以创建静音状态的音频片段，使用 -n 选项表示没有输入，通过 trim 效果指定需要静音的片段。 $ sox -n -r 48000 silence.wav trim 0.0 0.250在 slience.wav 文件中创建一段长度为 250ms 采样率为 48000Hz 的静音片段。 7. 混合音频sox 命令的 -m 选项可以将两个音频文件混合以后生成输出文件。 $ sox -m sine100.wav sine250.wav sine100-250.wav将 sine100.wav 和 sine250.wav 两个音频文件融合以后作为 sine100-250.wav 文件的音频数据。 $ sox -m -v0.5 music.mp3 -v2 speech.wav presentation.wav将背景音乐（music.mp3）音量降低一半后与放大 2 倍音量的人声数据（speech.wav）融合。 如果不确定融合效果，可以先通过 play 命令使用相同的参数对结果进行“预览”：$ play -m -v0.5 music.mp3 -v2 speech.wav PS：与前面的 -M 选项不同，-m 选项倾向于对声道数据的混合，即两个单声道文件通过 -m 混合以后输出仍是单声道数据。输出文件中的单个声道包含了输入的两个声道的特征。 而 -M 选项更倾向于对音频文件的合并，默认不对声道数据进行混合。所以两个单声道文件通过 -M 合并以后默认输出双声道音频。输出文件中的两个声道分别对应于输入的两个声道（数据没有混合）。除非通过 -c 选项手动指定输出文件的声道数量。 8. 改变播放速度可以通过 stretch 效果改变音频文件的播放速度，同时不会导致音高的变化。 如以 2x 倍速播放 Faded.wav 文件：$ play Faded.wav stretch 0.5 也可以通过 speed 效果调节播放速度（相应地音高也会发生变化）：$ play Faded.wav speed 2 此外，可以使用 pitch 效果调节音频片段的音高，以音分（cents）为单位。 $ play Faded.wav pitch 200将 Faded.wav 文件中的音频提高 200 音分，即提高 2 个半音的音程（每一个半音的音程等于 100 音分）。 参考资料SoXUsing SoxHow to process audio files from the command line with SoX]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Tools</tag>
        <tag>Software</tag>
        <tag>Media</tag>
        <tag>Audio</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 使用 crontab 创建定时任务]]></title>
    <url>%2F2018%2F12%2F14%2Fmake-schedule-using-crontab%2F</url>
    <content type="text"><![CDATA[Linux 系统里的 cron 守护进程，可以跟随系统启动，是一个用来创建定时任务的基本工具。所谓定时或计划任务，指的是在某些特定的时间点自动地执行特定的命令。这些相对应的时间点和命令可以在其配置文件 Crontab 中设置。 Crontabcrontab 即 cron table 的缩写，是 cron 程序的配置文件。其中包含了对每一条计划任务的具体配置。可以在命令行中使用 crontab -e 命令对该配置文件进行编辑。 使用限制 只有当用户的账号出现在 /usr/lib/cron/cron.allow 文件中时，该用户才可以使用 crontab 命令 如 /usr/lib/cron/cron.allow 文件不存在，而用户的账号没有出现在 /usr/lib/cron/cron.deny 文件中，该用户可以使用 crontab 命令 当只存在 cron.deny 文件且该文件内容不为空，则系统中所有用户都可以使用 crontab 两个文件都不存在时，则只有 root 用户可以访问 crontab 命令选项 crontab filename 从 filename 文件中导入配置，并替代之前的内容 crontab -e 编辑配置文件 crontab 的内容，定义计划任务 crontab -l 列出当前用户已经定义好的计划任务 crontab -r 移除当前用户的 crontab 配置文件（删除该用户所有的计划任务）配置文件格式crontab 配置文件中的每一行内容都代表了对某个计划的定义，一共分成 6 个字段。前 5 个字段定义时间，最后一个字段表明执行的命令。具体如下：minute hour day month weekday command 各时间字段的含义和取值范围如下： 字段 描述 取值范围 minute 具体某分钟 0 到 59 hour 具体某小时 0 到 23 day 一个月内的某天 1 到 31 month 具体某个月份 1 到 12 weekday 一周内的某天 0 到 6（0=周日） 时间字段的合法格式： 单独的数字（n）：表示当前时间单位下某个特定的时间点 被 - 连接的两个数字（n1-n2）：表示当前时间单位下的某个时间范围 由逗号分隔的多个数字或范围（n1,n2,n3...）：表示当前时间单位下多个时间点（段） 星号（*）：表示当前时间范围下的所有时间点（段） 时间范围和步长（n1-n2/n）：表示在某个时间范围内，每隔一段固定的时长，执行一次特定的命令 如： minute hour day/month month day/week 任务执行时间 30 9 14 3 * 每年3月14号的上午9点30分 0 2 * * 6 每个周六的凌晨2点整 45 8 * * 1-5 每周一到周五的上午8点45分 0 0 1,15 * * 每个月1号或15号半夜0点 0 * 13 * 5 每个月13号的整点，或者每个周五的整点 */10 * * * * 每隔10分钟 二、配置示例 30 1 * * * find /tmp -atime +3 -type f -exec rm -f {} &#39;;&#39;每天凌晨1点半，使用 find 命令查找 /tmp 目录下所有3天以上没有被访问过的文件，并将它们全部删除 30 2 * * 1 cd /home/joe/project; make每天凌晨2点半，进入 /home/joe/project 目录并执行 make 命令]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Admin</tag>
        <tag>System</tag>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我喜欢的开源软件合集（设计类）]]></title>
    <url>%2F2018%2F12%2F11%2Fmy-favorite-opensource-design-software%2F</url>
    <content type="text"><![CDATA[本人非专业设计人员，甚至连业余都算不上。。。只是平时无聊，偶尔做点小东西聊以自娱。下面列出的软件多为自己平时用过或者想要学习的一些开源软件，主要面向设计类工作（如图像编辑、音视频剪辑、CAD和电子电路等）。稍作总结，并无足够的专业性与参考价值。 一、图像处理1. GIMPGIMP (GNU Image Manipulation Program) 是一个开源的图像处理工具，支持多种操作系统。其基本理念和操作都和 Adobe Photoshop 类似，对于使用过同类软件的人基本没有入手难度。 GIMP 既可以作为简单的画图程序，也能作为专家级的照片处理（包括照片润饰、图像合成和创建图像等）程序，或在线批处理系统、批量图像渲染器，以及图像格式转换工具等。GIMP 具有可延伸性和可扩展性，能通过扩展插件完成各种事情。其高级脚本接口允许用户通过编写简单的脚本完成从最简单到最复杂的各种图像处理过程。 特性与功能 完整的图像工具套件，包括画笔、铅笔、喷枪、克隆等。 基于平铺(Tile-based)的内存管理使图像大小限制在可用的磁盘空间内。 对所有涂画工具都使用次像素(Sub-pixel)取样，能产生高品质的反锯齿效果。 完全的 Alpha 通道支持。 支持图层和通道。 允许从外部程序(如 Script-Fu) 调用 GIMP 内部命令。 先进的脚本化处理能力。 多级撤消/重做(只受磁盘空间大小限制)。 变换工具包括旋转，缩放，切变和翻转。 支持包括 GIF、JPEG、PNG、XPM、TIFF、TGA、MPEG、PS、PDF、PCX、BMP 在内的多种文件格式。 选择工具包括矩形、椭圆、自由、模糊、贝赛尔曲线和智能剪刀。 通过插件可以轻松地添加对新文件格式的支持和效果滤镜。 相关资源 GIMP 官网 用户手册 官方教程 2. InkscapeInkscape 是一个开源的矢量图形编辑软件，功能类似于 Adobe Illustrator。只不过它使用 SVG (Scalable Vector Graphics) 作为原生的格式。 Inkscape 拥有复杂的绘图工具，常被设计从业人员及爱好者用于创建各种图形，如插图，图标，徽标，图表，地图和 Web 图形。同时也支持导入和导出各种文件格式，包括 SVG，AI，EPS，PDF，PS 和 PNG。 相关资源 Inkscape 官网 软件功能与特性 官方教程 Logos By Nick 的视频教程（YouTube） 3. KritaKrita 是一款开源的专业绘画软件，其目标是打造一款人人都用得起的数字绘画工具。适用于： 概念美术设计 材质与电影布景 插画和漫画等 相关资源 Krita 官网 功能介绍 用户手册 二、音视频剪辑1. AudacityAudacity 是一款开源的多轨道音频编辑软件。虽然界面看起来有点复古。。。但是功能很实用且非常容易上手。 软件特性 Audacity 可以通过麦克风或混音器录制现场音频，或者将其他媒体上的录音数字化 导入、编辑和组合声音文件，并以多种不同的文件格式导出录制内容 通过重采样和抖动完成高质量的采样率和格式转换，支持 16位、24位和32位音频 支持 LADSPA、LV2、Nyquist、VST 和 Audio Unit 效果插件。可以在文本编辑器中轻松修改效果，甚至可以编写自己的插件。 通过剪切、复制、粘贴和删除轻松编辑音频数据，无限制地顺序撤销和重做 LADSPA、LV2、VST 和音频单元（macOS）效果的实时预览 可以使用键盘快捷键完全操纵音频轨道和选区 频谱图视图模式用于可视化和选择频率； Plot Spectrum 窗口用于详细的频谱分析 相关资源Audacity 官网官方文档（在线版） 2. ShotcutShotcut 是一个开源且跨平台的视频剪辑软件，适用于 Windows、Mac 和 Linux 系统。主要功能包括多种音视频格式的支持、原生时间线编辑、分辨率支持 4k 等。 相关资源 Shotcut 官网 功能与特性 官方教程 3. HandBrakeHandBrake 是一种视频格式转换器，可以将视频从几乎任何格式转换为当前受广泛支持的编码格式。 相关资源 Handbrake 官网 特性 官方文档 三、3D建模与CAD1. BlenderBlender 是一个开源的3D动画套件，支持整个 3D建模、装配、动画、模拟、渲染、合成和运动跟踪等创作流程，甚至包含视频编辑和游戏创建功能。 Blender 是非常惊艳的 Big Buck Bunny 等开源动画电影的主要制作工具。嗯，不明觉厉。。。 相关资源Blender 官网功能与特性官方支持（文档、示例等）Blender 2.79 中文手册 2. OpenSCADOpenSCAD 是用于创建实体3D CAD模型的开源软件。与主要用于创作3D动画的开源软件 Blender 不同，它更关注于3D建模的CAD方面。OpenSCAD 不是一个交互式建模软件。相反，它类似于3D编译器，读入描述对象的脚本文件并通过脚本中定义的建模过程呈现3D模型。 OpenSCAD 提供了两种主要的建模技术：建设性的实体几何（onstructive solid geometry）以及对2D轮廓的挤压。Autocad DXF文件可用作此类2D轮廓的数据交换格式。 相关资源OpenSCAD 官网官方文档Github 主页 2. QCADQCAD 是一个用于二维计算机辅助绘图（CAD）的开源软件。可以用其创建建筑物、室内设计、机械部件或电路图等技术图表。支持 Windows, macOS 和 Linux 系统，其源代码在 GPLv3 协议下发布。 相关资源QCAD 官网功能与特性官方文档 3. SketchUpSketchUp 是一个闭源的3D建模软件，适用于建筑学、室内设计、景观建设、土木和机械工程、电影和视频游戏设计等多种绘图场景。SketchUp 是一种以易用性著称的 CAD 解决方案，使用该应用程序就像使用笔和纸绘图一样简单。它采用直接推拉的编辑技术，确保可以快速生成日常用品的模型。 SketchUp 包括一个免费的在线版应用程序 SketchUp Free，一个免费的桌面版应用程序 SketchUp Make（2017年12月以后停止更新，迁移到在线版。但仍提供下载），和一个带有附加功能的付费版本 SketchUp Pro。SketchUp 还提供一个在线的模型组件库（门窗、桌椅、花草等等）3D Warehouse，用户可以向其上传自己创作的模型，同时也支持模型的免费下载。 相关资源SketchUp 官网帮助中心官方 YouTube 电子电路1. EAGLEAutodesk EAGLE 是一款闭源的电子设计自动化（EDA）软件。它使得印刷电路板（PCB）设计人员能够轻松地完成原理图设计、元件布局、PCB布线等工作。EAGLE 有提供免费版供爱好者和创客使用。 原理图编辑器 使用一整套SPICE仿真方法快速测试方案并验证电路性能 在项目之间自由拖放可重复使用的区块，自动同步原理图和PCB电路 通过一整套电子规则检查验证原理图设计 PCB布局编辑器 使用一整套对齐工具精确地组合与排列PCB设计对象 根据预先定义的设计原则自适应地、交互式地完成路径选择 通过完全可定制的PCB设计规则和约束控制设计流程，避免无法预料的意外情况。 再一次不明觉厉。。。有点尴尬 相关资源EAGLE 官网特性与功能官方学习中心 2. FritzingFritzing 是一款电子设计自动化软件，学习难度非常低，很适合创客和业余爱好者们的需求，在 Arduino 和 Raspberry Pi 用户中非常受欢迎。它提供了真实的“面包板”视图，其丰富的零件库中也包含了许多常用的高级组件（如各种型号的 Arduino 板）。Fritzing 还可以将实物化的电子设计转换成可用于生产的PCB布局，不过貌似功能很基础。。。 相关资源Fritzing 官网Github 主页官方文档 3. TinkercadTinkercad是一款免费的用于3D设计、电子电路和编程的在线软件，主要面向老师、孩子、业余爱好者和设计师。该软件主要由 3D Designs 和 Circuits 两个模块构成，之所以放在电子电路这一小节，主要是我个人对它的 3D设计模块不太感冒（有点儿童化？）。。。不过创建用于 3D打印的模型应该是挺方便的。 倒是电路模块比较吸引我，界面类似于 Fritzing ，可以利用 Blocks 或者纯代码编写程序。竟然还支持仿真，能够真实地模拟出实际电路的运行状态（比如 LED 闪烁、舵机转动等）。 相关资源Tkinercad 官网素材库官方教程 其他（个人爱好）StellariumStellarium 是一款免费开源的天文馆软件，可以用来显示逼真的 3D星空景观，就像用肉眼、双筒望远镜或天文望远镜看到的一样。。。有手机版，不过好像从 Google 应用商店下载是付费的。移动版可以开启“跟随”模式，根据手机方向的变动自动切换显示的星空区域，野外看星星的利器。 相关资源Stellarium 官网 附注呃，有点划水了。。基本上相关资源都是官网的链接，，有时间好好找找其他地方有价值的资料。。]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Tools</tag>
        <tag>Software</tag>
        <tag>Opensource</tag>
        <tag>Design</tag>
        <tag>media</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux find 命令详解]]></title>
    <url>%2F2018%2F12%2F05%2FLinux-find-reference-manual%2F</url>
    <content type="text"><![CDATA[Linux 上的 find 命令是 findutil 软件包的一部分，一般已经默认集成在了几乎所有的发行版中。find 命令有非常大的灵活性，可以向其指定丰富的搜索条件（如文件权限、属主、属组、文件类型、日期和大小等）来定位系统中的文件和目录。此外，find 还支持对搜索到的结果进行多种类型的命令操作。 一、简介find 命令的基本结构如下：find [paths] [expression] [actions] find 命令接受一个或多个路径（paths）作为搜索范围，并在该路径下递归地搜索。即检索完指定的目录后，还会对该目录下的子目录进行检索，以及子目录下的子目录。。。直到到达目录树底部。 默认情况下（不带任何搜索条件），find 命令会返回指定目录下的所有文件，所以常常需要通过特定的 expression 对结果进行筛选。 find 命令默认的 action 是将所有检索结果打印至标准输出。可以通过自定义 action ，让 find 命令对搜索到的结果执行特定的操作。 这里先不做详细解释，简单地测试下 find 命令： 有如下结构的示例目录 directory 1234567891011121314$ tree directorydirectory├── file1├── file2├── sub-dir1│ ├── file1│ ├── file2│ └── file3└── sub-dir2 ├── file2 └── sub-subdir1 └── file13 directories, 7 files 默认的 find 命令会列出该目录下的所有文件 123456789101112$ find directorydirectorydirectory/sub-dir1directory/sub-dir1/file3directory/sub-dir1/file2directory/sub-dir1/file1directory/file2directory/sub-dir2directory/sub-dir2/file2directory/sub-dir2/sub-subdir1directory/sub-dir2/sub-subdir1/file1directory/file1 为 find 命令指定 expression 以筛选出特定的文件 1234$ find directory -name file2directory/sub-dir1/file2directory/file2directory/sub-dir2/file2 为 find 命令指定特殊的 action（此处 -delete 表示删除搜索结果） 12345678910$ find directory -name file2 -delete$ find directorydirectorydirectory/sub-dir1directory/sub-dir1/file3directory/sub-dir1/file1directory/sub-dir2directory/sub-dir2/sub-subdir1directory/sub-dir2/sub-subdir1/file1directory/file1 二、搜索条件（expression）1. 根据文件名检索find 命令中的 -name 选项可以根据文件名称进行检索（区分大小写）。如需要忽略文件名中的大小写，可以使用 -iname 选项。 -name 和 -iname 两个选项都支持 wildcards 。如： ? 可以表示任意一个单一的符号 * 可以表示任意数量（包括 0）的未知符号 find /usr -name &#39;*.txt&#39; 查找 /usr 目录下所有文件名以 .txt 结尾的文件find /usr -name &#39;????&#39; 查找 /usr 目录下所有文件名刚好为 4 个字符的文件 有些时候，你需要在搜索时匹配某个文件或目录的完整路径，而不仅仅是匹配文件名。可以使用 -path 或 -ipath 选项。 如查找 /usr 下所有文件名以 .txt 结尾的文件或目录，且该文件的父目录必须是 src。可以使用以下命令：find /usr -path &#39;*/src/*.txt&#39; 2. 根据文件类型检索如果只想搜索得到文件或目录，即不想它们同时出现在结果中。可以使用 -type 选项指定文件类型。 -type 选项最常用的参数如下： f: 文件 d: 目录 l: 符号链接 find /usr -type d -name &#39;python*&#39; 检索 /usr 下所有文件名以 python 开头的目录 3. 检索空文件find 命令支持 -empty 选项用来检索为空的文件或目录。空文件即文件里没有任何内容，空目录即目录中没有任何文件或子目录。 find ~ -type d -empty 检索用户主目录下所有的空目录 4. 反义匹配find 命令也允许用户对当前的匹配条件进行“反义”（类似于逻辑非操作）。 如需要检索 /usr 下所有文件名不以 .txt 为后缀的文件。可以使用以下命令：find /usr -type f ! -name &#39;*.txt&#39; 也可以“翻转”任何其他的筛选条件，如：find /usr -type f ! -empty 检索 /usr 下所有内容不为空的文件 5. 根据文件的所属权检索为了检索归属于特定用户的文件或目录，可以使用 -user 选项。 find / -type f -user starky 检索根目录下所有属主为 starky 的文件 类似于 -user选项，-group 选项则可以根据文件或目录的属组进行检索。 6. 根据时间日期进行检索有些时候，需要根据文件创建或修改的时间进行检索。 Linux 系统中，与文件相关联的时间参数有以下三种： 修改时间（Modification time）：最后一次文件内容有过更改的时间点 访问时间（Access time）：最后一次文件有被读取过的时间点 变更时间（Change time）：最后一次文件有被变更过的时间点（如内容被修改，或权限等 metadata 被修改） 与此对应的是 find 命令中的 -mtime，-atime 和 -ctime 三个选项。 这三个选项的使用遵循以下示例中的规则： -mtime 2：该文件 2 天前被修改过 -mtime -2：该文件 2 天以内被修改过 -mtime +2：该文件距离上次修改已经超过 2 天时间 find /usr -type f -mtime 2 检索 /usr 下两天前被修改过的文件 如果觉得 -mtime 等选项以天为单位时间有点长，还可以使用 -mmin，-amin，-cmin 三个选项：find /usr -type f -mtime +50 -mtime -100 检索 /usr 下 50 到 100 天之前修改过的文件find /usr -type f -mtime 2 -amin 5 检索 /usr 下两天前被修改过且 5 分钟前又读取过的文件 7. 根据文件大小检索-size 选项允许用户通过文件大小进行搜索（只适用于文件，目录没有大小……）。 表示文件大小的单位由以下字符组成： c：字节 k：Kb M：Mb G：Gb 另外，还可以使用 + 或 - 符号表示大于或小于当前条件。 find / -size +1G 检索文件大小高于 1 GB 的文件 8. 根据文件权限检索find 命令可以使用 -perm 选项以文件权限为依据进行搜索。 使用符号形式如需要检索 /usr 目录下权限为 rwxr-xr-x 的文件，可以使用以下命令：find /usr -perm u=rwx,g=rx,o=rx 搜索 /usr 目录下所有权限为 r-xr-xr-x（即系统中的所有用户都只有读写权限）的文件和目录，可以使用以下命令：find /usr -perm a=rx 很多时候，我们只想匹配文件权限的一个子集。比如，检索可以直接被任何用户执行的文件，即只关心文件的执行权限，而不用管其读写权限是什么。 上述的需求可以通过以下命令实现：find / -type f -perm /a=x其中 a=x 前面的 / 符号即用来表示只匹配权限的某个子集（执行权限），而不用关心其他权限的具体设置。 使用数字形式-perm 选项也支持数字形式的文件权限标记。 find /usr -perm 644 搜索 /usr 目录下权限为 644（即 rwxr-xr-x）的文件 9. 限制遍历的层数find 命令默认是以递归的方式检索项目的，这有时候会导致得到的结果数量非常巨大。可以使用 -maxdepth 限制 find 命令递归的层数。 find / -maxdepth 3 搜索时向下递归的层数最大为 3 10. 逻辑组合在之前的例子中有出现多个搜索条件的组合以及对某个搜索条件的反转。实际上 find 命令支持 “and” 和 “or” 两种逻辑运算，对应的命令选项分别是 -a 和 -o。通过这两个选项可以对搜索条件进行更复杂的组合。 此外还可以使用小括号对搜索条件进行分组。注意 find 命令中的小括号常需要用单引号包裹起来。因小括号在 Shell 中有特殊的含义。 如检索 /usr 下文件名以 python 开头且类型为目录的文件find /usr -type d -name &#39;python*&#39; 该命令等同于：find /usr -type d -a -name &#39;python*&#39; 更复杂的组合形式如：find / &#39;(&#39; -mmin -5 -o -mtime +50 &#39;)&#39; -a -type f 三、对搜索结果执行命令1. 删除文件-delete 选项可以用来删除搜索到的文件和目录。 如删除 home 目录下所有的空目录：find ~ -type d -empty -delete 2. 执行自定义命令-exec 选项可以对搜索到的结果执行特定的命令。 如需要将 home 目录下所有的 MP3 音频文件复制到移动存储设备（假设路径是 /media/MyDrive），可使用下面的命令：find ~ -type f -name &#39;*.mp3&#39; -exec cp {} /media/MyDrive &#39;;&#39; 其中的大括号（{}）作为检索到的文件的 占位符 ，而分号（ ;）作为命令结束的标志。因为分号是 Shell 中有特殊含义的符号，所以需要使用单引号括起来。每当 find 命令检索到一个符合条件的文件，会使用其完整路径取代命令中的 {}，然后执行 -exec 后面的命令一次。 另一个很重要的用法是，在多个文件中检索某个指定的字符串。如在用户主目录下的所有文件中检索字符串 hello ，可以使用如下命令：find ~ -type f -exec grep -l hello {} &#39;;&#39; -exec 选项中的 + 符号创建 Gzip 格式的压缩文件的命令为：tar -czvf filename.tar.gz &lt;list of files&gt; 现在假设需要将用户主目录下所有的 MP3 文件添加到压缩包 music.tar.gz 中，直观的感觉是，其命令应为如下形式：find ~ -type f -name &#39;*.mp3&#39; -exec tar -czvf music.tar.gz {} &#39;;&#39; 实际情况是，这样得到的 music.tar.gz 其实只包含一个 MP3 文件。原因是 find 命令每次发现一个音频文件，都会再执行一次 -exec 选项后面的压缩命令。导致先前生成的压缩包被覆盖。 可以先让 find 命令检索出所有符合条件的音频文件，再将得到的文件列表传递给后面的压缩命令。完整的命令如下：find ~ -type f -name &#39;*.mp3&#39; -exec tar -czvf music.tar.gz {} + 显示文件信息如果想浏览搜索到的文件（目录）的详细信息（如权限和大小等），可以直接使用 -ls 选项。 find / -type file -size +1G -ls 浏览所有 1G 以上大小的文件的详细信息 四、常用参数汇总 参数 解析 -atime n[smhdw] 距离文件上次被访问时的时间间隔 -ctime n[smhdw] 距离文件创建时的时间间隔 -delete 删除检索到的文件 -depth n 检索深度为 n 的文件，即位于指定目录以下 n 层的文件 -empty 检索空文件或空目录 -fstype type 指定文件所在的文件系统的类型 -group gname 指定文件的属组 -iname pattern 同 -name，忽略大小写 -ipath pattern 同 -path，忽略大小写 -ls 打印搜索到的文件的详细信息 -maxdepth n 指定递归的最大层数为 n -mtime n[smhdw] 距离文件上次发生变更时的时间间隔 -name pattern 搜索时使用 pattern 对文件名进行匹配 -path pattern 搜索时使用 pattern 对文件路径进行匹配 -perm mode 根据文件权限搜索 -size n[ckMGTP] 根据文件大小搜索 -type t 根据文件类型搜索 -user uname 指定文件的属主 参考资料A Guide to the Linux “Find” Commandfind 命令手册：man find]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Admin</tag>
        <tag>Tools</tag>
        <tag>Commands</tag>
        <tag>Shell</tag>
        <tag>Manual</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 JavaScript 对 Arduino 编程]]></title>
    <url>%2F2018%2F12%2F03%2Fjavascript-arduino-programming%2F</url>
    <content type="text"><![CDATA[一、向 Arduino 刷入 Firmata 固件 Firmata 是一种开放的类似于 MIDI 的协议。它可以将微控制器（microcontroller）变成“客户端”，通过串口通信直接被“主机”电脑访问和控制。通过 Firmata 协议，可以在主机上使用 Ruby、Python、JavaScript 等多种语言与刷入了 Firmata 固件的 arduino 板“交流”。 首先安装 firmata-party 工具：$ npm install -g firmata-party安装成功后通过 USB 线将 Arduino 板连接至电脑，运行以下命令：123456$ firmata-party uno --debugfound uno on port /dev/tty.usbserial-14110connectedreset complete.flashing, please wait...flash complete. 刷写完毕后，可以通过 Firmata Test Program 进行简单的测试。 二、使用 JavaScript 编程Blink LED可以使用如下命令开始一个新的项目：123$ mkdir test &amp;&amp; cd test$ npm init -y$ npm install --save firmata 编辑源代码文件（blink_led.js）用来控制 LED 闪烁：123456789101112131415161718192021222324252627282930313233// 加载依赖库var Board = require(&apos;firmata&apos;);// 连接初始化Board.requestPort(function(error, port) &#123; if (error) &#123; console.log(error); return; &#125; var board = new Board(port.comName); // 等待连接 board.on(&quot;ready&quot;,function() &#123; console.log(&quot;Ready!&quot;); var ledOn = true; // 设置 pin 13 为输出引脚 board.pinMode(13, board.MODES.OUTPUT); // 使 LED 闪烁 setInterval(function() &#123; if (ledOn) &#123; console.log(&apos;ON&apos;); board.digitalWrite(13, board.HIGH); &#125; else &#123; console.log(&apos;OFF&apos;); board.digitalWrite(13, board.LOW); &#125; ledOn = !ledOn; &#125;, 1000); &#125;);&#125;); 运行效果如下：123456$ node blink_led2.jsReady!ONOFFON... 代码执行后 arduino 板子上 13 号引脚上接的 LED 开始以 1 秒的间隔闪烁，同时电脑的终端界面不停地输出 ON 和 OFF 表示当前 LED 的开关状态。 Analog InputArduino 板子上的 A0 - A5 引脚可以读取模拟输入信号。示例代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344// 加载依赖库var Board = require(&apos;firmata&apos;);// 引脚定义const LED = 5;const POT = 0;// 初始化变量var ledOn = 0;var delay = 0;// map 函数。将初始的数值范围转变成需要的数值范围function map(x, in_min, in_max, out_min, out_max)&#123; return (x - in_min) * (out_max - out_min) / (in_max - in_min) + out_min;&#125;// 连接初始化Board.requestPort(function(error, port) &#123; if (error) &#123; console.log(error); return; &#125; var board = new Board(port.comName); // 等待连接 board.on(&quot;ready&quot;, function() &#123; // 控制 LED 闪烁的 blink() 函数 function blink() &#123; board.digitalWrite(LED, ledOn); ledOn = !ledOn; setTimeout(blink, delay); &#125; // 读取并更新可变电阻提供的模拟输入 board.analogRead(0, function(d) &#123; delay = map(d, 0, 1023, 400, 1600); &#125;); blink(); &#125;);&#125;); 线路连接图如下： 即通过 Arduino 板 A0 引脚可以读取模拟输入的功能（连接可变电阻的中间引脚），获取可变电阻的取值（0-1023）。再通过程序中的 map 函数将 0-1023 的取值转变成 400-1600，作为接在 5 号引脚上 LED 的闪烁频率。 程序运行后，调节可变电阻的旋钮，LED 即以不同的时间间隔（0.4s - 1.6s）闪烁。 PWM (Pulse-Width Modulation)PWM 即脉宽调制，其机制为：通过 MCU 内部的计时器设置引脚的状态，使该引脚在一个周期内的某段时间保持 HIGH 状态，在该周期内的其余时间保持 LOW 状态。平均下来看，该引脚的输出电压即介于最低和最高输出电压之间（即 0~5 V 之间）。所以一般可以近似地作为模拟电压输出。1234567891011121314151617181920212223242526272829303132333435// 加载依赖库var Board = require(&apos;firmata&apos;);// 变量定义const LED = 5;var brightness = 0;var fadeAmount = 5;// 连接初始化Board.requestPort(function(error, port) &#123; if (error) &#123; console.log(error); return; &#125; var board = new Board(port.comName); // 等待连接 board.on(&quot;ready&quot;, function() &#123; // 设置 LED 引脚为 PWM 模式 board.pinMode(LED, board.MODES.PWM); // 每隔 30 ms 提高或降低 LED 亮度，循环执行 function fadeLed() &#123; brightness += fadeAmount; if (brightness ==0 || brightness == 255) &#123; fadeAmount = -fadeAmount; &#125; board.analogWrite(LED, brightness); setTimeout(fadeLed, 30); &#125; fadeLed(); &#125;);&#125;); 该程序执行后，5 号引脚上的 LED 灯先是缓慢变亮，达到最亮以后再缓慢变暗。依照此规则循环。 附录：JavaScript 的串口通信即使 Arduino 板子未刷入 Firmata 固件，运行的是普通的程序。也可以利用 Node.js 的 serialport 库和串口通信完成 Arduino 与主机的对话。 首先初始化项目并安装依赖库：123$ mkdir test2 &amp;&amp; cd test2$ npm init -y$ npm install --save-dev serialport 扫描串口设备12345678910$ cat list_ports.jsvar serialPort = require(&quot;serialport&quot;);serialPort.list(function (error, ports) &#123; ports.forEach(function(port) &#123; console.log(port.comName); &#125;);&#125;);$ node list_ports.js/dev/tty.Bluetooth-Incoming-Port/dev/tty.usbserial-14110 从 Arduino 收取数据首先通过 Arduino IDE 刷入以下 counter.ino 文件，作为发送端程序：123456789void setup() &#123; Serial.begin(9600);&#125;int i=0;void loop() &#123; Serial.println(i++); delay(1000);&#125; 上述代码以 1000 ms 的间隔生成从 0 开始不断递增的数字并发送至串口。 电脑端的接收程序 read_port.js 代码如下：123456const SerialPort = require(&apos;serialport&apos;)const Readline = require(&apos;@serialport/parser-readline&apos;)const port = new SerialPort(&apos;/dev/cu.usbserial-14110&apos;)const parser = port.pipe(new Readline(&#123; delimiter: &apos;\n&apos; &#125;))parser.on(&apos;data&apos;, console.log) 运行效果如下：发送端不断生成新的数字并发送至串口，接收端通过串口接收该数字后将其打印到终端输出。 向 Arduino 发送数据首先通过 Arduino IDE 刷入以下 receiver.ino 文件，作为接收端程序：1234567891011121314void setup() &#123; Serial.begin(9600);&#125;void loop() &#123; int incoming = 0; if (Serial.available() &gt; 0) &#123; incoming = Serial.parseInt(); if (Serial.read() == &apos;\n&apos;) &#123; Serial.println(incoming); &#125; &#125;&#125; 发送端的 write_port.js 程序代码如下：1234567891011121314151617var SerialPort = require(&apos;serialport&apos;);var Stream = require(&apos;stream&apos;);var modem = &apos;cu.usbserial-14110&apos;;var ws = new Stream();ws.writable = true;ws.write = function(data) &#123; serialPort.write(data);&#125;;ws.end = function(buf) &#123; console.log(&apos;bye&apos;);&#125;var serialPort = new SerialPort(&apos;/dev/&apos; + modem);process.stdin.pipe(ws); 运行效果如下： 电脑端发送程序运行后（$ node write_port.js），打开 Arduino IDE 的 Serial Monitor。在命令行输入任何一个数字并按回车进行确认，Arduino 板子接收到该数字后，又将其打印到串口输出（即 Serial Monitor 中显示的内容） 参考资料Node.js for Embedded Systems: Using Web Technologies to Build Connected Devices 1st EditionNode SerialPort]]></content>
      <categories>
        <category>IoT</category>
      </categories>
      <tags>
        <tag>IOT</tag>
        <tag>Maker</tag>
        <tag>JavaScript</tag>
        <tag>Programming</tag>
        <tag>Arduino</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell 脚本编程（高级篇）]]></title>
    <url>%2F2018%2F12%2F03%2Fshell-script-programming-professional%2F</url>
    <content type="text"><![CDATA[高级篇一、处理用户输入1. 读取脚本参数Bash Shell 将命令行中传递给脚本的参数赋值给一组特殊的变量，叫做位置变量（positional parameters）。位置变量用 $number 的形式表示。如 $0 表示脚本文件的名称，$1 表示脚本收到的第一个参数，$2 表示第二个参数，以此类推，直到 $9 表示第九个参数。从第十个参数起，使用 ${number} 的形式。即第十个参数表示为 ${10}。 示例程序：1234567891011$ cat add.sh#!/bin/bashtotal=$[ $1 + $2 ]echo &quot;The first parameter is $1&quot;echo &quot;The second parameter is $2&quot;echo &quot;The total value is $total&quot;$ ./add.sh 2 5The first parameter is 2The second parameter is 5The total value is 7 2. 参数检查在 Shell 脚本中使用命令行参数时，一般需要先对传入的参数进行检查。如脚本执行时没有接收到预想的参数，往往会在执行过程中报出错误。如：12345$ ./add.sh 2./add.sh: line 3: 2 + : syntax error: operand expected (error token is &quot; &quot;)The first parameter is 2The second parameter isThe total value is 所以参数检查是写脚本时很有必要的步骤：12345678910111213$ cat check_parameter.sh#!/bin/bashif [ -n &quot;$1&quot; ]then echo Hello $1, glad to meet you.else echo &quot;Sorry, you did not identify youself&quot;fi$ ./check_parameter.sh starkyHello starky, glad to meet you.$ ./check_parameter.shSorry, you did not identify youself 3. 特殊参数变量参数计数上面有提到，应该在使用命令行参数前先检查其是否符合要求。对于接收多个参数的脚本，有时候需要获取命令行中输入的参数数量。Shell 脚本中的 $# 变量保存了该脚本执行时接收到的参数的数量。如：12345678910$ cat count_parameters.sh#!/bin/bashecho There were $# parameters supplied.$ ./count_parameters.shThere were 0 parameters supplied.$ ./count_parameters.sh testThere were 1 parameters supplied.$ ./count_parameters.sh test testThere were 2 parameters supplied. 通过 $# 变量的使用，可以将之前的 add.sh 脚本优化为以下形式：1234567891011121314151617$ cat add2.sh#!/bin/bashif [ $# -ne 2 ]then echo Usage: add2.sh a belse total=$[ $1 + $2 ] echo The total is $totalfi$ ./add2.shUsage: add2.sh a b$ ./add2.sh 2Usage: add2.sh a b$ ./add2.sh 2 4The total is 6 获取所有参数某些情况下需要获取命令行提供的所有参数。除了通过 $# 变量使用循环，还可以直接使用另外两个特殊的变量。 $* 和 $@ 变量都可以包含命令行输入的所有参数。其中 $* 变量接收所有参数并将它们保存在一个单一的字符串中。$@ 变量接收所有参数并将它们保存在分开的字符串中。即 $* 变量将收到的所有参数作为整体的一个参数对待，而 $@ 变量将收到的所有参数作为不同的多个对象，可以使用 for 命令进行遍历。 这两个变量的区别可以通过以下脚本来区分：123456789101112131415161718192021222324$ cat iterate_parameters.sh#!/bin/bashcount=1for param in &quot;$*&quot;do echo &quot;\$* Parameter $count = $param&quot; count=$[ $count + 1 ]doneechocount=1for param in &quot;$@&quot;do echo &quot;\$@ Parameter $count = $param&quot; count=$[ count + 1 ]done$ ./iterate_parameters.sh rich barbara katie jessica$* Parameter 1 = rich barbara katie jessica$@ Parameter 1 = rich$@ Parameter 2 = barbara$@ Parameter 3 = katie$@ Parameter 4 = jessica 4. shift 命令shift 命令可以用来操作命令行参数，对它们进行整体的移位。默认情况下，shift 命令会将所有的命令行参数整体的向左移动一个位置。即 $3 变量的值移动到 $2，$2 变量的值移动到 $1。如：123456789$ cat shift.sh#!/bin/bashecho &quot;The original parameters: $*&quot;shift 2echo &quot;Here&apos;s the new parameters: $*&quot;$ ./shift.sh 1 2 3 4 5The original parameters: 1 2 3 4 5Here&apos;s the new parameters: 3 4 5 二、函数1. 函数定义Bash Shell 脚本中的函数可以用以下两种格式定义：123function name &#123; commands&#125; 或123name() &#123; commands&#125; 具体示例如下：1234567891011121314151617181920212223242526$ cat func1.sh#!/bin/bashfunction func1 &#123; echo &quot;This is an example of a function&quot;&#125;count=1while [ $count -le 5 ]do func1 count=$[ $count + 1 ]doneecho &quot;This is the end of the loop&quot;func1echo &quot;Now this is the end of the script&quot;$ ./func1.shThis is an example of a functionThis is an example of a functionThis is an example of a functionThis is an example of a functionThis is an example of a functionThis is the end of the loopThis is an example of a functionNow this is the end of the script 2. 函数返回值退出状态默认情况下，某个函数的完成状态（即退出码）即是该函数中最后一条命令的退出码。在该函数执行后，可以使用 $? 变量获取其退出状态码。12345678910111213141516$ cat exit_status.sh#!/bin/bashfunc1() &#123; echo &quot;trying to display a non-existent file&quot; ls -l badfile&#125;echo &quot;testing the function: &quot;func1echo &quot;The exit status is: $?&quot;$ ./exit_status.shtesting the function:trying to display a non-existent filels: badfile: No such file or directoryThe exit status is: 1 因为函数 func1 中的最后一条命令 ls -l badfile 没有执行成功，所以函数执行完后，变量 $? 的值为 1 而不是 0 return 命令Bash Shell 可以使用 return 命令指定函数退出时的状态值（整数）。123456789101112131415$ cat return.sh#!/bin/bashfunction db1 &#123; read -p &quot;Enter a value: &quot; value echo &quot;doubling the value&quot; return $[ $value *2 ]&#125;db1echo &quot;The new value is $?&quot;$ ./return.shEnter a value: 32doubling the valueThe new value is 64 PS: 注意函数执行结束后需要立即使用 $? 获取其返回值，前面不能隔有其他命令；使用 return 指定的退出码必须介于 0 到 255 之间 3. 函数输出就像可以把命令的输出内容赋值给 Shell 变量一样，函数的输出同样也可以通过 variable=$(function_name) 的形式赋值给某个变量。12345678910111213$ cat func2.sh#!/bin/bashfunction db1 &#123; read -p &quot;Enter a value: &quot; value echo $[ $value * 2 ]&#125;result=$(db1)echo &quot;The new value is $result&quot;$ ./func2.shEnter a value: 32The new value is 64 4. 函数中的变量向函数传递参数Bash Shell 对待函数就像对待普通的脚本文件一样。我们可以向脚本程序传递参数，也可以以类似的方式向函数传递参数。 函数可以使用标准参数（如 $#）环境变量代表它从命令语句里接收到的参数。如函数本身的名称由 $0 定义，$1 代表第一个参数，$# 代表接收到的参数的数目，$* 表示函数接收到的所有参数 ($1 $2 ...) ，&quot;$@&quot; 表示函数接收到的所有参数，且每一个参数都被双引号包裹 (&quot;$1&quot; &quot;$2&quot; ...) 123456789101112131415161718192021222324252627282930313233343536$ cat parameter.sh#!/bin/bashfunction addem &#123; if [ $# -eq 0 ] || [ $# -gt 2 ] then echo -1 elif [ $# -eq 1 ] then echo $[ $1 + $1 ] else echo $[ $1 + $2 ] fi&#125;echo &quot;Adding 10 and 15:&quot;value=$(addem 10 15)echo $valueecho &quot;Try adding just one number:&quot;value=$(addem 10)echo $valueecho &quot;Now trying adding no numbers:&quot;value=$(addem)echo $valueecho &quot;Finally, try adding three numbers:&quot;value=$(addem 10 15 20)echo $value$ ./parameter.shAdding 10 and 15:25Try adding just one number:20Now trying adding no numbers:-1Finally, try adding three numbers:-1 上述脚本中的 addem 函数通过 $# 变量检查传递给它的参数的数量： 如果参数数量等于 0 或大于 2（[ $# -eq 0 ] || [ $# -gt 2 ]），则返回 -1 表示程序非正常退出。 如果参数数量等于 1（[ $# -eq 1 ]），则返回两倍于该参数的值（$[ $1 + $1 ]）。 如果参数数量等于 2（[ $# -eq 2 ]），则返回这两个参数的加和（$[ $1 + $2 ]） 全局变量与局部变量变量的作用域是一个很容易引起问题的点。函数中定义的变量可以拥有区别于普通变量的作用域，即它们可以对脚本中的其他部分“不可见”。 函数使用两种类型的变量： 全局变量 局部变量 全局变量是在整个脚本中都保持有效的变量。默认情况下，Shell 脚本中的任何变量都是全局变量。12345678910111213$ cat global.sh#!/bin/bashfunction db1 &#123; value=$[ $value * 2 ]&#125;read -p &quot;Enter a value: &quot; valuedb1echo &quot;The new value is: $value&quot;$ ./global.shEnter a value: 24The new value is: 48 区别于函数中的全局变量，任何只在函数内部生效的变量可以声明为局部变量，只需要在变量的声明前面加上 local 关键字即可。 1234567891011121314151617$ cat local.sh#!/bin/bashfunction func1 &#123; local temp=$[ $value + 5 ] result=$[ $temp * 2 ]&#125;temp=4value=6func1echo &quot;The result is $result&quot;echo &quot;The temp value is $temp&quot;$ ./local.shThe result is 22The temp value is 4 由于使用了 local 关健字指定函数内部的 $temp 变量为局部变量，所以函数 func1 中 $temp 变量值的变化（变为 11）并不影响函数外部 $temp 变量的值（仍为 4）。 5. 函数递归这里用一个计算阶乘的示例简单说明下 Shell 脚本中的函数递归。1234567891011121314151617181920$ cat factorial.sh#!/bin/bashfunction factorial &#123; if [ $1 -eq 1 ] then echo 1 else local temp=$[ $1 - 1 ] local result=$(factorial $temp) echo $[ $result * $1 ] fi&#125;read -p &quot;Enter value: &quot; valueresult=$(factorial $value)echo &quot;The factorial of $value is: $result&quot;$ ./factorial.shEnter value: 4The factorial of 4 is: 24 6. 库函数的使用可以减少脚本中的重复代码。即可以在脚本的其他部分直接使用函数名调用函数，完成该函数定义的功能，而无需再重新输入一遍定义该函数的大段语句。 这种形式的代码复用可以扩展到多个脚本文件。Bash Shell 允许用户创建库文件，其他 Shell 脚本可以通过引用该库文件使用其中定义的函数。 示例如下：12345678910111213141516171819202122232425262728293031323334$ cat myfuncsfunction addem &#123; echo $[ $1 + $2 ]&#125;function multem &#123; echo $[ $1 * $2 ]&#125;function divem &#123; if [ $2 -ne 0 ] then echo $[ $1 / $2 ] else echo -1 fi&#125;$ cat use_myfuncs.sh. ./myfuncsvalue1=10value2=5result1=$(addem $value1 $value2)result2=$(multem $value1 $value2)result3=$(divem $value1 $value2)echo &quot;The result of adding them is: $result1&quot;echo &quot;The result of multiplying them is: $result2&quot;echo &quot;The result of dividing them is: $result3&quot;$ ./use_myfuncs.shThe result of adding them is: 15The result of multiplying them is: 50The result of dividing them is: 2 其中 myfuncs 库文件中分别定义了 addem multem divem 三个函数，use_myfuncs.sh 脚本用来引用 myfuncs 库并使用其中定义的函数（这两个文件都需要有执行权限）。 重点在于 use_myfuncs.sh 脚本中的第一行命令 . ./myfuncs。其中第一个 . 是 source 命令的缩写。source 命令的作用是在当前语境下调用另一个脚本，而不是创建一个新的 Shell 会话。这样 myfuncs 中的函数就可以直接被 use_myfuncs.sh 脚本使用。 参考资料Linux Command Line and Shell Scripting Bible 3rd Edition]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Admin</tag>
        <tag>Shell</tag>
        <tag>Programming</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell 脚本编程（基础篇）]]></title>
    <url>%2F2018%2F11%2F15%2Fshell-script-programming-basic%2F</url>
    <content type="text"><![CDATA[基础篇一、输出信息大部分 Shell 命令都会生成自己的输出信息，在脚本运行时打印到终端屏幕上。但是很多时候，仍需要在输出的信息中添加上自己的内容，以提示用户脚本运行时究竟发生着什么，达到更好的交互效果。 echo 命令可以用来打印字符串内容。123$ echo This is a testThis is a test$ PS：默认是不需要将 echo 命令后面的字符串包含在一对引号中的 echo 可以使用引号作为文本字符串的分隔符。如：1234$ echo &apos;Hello&gt; World&apos;HelloWorld 当输出的文本内容中本来就有引号出现时，如（Let&#39;s see if this&#39;ll work），可以结合单、双引号的使用，或者使用转义符（\）前缀123456789# 引号作为字符串分隔符而不是文本内容$ echo Let&apos;s see if this&apos;ll workLets see if thisll work# 使用 \ 前缀进行转义$ echo Let\&apos;s see if this\&apos;ll workLet&apos;s see if this&apos;ll work# 使用双引号作为分隔符，单引号作为中间的文本正常输出$ echo &quot;Let&apos;s see if this&apos;ll work&quot;Let&apos;s see if this&apos;ll work 脚本的执行权限默认创建的脚本文件没有执行权限，不能直接在命令行中运行。如创建包含以下内容的脚本文件 info.sh ：123456#!/bin/bashecho The time and date are:dateecho &quot;Let&apos;s see who&apos;s logged into the system:&quot;who 直接执行上述脚本时会提示 permission denied 错误：12$ ./info.shzsh: permission denied: ./info.sh 需要使用 chomd +x filename 命令为该脚本文件添加执行权限后再运行，效果如下：12345678$ chmod +x info.sh$ ./info.shThe time and date are:Wed Oct 31 11:48:07 CST 2018Let&apos;s see who&apos;s logged into the system:starky console Oct 28 12:42starky ttys000 Oct 29 16:52starky ttys001 Oct 31 11:23 二、变量1. 系统环境变量在 Shell 脚本中可以直接访问系统中的环境变量，以获取相关的系统信息（如计算机名称，当前登录用户的账户名、 UID 和主目录等）。当前定义的所有环境变量可以通过 set 命令获取。12345678910$ set...HISTCMD=2217HISTFILE=/Users/starky/.zsh_historyHISTSIZE=50000HOME=/Users/starkyHOST=skitars-MacBook-Pro.localIFS=$&apos; \t\n\C-@&apos;ITERM_PROFILE=starky... 当需要在 Shell 脚本中使用具体某个环境变量的值时，可以用环境变量名称加上 $ 前缀表示（如 $HOST）。编辑如下 sys_info.sh 文件：12345#!/bin/bashecho User info for userid: $USERecho UID: $UIDecho HOME: $HOME 运行效果如下：12345$ chmod +x sys_info.sh$ ./sys_info.shUser info for userid: starkyUID: 501HOME: /Users/starky PS：由于在 Shell 脚本中，$ 作为变量的前缀符，所以当需要在文本输出中显示 $ 时，应使用转义。123456# $15 被当成了代入到字符串中的“变量”$ echo &quot;The cost of the item is $15&quot;The cost of the item is# 使用 \ 转义后正常打印 $ 字符$ echo &quot;The cost of the item is \$15&quot;The cost of the item is $15 2. 用户自定义变量Shell 脚本允许用户自行定义和使用变量，这样就可以将脚本中用到的数据临时存储在指定的变量中，使用时再通过 $变量名 的形式获取。 变量赋值：var=value （注意 = 号两边不能有空格，即 var = value 是错误的） 变量使用：$var PS：Shell 脚本中的变量名区分大小写Shell 脚本会自动判断变量值的数据类型变量的有效性贯穿脚本的整个生命周期，即脚本执行完毕后变量会自行删除 编辑如下 variables.sh 文件：123456789#!/bin/bashdays=10guest=&quot;Katie&quot;echo &quot;$guest checked in $days days ago&quot;days=5guest=&quot;Jessica&quot;echo &quot;$guest checked in $days days ago&quot; 运行效果如下：12345$ chmod +x variables.sh$ ./variables.shKatie checked in 10 days agoJessica checked in 5 days ago$ echo $days 可以看到，脚本退出后，脚本中定义的 $days 变量又恢复为未定义的状态。 三、命令替换Shell 脚本最有用处的特性之一，就是它可以提取某个命令的输出信息，并将其赋值给一个变量。可以通过以下两种方式将命令输出赋值给变量： 反单引号（`） $() 格式 如：1234567891011# 使用 date 命令获取当前的日期和时间$ dateThu Nov 1 01:03:02 CST 2018# 将 date 命令的输出（即当前日期和时间）赋值给 var1 变量$ var1=`date`$ echo Today is: $var1Today is: Thu Nov 1 01:03:15 CST 2018# 将 date 命令的输出赋值给 var2 变量（使用 $() 格式）$ var2=$(date)$ echo Today is: $var2Today is: Thu Nov 1 01:03:36 CST 2018 示例程序：使用命令替换完成一个脚本（log.sh），该脚本可以创建以当前时间水印为后缀的文本文件，内容为 /usr/bin 目录下的所有文件列表。12345#!/bin/bashtoday=$(date +%y%m%d%H%M%S)ls -al /usr/bin &gt; log.$todayecho The file log.$today has been created, you can check it later. 其中 date +%y%m%d%H%M%S 命令可以输出纯数字格式的日期和时间运行效果如下：12345678910111213141516$ chmod +x log.sh$ ./log.shThe file log.181101012159 has been created, you can check it later.$ ls log*log.181101012159 log.sh$ head log.181101012159total 103992drwxr-xr-x 971 root wheel 31072 Oct 13 17:44 .drwxr-xr-x@ 9 root wheel 288 Sep 21 12:01 ..-rwxr-xr-x 4 root wheel 925 Aug 18 08:45 2to3-lrwxr-xr-x 1 root wheel 74 Oct 13 17:44 2to3-2.7 -&gt; ../../System/Library/Frameworks/Python.framework/Versions/2.7/bin/2to3-2.7-rwxr-xr-x 1 root wheel 55072 Sep 21 12:16 AssetCacheLocatorUtil-rwxr-xr-x 1 root wheel 53472 Sep 21 12:16 AssetCacheManagerUtil-rwxr-xr-x 1 root wheel 48256 Sep 21 12:17 AssetCacheTetheratorUtil-rwxr-xr-x 1 root wheel 18320 Sep 21 12:17 BuildStrings-rwxr-xr-x 1 root wheel 18288 Sep 21 12:17 CpMac 四、重定向输入和输出1. 输出重定向最基本的重定向，就是通过大于号（&gt;），将某个命令的输出内容保存至一个文件中。 格式：command &gt; outputfile 12345$ date &gt; current_date.txt$ ls -l current_date.txt-rw-r--r-- 1 starky staff 29 Nov 1 01:29 current_date.txt$ cat current_date.txtThu Nov 1 01:29:45 CST 2018 PS：如使用重定向时，指定的文件已存在，则该文件的原始内容会被新内容覆盖。如果只是想在文件末尾追加内容，则可以使用双大于号（&gt;&gt;）1234$ date &gt;&gt; current_date.txt$ cat current_date.txtThu Nov 1 01:29:45 CST 2018Thu Nov 1 01:34:03 CST 2018 2. 输入重定向输入重定向和输出重定向相反。即从文件中读取内容，并将该内容传递给某个命令。 格式：command &lt; inputfile 12345678910111213141516171819202122$ ls -l /Users/starkytotal 49864drwx------@ 3 starky staff 96 Oct 13 18:00 Applicationsdrwx------+ 23 starky staff 736 Oct 31 19:14 Desktopdrwx------+ 21 starky staff 672 Oct 31 19:15 Documentsdrwx------+ 37 starky staff 1184 Oct 30 20:18 Downloadsdrwx------+ 72 starky staff 2304 Oct 27 01:38 Librarydrwx------+ 6 starky staff 192 Oct 29 10:34 Moviesdrwx------+ 3 starky staff 96 Sep 27 13:13 Music...$ cat directory.txt/Users/starky$ ls -l &lt; directory.txttotal 49864drwx------@ 3 starky staff 96 Oct 13 18:00 Applicationsdrwx------+ 23 starky staff 736 Oct 31 19:14 Desktopdrwx------+ 21 starky staff 672 Oct 31 19:15 Documentsdrwx------+ 37 starky staff 1184 Oct 30 20:18 Downloadsdrwx------+ 72 starky staff 2304 Oct 27 01:38 Librarydrwx------+ 6 starky staff 192 Oct 29 10:34 Moviesdrwx------+ 3 starky staff 96 Sep 27 13:13 Music... 3. 管道有些时候，需要将某个命令的输出内容作为另一个命令的输入。如：123456$ ls -al &gt; tmp_file$ grep vim &lt; tmp_filedrwxr-xr-x 3 starky staff 96 Oct 20 15:45 .vim-rw------- 1 starky staff 23799 Nov 1 01:40 .viminfo-rw-r--r-- 1 starky staff 3935 Oct 21 01:31 .vimrc-rw-r--r-- 1 starky staff 24849808 Oct 25 21:02 vim.tar.gz 上面的命令先将当前目录下的文件列表（ls -al）保存在 tmp_file 中，再使用 grep 命令读取 tmp_file 的内容，筛选文件名中包含 vim 的文件。 其实可以通过管道（|）的使用，将前面命令的输出，定向给后面的命令作为输入。 格式：command1 | command2 12345ls -al | grep vimdrwxr-xr-x 3 starky staff 96 Oct 20 15:45 .vim-rw------- 1 starky staff 23799 Nov 1 01:40 .viminfo-rw-r--r-- 1 starky staff 3935 Oct 21 01:31 .vimrc-rw-r--r-- 1 starky staff 24849808 Oct 25 21:02 vim.tar.gz 五、数学运算操作数学运算对于任何编程语言来说，都是一个很重要的特性。但是 Shell 脚本并不能直接完成算术运算的操作，只能通过以下两种方式来实现。 1. expr 命令Shell 提供了一个特殊的命令（expr）用来处理数学算式，如：12$ expr 1 + 23 PS：注意算式中 + 号两边的空格expr 命令支持的算术操作符如下： 操作符 含义 ARG1 双管道符 ARG2 如果两个参数值都不为 null 或 0，返回 ARG1，否则返回 ARG2 ARG1 &amp;&amp; ARG2 如果两个参数值都不为 null 或 0，返回 ARG1，否则返回 0 ARG1 &lt; ARG2 如果 ARG1 小于 ARG2，返回 1，否则返回 0 ARG1 &gt; ARG2 如果 ARG1 大于 ARG2，返回 1，否则返回 0 ARG1 = ARG2 如果 ARG1 等于 ARG2，返回 1，否则返回 0 ARG1 &gt;= ARG2 如果 ARG1 大于或等于 ARG2，返回 1，否则返回 0 ARG1 &lt;= ARG2 如果 ARG1 小于或等于 ARG2，返回 1，否则返回 0 ARG1 != ARG2 如果 ARG1 不等于 ARG2，返回 1，否则返回 0 ARG1 + ARG2 返回 ARG1 与 ARG2 的数字加和 ARG1 - ARG2 求 ARG1 减去 ARG2 的数字差 ARG1 * ARG2 返回 ARG1 与 ARG2 的数字乘积 ARG1 / ARG2 求 ARG1 除以 ARG2 的数字商（结果为整数） ARG1 % ARG2 对 ARG1 和 ARG2 进行求余操作 数学运算示例（divide.sh）： 1234567#!/bin/bashvar1=10var2=20var3=`expr $var2 / $var1`echo $var2 divided by $var1 equals $var3 运行效果：123$ chmod +x divide.sh$ ./divide.sh20 divided by 10 equals 2 2. 使用中括号Bash Shell 中的 expr 命令主要是为了保持和 Bourne Shell 的兼容性，它其实还提供了一种更简单的方式用来处理数学运算。即使用这样的形式：$[ operation ] 如下面的脚本（compute.sh）12345678#!/bin/bashvar1=100var2=50var3=45result=$[$var1 * ($var2 - $var3)]echo The final result is $result 运行效果：123$ chmod +x compute.sh$ ./compute.shThe final result is 500 但是在进行除法运算时，上面的方式只支持整数。如两个数相除结果为小数，则该结果会舍去小数部分只保留整数。12345$ var1=10$ var2=3$ result=$[$var1 / $var2]$ echo The result is $resultThe result is 3 3. 浮点数运算有很多种方案可以克服 bash 的整数限制，最常用的一种就是使用系统内置的 bash calculator，即 bc 程序。bash calculator 其实是一种支持浮点数运算的编程语言，可以识别以下几种类型的数据： 数字（整数和浮点数） 变量（简单变量和数组） 注释（单行注释 # 和多行注释 /* */） 表达式 编程语句（如 if-then 语句） 函数 12345678910$ bcbc 1.06Copyright 1991-1994, 1997, 1998, 2000 Free Software Foundation, Inc.This is free software with ABSOLUTELY NO WARRANTY.For details type `warranty&apos;.12 * 5.464.83.156 * (3 + 5)25.248quit 计算结果精确到的小数位数是通过一个内建的 scale 变量定义的，默认的 scale 数值为 0（即默认舍去商的小数位数）：1234567$ bc -q3.44 / 50scale=43.44 / 5.6880quit bc 程序也支持自定义变量：12345678$ bc -qvar1=10var1 * 440var2=var1 / 5print var22quit 4. 在脚本中使用 bc可以通过管道将数学表达式传递给 bc 程序，再将计算得出的结果通过赋值语句赋值给某个变量：variable=$(echo &quot;options; expression&quot; | bc) 其中 variable=$(...) 用于提取命令的输出并赋值给一个变量（参考第三章命令替换） 如下面的脚本（bc1.sh）:1234567#!/bin/bashvar1=100var2=45var3=$(echo &quot;scale=4; $var1 / $var2&quot; | bc)echo The answer for this is $var3 运行效果：123$ chmod +x bc1.sh$ ./bc1.shThe answer for this is 2.2222 更复杂的形式在脚本中使用 bc 还可以通过如下的形式：123456variable=$(bc &lt;&lt; EOFoptionsstatementsexpressionsEOF) 示例程序如下（bc2.sh）： 12345678910111213141516#!/bin/bashvar1=10.46var2=43.67var3=33.2var4=71var5=$(bc &lt;&lt; EOFscale = 4a1=$var1 * $var2b1=$var3 * $var4a1 + b1EOF)echo The final answer for this mess is $var5 运行结果：123$ chmod +x bc2.sh$ ./bc2.shThe final answer for this mess is 2813.9882 参考资料Linux Command Line and Shell Scripting Bible 3rd Edition]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Admin</tag>
        <tag>Shell</tag>
        <tag>Programming</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell 脚本编程（中级篇）]]></title>
    <url>%2F2018%2F11%2F15%2Fshell-script-programming-medium%2F</url>
    <content type="text"><![CDATA[中级篇一、结构化命令在基础篇的示例中，Shell 大多数情况下都以顺序的方式依次执行脚本中的每一条指令。但是在实际情况中，很多程序都需要对脚本中命令的逻辑流进行控制。即根据某些条件和状态完成判断，再决定其后的程序该以怎样的规则执行。Shell 脚本支持一部分结构化指令，如 if-then、case 等，用于修改程序的执行流程。 1. if-then最基本的结构化语句即 if-then，其格式如下：1234if commandthen commandsfi Bash Shell 中的 if-then 语句和其他编程语言中的类似语句稍有些不同，其作用如下： 首先执行 if 后面跟随的命令 command 如果该命令 command 的结束状态（exit status）为 0（即该命令执行成功），则 then 后面的命令依次被执行 如果该命令 command 的结束状态为任何非 0 的值（该命令非正常退出），则不执行 then 后面的命令，Bash Shell 移动到脚本中的下一条命令（即 fi 后面的内容） 如下面的两个示例：1234567891011121314151617181920212223$ cat if1.sh#!/bin/bashif pwdthen echo &quot;It worked&quot;fiecho &quot;We are outside the if statement&quot;$ ./if1.sh/Users/starky/program/scripts/shellIt workedWe are outside the if statement$ cat if2.sh#!/bin/bashif IamNotaCommandthen echo &quot;It worked&quot;fiecho &quot;We are outside the if statement&quot;$ ./if2.sh./if2.sh: line 3: IamNotaCommand: command not foundWe are outside the if statement 在上面的示例中，if1.sh 脚本里 if 后面的命令（pwd）成功执行，则 then 后面的 echo 命令也跟着执行。而 if2.sh 脚本里 if 后面的命令（IamNotaCommand）执行出错，则 then 后面的 echo 命令不会被执行。无论如何，判断结束后都会继续执行 fi 后面的语句。 2. if-else-thenif-else-then 语句的格式为：123456if commandthen commandselse commandsfi 当 if 后面的命令执行后返回值为 0 时，则 then 后面的命令被执行。如果 if 后面的命令执行后返回值不为 0，则执行 else 后面的命令。 示例（if3.sh）如下：123456789101112#!/bin/bashtestuser=starkyif ls -d /Users/$testuserthen echo &quot;The bash files for user $testuser are:&quot; ls -a /Users/$testuser/.b* echoelse echo &quot;The user $testuser does not exist on this system.&quot; echofi 运行结果：1234567$ chmod +x if3.sh$ ./if3.sh/Users/starkyThe bash files for user starky are:/Users/starky/.bash_history /Users/starky/.bash_profile/Users/starky/.bash_sessions:... 但是将上述脚本中 testuser 变量的值改为系统中并不存在的用户时（如 NoSuchUser），则运行效果如下：12345678910111213141516$ cat if3.sh#!/bin/bashtestuser=NoSuchUserif ls -d /Users/$testuserthen echo &quot;The bash files for user $testuser are:&quot; ls -a /Users/$testuser/.b* echoelse echo &quot;The user $testuser does not exist on this system.&quot; echofi$ ./if3.shls: /Users/NoSuchUser: No such file or directoryThe user NoSuchUser does not exist on this system. 其他结构形式的 if-else-then 语句还包括：12345678if command1then commandselif command2then more commandsfi 当然理论上讲可以使用足够的 if-then-elif-then 语句，只不过类似情况下多使用更为恰当的 case 语句。 3. test 命令上面提到的 if-then 语句，大多是这样的形式：1234if commandthen commands... 即 if 后面跟的是一条普通的 Shell 命令，根据该命令是否成功执行，来确定 then 后面的命令是否执行。 可以借助 test 命令，使用如下形式的 if-then 语句：1234if test conditionthen commandsfi 如果 test 命令后面的 condition 计算后为 TRUE，则 test 命令退出并返回一个值为 0 的状态值。then 后面的命令被执行。如果 test 命令后面的 condition 计算后为 FALSE，则 test 命令退出并返回一个非零的状态值。跳出当前的 if-then 并继续执行后面的内容。 如下面的两个例子：1234567891011121314151617181920212223242526$ cat test_condition.sh#!/bin/bashmy_variable=&quot;Full&quot;if test $my_variablethen echo &quot;The $my_variable expression returns a True&quot;else echo &quot;The $my_variable expression returns a False&quot;fi$ ./test_condition.shThe Full expression returns a True$ cat test_condition2.sh#!/bin/bashmy_variable=&quot;&quot;if test $my_variablethen echo &quot;The $my_variable expression returns a True&quot;else echo &quot;The $my_variable expression returns a False&quot;fi$ ./test_condition2.shThe expression returns a False Bash Shell 还提供了另外一种不需要使用 test 命令来完成条件检查的 if-then 语句：1234if [ condition ]then commandsfi 方括号中的内容用来定义判断条件。注意方括号和 condition 之间的空格。支持三种形式的判断条件： 数字比较 字符串比较 文件比较 数字比较 操作 描述 n1 -eq n2 检查 n1 是否等于 n2 n1 -ge n2 检查 n1 是否大于或等于 n2 n1 -gt n2 检查 n1 是否大于 n2 n1 -le n2 检查 n1 是否小于或等于 n2 n1 -lt n2 检查 n1 是否 小于 n2 n1 -ne n2 检查 n1 是否不等于 n2 示例如下：1234567891011121314151617181920$ cat numeric_test.sh#!/bin/bashvalue1=10value2=11if [ $value1 -gt 5 ]then echo &quot;The test value $value1 is greater than 5&quot;fiif [ $value1 -eq $value2 ]then echo &quot;The values are equal&quot;else echo &quot;The values are different&quot;fi$ ./numeric_test.shThe test value 10 is greater than 5The values are different 字符串比较 操作 描述 str1 = str2 检查 str1 和 str2 是否相同 str1 != str2 检查 str1 和 str2 是否不相同 str1 &lt; str2 检查 str1 是否小于 str2 str1 &gt; str2 检查 str1 是否大于 str2 -n str1 检查 str1 是否长度大于 0（不为空） -z str1 检查 str1 是否长度为 0（为空） 示例1：12345678910111213$ cat welcome.sh#!/bin/bashtestuser=starkyif [ $USER = $testuser ]then echo &quot;Welcome $testuser&quot;else echo &quot;This is not $testuser&quot;fi$ ./welcome.shWelcome starky PS：在使用 str1 &gt; str2 或 str1 &lt; str2 这种类型的条件时，需加上转义符号。否则大于号或小于号会被当作重定向处理。 示例2：1234567891011121314$ cat compare.sh#!/bin/bashval1=Testingval2=testingif [ $val1 \&gt; $val2 ]then echo &quot;$val1 is greater than $val2&quot;else echo &quot;$val1 is less than $val2&quot;fi$ ./compare.shTesting is less than testing PS：if 条件中的比较依据的是基本 ASCII 顺序，通过每个字符（从首字母开始）的 ASCII 值的比较来判断大小顺序。 -n 和 -z 常常用来确定指定字符串是否为空。示例3：123456789101112131415161718192021222324252627282930$ cat empty.sh#!/bin/bashval1=testingval2=&apos;&apos;if [ -n $val1 ]then echo &quot;The string &apos;$val1&apos; is not empty&quot;else echo &quot;The string &apos;$val1&apos; is empty&quot;fiif [ -z $val2 ]then echo &quot;The string &apos;$val2&apos; is empty&quot;else echo &quot;The string &apos;$val2&apos; is not empty&quot;fiif [ -z $val3 ]then echo &quot;The string &apos;$val3&apos; is empty&quot;else echo &quot;The string &apos;$val3&apos; is not empty&quot;fi$ ./empty.shThe string &apos;testing&apos; is not emptyThe string &apos;&apos; is emptyThe string &apos;&apos; is empty 上述脚本中 val3 变量自始至终没有被定义，被自动判断为空字符串。 文件比较 操作 描述 -d file 检查 file 是否存在且是一个目录 -e file 检查 file 是否存在 -f file 检查 file 是否存在且是一个文件 -r file 检查 file 是否存在且可读 -s file 检查 file 是否存在且不为空 -w file 检查 file 是否存在且可写 -x file 检查 file 是否存在且可执行 -O file 检查 file 是否存在且其属主为当前用户 -G file 检查 file 是否存在且其默认数组和当前用户相同 file1 -nt file2 检查 file1 是否比 file2 更新（newer than） file1 -ot file2 检查 file1 是否比 file2 更老（older than） 示例1，目录检查：1234567891011121314151617$ cat check_dir.sh#!/bin/bashdirectory=/Users/starkyif [ -d $directory ]then echo &quot;The $directory directory exists&quot; cd $directory lselse echo &quot;The $directory directory does not exist&quot;fi$ ./check_dir.shThe /Users/starky directory existsApplications Downloads Music extract.sh programDesktop Library Pictures id_rsa.pub softwareDocuments Movies Public miniconda3 vim.tar.gz 示例2，删除空文件：12345678910111213141516171819202122232425262728293031323334$ cat check_empty.sh#!/bin/bashfile_name=empty# 检查该文件是否存在if [ -f $file_name ]then # 该文件存在，则继续检查其内容是否非空 if [ -s $file_name ] then # 内容不为空 echo &quot;The $file_name file exists and has data in it.&quot; echo &quot;Will not remove this file&quot; else # 内容为空 echo &quot;The $file_name file exists, but is empty.&quot; echo &quot;Deleting empty file...&quot; rm $file_name fielse # 该文件不存在 echo &quot;File, $file_name, does not exist.&quot;fi$ ./check_empty.shFile, empty, does not exist.$ touch empty$ ls emptyempty$ ./check_empty.shThe empty file exists, but is empty.Deleting empty file...$ ls emptyls: empty: No such file or directory 4. 组合判断if-then 语句允许使用布尔逻辑来完成多个条件的组合判断。 [ condition1 ] &amp;&amp; [ condition2 ] 逻辑与 [ condition1 ] || [ condition2 ] 逻辑或 示例：1234567891011121314cat compound_test.sh#!/bin/bashif [ -d $HOME ] &amp;&amp; [ -w $HOME/testing ]then echo &quot;The file exists and you can write to it&quot;else echo &quot;I cannot write to the file&quot;fi$ ./compound_test.shI cannot write to the file$ touch ~/testing$ ./compound_test.shThe file exists and you can write to it if-then 中的双括号Bash Shell 在 if-then 语句中还提供了一些更高级的特性： 双小括号（数学表达式） 双中括号（字符串处理函数） 使用双小括号双小括号允许在条件测试时使用（相对于 test 命令）更高级的数学表达式。格式：(( expression ))其中 expression 除了支持前面提到过的基本的数学操作符外，还支持以下操作符： 操作符 描述 val++ Post-increment val– Post-decrement ++val Pre-increment –val Pre-decrement ! 逻辑非 ~ 按位否定 ** 幂 &lt;&lt; 向左按位移位 &gt;&gt; 向右按位移位 &amp; 按位逻辑与 管道符 按位逻辑或 &amp;&amp; 逻辑与 双管道符 逻辑或 示例：123456789101112$ cat parenthesis.sh#!/bin/bashval1=10if (( $val1 ** 2 &gt; 90 ))then (( val2 = $val1 ** 2 )) echo &quot;The square of $val1 is $val2&quot;fi$ ./parenthesis.shThe square of 10 is 100 使用双中括号双中括号为 test 命令中的字符串比较提供了更高级的特性，尤其是支持 模式匹配。示例：1234567891011cat pattern.sh#!/bin/bashif [[ $USER == s* ]]then echo &quot;Hello $USER&quot;else echo &quot;Sorry, I do not know you&quot;fi$ ./pattern.shHello starky 4. case 命令很多时候，某个作为判断条件的变量有多个可能的取值，而你需要根据不同的取值指导程序去做对应的操作。如果使用 if-then-else 语句，代码免不了会拉得有些长。。。 不同于 if 语句（通过 if、elif 依次检查同一个变量的所有取值），case 命令以类似列表的形式检查同一个变量的所有取值：12345case variable in pattern1 | pattern2) commands1;; pattern3) commands2;; *) default commands;;esac case 命令将指定的变量与多个不同的模式进行比对，如果匹配，则执行该模式后面的命令。可以在同一行中定义多个模式（使用 | 符号分隔）。星号表示当之前的所有模式都不能被匹配时，默认执行的命令。 示例：12345678910111213141516$ cat case_user.sh#!/bin/bashcase $USER in rich | barbara) echo &quot;Welcome, $USER&quot; echo &quot;Please enjoy your visit&quot;;; testing) echo &quot;Special testing account&quot;;; jessica) echo &quot;Do not forget to logout when you&apos;re done&quot;;; *) echo &quot;Sorry, you are not allowed here&quot;;;esac$ ./case_user.shSorry, you are not allowed here 上面的脚本等同于使用如下的 if 语句：123456789101112131415161718$ cat if_user.sh#!/bin/bashif [[ $USER = &quot;rich&quot; || $USER = &quot;barbara&quot; ]]then echo &quot;Welcome $USER&quot; echo &quot;Please enjoy your visit&quot;elif [ $USER = &quot;testing&quot; ]then echo &quot;Special testing account&quot;elif [ $USER = &quot;jessica&quot; ]then echo &quot;Do not forget to logout when you&apos;re done&quot;else echo &quot;Sorry, you are not allowed here&quot;fi$ ./if_user.shSorry, you are not allowed here 二、更多结构化命令1. for 命令很多时候，需要重复地执行一系列命令直到某个特定的情况出现。for 命令允许创建一个循环来遍历某些值，并在循环过程中使用遍历到的值执行一系列特定的指令。语法格式：1234for var in listdo commandsdone 遍历列表12345678910111213$ cat for_list.sh#!/bin/bashfor state in Alabama Alaska Arizonado echo The next state is $statedoneecho &quot;The last state we visited was $state&quot;$ ./for_list.shThe next state is AlabamaThe next state is AlaskaThe next state is ArizonaThe last state we visited was Arizona 每次 for 命令遍历由后面列表（Alabama Alaska Arizona）提供的值时，会把列表中当前项目的值赋值给 $state 变量（即第一次遍历把 Alabama 赋值给 $state，第二次是 Alaska），该 $state 变量可以在后面的 do ... done 结构中使用。 for 循环结束后 $state 变量依旧有效，即保留最后一次遍历时得到的值（列表的最后一项 Arizona）而不会被销毁。 遍历字符串中的列表Bash Shell 中的for 循环可以直接接收单个字符串作为参数，并通过其中的空格将该字符串分割成多个遍历的项目。123456789101112131415$ cat for_variable.sh#!/bin/bashstates=&quot;Alabama Alaska Arizona&quot;states=$states&quot; Arkansas&quot;for state in $statesdo echo &quot;Have you ever visited $state?&quot;done$ ./for_variable.shHave you ever visited Alabama?Have you ever visited Alaska?Have you ever visited Arizona?Have you ever visited Arkansas? 脚本中 state=$state&quot; Arkansas&quot; 可以用来在 $state 变量中的字符串末尾添加新的字符串，也等同于在列表末尾添加了新的项目。 从命令中获取遍历的列表可以通过命令替换将命令的输出作为 for 命令循环遍历的列表：12345678910111213$ cat states.txtAlabama Alaska Arizona$ cat for_command.sh#!/bin/bashfor state in $(cat states.txt)do echo &quot;Visit beautiful $state&quot;done$ ./for_command.shVisit beautiful AlabamaVisit beautiful AlaskaVisit beautiful Arizona 遍历文件目录可以使用 for 命令直接循环目录中的文件（结合 * 符号）：1234567891011121314151617181920$ cat for_dir.sh#!/bin/bashfor file in /Users/starky/.vim* /Users/starky/badtestdo if [ -d &quot;$file&quot; ] then echo &quot;$file is a directory&quot; elif [ -f &quot;$file&quot; ] then echo &quot;$file is a file&quot; else echo &quot;$file doesn&apos;t exit&quot; fidone$ ./for_dir.sh/Users/starky/.vim is a directory/Users/starky/.viminfo is a file/Users/starky/.vimrc is a file/Users/starky/badtest doesn&apos;t exit 注意脚本中的 if [ -d &quot;$file&quot; ] 段代码， &quot;$file&quot; 被双引号包裹了起来。原因是文件名中包含空格是合法的，但是在 Shell 脚本中，如果 $file 变量的值包含空格，则不能直接在 if [ -d ... ] 中使用，所以这里使用了双引号。 2. C 语法的 for 命令Bash Shell 也支持语法类似于 C 语言形式的 for 循环：for (( variable assignment ; condition ; iteration process )) 123456789101112131415161718$ cat for_c.sh#!/bin/bashfor (( i=1; i &lt;= 10; i++ ))do echo &quot;The next number is $i&quot;done$ ./for_c.shThe next number is 1The next number is 2The next number is 3The next number is 4The next number is 5The next number is 6The next number is 7The next number is 8The next number is 9The next number is 10 3. while 命令while 命令允许用户定义一个判断指令，然后循环执行一系列命令，并在每次执行前检查判断指令的返回值（exit status）。直到判断指令的返回值不为 0，终止循环。 while 命令的格式为：1234while test commanddo other commandsdone 示例程序如下：123456789101112131415$ cat while.sh#!/bin/bashvar=5while [ $var -gt 0 ]do echo $var var=$[ $var -1 ]done$ ./while.sh54321 4. break 命令break 命令用于跳出循环 123456789101112131415161718$ cat break.sh#!/bin/bashfor var in 1 2 3 4 5 6 7 8 9 10do if [ $var -eq 5 ] then break fi echo &quot;Iteration number: $var&quot;doneecho &quot;The for loop is completed&quot;$ ./break.shIteration number: 1Iteration number: 2Iteration number: 3Iteration number: 4The for loop is completed 5. 处理循环的输出可以使用管道或重定向处理循环的输出信息，直接将管道或重定向命令加在循环语句块的末尾即可。 12345678910111213141516$ cat output.sh#!/bin/bashfor (( a = 1; a &lt; 5; a++ ))do echo &quot;The number is $a&quot;done &gt; numbers.txtecho &quot;The command is finished&quot;$ ./output.shThe command is finished$ cat numbers.txtThe number is 1The number is 2The number is 3The number is 4 参考资料Linux Command Line and Shell Scripting Bible 3rd Edition]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Admin</tag>
        <tag>Shell</tag>
        <tag>Programming</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[树莓派作为 FM 发射台和 Webcam 服务器（视频监控）]]></title>
    <url>%2F2018%2F11%2F11%2Fraspberry-pi-fm-emitter-and-webcam-server%2F</url>
    <content type="text"><![CDATA[在网上发现两个很有意思的树莓派小项目。一个是作为 FM 发射器，向短距离内的 FM 收音机发送声波信号。一个是作为视频监控（配合摄像头），可以远程访问网页客户端获取摄像头监控的画面。实际尝试了下效果都还不错。 一、FM 发射器项目地址：PiFmRds该发射器使用树莓派的 PWM 生成器 来产生 VHF（甚高频） 信号。 编译安装PiFmRds 需要从源代码编译，而编译时依赖 sndfile 库。可以使用如下命令安装：$ sudo apt-get install libsndfile1-dev之后使用如下命令获取源代码并完成编译：1234$ git clone https://github.com/ChristopheJacquet/PiFmRds.git$ cd PiFmRds/src$ make clean$ make 编译完成后 src 目录下的文件如下图： 其中的 pi_fm_rds 即编译好的二进制程序，可使用如下命令进行测试（注意命令开头的 sudo）：$ sudo ./pi_fm_rds -audio sound.wav该命令会以 107.9M HZ 的频率向空中发射包含 sound.wav 文件音频的电磁波。 详细使用为了使用起来更加方便，可以将编译好的二进制程序移动到 /usr/local/bin 目录并改名为 fm 命令:$ sudo cp pi_fm_rds /usr/local/bin/fm fm 命令主要有两个选项： -audio 用来指定生成电磁声波的媒体文件 -freq 用来指定生成的电磁声波的频率 1234567891011$ sudo fm -audio ~/Music/Faded_Alan\ Walker.wav -freq 108Using mbox device /dev/vcio.Allocating physical memory: size = 3403776 mem_ref = 5 bus_addr = fe7b0000 virt_addr = 0x768dc000ppm corr is 0.0000, divider is 1096.4912 (1096 + 2012*2^-12) [nominal 1096.4912].Using audio file: /home/pi/Music/Faded_Alan Walker.wavInput: 44100 Hz, upsampling factor: 5.172 channels, generating stereo multiplex.Created low-pass FIR filter for audio channels, with cutoff at 12000.0 HzPI: 1234, PS: &lt;Varying&gt;.RT: &quot;PiFmRds: live FM-RDS transmission from the RaspberryPi&quot;Starting to transmit on 108.0 MHz. 下面是用小米手机自带的 FM Radio 录制的一段，呃，截图。。。 对于传输 mp3 格式文件，可以借助 sox 工具：$ sudo apt-get install sox 再通过 sox 命令将 mp3 格式文件转换为 wav 格式的音频流，重定向给 fm 命令：sox -t mp3 ~/Music/baby-alian.mp3 -t wav - | sudo fm -freq 108 -audio - 实际的使用效果还是非常棒的，近距离内收音很清晰。如果需要增加收音距离，可以在树莓派的 GPIO 4（即 7 号引脚）插上一根 杜邦线 作为天线。 二、视频监控上面的图片即树莓派 3 代 B+ 装上专用的摄像头模块后的样子。该模块某宝上可以轻松买到，不附链接。树莓派也支持大多数常用的 USB 摄像头，没尝试过，不细说。 拍照和摄像树莓派需要先在软件配置里开启摄像头模块。可以使用 sudo raspi-config 命令，选择 5 Interfacing Options -&gt; P1 Camera。 之后就可以使用 raspistill 命令拍照和 raspivid 命令录制视频了。 1234# 拍摄照片并保存至 image1.jpg 文件$ raspistill -o image1.jpg# 拍摄长度为 10000 毫秒的视频并保存至 video.h264 文件$ raspivid -o video.h264 -t 10000 mjpg-streamermjpg-streamer 是一个命令行工具，可以通过多种输入和输出插件将 JPEG 帧作为视频流传输。支持树莓派摄像头模块。项目地址：mjpg-streamer 编译安装使用如下命令获取 mjpg-streamer 源代码并编译安装：1234567# 安装依赖库和编译工具 cmake$ sudo apt-get install cmake libjpeg8-dev libv4l-dev# 获取源代码并编译$ git clone https://github.com/jacksonliam/mjpg-streamer.git$ cd mjpg-streamer/mjpg-streamer-experimental$ make$ sudo make install 安装成功后便可以通过如下命令开启视频流：12345678910111213141516171819$ mjpg_streamer -i &quot;input_raspicam.so -x 640 -y 480 -fps 30&quot; -o &quot;output_http.so -w ./www&quot;MJPG Streamer Version: git rev: ddb69b7b4f114f3c2ca01adf55712792ca8aed43 i: fps.............: 30 i: resolution........: 640 x 480 i: camera parameters..............:Sharpness 0, Contrast 0, Brightness 50Saturation 0, ISO 0, Video Stabilisation No, Exposure compensation 0Exposure Mode &apos;auto&apos;, AWB Mode &apos;auto&apos;, Image Effect &apos;none&apos;Metering Mode &apos;average&apos;, Colour Effect Enabled No with U = 128, V = 128Rotation 0, hflip No, vflip NoROI x 0.000000, y 0.000000, w 1.000000 h 1.000000 o: www-folder-path......: ./www/ o: HTTP TCP port........: 8080 o: HTTP Listen Address..: (null) o: username:password....: disabled o: commands.............: enabled i: Starting CameraEncoder Buffer Size 81920 其中 -i 选项后面的 input_rapsicam.so 用于指定输入插件，-x 和 -y 选项指定视频流的分辨率，-fps 选项指定帧率。-o 选项后面的 output_http.so 用于指定输出插件，-w 指定 Webcam 服务器使用的网页源文件。 使用测试Webcam 服务器地址为：IP_Address:8080使用浏览器访问时效果如下： 可以借助 VLC 或 iina 视频播放器的 打开 URL 功能，远程播放视频流。URL 为 IP_Address:8080/?action=stream 。效果如下： 呃，实话说，有点小卡。。。哈哈哈 参考资料Raspberry Pi Cookbook, 2nd EditionRaspberry Pi for Secret Agents (English Edition)]]></content>
      <categories>
        <category>IoT</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Admin</tag>
        <tag>Hardware</tag>
        <tag>RaspberryPi</tag>
        <tag>Raspbian</tag>
        <tag>Camera</tag>
        <tag>Webcam</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过 JavaScript (Johnny-Five) 控制 Ardunio]]></title>
    <url>%2F2018%2F10%2F25%2Fprogramming-arduino-with-javascript%2F</url>
    <content type="text"><![CDATA[Johnnt-Five 是一个支持 JavaScript 语言编程的机器人和 IOT 开发平台，基于 Firmata 协议。该项目在 Github 上有着很好的活跃度，官网上也有非常详尽的 API 文档和丰富的实例(http://johnny-five.io/examples/)。 一、环境搭建安装 Arduino IDE安装 Arduino IDE 主要是为了向开发板中刷入 Firmata 程序。Firmata 是计算机软件和微控制器之间的一种通信协议。当开发板中刷入了 Firmata 固件后，电脑端就可以使用同样基于 Firmata 协议的框架对开发板进行编程。 Arduino IDE 可以直接从官网下载对应系统版本的安装包进行安装。安装完成后进入 文件 - 示例 - Firmata - StandardFirmataPlus ，将该程序刷入 Arduino 开发板即可。 Johnny-Five 框架Johnny-Five 框架需要电脑系统里安装 Node.js 程序。可以直接从官网下载安装，也可以使用 nvm 等版本管理工具安装需要的版本nvm 方式可参考版本管理工具（nvm、virtualenv(wrapper) 和 rbenv 的安装与使用） 安装完成后直接在项目目录下运行 npm 命令即可：$ npm install johnny-five 二、Hello World在项目目录下创建 blink.js 文件：12345678910111213var five = require(&quot;johnny-five&quot;);var board = new five.Board();// The board&apos;s pins will not be accessible until the board has reported that it is readyboard.on(&quot;ready&quot;, function() &#123; console.log(&quot;Ready!&quot;); // Create a standard `led` component instance var led = new five.Led(13); // &quot;blink&quot; the led in 500ms led.blink(500);&#125;); 使用 node blink.js 命令运行项目，效果如下：此时 Arduino 板子上接 13 引脚的红色 LED 开始以 500 毫秒的间隔闪烁，使用 .exit 命令退出 nodejs 的 Repl 后停止闪烁。 REPL在项目目录下创建 repl.js 文件：12345678910111213141516171819var five = require(&quot;johnny-five&quot;);var board = new five.Board();board.on(&quot;ready&quot;, function() &#123; console.log(&quot;Ready event. Repl instance auto-initialized!&quot;); var led = new five.Led(13); this.repl.inject(&#123; // Allow limited on/off control access to the // Led instance from the REPL. on: function() &#123; led.on(); &#125;, off: function() &#123; led.off(); &#125; &#125;);&#125;); 运行效果如下：可以在 nodejs 的 Repl 中使用 on() 和 off() 对 LED13 进行打开和关闭操作。 三、Button创建 button.js 文件：12345678910111213141516171819202122232425262728293031var five = require(&quot;johnny-five&quot;), board, button;board = new five.Board();board.on(&quot;ready&quot;, function() &#123; // Create a new `button` hardware instance. button = new five.Button(2); // Inject the `button` hardware into the Repl instance&apos;s context; board.repl.inject(&#123; button: button &#125;); // &quot;down&quot; the button is pressed button.on(&quot;down&quot;, function() &#123; console.log(&quot;down&quot;); &#125;); // &quot;hold&quot; the button is pressed for specified time. // defaults to 500ms (1/2 second) button.on(&quot;hold&quot;, function() &#123; console.log(&quot;hold&quot;); &#125;); // &quot;up&quot; the button is released button.on(&quot;up&quot;, function() &#123; console.log(&quot;up&quot;); &#125;);&#125;); 线路接法如下： 运行效果： 按下并释放按键时 Repl 中输出 down 和 up。按住按键时输出 hold。 尬尴，JavaScript 不太熟悉，以后有时间多做尝试。官方文档真的很详细。。。]]></content>
      <categories>
        <category>IoT</category>
      </categories>
      <tags>
        <tag>IOT</tag>
        <tag>JavaScript</tag>
        <tag>Programming</tag>
        <tag>Arduino</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 Docker 创建简单的 Web 应用]]></title>
    <url>%2F2018%2F10%2F19%2Fsimple-web-application-with-docker%2F</url>
    <content type="text"><![CDATA[一、Flask 小程序首先创建一个简单的 Flask 小程序，用来返回一个比较原始的 HTML 页面。该项目的文件结构如下：1234avatar├── Dockerfile├── app └── avatar.py 其中的 Dockerfile 用于创建运行该项目的容器，app 目录下的 avatar.py 为程序的源文件。 avatar.py 的源代码如下：12345678910111213141516171819202122from flask import Flaskapp = Flask(__name__)default_name = &apos;skitarniu&apos;# 创建关联于网站根 URL（&apos;/&apos;）的路由。当该 URL 被请求时，将返回 get_avatar() 函数的结果@app.route(&apos;/&apos;)def get_avatar(): name = default_name header = &apos;&lt;html&gt;&lt;head&gt;&lt;title&gt;Avatar&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&apos; body = &apos;&apos;&apos;&lt;form method=&quot;POST&quot;&gt; Hello &lt;input type=&quot;text&quot; name=&quot;name&quot; value=&quot;&#123;&#125;&quot;&gt; &lt;input type=&quot;submit&quot; value=&quot;submit&quot;&gt; &lt;/form&gt; &lt;p&gt;You look like a: &lt;img src=&quot;&quot;/&gt; &apos;&apos;&apos;.format(name) footer = &apos;&lt;/body&gt;&lt;/html&gt;&apos; return header + body + footer# 初始化 web 服务器if __name__ == &apos;__main__&apos;: app.run(debug=True, host=&apos;0.0.0.0&apos;) 编辑 Dockerfile用于构建容器的 Dockerfile 内容如下：123456789101112# 初始镜像为 Docker Hub 上的 Python:3.6 镜像FROM python:3.6# 执行 pip 命令安装 flask 框架RUN pip install Flask==1.0.2# 工作目录设置为容器中的 /appWORKDIR /app# 将本地主机上的项目源码文件夹复制到容器中COPY app /app# 容器运行时其内部执行的命令CMD [&quot;python&quot;, &quot;avatar.py&quot;] 构建容器并运行项目可以使用 docker build 命令根据 Dockerfile 中的步骤创建容器的镜像文件，之后使用 docker run 命令利用刚刚创建的镜像加载容器并运行项目。12345678$ docker build -t avatar ....$ docker run -d -p 5000:5000 --name simple-flask avatare90b14c39b23fb97956af8128ae01c73b9bd5e8917578d755e477efd6337e740$ curl localhost:5000&lt;html&gt;&lt;head&gt;&lt;title&gt;Avatar&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;form method=&quot;POST&quot;&gt; &lt;h3&gt;Hello&lt;/h3&gt;... 其中 docker run 命令的 -d 选项指定容器在后台运行；-p 5000:5000 用来指定本地主机到容器的端口映射（即访问本地主机的 5000 端口等同于访问容器中 5000 端口上运行的服务）；--name simple_flask 用于指定容器的名字为 simple_flask ；最后的 avatar 指定使用的镜像文件。 可以使用 docker logs &lt;container_name&gt; 命令查看后台运行的容器的输出：12345678910111213$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESe90b14c39b23 avatar &quot;python avatar.py&quot; 11 minutes ago Up 11 minutes 0.0.0.0:5000-&gt;5000/tcp simple_flask$ docker logs simple_flask * Serving Flask app &quot;avatar&quot; (lazy loading) ... * Debug mode: on * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit) * Restarting with stat * Debugger is active! * Debugger PIN: 495-921-379172.17.0.1 - - [10/Oct/2018 11:28:31] &quot;GET / HTTP/1.1&quot; 200 -10.2.67.88 - - [10/Oct/2018 11:32:02] &quot;GET / HTTP/1.1&quot; 200 - Bind Mounts可以在执行 docker run 命令时使用 -v HOST_DIR:CONTAINER_DIR 选项，将本地主机上的项目目录映射到容器中，并覆盖容器中原目录下的内容。这样当本地主机上的项目源码被修改后，更新的内容会直接同步至容器中的对应文件，就不需要重新构建容器了。123456789101112131415$ docker stop $(docker ps -lq)e90b14c39b23$ docker rm $(docker ps -lq)e90b14c39b23$ docker run -d -p 5000:5000 -v &quot;$(pwd)&quot;/app:/app avatar899831690d5eb7e2e1f7882c00bfef7284f629518e66b581bd5979f3712bf241$ curl localhost:5000&lt;html&gt;&lt;head&gt;&lt;title&gt;Avatar&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;form method=&quot;POST&quot;&gt; &lt;h3&gt;Hello&lt;/h3&gt;...$ sed -i &apos;s/Avatar/Avatar_Modified/&apos; app/avatar.py$ curl localhost:5000&lt;html&gt;&lt;head&gt;&lt;title&gt;Avatar_Modified&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;form method=&quot;POST&quot;&gt; &lt;h3&gt;Hello&lt;/h3&gt;... 以上的命令中，docker stop 和 docker rm 用于停止并删除当前的容器。docker run 命令中的 -v &quot;$(pwd)&quot;/app:/app 选项用来将本地主机上的项目目录（&quot;$(pwd)&quot;/app）关联给容器中的 /app 目录。所以当使用 sed -i 命令将源码中的 Avatar 替换为 Avatar_Modified 之后，不需要重新构建，容器返回的 HTML 文档中的 标签已经变成新值。 二、uWSGI 服务器WSGI（即 Web Server Gateway Interface）是 Web 服务器（如 nginx）和 Web 应用程序或框架（如 Flask）之间的一种通用接口。它就像是一个桥梁，一边连着 Web 服务器，一边连着 Web 应用程序。 很多框架都自带了 WSGI server（如 Flask 的 webserver），但更多是测试用途，发布时则使用生产环境的 WSGI server 或是联合 nginx 做 uwsgi 。 而 uWSGI 是一个 Web 服务器，实现了 WSGI、uwsgi、http 等协议。 这里使用 uWSGI 替代 Flask 自带的 webserver，可对之前的 Dockerfile 做如下修改：1234567FROM python:3.6RUN pip install Flask==1.0.2 uWSGI==2.0.17.1WORKDIR /appCOPY app /appCMD [&quot;uwsgi&quot;, &quot;--http&quot;, &quot;0.0.0.0:9090&quot;, &quot;--wsgi-file&quot;, &quot;/app/avatar.py&quot;, &quot;--callable&quot;, &quot;app&quot;, &quot;--stats&quot;, &quot;0.0.0.0:9191&quot;] 重新构建 docker 镜像并运行容器：12345678$ docker build -t avatar ....$ docker run -d -p 9090:9090 -p 9191:9191 avatar2ca0aed60d53803a7eaaf6ca9146c1786593f3d1d1c86b498ea4577cade854e8$ curl localhost:9090&lt;html&gt;&lt;head&gt;&lt;title&gt;Avatar_Modified&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;form method=&quot;POST&quot;&gt; &lt;h3&gt;Hello&lt;/h3&gt;... 上面的 uWSGI 是在 root 用户下运行的，存在安全隐患。需要将 Dockerfile 改为如下版本：1234567891011121314FROM python:3.6# 创建用户和用户组，名为 uwsgiRUN groupadd -r uwsgi &amp;&amp; useradd -r -g uwsgi uwsgiRUN pip install Flask==1.0.2 uWSGI==2.0.17.1WORKDIR /appCOPY app /app# 使用 EXPOSE 声明可供外部访问的端口号EXPOSE 9090 9191# USER 用于指定某个用户，其后的所有命令（包括 CMD 和 ENTRYPOINT）都将由该用户执行USER uwsgiCMD [&quot;uwsgi&quot;, &quot;--http&quot;, &quot;0.0.0.0:9090&quot;, &quot;--wsgi-file&quot;, &quot;/app/avatar.py&quot;, &quot;--callable&quot;, &quot;app&quot;, &quot;--stats&quot;, &quot;0.0.0.0:9191&quot;] 区分测试和生产环境可以将 Dockerfile 中 CMD 调用的命令单独存放在一个 Shell 脚本中。如在 avatar 目录下新建 cmd.sh 文件并添加执行权限（chmod +x cmd.sh），再添加文件内容如下：1234567891011#!/bin/bashset -eif [ &quot;$ENV&quot; = &apos;DEV&apos; ]; then echo &quot;Running Development Server&quot; exec python &quot;avatar.py&quot;else echo &quot;Running Production Server&quot; exec uwsgi --http 0.0.0.0:9090 --wsgi-file /app/avatar.py \ --callable app --stats 0.0.0.0:9191fi 此时的 Dockerfile 内容如下：12345678910111213FROM python:3.6RUN groupadd -r uwsgi &amp;&amp; useradd -r -g uwsgi uwsgiRUN pip install Flask==1.0.2 uWSGI==2.0.17.1WORKDIR /appCOPY app /appCOPY cmd.sh /EXPOSE 9090 9191USER uwsgi# CMD 选项改为包含一系列命令且拥有执行权限的脚本文件CMD [&quot;/cmd.sh&quot;] 重新构建 Docker 镜像，在测试环境下运行时使用$ docker run -e &quot;ENV=DEV&quot; -p 5000:5000 avatar其中 -e 选项用于指定环境变量 在生产环境下运行时则使用$ docker run -d -p 9090:9090 -p 9191 avatar 三、Docker ComposeCompose 工具用于快速地搭建和运行 Docker 开发环境。它使用 YAML 文件保存容器集群的配置信息。 安装 ComposeUbuntu 系统下安装 Compose 可参考以下命令：1234# 从 Github 上获取 Docker Compose 的二进制程序$ sudo curl -L &quot;https://github.com/docker/compose/releases/download/1.22.0/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose# 为获取到的 compose 程序添加执行权限$ sudo chmod +x /usr/local/bin/docker-compose 编辑 docker-compose 文件在 avatar 目录下新建一个名为 docker-compose.yml 的文件，该文件是 docker-compose 命令运行时参考的配置文件：12345678avatar: build: . ports: - &quot;5000:5000&quot; environment: ENV:DEV volumes: - ./app:/app 其中第一行的 avatar 用于声明需要构建的容器的名称，同一个 YAML 文件中可以同时存在多个容器的定义；第二行的 build: . 表示用于构建容器镜像文件的 Dockerfile 位于当前目录下；ports 项等同于 docker run 命令中的 -p 选项，用于定义端口转发；environment 项等同于 docker run 命令中的 -e 选项，用于定义容器中的环境变量；volumes 项等同于 docker run 命令中的 -v 选项，用于定义存储卷。 运行项目可直接使用 docker-compose up 命令构建容器并执行项目：12345678910111213$ docker-compose upBuilding avatar...Successfully built 1f883bd34e9fSuccessfully tagged avatar_avatar:latestWARNING: Image for service avatar was built because it did not already exist. To rebuild this image you must use `docker-compose build` or `docker-compose up --build`.Creating avatar_avatar_1 ... doneAttaching to avatar_avatar_1avatar_1 | Running Development Serveravatar_1 | * Serving Flask app &quot;avatar&quot; (lazy loading)...avatar_1 | * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)... 四、关联其他镜像（dnmonster）dnmonster 镜像是一个整合在 Docker 容器中的 Node.js 应用，可以直接从 Docker Hub 上拉取到本地。它提供了一个 RESTful API，当访问 http://0.0.0.0:8080/monster/MY_ID 时，返回一个独一无二的“怪兽”头像。1234$ docker pull amouat/dnmonster...$ docker run -d -p 8080:8080 amouat/dnmonster... 此时打开浏览器访问 http://ip_address:8080/monster/some_string?size=200 ，结果如图所示： 整合 dnmonster 镜像前面的 flask 应用只包含一个最基本的功能，即访问它的主页时返回一个简单的 HTML 页面，页面中包含一个获取用户输入的表单，和一个 src 属性值为空字符串的 &lt;img&gt; 标签（“空白”图片）。 结合 dnmonster 镜像的使用，可以将表单中获取到的输入整合到图片标签 的 src 属性中（/monster/&lt;user_input&gt;） 将该图片的 URL 路径 （/monster/&lt;user_input&gt;）绑定给另一个函数（get_avatar），该函数访问 dnmonster 容器中的 RESTful API，所以网页中最终显示的是从 dnmonster 容器获取到的头像图片，并随用户输入而更新。 app/avatar.py 文件的具体代码如下：12345678910111213141516171819202122232425262728293031323334353637383940from flask import Flask, Response, requestimport requestsimport hashlibapp = Flask(__name__)default_name = &apos;skitarniu&apos;# 声明网站主页将会处理 GET 和 POST 请求（因为表单的提交属于 POST 请求），主页绑定 mainpage 函数@app.route(&apos;/&apos;, methods=[&apos;GET&apos;,&apos;POST&apos;])def mainpage(): name = default_name# 表单提交时，获取用户输入的内容，调用 hashlib 库将其变成 hash 形式，保存在 name_hash 变量中 if request.method == &apos;POST&apos;: name = request.form[&apos;name&apos;] name_hash = hashlib.sha256(name.encode()).hexdigest() header = &apos;&lt;html&gt;&lt;head&gt;&lt;title&gt;Avatar_Modified&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&apos; body = &apos;&apos;&apos;&lt;form method=&quot;POST&quot;&gt; &lt;h3&gt;Hello&lt;/h3&gt; &lt;input type=&quot;text&quot; name=&quot;name&quot; value=&quot;&#123;0&#125;&quot;&gt; &lt;input type=&quot;submit&quot; value=&quot;submit&quot;&gt; &lt;/form&gt; &lt;p&gt;You look like a: &lt;img src=&quot;/monster/&#123;1&#125;&quot;/&gt; &apos;&apos;&apos;.format(name, name_hash)# img 标签的 src 属性由 name_hash 的值确定，即网页中图片的源路径根据用户输入自行更新 footer = &apos;&lt;/body&gt;&lt;/html&gt;&apos; return header + body + footer# 网页中图片的 URL 绑定给 get_avatar 函数，该函数通过 requests 库访问 dnmonster 容器中的 API 以获取“怪兽”图像@app.route(&apos;/monster/&lt;name&gt;&apos;)def get_avatar(name): r = requests.get(&apos;http://dnmonster:8080/monster/&apos; + name + &apos;?size=200&apos;) image = r.content return Response(image, mimetype=&apos;image/png&apos;)if __name__ == &apos;__main__&apos;: app.run(debug=True, host=&apos;0.0.0.0&apos;) 然后在 Dockerfile 里添加上前面用到的 requests 模块123456789101112FROM python:3.6RUN groupadd -r uwsgi &amp;&amp; useradd -r -g uwsgi uwsgiRUN pip install Flask==1.0.2 uWSGI==2.0.17.1 requests==2.5.1WORKDIR /appCOPY app /appCOPY cmd.sh /EXPOSE 9090 9191USER uwsgiCMD [&quot;/cmd.sh&quot;] 输入以下命令运行项目：123456$ docker build -t avatar ....$ docker run -d --name dnmonster amouat/dnmonster48f77f0e0f7ac503b27786f73ea8d25fa4237eea042dfb5cc1331bb07001dae3$ docker run -d -p 5000:5000 -e &quot;ENV=DEV&quot; --link dnmonster:dnmonster avatar8cf94a54744f92c206917c474dc8619c417d7b7937fd6d38df3cd05d5813d5fd 其中 docker build 命令用于重新构建容器。docker run -d --name dnmonster amouat/dnmonster 命令用于加载 dnmonster 容器并指定其名称（--name）为 dnmonster 。docker run -d -p 5000:5000 -e &quot;ENV=DEV&quot; --link dnmonster:dnmonster avatar 命令中的 --link dnmonster:dnmonster 选项用于将 flask 应用容器和 dnmonster 容器关联起来。其中第一个 dnmonster 用于指定关联容器的名称，第二个 dnmonster 用于指定该容器的别名。关联后 flask 应用容器就可以通过别名直接访问 dnmonster 容器，而无需获知其 IP 地址（所以源文件 app/avatar.py 中 get_avatar 函数才可以通过 http://dnmonster:8080/ 类似的 URL 访问 dnmonster 的 API）。 效果如下：输入不同的字符串并提交，将得到不一样的头像图片。 使用 Docker Compose上面的例子虽然可以正常运行，但运行项目时手动输入 docker run 命令过于繁琐。可以通过修改 docker-compose.yml 配置文件，借助 Compose 的“自动化”简化操作步骤。 12345678910111213avatar: build: . ports: - &quot;5000:5000&quot; environment: ENV: DEV volumes: - ./app:/app links: - dnmonsterdnmonster: image: amouat/dnmonster 其中 links 项定义了 avatar 容器到 dnmonster 容器的关联dnmonster 及后面的内容则定义了 dnmonster 容器的配置信息，通过 image 项指定用于生成该容器的镜像文件。 停止并删除之前的容器，重新构建运行项目：123456789$ docker-compose build...$ docker-compose up -dCreating avatar_dnmonster_1 ... doneCreating avatar_avatar_1 ... done$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES1f85363c7ed4 avatar_avatar &quot;/cmd.sh&quot; 10 seconds ago Up 9 seconds 9090/tcp, 0.0.0.0:5000-&gt;5000/tcp, 9191/tcp avatar_avatar_15cca0f851ac5 amouat/dnmonster &quot;npm start&quot; 11 seconds ago Up 9 seconds 8080/tcp avatar_dnmonster_1 五、添加缓存支持（Redis）当前的 flask 应用，每获取一次“怪兽”头像，dnmonster 服务就会收到一次比较消耗资源的请求。由于通过特定的输入生成的图片是保持不变的，所以可以利用缓存对应用进行优化。 Redis 是一种基于内存的 Key-Value 类型的数据库，适合此处的应用场景。 最终的项目文件结构如下：123456avatar├── app│ └── avatar.py├── cmd.sh├── docker-compose.yml└── Dockerfile app/avatar.py:1234567891011121314151617181920212223242526272829303132333435363738394041from flask import Flask, Response, requestimport requestsimport hashlibimport redisapp = Flask(__name__)cache = redis.StrictRedis(host=&apos;redis&apos;, port=6379, db=0)default_name = &apos;skitarniu&apos;@app.route(&apos;/&apos;, methods=[&apos;GET&apos;,&apos;POST&apos;])def mainpage(): name = default_name if request.method == &apos;POST&apos;: name = request.form[&apos;name&apos;] name_hash = hashlib.sha256(name.encode()).hexdigest() header = &apos;&lt;html&gt;&lt;head&gt;&lt;title&gt;Avatar_Modified&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&apos; body = &apos;&apos;&apos;&lt;form method=&quot;POST&quot;&gt; &lt;h3&gt;Hello&lt;/h3&gt; &lt;input type=&quot;text&quot; name=&quot;name&quot; value=&quot;&#123;0&#125;&quot;&gt; &lt;input type=&quot;submit&quot; value=&quot;submit&quot;&gt; &lt;/form&gt; &lt;p&gt;You look like a: &lt;img src=&quot;/monster/&#123;1&#125;&quot;/&gt; &apos;&apos;&apos;.format(name, name_hash) footer = &apos;&lt;/body&gt;&lt;/html&gt;&apos; return header + body + footer@app.route(&apos;/monster/&lt;name&gt;&apos;)def get_avatar(name): image = cache.get(name) if image is None: print(&quot;Cache miss&quot;, flush=True) r = requests.get(&apos;http://dnmonster:8080/monster/&apos; + name + &apos;?size=200&apos;) image = r.content cache.set(name, image) return Response(image, mimetype=&apos;image/png&apos;)if __name__ == &apos;__main__&apos;: app.run(debug=True, host=&apos;0.0.0.0&apos;) Dockerfile:123456789101112FROM python:3.6RUN groupadd -r uwsgi &amp;&amp; useradd -r -g uwsgi uwsgiRUN pip install Flask==1.0.2 uWSGI==2.0.17.1 requests==2.5.1 redis==2.10.6WORKDIR /appCOPY app /appCOPY cmd.sh /EXPOSE 9090 9191USER uwsgiCMD [&quot;/cmd.sh&quot;] docker-compose.yml:1234567891011121314151617avatar: build: . ports: - &quot;5000:5000&quot; environment: ENV: DEV volumes: - ./app:/app links: - dnmonster - redisdnmonster: image: amouat/dnmonsterredis: image: redis cmd.sh 文件保持之前的版本即可。然后就可以先使用 docker-compose stop 命令停止之前版本的容器，再使用 docker-compose build 和 docker-compose up -d 命令重新构建并运行新版本的容器。 1234567891011$ docker-compose builddnmonster uses an image, skippingredis uses an image, skippingBuilding avatar...Successfully built d1aa92c39f97Successfully tagged avatar_avatar:latest$ docker-compose up -dCreating avatar_redis_1 ... doneCreating avatar_dnmonster_1 ... doneCreating avatar_avatar_1 ... done 参考资料Using Docker: Developing and Deploying Software with Containers]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Web</tag>
        <tag>Development</tag>
        <tag>Docker</tag>
        <tag>Service</tag>
        <tag>Operation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[树莓派 3B+ 连接 WPA2 企业级加密的 WIFI]]></title>
    <url>%2F2018%2F10%2F16%2Fraspberry-pi-wifi-wpa2-eap%2F</url>
    <content type="text"><![CDATA[陪伴我三年多的树莓派二代目前阵子挂掉了，电源指示灯异常。想修，无从下手。含泪送别，然后买了个三代目。。。已经算驾轻就熟了。直接刷好系统，走起。结果连 WIFI 的时候出了点小状况 树莓派 3 代 B+ 已自带了蓝牙和 WIFI 模块，且支持 2.4/5G HZ 双频段无线网络。本以为连下 WIFI 就是动动手指的事情。偏偏公司是 WPA2 企业级加密的无线网，图形界面下显示的 WIFI 名称是灰色的，无法直接连接。无奈只好通过命令行配置。 树莓派用的是当前最新版本的 Raspbian 系统（2018-10-09），无线网络配置文件为 /etc/wpa_supplicant/wpa_supplicant.conf。所以直接将 WIFI 的连接信息补充到该配置文件中即可。 一、连接普通 WIFI连接“最简单”的 WIFI （如手机热点）时配置如下：12345678ctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdevupdate_config=1country=CNnetwork=&#123; ssid=&quot;your_AP_name&quot; psk=&quot;password&quot;&#125; 其中 WIFI 的连接信息主要是 network 项中的内容。 多个 WIFI 设置优先级如果需要同时配置多个 WIFI 的连接并为其设置优先级，可参考以下配置：12345678910111213network=&#123; ssid=&quot;your_AP_name1&quot; psk=&quot;password1&quot; priority=1 id_str=&quot;Home1&quot;&#125;network=&#123; ssid=&quot;your_AP_name2&quot; psk=&quot;password2&quot; priority=2 id_str=&quot;Home2&quot;&#125; 其中 priority 项用于设置优先级，该值越大则优先级越高。 二、连接隐藏 WIFI隐藏 WIFI 不能被自动搜索到，需要手动添加连接。12345network=&#123; ssid=&quot;your_AP_name&quot; scan_ssid=1 psk=&quot;password&quot;&#125; 主要是添加 scan_ssid=1 项。 三、连接 WPA2 企业级加密的 WIFI示例配置文件如下（尴尬，不是很懂。但我是可以连的。。）：1234567891011network=&#123; ssid=&quot;your_AP_name&quot; key_mgmt=WPA-EAP pairwise=CCMP TKIP group=CCMP TKIP eap=PEAP identity=&quot;your_username&quot; password=&quot;password&quot; phase1=&quot;peaplabel=auto pepver=auto&quot; phase2=&quot;MSCHAPV2&quot;&#125; 更多 wpa_supplicant.conf 文件的配置实例可参考 man wap_supplicant.conf 附录wpa_supplicant.conf 文件的配置说明可参考这篇博客（内容太详细了，，没细看）]]></content>
      <categories>
        <category>IoT</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Admin</tag>
        <tag>Network</tag>
        <tag>IoT</tag>
        <tag>Wi-Fi</tag>
        <tag>RaspberryPi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker 初探]]></title>
    <url>%2F2018%2F10%2F09%2Fdocker-beginning-guide%2F</url>
    <content type="text"><![CDATA[一、容器（Container）简单来说，容器是对应用程序及其依赖库的一种封装。 乍看上去，容器就像一个轻量级的虚拟机系统（VM），也封装了一个操作系统实例用来运行某些应用程序。相比于传统的虚拟机，容器的优势主要在以下几个方面： 容器与宿主机共享资源，使得其效率有了很大的提升。与主机中运行的应用程序相比，在容器中运行的应用程序几乎没有任何额外的开销。 容器可移植的特性可以解决由于运行环境的微小变化引发的一系列问题。 容器的轻量级特性意味着开发人员可以同时运行数十个容器，从而可以模拟出生产级别的分布式系统。 对于不使用云端应用的用户和开发者，用户可以节省下大量的安装和配置时间，也不用担心系统的依赖冲突等问题。而开发者同时也可以避免由于用户系统环境的差异导致的可用性问题。 总的来说，虚拟机的基本目标，是完整地虚拟出一个外部（独立）的系统环境，而容器是为了达到应用程序的可移植和自成一体。 而 Docker Engine 为运行容器提供了快捷方便的交互接口。 二、Docker 安装（Linux）Linux 系统上的 Docker 安装，可以直接使用官方提供的安装脚本（https://get.docker.com），命令如下：$ sudo wget -qO- https://get.docker.com/ | sh或$ sudo curl -sSL https://get.docker.com/ | sh Mac OS 和 Windows 系统上的 Docker 安装，可参考官方文档 Docker for Mac 和 Docker for Windows Docker 官方镜像访问缓慢，可以使用阿里云提供的加速服务（参考 镜像加速器） Docker 需要特定的权限才能运行，即普通用户执行 docker 命令时需要加上 sudo 。12345678910$ docker versionClient: Version: 18.06.1-ce API version: 1.38 Go version: go1.10.3 Git commit: e68fc7a Built: Tue Aug 21 17:24:51 2018 OS/Arch: linux/amd64 Experimental: falseGot permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/version: dial unix /var/run/docker.sock: connect: permission denied 可以将本地用户添加到 docker 用户组中，后续使用 docker 命令时即无需加上 sudo 前缀。$ sudo usermod -aG docker &lt;username&gt;12345678910111213141516171819$ docker versionClient: Version: 18.06.1-ce API version: 1.38 Go version: go1.10.3 Git commit: e68fc7a Built: Tue Aug 21 17:24:51 2018 OS/Arch: linux/amd64 Experimental: falseServer: Engine: Version: 18.06.1-ce API version: 1.38 (minimum version 1.12) Go version: go1.10.3 Git commit: e68fc7a Built: Tue Aug 21 17:23:15 2018 OS/Arch: linux/amd64 Experimental: false 三、操作入门Hello World1234567$ docker run debian echo &quot;Hello World&quot;Unable to find image &apos;debian:latest&apos; locallylatest: Pulling from library/debian05d1a5232b46: Pull completeDigest: sha256:07fe888a6090482fc6e930c1282d1edf67998a39a09a0b339242fbfa2b602fffStatus: Downloaded newer image for debian:latestHello World docker run 命令用于加载容器并执行某个命令。上述命令中的 debian 用于指定所使用的镜像的名字。如本地磁盘上没有名为 debian 的镜像文件，则 Docker 会检查在线的 Docker Hub 并将最新版本的 Debian 镜像下载到本地。之后将下载好的镜像转化成运行的容器，并在容器中执行指定的命令。命令执行完毕后，输出的结果传送到标准输出，容器停止运行。 交互式 Shell12345$ docker run -i -t debian /bin/bashroot@4af9c13b78d7:/# echo &quot;Hello from Container&quot;Hello from Containerroot@4af9c13b78d7:/# exitexit 上面的命令会在容器中打开一个交互式 Shell （就像是 ssh 到了一个远程主机上）。-i 和 -t 选项表示打开一个已绑定了 tty 的交互式会话。当使用 exit 命令退出 bash 后，运行中的容器也会停止。 可以使用 docker start -i &lt;Container_name&gt; 命令回到交互式 Shell 中 列出 / 删除容器docker ps 命令可以列出当前正在运行的容器及其相关信息，如容器ID、使用的镜像、执行的命令、创建时间、当前状态和名称等，加上 -a 选项则列出所有容器（包含已停止运行的容器）1234567$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES$$ docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESf74ed03352d3 debian &quot;/bin/bash&quot; 9 minutes ago Exited (0) 8 minutes ago mystifying_beaver45e9e3f3847b debian &quot;echo &apos;Hello World&apos;&quot; 9 minutes ago Exited (0) 9 minutes ago quirky_mirzakhani 可以使用 docker rm &lt;Container_name&gt; 命令删除已停止运行的容器。12345$ docker rm mystifying_beavermystifying_beaver$ docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES45e9e3f3847b debian &quot;echo &apos;Hello World&apos;&quot; 13 minutes ago Exited (0) 13 minutes ago quirky_mirzakhani docker rm -v $(docker ps -aq -f status=exited) 命令可以删除所有已停止运行的容器 手动创建镜像文件从 Docker Hub 上拉取的镜像很多为初始的精简系统，运行容器后，可以给容器内的系统安装软件并提交更改，做成新的镜像供后期使用。 使用 docker run 命令运行容器并安装软件1234567891011121314$ docker run -it --name cowsay --hostname cowsay debian /bin/bashroot@cowsay:/# apt-get update...root@cowsay:/# apt-get install -y cowsay fortune...root@cowsay:/# /usr/games/fortune | /usr/games/cowsay ________________________&lt; Don&apos;t get to bragging. &gt; ------------------------ \ ^__^ \ (oo)\_______ (__)\ )\/\ ||----w | || || 其中 --name 选项用于指定容器的名称，--hostname 选项用于指定容器系统的主机名。 使用 docker commit 命令将容器转换成镜像文件。123456$ docker commit cowsay test/cowsayimagesha256:2dcb2f4d09f824120db19f79d3bfbdb85c24d4888732bcc7eaae79f707d80e32$ docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEtest/cowsayimage latest 2dcb2f4d09f8 13 minutes ago 159MBdebian latest f2aae6ff5d89 3 weeks ago 101MB docker images 命令用来查看已在本地的镜像文件及其信息。 使用生成的镜像文件12345678910$ docker run test/cowsayimage /usr/games/fortune | /usr/games/cowsay _______________________________________/ Today is the first day of the rest of \\ the mess. / --------------------------------------- \ ^__^ \ (oo)\_______ (__)\ )\/\ ||----w | || || 使用 Dockerfile 创建镜像文件Dockerfile 其实就是一个简单的文本文件，里面包含了创建 Docker 镜像的一系列步骤。相比于手动创建 Docker 镜像，使用 Dockerfile 自动地创建镜像文件，省去了大量重复的操作，同时也便于分享给其他人。 编辑 Dockerfile12$ mkdir cowsay &amp;&amp; cd cowsay$ vim Dockerfile 然后在新建的 Dockerfile 中填入以下内容：12FROM debian:wheezyRUN apt-get update &amp;&amp; apt-get install -y cowsay fortune 其中 FROM 用于指定构建时使用的初始镜像文件，RUN 用于指定在镜像中执行的 Shell 命令 构建镜像并测试使用 docker build 命令创建 Docker 镜像： 12345678910111213141516$ docker build -t test/cowsay-dockerfile .Sending build context to Docker daemon 2.048kBStep 1/2 : FROM debian:wheezywheezy: Pulling from library/debian703d6f3fb41c: Pull completeDigest: sha256:d00f167f8f2e70ecc2e0f5410a3cb74cd4ad720e33b9810da6a2dcfa81dccfc0Status: Downloaded newer image for debian:wheezy ---&gt; 94825a89630cStep 2/2 : RUN apt-get update &amp;&amp; apt-get install -y cowsay fortune ---&gt; Running in efcf246bde0f...Setting up cowsay (3.03+dfsg1-4) ...Removing intermediate container efcf246bde0f ---&gt; 88e9a0f834cdSuccessfully built 88e9a0f834cdSuccessfully tagged test/cowsay-dockerfile:latest 测试刚构建好的 Docker 镜像：123456789$ docker run test/cowsay-dockerfile /usr/games/cowsay &quot;Moo&quot; _____&lt; Moo &gt; ----- \ ^__^ \ (oo)\_______ (__)\ )\/\ ||----w | || || ENTRYPOINTDockerfile 中的 ENTRYPOINT 选项可以用来指定容器运行时自动执行的命令。如将 Dockerfile 改为如下内容并重新构建：123FROM debian:wheezyRUN apt-get update &amp;&amp; apt-get install -y cowsay fortuneENTRYPOINT [&quot;/usr/games/cowsay&quot;] 1234567891011$ docker build -t test/cowsay-dockerfile ....$ docker run test/cowsay-dockerfile &quot;Moo&quot; _____&lt; Moo &gt; ----- \ ^__^ \ (oo)\_______ (__)\ )\/\ ||----w | || || 运行上述容器时则不需要再指定命令（/usr/games/cowsay）而只输入命令的参数即可。 可以在当前目录下新建一个 entrypoint.sh 脚本：123456#!/bin/bashif [ $# -eq 0 ]; then /usr/games/fortune | /usr/games/cowsayelse /usr/games/cowsay &quot;$@&quot;fi 上述内容为 Shell 脚本文件，不作详细解释。作用是当 docker run 没有为容器中执行的命令提供参数时，执行 fortune | cowsay ，如提供了参数，则执行 cowsay &lt;参数&gt; 命令。 将 entrypoint.sh 文件添加执行权限：chmod +x entrypoint.sh将 Dockerfile 改为如下版本：1234FROM debian:wheezyRUN apt-get update &amp;&amp; apt-get install -y cowsay fortuneCOPY entrypoint.sh /ENTRYPOINT [&quot;/entrypoint.sh&quot;] 其中 COPY 选项用来将本地主机上的文件复制到镜像的文件系统里（类似于 cp 命令） 最终效果如下：123456789101112131415161718192021$ docker build -t test/cowsay-dockerfile ....$ docker run test/cowsay-dockerfile _________________________________________/ You don&apos;t become a failure until you&apos;re \\ satisfied with being one. / ----------------------------------------- \ ^__^ \ (oo)\_______ (__)\ )\/\ ||----w | || ||$ docker run test/cowsay-dockerfile Hello Moo ___________&lt; Hello Moo &gt; ----------- \ ^__^ \ (oo)\_______ (__)\ )\/\ ||----w | || || 四、基本使用端口转发假如容器中运行着一个 Web 服务器，需要外部世界可以访问。此时可以使用 docker 的 -p 或 -P 选项，将本地主机的端口转发至容器内的端口。如：12345678910111213141516$ docker run -d -p 8000:80 nginxUnable to find image &apos;nginx:latest&apos; locallylatest: Pulling from library/nginx...Status: Downloaded newer image for nginx:latestbe1364f343ae7aff9d5a6f6040b5d6ca69363a4480f04548988dd798ab04ab7b$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESbe1364f343ae nginx &quot;nginx -g &apos;daemon of…&quot; 8 seconds ago Up 7 seconds 0.0.0.0:8000-&gt;80/tcp quirky_mclean$ curl localhost:8000&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;...$ 其中 docker run -d -p 8000:80 nginx 命令用于在后台（-d 选项）启动一个由官方 nginx 镜像创建的容器，并将本地主机的 8000 端口映射到容器的 80 端口（-p 8000:80），即容器中 nginx 服务运行的端口。可以看到，当使用 curl 命令访问本地主机的 8000 端口时，等同于访问了容器的 80 端口，即容器中的 nginx 服务。 而 -P 选项可以自动选择空闲的端口进行转发，无需指定本地主机或容器的端口。可参考以下实例：123456789$ ID=$(docker run -d -P nginx)$ docker port $ID 800.0.0.0:32768$ curl localhost:32768&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;... 关联容器容器关联可以允许同一个主机上的多个容器相互交换数据。当使用默认的网络模型时，这些关联的容器通过其“内部”网络传输数据，即关联容器间的相互交流不会暴露给本地主机。 可参考以下实例：1234567$ docker run --name myredis -d redisbe53967c42fd3292dfd59fd5d15e7025fa436816e46f6e7cbc3c47b06ddb0047$ docker run --rm -it --link myredis:redis redis /bin/bashroot@b27aca7d8c54:/data# redis-cli -h redis -p 6379redis:6379&gt; pingPONGredis:6379&gt; 其中 docker run --name myredis -d redis 命令用于在后台启动一个 redis 容器，并将其命名为 myredis 。同时返回该容器的 ID 到标准输出。docker run --rm -it --link myredis:redis redis /bin/bash 命令用于启动另一个 redis 容器，并以交互的方式访问其 Shell （-it /bin/bash）。--rm 选项表示该容器退出后将自动删除。 容器关联的操作则由 --link myredis:redis 选项实现。表示将新容器关联至已存在的 “myredis” 容器，并为 “myredis” 容器设置别名为 “redis” ，即可以在当前的新容器中通过别名（redis）访问。 该选项会在新容器的 /etc/hosts 文件中添加一条主机名为 redis 的记录，并将其指向 “myredis” 容器的 IP 地址。所以在当前容器的 Shell 中使用 redis-cli 命令访问 “myredis” 中的服务时，可以无需指定其 IP 地址，直接使用主机名 “redis” 即可。（redis-cli -h redis -P 6379） 存储卷可以在使用 docker run 时通过 -v 选项指定存储卷：123456$ docker run -it --name container-test -h CONTAINER -v /data debian /bin/bashroot@CONTAINER:/# cd /data ; touch test-fileroot@CONTAINER:/data# lstest-fileroot@CONTAINER:/data# exitexit 上面的命令会将容器中的 /data 目录变成一个存储卷，该目录下的任何文件都会被复制到卷中。 可以使用 docker inspect 命令查看该存储卷在本地主机中的位置：12$ docker inspect -f &#123;&#123;.Mounts&#125;&#125; container-test[&#123;volume 7ae1... /var/lib/docker/volumes/7ae1.../_data /data local true &#125;] 可以在存储卷对应于本地主机的目录（/var/lib/docker/volumes/7ae1.../_data）中创建文件，容器中对应目录（/data）下则会立即出现同样的文件。1234567$ sudo ls /var/lib/docker/volumes/7ae1.../_datatest-file$ sudo touch /var/lib/docker/volumes/7ae1.../_data/test-file2$ docker start -i container-testroot@CONTAINER:/# ls /datatest-file test-file2root@CONTAINER:/# 存储卷还可以通过 Dockerfile 中的 VOLUME 选项指定。如：VOLUME /data 共享数据可以使用 -v HOST_DIR:CONTAINER_DIR 选项在本地主机和一（或多）个容器间共享数据。如：$ docker run -v /home/starky/data:/data debian ls /data 该命令会将本地主机上的 /home/starky/data 目录挂载到容器中的 /data 目录下，所有已经存在于 /home/starky/data 目录下的文件在容器中也同样能够被访问。但是原本存在于容器的 /data 目录下的文件则被隐藏。如某些配置文件可以一直存放在本地主机上，并在需要时挂载到通用镜像构建的容器中。 可以使用 docker run 命令的 --volumes-from CONTAINER 选项在容器间共享数据。如：1234$ docker run -it -h NEWCONTAINER --volumes-from container-test debian /bin/bashroot@NEWCONTAINER:/# ls /datatest-file test-file2root@NEWCONTAINER:/# 上面的命令创建了一个新的容器，且通过 --volumes-from 选项，该容器可以访问之前的 container-test 容器中的存储卷（/data）。 数据容器数据容器是一种特殊的容器，其唯一目的是为了方便其他容器之间共享数据。如创建一个 PostgreSQL 的数据容器：$ docker run --name dbdata postgres echo &quot;Data-only container for postgres&quot;该命令用于从 postgres 镜像创建一个容器，并初始化镜像里定义的存储卷。 之后可以通过 --volumes-from 选项使用数据容器里的存储卷：$ docker run -d --volumes-from dbdata --name db1 postgres 参考资料Using Docker: Developing and Deploying Software with Containers]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Admin</tag>
        <tag>Tools</tag>
        <tag>Development</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 用户管理简介]]></title>
    <url>%2F2018%2F09%2F05%2Flinux-user-management%2F</url>
    <content type="text"><![CDATA[一、创建用户Linux 系统可以使用 useradd 命令创建新用户：$ sudo useradd -m -c &#39;description&#39; &lt;username&gt; -m 选项表示创建用户的同时自动在 /home 目录下创建该用户的主目录（/home/&lt;username&gt;） -c 选项用于给新用户添加描述，该描述将保存在 /etc/passwd 文件中 默认情况下，新创建的用户并未分配密码，需要使用 passwd &lt;username&gt; 命令为新用户设置密码。 PS：在为新用户自动创建主目录时，可以同时复制一部分初始文件（如 .bashrc、.vimrc 等）到该目录下，复制的源文件默认位于 /etc/skel 目录下。即创建新用户时，/etc/skel/ 目录下的所有文件都将自动复制到新用户的主目录中。 在 Ubuntu 系统中，useradd 命令默认不自动创建用户主目录，所以需要带上 -m 选项。而 Centos 系统中，useradd 命令默认会自动创建用户主目录，可以加上 -M 选项表示不创建用户主目录。 useradd 的部分命令选项： 选项 描述 -c, –comment 添加用户描述 -d, –home-dir 指定用户的主目录位置 -m, –create-home 自动创建用户的主目录 -M, –no-create-home 不自动创建用户主目录（CentOS） -N, –no-user-group 不创建同名的组 -s, –shell 指定用户使用的 shell -g, –gid 指定新账户主组的名称或 ID -G, –groups 指定新账户的附加组列表 -e, –expiredate 指定新账户的过期日期 -f, –inactive 用户密码过期后的重置密码期限 -r, –system 创建一个系统账户 -k, –skel 指定骨架目录（默认为 /etc/skel） PS：其中的 INACTIVE 和 EXPIRE 选项用于设置用户账号的过期时间。INACTIVE 用于指定一个期限（单位为天），在该期限内，密码失效后的用户可以重置自己的密码。该选项值为 -1 时则禁用此特性。EXPIRE 用于指定一个截止日期（格式为 YYYY-MM-DD），超过该期限后用户账号即被禁用。 $ sudo useradd -e 2018-10-01 temp_account # 创建一个临时账户 用户默认设置新用户在创建时会使用一些预先定义的默认设置，useradd 命令从 /etc/default/useradd 文件中获取这些默认设置。当前的默认配置可以通过 useradd -D 命令显示：12345678$ useradd -DGROUP=100HOME=/homeINACTIVE=-1EXPIRE=SHELL=/bin/bashSKEL=/etc/skelCREATE_MAIL_SPOOL=no 可以直接通过 useradd -D 命令修改 useradd 的默认设置，如：$ sudo useradd -D -s /bin/bash # 将新建用户的默认 shell 设置为 /bin/bash 二、用户组在 Linux 系统中，任何一个用户都必须属于至少一个用户组。对于大多数 Linux 发行版，创建新用户时会自动创建一个同名的用户组。初始创建的同名用户组叫做基础属组（primary group），用户还可以同时属于其他用户组，这些用户组叫做附加属组（supplementary group）。如：12$ id starkyuid=1000(starky) gid=1000(starky) 组=1000(starky),4(adm),24(cdrom),27(sudo),30(dip),46(plugdev),116(lpadmin),122(sambashare) 每一个用户和用户组在创建时都会关联于一个唯一的 UID 和 GID。UID 和 GID 的取值范围都是 0-65535 。root 用户的 UID 和 GID 永远都是 0 。12$ id rootuid=0(root) gid=0(root) 组=0(root Ubuntu 系统中 1-99 的 ID 只用于分配给系统用户（如运行服务的 www-data），100-999 则动态地分配给系统守护进程的用户（在创建用户时使用 --system 选项）。而第一个普通用户则分配值为 1000 的 UID 和 GID。 使用 useradd 命令创建新用户时，可以同时为该用户关联附加属组。用户创建完成后也可以使用 usermod 命令修改该用户的附加属组。如：1234567$ sudo useradd test -G lpadmin,sambashare # 创建用户 test 并将其添加至 lpadmin 和 sambashare 组$ id testuid=1004(test) gid=1004(test) 组=1004(test),116(lpadmin),122(sambashare)$$ sudo usermod test -a -G sudo # 将用户 test 添加（-a）至 sudo 用户组$ id testuid=1004(test) gid=1004(test) 组=1004(test),27(sudo),116(lpadmin),122(sambashare) usermod 命令用于修改已经存在的用户。常用命令选项如下：1234567891011121314151617181920212223$ usermod用法：usermod [选项] 登录选项： -c, --comment 注释 GECOS 字段的新值 -d, --home HOME_DIR 用户的新主目录 -e, --expiredate EXPIRE_DATE 设定帐户过期的日期为 EXPIRE_DATE -f, --inactive INACTIVE 过期 INACTIVE 天数后，设定密码为失效状态 -g, --gid GROUP 强制使用 GROUP 为新主组 -G, --groups GROUPS 新的附加组列表 GROUPS -a, --append GROUP 将用户追加至上边 -G 中提到的附加组中， 并不从其它组中删除此用户 -h, --help 显示此帮助信息并退出 -l, --login LOGIN 新的登录名称 -L, --lock 锁定用户帐号 -m, --move-home 将家目录内容移至新位置 (仅与 -d 一起使用) -o, --non-unique 允许使用重复的(非唯一的) UID -p, --password PASSWORD 将加密过的密码 (PASSWORD) 设为新密码 -R, --root CHROOT_DIR chroot 到的目录 -s, --shell SHELL 该用户帐号的新登录 shell -u, --uid UID 用户帐号的新 UID -U, --unlock 解锁用户帐号 -Z, --selinux-user SEUSER 用户账户的新 SELinux 用户映射 具体可参考命令：man usermod 三、删除用户（组）userdel 命令可用于删除用户，groupdel 命令可用于删除用户组。默认不带选项的 userdel 命令只会删除用户，并不会同时删除该用户的主目录（可以通过加上 -r 选项强制删除用户主目录）。 删除某个用户后，所有原本属于该用户的文件都将失去属主，而被对应的 UID 所代替。如果之后又新建一个用户，而该用户使用了之前已删除账户的 UID，则新账户会替代已删除的账户并获取其文件的权限。 可以使用 find / -user UID -o -group GID 命令定位已删除账户拥有的所有文件 四、密码使用 useradd 命令创建新用户时，是不自动提示创建密码的（Ubuntu系统中的 adduser 命令可以交互地创建新用户）。需要使用 passwd 命令为用户设置或修改密码。 密码时效可以使用 chage 命令设置用户密码的有效期限，如：$ sudo chage -M 30 test30 天后，用户 test 的密码将会过期，并收到提示需要输入新的密码。 chage 命令的常用选项：|选项|描述||-|-||-m days|设置用户修改密码的最小间隔时间，值为 0 时表示可以在任何时间修改密码||-M days|设置密码保持有效的最长期限，即修改密码的最大间隔时间||-E date|设置用户账户过期并自动被禁用的日期||-W days|设置密码过期前多少天用户被警告需要修改密码||-I days|设置密码失效多长时间后账户被锁定| 不带任何选项的 chage 命令可以交互地修改密码时效：1234567891011$ sudo chage test正在为 test 修改年龄信息请输入新值，或直接敲回车键以使用默认值 最小密码年龄 [0]: 最大密码年龄 [99999]: 60 最近一次密码修改时间 (YYYY-MM-DD) [2018-09-03]: 密码过期警告 [7]: 密码失效 [-1]: 帐户过期时间 (YYYY-MM-DD) [-1]:$ 用户可以使用 chage -l 命令查看自己的密码时效设置：12345678chage -l test最近一次密码修改时间 ： 9月 03, 2018密码过期时间 ： 11月 02, 2018密码失效时间 ： 从不帐户过期时间 ： 从不两次改变密码之间相距的最小天数 ：0两次改变密码之间相距的最大天数 ：60在密码过期之前警告的天数 ：7 账户禁用可以使用 passwd -l &lt;user&gt; 命令禁用用户账号，使用 passwd -u &lt;user&gt; 命令解除账户禁用。但是这个命令并不能完全禁止用户的访问（如该用户还可以通过 SSH 远程登录主机）。 如需完全禁用某用户，可使用如下命令：sudo usermod --expiredate 1 &lt;user&gt;该命令会将用户账号的失效日期设置为 1970 年 1月 1 日（即立即禁用）。 或者将用户登录时的 shell 修改为 /bin/false 或 /usr/sbin/nologin。$ sudo usermod -s /bin/false &lt;user&gt;该命令不会锁定账户，但该账户对 shell 的访问已被限制。 五、用户信息Linux 系统将用户、群组等信息保存在以下三个文件中：/etc/passwd、/etc/shadow、/etc/group。 /etc/passwd 文件中包含了所有用户的列表及详细信息：1234567root:x:0:0:root:/root:/bin/bash...starky:x:1000:1000:starky,,,:/home/starky:/bin/bashsshd:x:112:65534::/run/sshd:/usr/sbin/nologinpostgres:x:113:123:PostgreSQL administrator,,,:/var/lib/postgresql:/bin/bashskitar:x:1001:1001::/home/skitar:/bin/bashmysql:x:114:124:MySQL Server,,,:/nonexistent:/bin/false 该文件的格式为：username:password:UID:GID:GECOS:Home:Shell其中的 password 项都为 x ，而实际的密码保存在 /etc/shadow 文件中。 /etc/group 文件的格式为：groupname:password:GID:member,member 六、sudosudo 命令可以使普通用户以 root 用户身份执行命令。使用 useradd 命令新建的用户默认没有使用 sudo 命令的权限，需要先将其加入 sudo 用户组。$ sudo usermod &lt;user&gt; -a -G sudo sudo 的本意是以其他用户的身份执行命令。可以使用 -u 选项指定“其他”身份。默认即为 root 用户。 配置 sudosudo 命令通过检查 /etc/sudoers 中的配置来确定授权规则。可以通过编辑 sudoers 文件将 sudo 的授权限制为指定的用户，指定的主机，或只能执行特定的命令。sudoers 文件的格式为：username host = command如：test ALL=/bin/userdel,/bin/useradd 可以将授权使用的命令限定为某个目录中的所有命令（但不包含其子目录），如：test ALL=/bin/*,/sbin/* 有些时候需要将使用某个命令的权限授予一个用户，但该命令又需要使用另外一个用户的身份执行（如 MySQL 的系统守护进程）。可以使用下面的格式：test ALL=(mysql) /usr/bin/mysqld 还可以通过用户组信息完成对 sudo 的授权：%groupname ALL=(ALL) ALL上面的配置表示该组的所有用户可以在任何主机使用 sudo 执行任何命令。 别名设置/etc/sudoers 文件中允许定义和使用别名，包括用户别名（User_Alias）、主机别名（Host_Alias）和命令别名（Cmnd_Alias）。如：123User_Alias ADMIN = skitar,testCmnd_Alias USER_COMMANDS = /bin/userdel,/bin/useraddADMIN ALL=/bin/groupadd,USER_COMMANDS 上面的配置表示用户 skitar 和 test 可以在所有主机上通过 sudo 执行 userdel、useradd 和 groupadd 命令。 还可以在别名前加上感叹号（!）表示拒绝：12Cmnd_Alias DENIED_COMMANDS = /bin/su,/bin/mount/,/bin/umounttest ALL=/bin/*,!DENIED_COMMANDS 上面的配置表示 test 用户可以在所有主机上通过 sudo 执行除了 su、mount 和 umount 以外的所有 /bin 目录下的命令。 参考资料Pro Linux System Administration: Learn to Build Systems for Your Business Using Free and Open Source Software 2nd Edition]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Admin</tag>
        <tag>System</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Glances - Linux 上的实时系统监控工具]]></title>
    <url>%2F2018%2F08%2F24%2Fuse-glances-monitor-system%2F</url>
    <content type="text"><![CDATA[Glances 是一个跨平台的、基于命令行的系统监控工具，由 Python 语言编写，使用 Python 的 psutil 库来抓取系统数据。可以监控 CPU、负载均衡、内存、网络设备、磁盘 I/O、进程和文件系统使用等。 一、输出信息概览 CPU 信息（用户应用、系统核心程序、闲置） 内存信息，包括 RAM、交换空间、闲置内存等 CPU 的平均负载（过去 1 分钟、5 分钟、15 分钟） 网络连接的下载 / 上传速率 进程总数（running、sleeping 等） 磁盘 I/O 读写速度 当前已挂载设备的磁盘空间使用 高资源占用的进程，及其 CPU/内存占用、PID、状态等 底部显示当前时间 将资源消耗过高的进程红色高亮显示 二、软件安装Glances 一般已集成到大多数 Linux 发行版的官方软件源中。可以直接使用系统的包管理器（如 apt-get、yum）安装：sudo apt-get install glances当然也可以使用 Python 的包管理器（pip 命令）进行安装：pip install glances 默认情况下，监控信息的刷新时间为 1 秒钟。可以使用 -t 选项自定义间隔时间：glances -t 2 Glances 有 4 种颜色标记，分别表示不同的紧急程度： 绿色：OK 蓝色：CAREFUL 紫色：WARNING 红色：CRITICAL 可以在配置文件（默认为 /etc/glances/glances.conf ）中自行更改阈值。默认为 careful = 50、warning = 70、critical = 90 。 三、命令选项（热键） a：自动排序进程 c：按 CPU 使用率排序进程 m：按内存占用排序进程 p：按名称排序进程 i：按 I/O 速率排序进程 d：显示或隐藏磁盘 I/O 统计 f：显示或隐藏文件系统使用统计 n：显示或隐藏网络流量统计 s：显示或隐藏传感器数据统计 l：显示或隐藏日志 h：显示帮助信息 q：退出 四、监控远程系统可以在远程系统中以服务模式运行 glances 程序，再通过客户端上的 glances 连接到远程系统，以监控其状态。可以使用 -s 选项启用服务器/客户端模式：123456$ glances -s --usernameDefine the Glances server username: starkyDefine the Glances server password (starky username):Password (confirm):Do you want to save the password? [Yes/No]: YesGlances XML-RPC server is running on 0.0.0.0:61209 客户端使用 -c 选项连接：glances -c ip_address --username WebServer 模式在 glances 的 WebServer 模式下，客户端只通过浏览器访问就可以获取远程服务器的运行状态。该模式需要额外安装 Python 的 Bottle 模块：pip install bottle安装成功后，使用 glances -w 命令即可开启 WebServer 模式。客户端使用浏览器访问 http://SERVER_IP:61208/ 进入监控界面。 将 WebServer 模式配置为系统服务 创建 Unit 文件sudo vim /etc/systemd/system/glancesweb.service文件内容如下： 1234567[Unit]Description = Glances in Web Server ModeAfter = network.target[Service]ExecStart = /usr/bin/glances -w -t 5 # glances路径因安装方法不同根据实际情况确定，可使用 which glances 命令获取[Install]WantedBy = multi-user.target 启用 systemd 服务并运行 123456789101112$ sudo systemctl enable glancesweb$ sudo systemctl start glancesweb$ systemctl status glancesweb● glancesweb.service - Glances in Web Server Mode Loaded: loaded (/etc/systemd/system/glancesweb.service; enabled; vendor preset: enabled) Active: active (running) since Tue 2018-08-21 00:02:17 CST; 8min ago Main PID: 27912 (glances) Tasks: 1 (limit: 4915) CGroup: /system.slice/glancesweb.service └─27912 /home/starky/miniconda3/envs/python2/bin/python /home/starky/miniconda3/envs/python2/bin/glances -w -t 58月 21 00:02:17 starky-ThinkPad-T460 systemd[1]: Started Glances in Web Server Mode. 参考文章Glances – An Advanced Real Time System Monitoring Tool for LinuxUse Glances to Monitor Remote Linux in Web Server Mode]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Admin</tag>
        <tag>System</tag>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 进程管理详解]]></title>
    <url>%2F2018%2F08%2F17%2FLinux-Process-Management%2F</url>
    <content type="text"><![CDATA[进程 是 Unix 和 Linux 系统中对正在运行中的应用程序的抽象，通过它可以管理和监视程序对内存、处理器时间和 I / O 资源的使用。 一、进程的组成一个进程包含内核中的一部分地址空间和一系列数据结构。其中地址空间是内核标记的一部分内存以供进程使用，而数据结构则用来纪录每个进程的具体信息。 最主要的进程信息包括： 进程的地址空间图 进程当前的状态（ sleeping、stopped、runnable 等） 进程的执行优先级 进程调用的资源信息 进程打开的文件和网络端口信息 进程的信号掩码（指明哪种信号被屏蔽） 进程的属主 PID ：进程 ID每个进程都会从内核获取一个唯一的 ID 值。绝大多数用来操作进程的命令和系统调用，都需要用 PID 指定操作的进程对象。 PPID ：父进程 ID在 Unix 和 Linux 系统中，一个已经存在的进程必须“克隆”它自身来创建一个新的进程。当新的进程克隆后，最初的进程便作为父进程存在。 UID &amp; EUID：真实用户 ID 和有效用户 ID一个进程的 UID 是其创建者的身份标志（也是对其父进程 UID 的复制）。通常只有进程的创建者和超级用户才有操作该进程的权限。EUID 是一个额外的 UID，用来决定在任意一个特定时间点，一个进程有权限访问的文件和资源。对绝大多数进程而言，UID 和 EUID 是相同的（特殊情况即 setuid） Niceness一个进程的计划优先级决定了它能获取到的 CPU 时间。内核有一个动态的算法来计算优先级，同时也会关注一个 Niceness 值，来决定程序运行的优先顺序。 二、信号信号属于进程级别的中断请求。它们可以作为进程间通信的手段，或者由终端发送以杀死、中断、挂起某个进程。 常见信号列表： # name Description Default Can catch? Can block? Dump core? 1 HUP Hangup Terminate Yes Yes No 2 INT Interrupt（Ctrl + C） Terminate Yes Yes No 3 Quit Quit（Ctrl + \） Terminate Yes Yes Yes 9 KILL Kill Terminate No No No BUS Bus error Terminate Yes Yes Yes 11 SEGV Segmentation fault Terminate Yes Yes Yes 15 TERM Software terminatation Terminate Yes Yes No STOP Stop（Ctrl + Z） Stop No No No TSTP Keyboard stop Stop Yes Yes No CONT Continue after stop Ignore Yes No No 三、Kill 命令kill 命令常用来终止某个进程，它可以向进程传递任意信号（默认为 TERM）。kill [-signal] pid不带任何数字（信号）选项的 kill 命令并不能保证指定进程被杀死，因为 kill 命令默认发送 TERM 信号，而 TERM 是可以被捕获、屏蔽或忽略的。可以使用 kill -9 pid 命令强制杀死进程（9 代表 KILL 信号，不可被捕获、屏蔽或忽略）。 kill 命令需要指定进程的 PID 号。pgrep 命令可以通过程序名称（或其他属性如 UID）筛选进程号，pkill 命令可以直接发送指定信号给筛选结果。如 sudo pkill -u ben该命令将发送 TERM 信号给所有属于用户 ben 的进程。 killall 命令可以通过程序名称杀死指定进程的所有实例。如：sudo killall apache2123456789101112131415161718192021$ pgrep postgres # 筛选 postgres 进程的 PID 号 25874258762587725878258792588025881$ pgrep -a postgres # 筛选 postgres 进程的 PID 号，并输出详细信息25874 /usr/lib/postgresql/10/bin/postgres -D /var/lib/postgresql/10/main -c config_file=/etc/postgresql/10/main/postgresql.conf25876 postgres: 10/main: checkpointer process25877 postgres: 10/main: writer process25878 postgres: 10/main: wal writer process25879 postgres: 10/main: autovacuum launcher process25880 postgres: 10/main: stats collector process25881 postgres: 10/main: bgworker: logical replication launcher$ sudo kill -9 `pgrep postgres` # 杀死 postgres 进程$ sudo pkill postgres # 同上一条命令$ sudo killall postgres # 杀死 postgres 进程的所有实例$ sudo pkill -9 -u postgres # 杀死属于 postgres 用户的所有进程 根据进程 PID 号查找进程可以使用 ps -p &lt;pid&gt; -o comm= 命令 四、进程状态 状态 含义 Runnable 该进程正在（正准备）执行 Sleeping 该进程正等待某些资源 Zombie 该进程正努力尝试结束 Stopped 该进程已挂起（不允许执行） Runnable 表示进程已经获取到了运行所需的所有资源，只是等待相应的 CPU 时间来处理数据。 Sleeping 表示进程处于等待特定事件发生的状态。交互式 Shell 和系统守护进程的大部分时间都是 Sleeping 状态，等待用户输入或网络连接。 Zombies 表示进程已经结束执行，但是还没有收集完所有的状态，在进程表中仍有纪录。 Stopped 表示进程已停止运行，通常是收到了某种停止信号。 五、PS 命令：监控资源ps 命令是系统管理员监控进程的主要工具。该命令可以显示进程的 PID、UID、优先级和控制终端，以及进程占用的内存、消耗的 CPU 时间和当前的状态等信息。 常用的 PS 命令选项组合： 1. ps auxa 选项表示显示所有进程，x 选项表示同时显示没有控制终端的进程（TTY 显示为 ?），u 选项表示使用基于用户的信息输出格式1234567891011121314151617181920212223$ ps auxUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDroot 1 0.0 0.1 225428 9548 ? Ss 7月30 0:30 /lib/systemd/systemd --system --deserialize 19root 2 0.0 0.0 0 0 ? S 7月30 0:00 [kthreadd]root 4 0.0 0.0 0 0 ? I&lt; 7月30 0:00 [kworker/0:0H]root 6 0.0 0.0 0 0 ? I&lt; 7月30 0:00 [mm_percpu_wq]root 7 0.0 0.0 0 0 ? S 7月30 0:03 [ksoftirqd/0]root 8 0.0 0.0 0 0 ? I 7月30 14:49 [rcu_sched]...starky 6874 0.0 0.1 33016 8556 pts/2 Ss 8月07 0:00 bashstarky 7150 0.0 0.0 33016 6044 pts/2 S+ 8月07 0:00 bashstarky 7151 3.1 16.1 4763784 1227932 pts/2 Sl+ 8月07 272:54 java -Xmx1024M -Xms512M -jar minecraft_server.1.12.2.jar nogui...root 18447 0.0 0.0 107984 7116 ? Ss 13:55 0:00 sshd: starky [priv]starky 18535 0.0 0.0 108092 4268 ? S 13:55 0:00 sshd: starky@pts/1starky 18536 0.0 0.1 33096 8336 pts/1 Ss 13:55 0:00 -bashroot 18761 0.0 0.0 0 0 ? I 13:55 0:00 [kworker/u8:0]root 18799 0.0 0.0 0 0 ? I 14:01 0:00 [kworker/u8:1]root 18805 0.0 0.0 0 0 ? I 14:05 0:00 [kworker/0:2]starky 18874 0.0 0.0 46780 3568 pts/1 R+ 14:10 0:00 ps -auxredis 19235 0.2 0.0 58548 3736 ? Ssl 8月04 30:03 /usr/bin/redis-server 127.0.0.1:6379root 20799 0.0 0.0 107548 7504 ? Ss 8月05 0:00 /usr/sbin/cupsd -lroot 28342 0.0 0.4 535068 36940 ? Ss 8月10 0:16 /usr/sbin/apache2 -k start 其中带中括号的命令（如 [kthreadd]）并不是真正的命令而是内核线程。 ps aux 命令输出的各列信息含义如下： 项目 解释 USER 进程属主的用户名 PID 进程 ID %CPU 进程占用的 CPU 百分比 %MEM 进程使用的内存百分比 VSZ 进程的虚拟大小 RSS 驻留内存大小（内存中的页数） TTY 控制终端 ID STAT 进程当前的状态：R = RunnableD = In uninterruptible sleepS = Sleeping(&lt;20s)T = Traced or stoppedZ = Zombie额外标记：W = Process is swapped out&lt; = 进程有相对于平时更高的优先级N = 进程有相对于平时更低的优先级L = Some pages are locked in cores = Process is a session leader TIME 进程已经消耗的 CPU 时间 COMMAND 进程的命令和命令选项 2. ps laxl 选项表示以详细的格式输出进程信息。1234567891011121314151617181920212223242526$ ps laxF UID PID PPID PRI NI VSZ RSS WCHAN STAT TTY TIME COMMAND4 0 1 0 20 0 225428 9548 - Ss ? 0:30 /lib/systemd/systemd --system --deserialize 191 0 2 0 20 0 0 0 - S ? 0:00 [kthreadd]1 0 4 2 0 -20 0 0 - I&lt; ? 0:00 [kworker/0:0H]1 0 6 2 0 -20 0 0 - I&lt; ? 0:00 [mm_percpu_wq]1 0 7 2 20 0 0 0 - S ? 0:03 [ksoftirqd/0]1 0 8 2 20 0 0 0 - I ? 14:58 [rcu_sched]...0 1000 6874 6871 20 0 33016 8556 wait Ss pts/2 0:00 bash1 1000 7150 6874 20 0 33016 6044 wait S+ pts/2 0:00 bash0 1000 7151 7150 20 0 4763784 1227932 futex_ Sl+ pts/2 275:03 java -Xmx1024M -Xms512M -jar minecraft_server.1.12.2.jar nogui...4 0 18447 619 20 0 107984 7116 - Ss ? 0:00 sshd: starky [priv]5 1000 18535 18447 20 0 108092 4268 - S ? 0:00 sshd: starky@pts/10 1000 18536 18535 20 0 33096 8336 wait Ss pts/1 0:00 -bash1 0 19051 2 20 0 0 0 - I ? 0:00 [kworker/3:0]1 0 19141 2 20 0 0 0 - I ? 0:00 [kworker/2:3]1 115 19235 1 20 0 58548 3736 - Ssl ? 30:22 /usr/bin/redis-server 127.0.0.1:63791 0 19246 2 20 0 0 0 - I ? 0:00 [kworker/2:0]1 0 19291 2 20 0 0 0 - I ? 0:00 [kworker/u8:0]1 0 19312 2 20 0 0 0 - I ? 0:00 [kworker/0:2]1 0 19405 2 20 0 0 0 - I ? 0:00 [kworker/u8:1]0 1000 19417 18536 20 0 36024 1596 - R+ pts/1 0:00 ps -lax4 0 20799 1 20 0 107548 7504 - Ss ? 0:00 /usr/sbin/cupsd -l5 0 28342 1 20 0 535068 36940 - Ss ? 0:16 /usr/sbin/apache2 -k start ps lax 命令的输出包含了父进程 ID（PPID）、nice 值（NI）还有进程正在等待的资源类型（WCHAN）等。 3. ps axjfps axjf 命令能够以树状结构显示各进程间的层级关系f 选项表示用 ASCII 字符显示树状结构，表达程序间的相互关系。12345678910111213141516171819202122$ ps axjf PPID PID PGID SID TTY TPGID STAT UID TIME COMMAND 0 2 0 0 ? -1 S 0 0:00 [kthreadd] 2 4 0 0 ? -1 I&lt; 0 0:00 \_ [kworker/0:0H] 2 6 0 0 ? -1 I&lt; 0 0:00 \_ [mm_percpu_wq] 2 7 0 0 ? -1 S 0 0:02 \_ [ksoftirqd/0] 2 8 0 0 ? -1 I 0 4:26 \_ [rcu_sched]... 1 672 672 672 ? -1 Ss 0 0:00 /usr/sbin/sshd -D 672 27078 27078 27078 ? -1 Ss 0 0:00 \_ sshd: starky [priv]27078 27166 27078 27078 ? -1 S 1000 0:00 \_ sshd: starky@pts/127166 27167 27167 27167 pts/1 27438 Ss 1000 0:00 \_ -bash27167 27438 27438 27167 pts/1 27438 R+ 1000 0:00 \_ ps axjf 1 681 681 681 ? -1 Ssl 115 9:40 /usr/bin/redis-server 127.0.0.1:6379 1 700 700 700 tty1 700 Ss+ 0 0:00 /sbin/agetty -o -p -- \u --noclear tty1 linux 1 710 710 710 ? -1 Ss 0 0:14 /usr/sbin/apache2 -k start 710 25651 710 710 ? -1 S 33 0:00 \_ /usr/sbin/apache2 -k start 710 25652 710 710 ? -1 S 33 0:00 \_ /usr/sbin/apache2 -k start 710 25653 710 710 ? -1 S 33 0:00 \_ /usr/sbin/apache2 -k start 710 25654 710 710 ? -1 S 33 0:00 \_ /usr/sbin/apache2 -k start 710 25655 710 710 ? -1 S 33 0:00 \_ /usr/sbin/apache2 -k start ... 4. ps ops o 命令加上选项可以指定信息的输出格式，同时加上 --sort 选项可指定排序依据如：ps axo pid,ppid,%mem,%cpu,cmd --sort=-%mem上面的命令表示输出进程的 PID、PPID、内存占用、CPU占用和命令选项。并以内存占用大小排序。（--sort=-%mem 中的 - 表示逆向排序，即由大到小排序）1234567891011$ ps axo pid,ppid,%mem,%cpu,cmd --sort=-%mem | head PID PPID %MEM %CPU CMD 1790 1789 14.1 3.8 java -Xmx1024M -Xms512M -jar minecraft_server.1.12.2.jar nogui 1357 1 2.6 0.1 /usr/sbin/mysqld --daemonize --pid-file=/run/mysqld/mysqld.pid 9343 1 2.0 0.0 /usr/bin/python3 /usr/bin/update-manager --no-update --no-focus-on-map 1244 1 1.5 0.0 sogou-qimpanel %U 1024 1 1.0 0.0 /usr/bin/fcitx 1454 1 0.9 0.0 fcitx-qimpanel 7401 1067 0.7 0.0 lxterminal 248 1 0.6 0.0 /lib/systemd/systemd-journald 1119 1 0.6 0.0 nm-applet 可以尝试不同的命令选项组合来获取相应的信息，具体可参考 man ps 六、使用 TOP 命令动态监控进程top 命令可以实时显示系统当前活跃进程的总体信息及其占用的资源。top 命令的 -d 选项可以指定信息刷新的时间间隔。同时还有一些常用的交互命令 命令 描述 h 显示帮助信息 k 终止某个进程 i 忽略闲置和僵死进程（这是一个开关式命令） q 退出 top 程序 r 重新设置某个进程的优先级 s 改变两次刷新之间的延迟时间（单位为s） f 或 F 从当前显示中添加或者删除项目 l 切换显示平均负载和启动时间信息 m 切换显示内存信息 t 切换显示进程和CPU状态信息 c 切换显示命令名称和完整命令 M 根据驻留内存大小进行排序 P 根据CPU使用百分比大小进行排序 T 根据时间/累计时间进行排序 w 将当前设置写入 ~/.toprc 文件中 七、前台/后台进程 前台进程（也称作交互式进程）：由某个终端会话创建和控制的进程。即需要用户控制而不能作为系统服务自动启动。 后台进程（也称作非交互式进程）：不和终端绑定的进程，不等待用户输入。 可以在命令后带上 &amp; 符号，在后台启用一个 Linux 进程执行该命令。并通过 jobs 命令查看当前的任务。使用 fg 命令将后台执行的进程调到前台执行使用 Ctrl + Z 组合键（发送 SIGSTOP 信号）挂起当前进程（前台），并使用 bg 命令令其在后台继续执行1234567891011121314$ python -m SimpleHTTPServer &amp; # 后台启动 python 进程[1] 28036$ Serving HTTP on 0.0.0.0 port 8000 ...$ jobs # 使用 jobs 命令查看后台进行的任务[1]+ 运行中 python -m SimpleHTTPServer &amp;$ fg %1 # 将后台执行的第一个任务调到前台执行（fg %1）python -m SimpleHTTPServer^Z # 使用 Ctrl + Z 组合键（发送 STOP 信号）停止当前进程[1]+ 已停止 python -m SimpleHTTPServer$ bg # 使用 bg 命令将进程调至后台继续执行[1]+ python -m SimpleHTTPServer &amp;$ fg %1python -m SimpleHTTPServer 参考资料UNIX and Linux System Administration Handbook, 4th EditionAll You Need To Know About Processes in Linux]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Admin</tag>
        <tag>System</tag>
        <tag>Tools</tag>
        <tag>Trick</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 文本处理命令详解（tr cut sort uniq）]]></title>
    <url>%2F2018%2F07%2F03%2FLinux-text-manipulation%2F</url>
    <content type="text"><![CDATA[一、tr 命令tr (translate) 命令可以对来自标准输入的字符进行替换、压缩和删除操作。 语法1tr [option] string1 string2 选项tr string1 string2 ：将标准输入中所有属于 string1 的字符替换为 string2 中的字符-d ：删除标准输入中所有属于 string1 的字符-s ：把标准输入中连续的重复字符压缩成一个字符显示-c ：取代或删除标准输入中所有不属于 string1 的字符 示例123456789101112131415# 替换指定字符$ echo &quot;hello world&quot; | tr &apos;h&apos; &apos;H&apos;Hello world# 删除指定字符（数字和空格）$ echo &quot;hello 12345 world&quot; | tr -d &apos;0-9 &apos;helloworld# 压缩指定字符$ echo &quot;heeeeeeeeello world&quot; | tr -s &apos;e&apos;hello world# 字符集补集$ echo &quot;hello 12345 world&quot; | tr -c -d &apos;0-9&apos;12345 字符集格式（string1 / string2）字符集合（即命令参数中的 string1 和 string2）用于指定需要替换或删除的字符。&#39;A-Za-z&#39;、&#39;A-F0-9&#39;、&#39;}.\t&#39; 等都是合法的字符集合。 字符 含义 \b 退格符 \n 新行 \r 回车符 \t Tab 符 CHAR1-CHAR2 从 CHAR1 到 CHAR2 的所有字符（按 ASCII 字符顺序） [:alnum:] 所有字母和数字 [:alpha:] 所有字母 [:blank:] 所有空格和 Tab 字符 [:cntrl:] 所有控制字符 [:graph:] 所有可打印字符，不包括空格 [:lower:] 所有小写字符 [:punct:] 所有标点符号 [:space:] 所有横向或纵向的空白字符 [:upper:] 所有大写字符 二、cut 命令cut 命令用于切割并筛选文本行中的指定部分，其操作对象可以是一个或多个文件，如未指定文件选项或该选项为 “-“，则从标准输入中读取需要操作的内容。 语法cut &lt;option&gt; list [file ...]其中 list 选项为由逗号分隔的数字或 “-“ 号连接的数字范围，用于指定文本行中需要显示的字段。 N-：从第 N 个字节、字符、字段到结尾 N-M：从第 N 个字节、字符、字段到第 M 个（包括 M 在内） -M：从第 1 个字节、字符、字段到第 M 个（包括 M 在内） 选项-b list：list 选项指定的是 byte 的范围-c list：list 选项指定的是字符的范围-d：指定字段的分隔符，默认是 Tab-f list：list 选项指定的是字段的范围 示例用于演示的文件内容如下：12345$ cat students.txtNo Name Mark01 rose 6902 jack 7103 alex 68 使用 -f 选项提取指定字段12345$ cut -f 2,3 students.txtName Markrose 69jack 71alex 68 使用 -d 选项指定字段分隔符12345678910$ cat students2.txtNo,Name,Mark01,rose,6902,jack,7103,alex,68$ cut -f 2,3 -d &quot;,&quot; students2.txtName,Markrose,69jack,71alex,68 使用 -c 选项提取指定字符范围里的内容123456789101112$ cat test.txtabcdefghijklmnopqrstuvwxyzabcdefghijklmnopqrstuvwxyzabcdefghijklmnopqrstuvwxyz$ cut -c -5 test.txtabcdeabcdeabcde$ cut -c 5- test.txtefghijklmnopqrstuvwxyzefghijklmnopqrstuvwxyzefghijklmnopqrstuvwxyz 三、sort 命令sort 命令用于将文件内容进行排序，并将排序结果打印到标准输出。它将文件的每一行文本视为一个单位，从首字母向后，依次按该字母的 ASCII 码值进行比较，并按升序输出。 选项-b：忽略每行行首的空格字符-c：检查文件是否已按顺序排序-d：排序时，只考虑字母、空格和数字，忽略其它字符-f：排序时，将小写字母视为大写字母（即忽略大小写）-i：排序时，忽略所有非打印字符-M：将前面三个字母按月份的缩写进行排序-n：按照数值的大小进行排序-o：将排序好的结果输出到指定文件中-r：以相反的顺序输出排序后的结果-t：指定排序时使用的栏位分隔符-u：合并显示内容相同的行 示例用于演示的文件内容如下：123456$ cat sort.txtAAA:BBaaa:4ccc:10bbb:20bbb:8 简单排序123456$ sort sort.txtAAA:BBaaa:4bbb:20bbb:8ccc:10 按照 BB 列的数字由大到小排序12345678$ sort -nr -t: -k2 sort.txtbbb:20ccc:10bbb:8aaa:4AAA:BB# -n 表示按照数字大小排序，-r 表示反向排序# -t: 表示冒号作为栏位分隔符，-k2 表示第二栏（即 BB 列）作为排序依据 四、uniq 命令uniq 命令用于报告或过滤文件中内容重复的行 选项-c：在每行输出内容的行首加上该行重复的次数-d：仅显示内容重复的行-u：仅显示内容未重复的行-f：不比较指定的栏位-s：不比较指定的字符 示例1234567891011121314151617181920212223242526# 源文件$ cat uniq.txthelloworldhelloworldhelloshellhellotext# 删除重复行$ uniq uniq.txthelloworldhelloshellhellotext# 只显示未重复的内容$ uniq -u uniq.txthelloshellhellotext# 统计各行出现的次数$ uniq -c uniq.txt 2 helloworld 1 helloshell 1 hellotext# 只显示重复行$ uniq -d uniq.txthelloworld]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Admin</tag>
        <tag>Tools</tag>
        <tag>Trick</tag>
        <tag>Text</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gawk 使用方法简介]]></title>
    <url>%2F2018%2F06%2F30%2Fgawk-manual%2F</url>
    <content type="text"><![CDATA[gawk 是最初 Unix 系统上 awk 程序的 GNU 版本。相对于作为流式编辑器的 sed 而言，它提供了更为强大的编程语言特性。 其功能与特性包括： 定义变量来存储数据 通过代数运算符和字符串操作符来处理数据 使用结构化编程语句如 if-then 和循环等 从数据文件中提取出有价值的字段再重新组合以生成结构化的报表 基本语法gawk options program file 构成 gawk 脚本的语句须包含在一对大括号（ {} ）中，而作为命令选项的整个脚本需要包含在一对引号中：1234$ cat test.txtHello World!$ gawk &apos;&#123;print $0&#125;&apos; test.txtHello World! 1. 使用字段变量gawk 会自动地将每行文本中的每个数据字段赋值给一个指定的变量，默认情况下，预先定义的变量为： $0 表示一整行文本 $1 表示该行文本的第一个字段 $2 表示该行文本的第二个字段 $n 表示该行文本的第 n 个字段 文本行中的数据字段是通过预先定义的字段分隔符来分隔开的，默认为空格（包括 TAB ）12345678$ cat data.txtOne line of test text.Two lines of test text. Three lines of test text.$ gawk &apos;&#123;print $1&#125;&apos; data.txt OneTwoThree 可以通过 -F 选项指定另外的分隔符（如 ‘ , ‘ ）12345678$ cat user.csvJack,male,20Rose,female,18Mike,male,24$ gawk -F, &apos;&#123;print $1&#125;&apos; user.csvJackRoseMike 2. 多个命令gawk 语言允许在脚本语句中组合多个命令使用，只需要在各命令之间使用分号（ ; ）分隔开即可12$ echo &quot;My name is Rich&quot; | gawk &apos;&#123;$4=&quot;Christine&quot;; print $0&#125;&apos; My name is Christine 也可以这样：12345$ gawk &apos;&#123;&gt; $4=&quot;Christine&quot;&gt; print $0&#125;&apos;My name is RichMy name is Christine 其中 My name is Rich 是运行时程序获取的用户输入，My name is Christine 是程序运行后的输出 3. BEGIN &amp; END默认情况下，gawk 从输入中读取一行文本，再对该文本执行程序指令。而有时候需要在读取待处理数据之前先执行某些指令，此时就要用到BEGIN关键字。同样的，END 关键字允许你指定在数据处理完成后才执行的脚本。12345678$ gawk &apos;BEGIN &#123;print &quot;The data File Contents:&quot;&#125; &gt; &#123;print $0&#125;&gt; END &#123;print &quot;End of File&quot;&#125;&apos; data.txt The data File Contents:One line of test text.Two lines of test text. Three lines of test text.End of File 4. 从文件中获取脚本gawk 允许先将其程序脚本保存在某个文件中，再通过 -f 选项指定该文件的文件名。而在脚本文件中，各命令不再需要通过 ‘;’ 符号分隔，直接分行列出即可。12345678910111213141516171819$ cat script.gawkBEGIN &#123;print &quot;Users and their age&quot; print &quot;User \t Age&quot;FS=&quot;,&quot;&#125;&#123; print $1 &quot; \t &quot; $3&#125;END &#123;print &quot;There are three people&quot; &#125;$ gawk -f script.gawk user.csvUsers and their ageUser AgeJack 20Rose 18Mike 24There are three people 上述脚本文件中的 FS=”,” 用于定义字段分隔符，效果等同于 -F 选项。 高级特性1. 变量程序语言最重要的特性之一就是定义和引用变量。gawk 语言支持两种类型的变量：内建变量和用户自定义变量。 gawk 程序在处理文本数据时，一次只读取一小段文本，称为 Record 。默认的 Record 分隔符即为换行符。而每条 Record 又可进一步划分成字段（Data Field），并按顺序依次赋值给 $1，$2，$n 等。默认的字段分隔符为空格（包括 TAB） 控制数据字段和 Record 的内建变量： 变量名 描述 FIELDWIDTHS 用一串由空格分隔的数字定义每个数据字段的具体宽度 FS 定义数据字段分割符（输入） RS 定义 Record 分割符（输入） OFS 定义数据字段分割符（输出） ORS 定义 Record 分割符（输出） 默认的 OFS 为空格12345678$ gawk &apos;BEGIN&#123;FS=&quot;,&quot;&#125; &#123;print $1,$2,$3&#125;&apos; user.csvJack male 20Rose female 18Mike male 24$ gawk &apos;BEGIN&#123;FS=&quot;,&quot;;OFS=&quot;:&quot;&#125; &#123;print $1,$2,$3&#125;&apos; user.csvJack:male:20Rose:female:18Mike:male:24 当定义了 FIELDWIDTHS 变量时，gawk 在读取数据时就会忽略字段分割符（FS），转而使用字段宽度来分割数据。12345678$ cat numbers.txt1005.3247596.3711522.349194.0005810.1298100.1$ gawk &apos;BEGIN&#123;FIELDWIDTHS=&quot;3 5 2 5&quot;&#125; &#123;print $1,$2,$3,$4&#125;&apos; numbers.txt100 5.324 75 96.37115 22.34 91 94.00 058 10.12 98 100.1 有些时候会遇到如下组织方式的文本文件：12345678910$ cat people.txtRiley Mullen123 Main StreetChicago, IL 60601(312)555-1234Frank Williams456 Oak StreetIndianapolis, IN 46201(317)555-9876 此时可将字段分隔符（FS）设置为 “\n”，Record 分隔符（RS）设置为空字符串，则 gawk 程序会将空行作为一条 Record 的终止点。123$ gawk &apos;BEGIN&#123;FS=&quot;\n&quot;; RS=&quot;&quot;&#125; &#123;print $1,$4&#125;&apos; people.txtRiley Mullen (312)555-1234Frank Williams (317)555-9876 其他内建变量 变量 描述 ARGC 当前命令行参数的数目 ARGV 由命令行参数组成的数组 CONVFMT 数字的转换格式，默认值为 %.6 g ENVIRON 包含当前系统环境变量的关联数组（字典） ERRNO 当读取或关闭文件出现错误时返回的系统错误 FILENAME gawk 处理的数据文件的文件名 FNR 当前正在处理的 Record 序号 IGNORECASE 设置为非零值时忽略大小写 NF 数据文件中的字段序号 NR 已处理的 Record 总数 OFMT 数字的输出格式，默认为 %.6 g 123456789$ gawk &apos;BEGIN&#123;FS=&quot;,&quot;;&gt; print ARGC,ARGV[0],ARGV[1];&gt; print ENVIRON[&quot;HOME&quot;]&#125;&gt; &#123;print FILENAME,FNR &quot;:&quot; $1&#125;&apos; user.csv2 gawk user.csv/Users/starkyuser.csv 1:Jackuser.csv 2:Roseuser.csv 3:Mike ARGV 的索引是从 0 开始的，表示第一个命令行参数（呃，所以通常就是 gawk 这个命令本身）。程序脚本（引号中的内容）不算在参数内。 用户自定义变量 在脚本中定义变量 1234567891011$ gawk &apos;&gt; BEGIN&#123;&gt; testing = &quot;This is a test&quot; &gt; print testing&gt; testing = 45&gt; print testing&gt; &#125;&apos;This is a test45$ gawk &apos;BEGIN&#123;x = 4; x = x * 2 + 3; print x&#125;&apos;11 在命令行参数中定义变量 1234567$ cat script1.gawkBEGIN&#123;FS = &quot;,&quot;&#125;&#123;print $n&#125;$ gawk -f script1.gawk n=1 user.csvJackRoseMike 2. 数组定义数组：var[index]=element1234567$ gawk &apos;BEGIN&#123;&gt; var[1] = 34&gt; var[2] = 3&gt; total = var[1] + var[2] &gt; print total&gt; &#125;&apos; 37 遍历数组：1234for (var in array) &#123; statements&#125; 1234567891011121314$ gawk &apos;BEGIN&#123;&gt; var[&quot;a&quot;] = 1&gt; var[&quot;g&quot;] = 2&gt; var[&quot;m&quot;] = 3&gt; var[&quot;u&quot;] = 4&gt; for (test in var) &gt; &#123;&gt; print &quot;Index:&quot;,test,&quot; Value:&quot;,var[test] &gt; &#125;&gt; &#125;&apos;Index: u Value: 4Index: m Value: 3Index: a Value: 1Index: g Value: 2 关联数组遍历的顺序是随机的 3. 模式匹配正则表达式123456$ cat user.csvJack,male,20Rose,female,18Mike,male,24$ gawk &apos;BEGIN&#123;FS=&quot;,&quot;&#125; /Jack/&#123;print $0&#125;&apos; user.csvJack,male,20 匹配符（~）匹配符（~）用来对 Record 中的特定字段使用正则表达式。!~ 表示不匹配。1234567891011$ cat dataThis is line 1Another lineline threeThis is line four$ gawk &apos;$3 ~ /line/&#123;print $0&#125;&apos; dataThis is line 1This is line four$ gawk &apos;$3 !~ /line/&#123;print $0&#125;&apos; dataAnother lineline three 数学表达式1234567$ cat user.csvJack,male,20Rose,female,18Mike,male,24$ gawk &apos;BEGIN&#123;FS=&quot;,&quot;&#125; $3 &gt;= 20&#123;print $0&#125;&apos; user.csvJack,male,20Mike,male,24 4. 结构化命令if if (condition) statement123456789101112131415161718192021$ cat numbers246810$ gawk &apos;&#123;&gt; if ($1 &lt; 5)&gt; &#123;&gt; x = $1 - 2&gt; print x&gt; &#125; else&gt; &#123;&gt; x = $1 / 2&gt; print x&gt; &#125;&#125;&apos; numbers02345 while1234while (condition)&#123; statements&#125; 123456789101112131415161718cat number130 120 135160 113 140145 170 215$ gawk &apos;&#123;&gt; total = 0&gt; i = 1&gt; while (i &lt;= 3)&gt; &#123;&gt; total += $i&gt; i++&gt; &#125;&gt; avg = total / 3&gt; print &quot;Average:&quot;,avg&gt; &#125;&apos; numberAverage: 128.333Average: 137.667Average: 176.667 forfor( variable assignment; condition; iteration process)123456789101112$ gawk &apos;&#123;&gt; total = 0&gt; for (i = 1; i &lt; 4; i++)&gt; &#123;&gt; total += $1&gt; &#125;&gt; avg = total / 3&gt; print &quot;Average:&quot;,avg&gt; &#125;&apos; numberAverage: 130Average: 160Average: 145 5. 格式化输出printf 命令格式：printf &quot;format string&quot;, var1, var2 . . .常用格式控制符如下表所示： 控制字符 描述 c 将数字显示为对应的 ASCII 字符 d 或 i 显示整数 e 将数字以科学记数法显示 f 显示浮点数 g 以科学计算法或浮点数显示（看哪种更短） o 以八进制显示 s 显示字符串 x 以十六进制显示 X 以十六进制显示，使用大写的 A-F 12345$ gawk &apos;BEGIN&#123;&gt; x = 10 * 100&gt; printf &quot;The answer is: %e\n&quot;, x&gt; &#125;&apos;The answer is: 1.000000e+03 除控制字符以外，还可以使用另外三种修饰符以对输出进行更多的控制。 width ：该数值用于指定输出的最小宽度。如长度不够，用空格补充 prec ：该数值用于指定浮点数的精确度，或者字符串能包含字符的最大数量 -（减号）：格式化输出时，使用左对齐 1234567$ gawk &apos;BEGIN&#123;FS=&quot;\n&quot;; RS=&quot;&quot;&#125; &#123;printf &quot;%16s %s\n&quot;, $1, $4&#125;&apos; people.txt Riley Mullen (312)555-1234 Frank Williams (317)555-9876$$ gawk &apos;BEGIN&#123;FS=&quot;\n&quot;; RS=&quot;&quot;&#125; &#123;printf &quot;%-16s %s\n&quot;, $1, $4&#125;&apos; people.txtRiley Mullen (312)555-1234Frank Williams (317)555-9876 参考下面的示例， %10.1f 中的 10 用于指定字段的最小宽度（右对齐，前面用空格补），.1 用于指定精确度。123456789101112$ gawk &apos;&#123;&gt; total = 0&gt; for (i = 1; i &lt; 4; i++)&gt; &#123;&gt; total += $i&gt; &#125;&gt; avg = total / 3&gt; printf &quot;Average: %10.1f\n&quot;,avg&gt; &#125;&apos; numberAverage: 128.3Average: 137.7Average: 176.7 6. 内建函数数学函数 函数 描述 atan2(x,y) x / y 的正切 cos(x) x 的余弦 exp(x) x 以 e 为底的指数 int(x) x 的整数部分 log(x) x 的自然对数 rand() 生成介于 0 和 1 之间的随机数 sin(x) x 的正弦 sqrt(x) x 的平方根 srand(x) 指定生成随机数的种子 1234$ gawk &apos;BEGIN&#123;x=exp(100); print x&#125;&apos;26881171418161356094253400435962903554686976$ gawk &apos;BEGIN&#123;x=exp(1000); print x&#125;&apos;inf 字符串函数 函数 描述 gensub(r, s, h [, t]) 该函数用于检索字符串（默认为 $0 ，如 t 指定，则检索字符串 t），用正则表达式 r 进行匹配，并将匹配结果替换为 s 。如 h 为 “g” 或 “G” ，则执行全局替换；如 h 为数字，则只将第 h 个匹配项替换为 s gsub(r, s [,t] 该函数用于检索字符串（默认为 $0 ，如 t 指定，则检索字符串 t），用正则表达式 r 进行匹配，并将匹配结果替换为 s （全局替换） index(s, t) 该函数用于返回字符串 t 在字符串 s 中的位置索引（如 s 不包含 t ，则返回 0） length([s]) 该函数用于返回字符串 s 的长度，如 s 未指定，则返回 $0 的长度 match(s, r ) 该函数用于返回字符串 s 中正则表达式 r 的位置索引 split(s, a [,r]) 该函数用于将字符串 s 根据 FS 符分割后的字段保存在数组 a 中。如已指定正则表达式 r ，则根据 r 而不是 FS 进行分割 sprintf(format, variablies) 该函数用于返回一个格式化后的字符串，该字符串类似 printf 函数的输出 sub(r, s [,t]) 该函数用于检索指定字符串 t （如果未指定 t ，则检索 $0），并使用 s 替换第一个符合条件的匹配结果 tolower(s) 将字符串 s 中的所有字符转换成小写 toupper(s) 将字符串 s 中的所有字符转换成大写 123456789101112131415161718192021222324252627$ gawk &apos;BEGIN&#123;&gt; x = &quot;hello world, hello gawk, hello text&quot;&gt; y = gensub(&quot;hello&quot;,&quot;nihao&quot;,&quot;g&quot;,x)&gt; print y&#125;&apos;nihao world, nihao gawk, nihao text$ gawk &apos;BEGIN&#123;&gt; x = &quot;hello world, hello gawk, hello text&quot;&gt; y = gensub(&quot;hello&quot;,&quot;nihao&quot;,2,x)&gt; print y&#125;&apos;hello world, nihao gawk, hello text$$ gawk &apos;BEGIN&#123;&gt; x = &quot;hello world, hello gawk, hello text&quot;&gt; gsub(&quot;hello&quot;,&quot;nihao&quot;,x)&gt; print x&#125;&apos;nihao world, nihao gawk, nihao text$$ gawk &apos;BEGIN&#123;&gt; x = &quot;hello world, hello gawk, hello text&quot;&gt; split(x,var)&gt; print var[2] var[4] var[6]&#125;&apos;world,gawk,text$ gawk &apos;BEGIN&#123;&gt; x = &quot;hello world, hello gawk, hello text&quot;&gt; split(x,var,&quot;,&quot;)&gt; print var[1] var[2] var[3]&#125;&apos;hello world hello gawk hello text 时间函数 函数 描述 mktime(datespec) 将普通格式（ YYYY MM DD HH MM SS ）的时间日期转换成时间戳 strftime(format [,timestamp]) 将指定时间戳（如未指定，使用当前时间戳）转换成指定的时间日期格式 systime() 返回当前时间的时间戳 123456$ gawk &apos;BEGIN&#123;&gt; date = systime()&gt; day = strftime(&quot;%A, %B %d, %Y&quot;, date)&gt; print day&gt; &#125;&apos;Saturday, June 30, 2018 用户自定义函数定义函数1234function name([variables])&#123; statements&#125; 使用函数1234567891011$ gawk &apos;&gt; function myprint()&gt; &#123;&gt; printf &quot;%-16s - %s\n&quot;, $1, $4&gt; &#125;&gt; BEGIN&#123;FS=&quot;\n&quot;; RS=&quot;&quot;&#125;&gt; &#123;&gt; myprint()&gt; &#125;&apos; people.txtRiley Mullen - (312)555-1234Frank Williams - (317)555-9876 函数库创建函数库12345678910111213$ cat funclibfunction myprint()&#123; printf &quot;%-16s - %s\n&quot;, $1, $4&#125;function myrand(limit)&#123; return int(limit * rand())&#125;function printthird()&#123; print $3&#125; 调用函数库123456789$ cat scriptBEGIN&#123; FS=&quot;\n&quot;; RS=&quot;&quot;&#125;&#123; myprint()&#125;$$ gawk -f funclib -f script people.txtRiley Mullen - (312)555-1234Frank Williams - (317)555-9876 参考书籍Linux Command Line and Shell Scripting Bible 3rd Edition]]></content>
      <categories>
        <category>Programming</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Admin</tag>
        <tag>Tools</tag>
        <tag>Text</tag>
        <tag>Programming</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[emacs 速查手册]]></title>
    <url>%2F2018%2F06%2F29%2Femacs-quick-reference%2F</url>
    <content type="text"><![CDATA[Emacs 是一个历史悠久的文本编辑器（最初版本发布于 1976 年）。它的核心是一个 Emacs Lisp（Lisp 编程语言的一种方言）的解释器，这给予了它近乎变态的扩展性和定制性。Emacs 有着“神之编辑器”和“伪装成操作系统的编辑器”的称号，功能的强大与灵活可想而知。 一、进入 emacs直接在终端输入 emacs 命令即可进入 emacs 编辑器，该命令后面可跟一个或多个需要编辑的文件。使用 --no--init-file 或 -q 选项可以在启动时不使用任何初始配置文件（ ~/.emacs 或 default.el ）当然这个界面，看上去稍微有些年代感……稍微修改一下启动配置文件（~/.emacs），内容如下：123456789101112; .emacs 界面配置(setq default-frame-alist &apos;((vertical-scroll-bars) (top . 25) (left . 45) (background-color . &quot;black&quot;) (foreground-color . &quot;grey&quot;) (cursor-color . &quot;gold1&quot;) (tool-bar-lines . 0) (menu-bar-lines . 1)))(set-default-font &quot;Source Code Pro 16&quot;)(setq inhibit-startup-message t) 修改后的效果： 二、退出 emacs 组合键定义：C 表示 Ctrl 键，M 表示 Windows系统里的 alt 键和 MacOS 系统里的 option 键。 功能 快捷键 命令（按下 M-x 后输入） 挂起 emacs（在图形模式下：最小化/还原） C-z suspend-emacs（suspend-frame） 退出 emacs C-x C-c save-buffers-kill-terminal 三、文件操作 功能 快捷键 命令（按下 M-x 后输入） 读取文件内容到 emacs 中（打开文件） C-x C-f find-file 保存文件 C-x C-s save-buffer 保存所有文件 C-x s save-some-buffers 将另一个文件的内容插入到当前正在编辑的文件中 C-x i insert-file 关闭当前文件并打开另一个文件 C-x C-v find-alternate-file 将当前 buffer 中的内容写入到指定的文件（另存为） C-x C-w write-file 启用/关闭当前 buffer 的只读模式 C-x C-q read-only-mode 四、获取帮助 功能 快捷键 命令 新手指引 C-h t help-with-tutorial 显示匹配指定正则表达式的命令 C-h a apropos-command 显示绑定指定快捷键的函数的帮助信息 C-h k describe-key 显示指定函数（命令）的帮助信息 C-h f describe-function 显示 Mode 相关的信息 C-h m describe-mode 五、错误恢复 功能 快捷键 命令 中断正在输入或执行中的命令 C-g keyboard-quit 恢复由于系统崩溃未保存的文件 M-x recover-session recover-session 撤销不想要的操作 C-x u 或 C-_ 或 C-/ undo 将 buffer 恢复到初始状态 M-x revert-buffer revert-buffer 六、增量搜索 功能 快捷键 命令 向前搜索（向文档底部搜索） C-s isearch-repeat-forward 向后搜索（向文档顶部搜索） C-r isearch-repeat-backward 正则表达式搜索（向文档底部） C-M-s isearch-forward-regexp 正则表达式搜索（想文档顶部） C-M-r isearch-backward-regexp 中断当前搜索 C-g keyboard-quit 重复使用 C-s 或 C-r 可以继续当前方向对同一关键字的搜索（即跳转到下一个匹配项） 七、Buffers 功能 快捷键 命令 列出所有的 Buffer 信息 C-x C-b list-buffers 切换到另一个 Buffer C-x b switch-to-buffer 关闭 Buffer C-x k kill-buffer 八、Shell 命令 功能 快捷键 命令 执行 Shell 命令 M-! shell-command 异步执行 Shell 命令 M-&amp; async-shell-command 开启一个 *Shell* 窗口用于执行命令 M-x shell shell 九、移动 对象 方向向后（文档顶部） 方向向前（文档底部） 字符 C-b C-f 单词 M-b M-f 行 C-p C-n 跳转到行首（行尾） C-a C-e 句子 M-a M-e 段落 M-{ M-} 页面 C-x [ C-x ] 函数 C-M-a C-M-e 跳转到文档开头（结尾） M-&lt; M-&gt; 十、跳转 功能 快捷键 命令 滚动到下（后）一屏 C-v scroll-up-command 滚动到上（前）一屏 M-v scroll-down-command 向左滚动屏幕 C-x &lt; scroll-left 向右滚动屏幕 C-x &gt; scroll-right 将当前行置于屏幕中央/顶部/底部 C-l recenter-top-bottom 跳转到指定行 M-g g goto-line 跳转到指定字符 M-g c goto-char 十一、选择 功能 快捷键 命令 在当前位置设置标记 C-@ set-mark-command 选中整个段落 M-h mark-paragrath 选中整个页面 C-x C-p mark-page 选中整个函数 C-M-h mark-defun 选中整个 Buffer C-x h mark-whole-buffer 十二、搜索替换 功能 快捷键 命令 以交互的方式检索并替换字符串 M-% query-replace 使用正则表达式检索替换 M-x query-replace-regexp query-replace-regexp 交换模式中的合法输入 替换当前匹配并跳转到下一个 SPACE 或 y 替换当前匹配后不做移动 , 跳过当前匹配直接到下一个 DELETE 或 n 替换剩余的所有匹配项 ! 跳转到上一个匹配项 ^ 退出搜索替换模式 ENTER 十三、多窗口 功能 快捷键 命令 关闭其他所有窗口（只显示当前窗口） C-x 1 delete-other-windows 分割当前窗口（上下） C-x 2 split-window-below 关闭当前窗口 C-x 0 delete-window 分割当前窗口（左右） C-x 3 split-window-right 滚动另一个窗口的内容 C-M-v scroll-other-window 移动光标到另一个窗口 C-x o other-window 在另一个窗口打开文件 C-x 4 f find-file-other-window 在另一个窗口运行 Dired C-x 4 d dired-other-window 增大当前窗口高度 C-x ^ enlarge-window 缩减当前窗口宽度 C-x { shrink-window-horizontally 增大当前窗口宽度 C-x } enlarge-window-horizontally 十四、Minibuffer 功能 快捷键 尽可能补全 TAB 补全至一个完整单词 SPACE 补全并执行 ENTER 显示所有可能的补全结果 ? 获取上一个输入 M-p 获取下一个或默认输入 M-n 向后搜索输入历史（正则表达式） M-r 向前搜索输入历史（正则表达式） M-s 中断命令或输入 C-g 十五、简单定制 功能 按键 定义变量或外观 M-x customize 自定义全局按键映射（例子） (global-set-key (kbd “C-c g”) ‘search-forward) 参考资料 &amp; 拓展阅读Emacs Reference CardsGNU Emacs manualAn Introduction to Programming in Emacs LispEmacs Lisp Reference Manual]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>Admin</tag>
        <tag>Tools</tag>
        <tag>Trick</tag>
        <tag>Software</tag>
        <tag>Editor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vim 速查手册]]></title>
    <url>%2F2018%2F06%2F06%2Fvim-quick-reference%2F</url>
    <content type="text"><![CDATA[一、移动光标字符级 命令 功能 h 向 左 移动一个字符单位 l 向 右 移动一个字符单位 j 向 下 移动一个字符单位 k 向 上 移动一个字符单位 单词级 命令 功能 w/W 向 右 移动到下一单词开头 e/E 向 右 移动到单词结尾 b/B 向 左 移动到单词开头 PS：所谓“单词”，是按照英文的书写和使用习惯来定义的。用在中文上，一般就会以标点符号和空格作为“单词”的界限。所以常常是一句话一句话地跳转。 块级 命令 功能 0 移动到当前行的第一个字符 ^ 移动到当前行第一个非空白字符 $ 移动到当前行行尾 + 移动到下一行的首字母 - 移动到上一行的首字母 gg 移动到文档第一行 G 移动到文档最后一行 H 移动到当前屏幕的第一行 M 移动到当前屏幕的中间一行 L 移动到当前屏幕的最后一行 : 或 gg 跳转到第 n 行 :+ 或 j 从当前位置向下跳 n 行 :- 或 k 从当前位置向上跳 n 行 滚动屏幕 命令 功能 Ctrl-d 向下滚动半页 Ctrl-u 向上滚动半页 Ctrl-f 向下移滚动一页 Ctrl-b 向上滚动一页 z 将当前行滚动到屏幕顶部 z. 将当前行滚动到屏幕中间 z- 将当前行滚动到屏幕底部 PS：绝大部分命令前都可以加一个数字 n ，通常表示对其后的命令连续执行 n 次。所以 3j 可以表示向下移动 3 个字符单位（即下移 3 行）。3l 表示向右移动 3 个字符单位。相当于连续执行了 l 命令 3 次。而 9z. 则表示光标移动到第 9 行的同时，滚动屏幕并使得第 9 行位于屏幕中间。（这个 9 的含义不同于 3l 命令中的 3） 前面带冒号的命令（如 :+&lt;n&gt;，命令内容会显示在底部）是需要手动输入回车后才执行的。而不带冒号的命令（如 &lt;n&gt;gg）需要在键盘上不间断地按下，之后命令会自动执行。 二、文档操作 插入 命令 功能 i 当前字符前插入 a 当前字符后插入 I 行首插入 A 行尾插入 o 在下一行插入 O 在上一行插入 PS：以上命令会使 vim 进入 insert 模式（即编辑模式），此时输入的任何命令都会作为字符插入到文档中。按 esc 键可退出 insert 模式。 删除（并将删除的内容保存至 vim 剪贴板） 命令 功能 x 删除当前字符（等于 insert 模式下的 Delete） X 删除前一个字符（等于 insert 模式下的 Backspace） dd 删除当前行 d 删除指定内容 D 删除当前光标位置到行尾的所有内容。等于 d$ cc 替换整行内容。即将整行内容删除并进入 insert 模式 c 删除指定内容后，进入 insert 模式。相当于 d&lt;x&gt;a C 替换当前光标位置到行尾的所有内容。等于 c$ 部分用于指定删除的范围。如 j 表示将光标向下移动一个字符单位（即下移一行），则 dj 表示删除当前行和下一行的内容。G 表示将光标移动到文档末尾，则在光标定位在文档首行时，使用 dG 命令可以清空整个文档的内容。 PS：使用以上命令删除的内容会自动保存到 vim 的剪贴板中，即所谓“删除”实际上是“剪切”，使用 p 命令即可粘贴删除的内容。而且该剪贴板限于 vim 内部，不是系统剪贴板。 复制与粘贴 命令 功能 yy 复制当前内容到 vim 剪贴板 y 复制指定内容到 vim 剪贴板 p 在当前位置后粘贴 P 在当前位置前粘贴 J 将当前行与下一行内容合并为一行 y&lt;x&gt; 命令中的 &lt;x&gt; 同样用于指定复制的范围。如 4j 表示将光标下移 4 行，则 y4j 表示将当前行及其后 4 行内容复制到 vim 剪贴板。8gg 表示将光标定位至第 8 行，则 y8gg 表示复制当前行到第 8 行的所有内容。当 vim 剪贴板中的内容为整行时，则粘贴命令（p/P）执行时，也会变成在当前行的前（后）一行粘贴。 查找行内查找 命令 功能 f 当前行向行尾方向查找并定位到字符 x F 当前行向行首方向查找并定位到字符 x t 当前行向行尾方向查找并定位到字符 x 之前 T 当前行向行首方向查找并定位到字符 x 之后 ; 继续向当前方向查找下一个字符 , 向当前方向的相反方向查找下一个字符 文档内查找 命令 功能 * 向后查找光标当前所在单词 # 向前查找光标当前所在单词 / 向后查找指定字符串或模式 ? 向前查找指定字符串或模式 n 继续查找下一个（依照原方向继续查找） N 继续查找上一个（依照原方向进行反向查找） PS：vim 中可使用 % 对括号 ()[]{} 进行匹配查找，当光标位于其中一个符合上时，按下 % 会跳转到与之匹配的另外一个符合上。 替换 命令 功能 r 将当前字符替换为字符 x s 删除当前字符并进入 insert 模式 R 进入 replace 模式，逐字对当前字符进行替换操作，可以移动光标定位需要替换的字符。直到按下 ESC 键退出该模式 ~ 对当前字符进行大小写切换（即大写转小写，小写转大写） gu 将指定的文本转换为小写 gU 将指定的文本转换为大写 g~ 将指定文本进行大小写切换 :,s// 以某个模式（pattern）检索整个文档，并将第 n1 行到第 n2 行中的匹配项替换为指定内容（replace） :%s// 以某个模式（pattern）检索整个文档并将匹配项替换为指定内容（replace）。等同于 :1,$s// PS：:%s/&lt;pattern&gt;/&lt;replace&gt; 命令中的 可以是正则表达式，且该命令只替换每行中的第一个匹配项。如需要全局匹配，可以使用 :%s/&lt;pattern&gt;/&lt;replace&gt;/g 命令 撤销、重做 命令 功能 . 重复执行上一次的命令 u 撤销 U 撤销对当前行的所有操作 Ctrl-r 重做 打开、关闭文档 命令 功能 :e 打开名为 filename 的文件，如文件不存在则创建 :Ex 在 vim 中打开目录树，光标选定后回车打开对应文件（- 命令进入上级目录） :w 保存当前文件 :wa 保存全部文件 :wq 或 ZZ 保存文件并退出 vim :q! 或 ZQ 强制退出 vim ，不保存文件 :r 读入另一个文档（filename）的数据，并将其内容附加到当前文档光标所在行的后面 :saveas &lt;new_filename&gt; 文件另存为 :w &lt;new_name&gt; 另存为一份名为 new_name 的副本并继续编辑原文件 :,w &lt;new_name&gt; 将 n1 行到 n2 行的所有内容保存到名为 new_name 的新文档中 BufferBuffer（缓冲区）指 vim 中打开的文件所占的内存空间，当未写入磁盘时，所有的修改都发生在内存中。vim 打开过的每个文件都会放到一个 Buffer 中，可以随意切换已打开的 Buffer。 命令 功能 :ls 或 :buffers 查看 buffer 列表 :bn 打开缓冲区中下一个文件 :bp 打开缓冲区中上一个文件 :b 打开缓冲区中第 n 个文件 :bdelete 删除需要关闭的缓冲区文件 三、其他技巧缩进 &gt;&gt; 向右缩进当前行 &lt;&lt; 向左缩进当前行 4&gt;&gt; 向右缩进当前行的同时，缩进当前行下面的 3 行内容 &gt;G 向右缩进当前行到文档末尾的所有内容自动排版 == 自动排版当前行 gg=G 自动排版整个文档 &lt;n&gt;== 对从当前行开始的 n 行进行自动排版 =&lt;n&gt;j 对当前行以及下面的 n 行进行自动排版执行 shell 命令:!&lt;command&gt; 可以执行相应的 shell 命令，命令执行完成后按 Enter 回到 vim 界面。如使用 :1,9!sort 命令可以将当前文件中第 1 行到第 9 行的内容重新排序。:r !&lt;command&gt; 可以将相应 shell 命令执行后的输出读取到当前文件中。如使用 :r !date 命令可以将当前详细的时间日期插入到 vim 编辑的文件中。四、分屏与标签页 窗口分屏 分屏方式 :split 或 :sp 或 Ctrl-w s ：上下分屏 :vsplit 或 :vs 或 Ctrl-w v` ：左右分屏 :diffsplit 或 :diffs ：diff 模式打开一个分屏，后面可以加 &lt;filename&gt; 窗口跳转 Ctrl-w w ：激活下一个窗口 Ctrl-w j ：激活下方窗口 Ctrl-w k ：激活上方窗口 Ctrl-w h ：激活左侧窗口 Ctrl-w l ：激活右侧窗口 屏幕缩放 Ctrl-w = ：平均窗口尺寸 Ctrl-w + ：增加当前窗口高度 Ctrl-w - ：缩减窗口高度 Ctrl-w _ ：最大窗口高度 Ctrl-w &gt; ：增加窗口宽度 Ctrl-w &lt; ：缩减窗口宽度 Ctrl-w | ：最大窗口宽度 标签页 创建标签页:tabnew 或 :tabedit 或 :tabe ：打开新标签页该命令包括上面的分屏命令（:sp 或 :vs 等）后面都可以跟 &lt;filename&gt; 选项，用以在新标签页（或窗口）中打开指定文件 切换标签页 gt 或 :tabnext 或 :tabn ：切换到下一个标签页（最后一个会循环到第一个） gT 或 :tabprevious 或 :tabp ：切换到上一个标签页 :tabrewind 或 :tabr 或 :tabfir ：切换到第一个标签页 :tablast 或 :tabl ：切换到最后一个标签页 关闭标签页 :tabclose 或 :tabc ：关闭当前标签页 :-tabc ：关闭上一个标签页 :+tabc ：关闭下一个标签页 :tabonly 或 :tabo ：关闭其他标签页 附录：vim 模式介绍大致上 vim 分为三种模式，分别是命令模式（Command mode），编辑模式（Insert mode）和底线命令模式（Last line mode）。 1. 命令模式vim 启动即进入命令模式。此时敲击键盘动作会被识别为命令，而不是作为字符插入到文档中。如： i 切换到输入模式（在当前字符前插入） : 切换到底线命令模式，此时输入的命令显示在最底下一行， : 符号后面命令模式下只有一些最基本的命令，而底线命令模式下拥有更多的命令。2. 编辑模式在命令模式下键入 i （或 a、e 等）即进入编辑模式在编辑模式下，可以像在记事本中那样，使用键盘输入或修改文档内容。注意编辑完成时，可使用 ESC 键退出编辑模式，回到命令模式。3. 底线命令模式在命令模式下按下 : 即进入底线命令模式该模式下可以输入单个或多个字符的命令，以完成比命令模式下更复杂的操作（如 :wq 保存文件并退出）按 ESC 键可随时退出底线命令模式。 参考书籍vimtutorLearning The Vi And Vim Editors, 7th Edition]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Admin</tag>
        <tag>Tools</tag>
        <tag>Efficiency</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[命令行使用 gmail 的 SMTP 服务发送电子邮件]]></title>
    <url>%2F2018%2F05%2F29%2Fusing-gmail-smtp-in-shell%2F</url>
    <content type="text"><![CDATA[SMTP 即简单邮件传输协议（Simple Mail Transfer Protocol），是一种基于 TCP 的应用层协议，用于将电子邮件发送到收件人的邮件服务器。不使用 SSL/TLS 加密的 SMTP 协议默认使用 25 端口，通过 SSL/TLS 加密的 SMTP 协议使用 465/587 端口。命令行结合 SMTP 协议主要是为了通过一些简单的脚本，完成在特定情景下通知邮件的自动发送。 MacOS 系统和很多 Linux 发行版默认已经配置好了 postfix 服务，可以直接发送邮件。不过此时使用的发件服务器在本地，发件人为用户名@本地主机名，而该种类型的邮件会被现在绝大多数的邮箱服务封禁。导致邮件发送失败。 而 postfix 本身的配置也较复杂，所以这里讨论通过 QQ 邮箱或 gmail 等第三方 SMTP 服务器进行邮件发送的方式。 一、msmtpmsmtp 是一个非常简单又易用的 SMTP 客户端，且它与 sendmail有很好的兼容性。MacOS 系统和大部分 Linux 都可以使用包管理器进行安装。 软件包安装：brew install msmtp（MacOS）sudo apt-get install msmtp（Ubuntu） Ubuntu 系统下还需要安装 ca-certificates 软件包（证书）sudo apt-get install ca-certificates 软件配置msmtp 配置文件（Linux）如下（~/.msmtprc）：123456789101112131415defaultsaccount gmailhost smtp.gmail.comtls ontls_starttls ontls_trust_file /etc/ssl/certs/ca-certificates.crt tls_certcheck onport 587auth loginfrom username@gmail.comuser username@gmail.compassword ****************account default: gmail 其中 host 项用于配置使用的发件服务器（smtp.gmail.com） tls_starttls on 用于指定启用 STARTTLS 加密，此时 port （端口号）则为 587 。默认的 25 端口不使用加密，在 gmail 等服务器中是不允许访问的 tls_trust_file 用于指定证书文件。MacOS 系统下此路径不存在，则可以注释掉（#）该行配置，并将 tls_certcheck （是否验证证书）设置为 off 。（可以正常发件，但不够安全） from 和 user 为 gmail 邮箱地址，必须为同一个邮箱账号，否则无法通过验证 password 并非登录 gmail 时的密码，而是 Google 账号应用专用密码，可在此地址进行创建。 编辑 /etc/mail.rc 配置文件，令 mail 命令使用 msmtp 作为发件程序（可通过 which msmtp 命令查看 msmtp 程序的具体路径）1set sendmail=/usr/bin/msmtp 配置完成后，即可使用 mail 命令发送邮件了 二、sendemailsendemail 是一个轻量级的命令行下的 SMTP 邮件客户端，用 Perl 语言编写，简单但功能丰富。无需额外配置，只需要配合适当的命令选项和参数，即可使用 gmail 的 SMTP 服务发送电子邮件。MacOS 和 Linux 系统下都可直接使用包管理器进行安装：（brew install sendemail 或 sudo apt-get install sendemail） 命令示例：sendemail -l email.log -f &quot;sender@gmail.com&quot; -u &quot;subject&quot; -t &quot;recipient@xx.com&quot; -s &quot;smtp.gmail.com:587&quot; -o tls=yes -xu &quot;sender@gmail.com&quot; -xp &quot;your_password&quot;可以通过它创建简单的 shell 脚本，作为一个交互式的发件程序。更多用法可参考 man sendemail 三、Python &amp; smtplibPython 语言的内置库中即包含了对电子邮件的支持，比如 email 模块可用于编辑邮件内容，smtplib 模块可用于访问 SMTP 服务。通过 Python 脚本使用 gmail 的 SMTP 服务发送邮件的示例如下：12345678910111213141516171819202122232425262728293031323334353637383940#!/usr/bin/env python3import getpassimport smtplibfrom email.mime.image import MIMEImagefrom email.mime.multipart import MIMEMultipartfrom email.mime.text import MIMETextSMTP_SERVER = &apos;smtp.gmail.com&apos;SMTP_PORT = 587def send_email(sender,recipient): msg = MIMEMultipart() msg[&apos;To&apos;] = recipient msg[&apos;From&apos;] = sender msg[&apos;Subject&apos;] = input(&apos;Subject: &apos;) message = input(&apos;Enter your message. Press Enter when finished:\n&apos;) part = MIMEText(&apos;text&apos;,&quot;plain&quot;) part.set_payload(message) msg.attach(part) session = smtplib.SMTP(SMTP_SERVER, SMTP_PORT)# session.set_debuglevel(1) session.ehlo() session.starttls() session.ehlo# password = getpass.getpass(prompt=&quot;Enter your email password:&quot;) password=&quot;your_password&quot; session.login(sender, password) session.sendmail(sender, recipient, msg.as_string()) print(&quot;Your email is sent to &#123;0&#125;.&quot;.format(recipient)) session.quit()if __name__ == &apos;__main__&apos;: sender=&quot;sender@gmail.com&quot; recipient = input(&quot;Enter recipient address: &quot;) send_email(sender, recipient) 取消 # session.set_debuglevel(1) 前面的注释，可以在程序运行时输出调试信息 参考资料：Learning Python Network Programming by Dr. M. O. Faruque Sarker et al. msmtp - ArchWiki]]></content>
      <categories>
        <category>Admin</category>
      </categories>
      <tags>
        <tag>Admin</tag>
        <tag>Tools</tag>
        <tag>Shell</tag>
        <tag>Python</tag>
        <tag>Script</tag>
        <tag>Programming</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MacOS 系统使用命令安装软件包]]></title>
    <url>%2F2018%2F05%2F17%2Fmacos-install-software%2F</url>
    <content type="text"><![CDATA[Linux 操作系统各发行版都有自己的软件包管理器，如 Ubuntu 的 apt-get ，Fedora 的 yum 及 Arch 的 pacman 等。安装软件不要太方便。而 MacOS 系统可在 Appstore 中获取安装软件，或者从网上下载 pkg 格式的安装包双击运行。其实 MacOS 系统下也有一个很强大的包管理软件 Homebrew （以及 Homebrew-Cask），使用方便，功能强大。但不是内置软件，需要自己手动安装。其实 pkg 格式的安装包，一样可以通过命令（install）来安装。而常见的 dmg 格式的软件包，其实只是将安装文件又打包成了 dmg 磁盘镜像。挂载后即可继续操作。 一、Homebrew &amp; Homebrew-Cask 1. HomebrewHomebrew 是 MacOS 系统里的软件包管理系统，类似于 Ubuntu 中的 apt-get ，这个软件本身安装起来也很简单。 Homebrew 官网提供了安装命令：/usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot;将该命令直接复制到 terminal 中并运行，执行完成后即可使用 brew 命令搜索或安装软件了。 2. Homebrew-caskHomebrew-cask 相当于 Homebrew 的扩展，区别在于，brew 命令首先获取程序源码然后编译安装（包括依赖库），并自动做好必要的配置（如环境变量等）；而 brew cask 命令是下载已经编译好的应用包并放在统一的目录中。 安装好 Homebrew 后，可使用 brew tap caskroom/cask 命令直接安装 Homebrew-cask 。 3. 常用命令选项 install &lt;formula&gt; ：安装软件 uninstall &lt;formula&gt; ：卸载软件 update ：使用 git 获取最新版本的 Homebrew list ：列出所有已通过 brew 命令安装的软件 search &lt;text|/text/&gt; ：通过关键字 text 搜索可供安装的软件，如搜索关键字为 /text/ ，则表示由 text 组成的正则表达式 info &lt;formula&gt; ：获取软件包的简要信息 更多用法可参考：man brew 二、安装 pkg 软件包在图形界面下，pkg 软件包可以直接双击运行。而命令行界面下，也可以使用 installer 命令进行安装。命令格式：sudo installer -pkg &lt;package&gt; -target / 三、dmg 格式的软件包dmg 格式的磁盘镜像文件，通常是对应用程序文件或安装程序的打包压缩。所以安装时需要先使用 hdiutil 命令挂载 dmg，再根据文件类型确定需要执行的安装操作。 1. 应用文件像 Tor Browser 这种，下载下来是 dmg 格式的镜像文件，挂载后目录中是已编译好的应用程序文件，直接拖动到 Applications 文件夹即可安装成功。 在命令行中操作时，则需要先使用 hdiutil attach &lt;imgFile&gt; 挂载镜像文件（一般默认会挂载到 /Volumes 目录下），然后直接将应用程序复制到 /Applications 目录下即可。 2. pkg 安装包像 Wireshark 这种，挂载 dmg 文件后，目录中是已编译好的 pkg 安装包，则需要使用 installer 命令进行安装。命令行安装过程如下： 附录Linux 包管理器1. pacman pacman -S &lt;package&gt; 安装软件包 pacman -Ss &lt;regex&gt; 搜索软件包 pacman -Su 更新系统 pacman -Syu 同步源并更新系统 pacman -R &lt;package&gt; 删除软件包 pacman -Rc &lt;package&gt; 删除软件包及依赖该软件的包 pacman -Rs &lt;package&gt; 删除软件包，及其所有未被其他软件包使用的依赖关系 pacman -Rsc &lt;package&gt; 卸载软件及其依赖的包 pacman -Sc 清理 /var/cache/pacman/pkg 目录下的旧软件包 pacman -Scc 清理所有缓存的软件包和数据库 pacman -U &lt;path_to_package&gt; 安装本地的软件包 pacman -Qi &lt;package&gt; 显示已安装软件包的信息大小、安装日期、创建日期、依赖关系、冲突等） pacman -Qip &lt;package.tar.gz&gt; 显示未安装软件包的信息 pacman -Ql &lt;package&gt; 显示软件包所包含的文件列表 2. apt-get apt-cache search &lt;package&gt; 搜索软件包 apt-cache show &lt;package&gt; 获取软件包的信息 apt-get install &lt;package&gt; 安装软件包 apt-get -f install &lt;package&gt; 修复安装 apt-get remove &lt;package&gt; 卸载软件包 apt-get purge &lt;package&gt; 卸载软件包（包括删除配置文件等） apt-get update 更新软件源 apt-get upgrade 更新已安装的软件包 apt-get dist-upgrade 升级系统 3. yum yum update 更新所有软件包 yum update &lt;package&gt; 更新指定的软件包 yum install &lt;package&gt; 安装软件包 yum remove &lt;package&gt; 删除软件包 yum search &lt;pattern&gt; 搜索匹配特定内容的软件包 yum info &lt;package&gt; 查看软件包信息 yum clean 清除缓存和旧的包 yum list installed 列出已安装的软件包]]></content>
      <categories>
        <category>MacOS</category>
      </categories>
      <tags>
        <tag>Admin</tag>
        <tag>System</tag>
        <tag>Tools</tag>
        <tag>MacOS</tag>
        <tag>software</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MacOS 系统使用 dd 命令创建 Linux 启动U盘]]></title>
    <url>%2F2018%2F05%2F14%2Fcreate-startup-disk-using-dd%2F</url>
    <content type="text"><![CDATA[dd) 命令可以从标准输入或文件中读取数据，根据指定的格式来转换数据，再输出到文件、设备或标准输出。同样是对数据的复制转移操作，cp 命令针对的是文件系统级别，操作的是文件和目录；而 dd 针对的是扇区级别，对 blocks 进行操作。所以可以用它来做整盘数据的备份与恢复、备份 MBR 及启动盘的制作等。 比如将 disk1 上的数据使用 dd 命令复制到 disk2 上，则两块硬盘上的数据包括布局都是完全一样的（扇区级别）。而 cp 命令只是将 disk1 上的数据复制到 disk2 上，由于系统写硬盘不是顺序写的，则两块硬盘上相同扇区号上的数据有可能不一样。 dd 命令将原始数据按照数据源的格式原封不动地拷贝到目的地；而cp将文件和目录拷贝到目的地后按照目的地的格式排列新数据。对于不能以文件或目录格式呈现的数据（如引导扇区的数据），cp 是不能操作的。所以需要使用 dd 命令来创建启动 U 盘。 一、镜像格式转换从网上下载的 Linux iso 镜像文件，是不受 MacOS 系统支持的。需要先使用 hdiutil 命令进行格式转换，才可以使用 dd 命令读取。$ hdiutil convert -format UDRW -o &lt;dmg 文件&gt; &lt;iso 文件&gt;-format 指定生成文件的权限，UDRW 表示转换成有 read/write 权限的镜像PS：前面讲过 dd 命令的原理，即无视文件系统，完成扇区级别的数据转移。所以虽然，网上所有的教程都有格式转换这一步。我尝试了不做转换直接将 iso 文件写入磁盘，事实证明也是可行的。 二、卸载U盘查看U盘的设备号$ diskutil list可以通过 diskutil 的 list 选项查看系统当前挂载的磁盘设备。其中的 /dev/disk2 即用来制作启动盘的U盘。可使用 diskutil 的 unmountDisk 选项来卸载U盘。$ diskutil unmountDisk /dev/disk2只有当U盘成功卸载后，才可以使用 dd 命令将镜像文件写入U盘（否则会报 Resource busy 错误） 三、将镜像文件写入U盘$ sudo dd if=lubuntu-16.04.dmg of=/dev/disk2 bs=1m其中 if 选项用于指定输入文件，of 选项用于指定输出文件，bs 选项用于指定块大小。出现以上提示后，则数据写入成功。Linux 启动U盘制作完成。 附：dd 命令介绍dd 命令可以用指定大小的 blocks 复制一个文件，并在复制的同时进行指定的转换。 命令参数 if=文件名：指定输入文件名，缺省为标准输入 of=文件名：指定输出文件名，缺省为标准输出 ibs=bytes：一次读入 bytes 个字节，即指定一个块大小为 bytes 个字节 obs=bytes：一次输出 bytes 个字节，即指定一个块大小为 bytes 个字节 bs=bytes：同时设置读入/输出的块大小为 bytes 个字节 cbs=bytes：一次转换 bytes 个字节，即指定转换缓冲区大小 skip=blocks：从输入文件开头跳过 blocks 个块后再开始复制 seek=blocks：从输出文件开头跳过 blocks 个块后再开始复制 count=blocks：仅复制 blocks 个块，块大小等于 ibs 指定的字节数 命令示例 将 /dev/disk2 全盘数据备份到指定路径的 image 文件dd if=/dev/disk2 of=/home/starky/image 将备份文件恢复到指定磁盘dd if=/home/starky/image of=/dev/disk2 备份 /dev/disk2 全盘数据，并利用 gzip 工具进行压缩，保存到指定路径dd if=/dev/disk2 | gzip &gt; /home/starky/image.gz 将压缩的备份文件恢复到指定盘gzip -dc /home/starky/image.gz | dd of=/dev/disk2 备份磁盘开始的 512 个字节大小的 MBR 信息到指定文件dd if=/dev/disk2 of=/home/starky/image count=1 bs=512count=1 指仅拷贝一个块；bs=512 指块大小为 512 个字节。 拷贝内存内容到硬盘（Linux）dd if=/dev/mem of=/home/starky/mem.bin bs=1024（指定块大小为 1k） 销毁磁盘数据（利用随机的数据填充硬盘）dd if=/dev/urandom of=/dev/disk2 bs=16M 测试 使用 dd 命令将整个U盘（包括分区信息和文件数据）写入 dmg 格式镜像文件上图中的 hdiutil 命令在 MacOS 系统中用于操作 dmg 格式的磁盘镜像（包括挂载、验证、转换、压缩、烧录等）。而 attach 选项则用于挂载 dmg 文件（就像使用 mount 命令挂载物理磁盘一样）。而从截图中可以看出，原 U 盘（disk2）和挂载的 dmg 磁盘镜像（disk3）分区信息是完全一样的，同样的磁盘（分区）大小、分区表类型（mbr）、文件系统（FAT32）和卷标（F01）。dmg 文件就像是对整个 U 盘的克隆，而不只是文件数据的转移。而分区中的文件内容也完全一致。 使用 dd 命令将部分U盘写入 dmg 格式的磁盘镜像文件这种行为，其实当前我也不是很理解。。。 参考资料man diskutilman hdiutilman dd]]></content>
      <categories>
        <category>MacOS</category>
      </categories>
      <tags>
        <tag>Admin</tag>
        <tag>System</tag>
        <tag>Tools</tag>
        <tag>Hardware</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MacOS 磁盘管理工具 diskutil 介绍]]></title>
    <url>%2F2018%2F04%2F27%2Fdiskutil-manual%2F</url>
    <content type="text"><![CDATA[电脑上的操作系统、应用程序和应用数据一般都需要保存在永久存储器中（通常就是硬盘），这样电脑断电后应用数据等就不会丢失。为了更有效地组织磁盘上的数据信息，通常将磁盘预先划分成一个或多个磁盘分区，创建对应的文件系统，以方便计算机对各分区分别进行管理。MacOS 系统自带一个图形化的磁盘管理工具（Disk Utility），同时还有一个命令行版本的 diskutil。通过该命令的使用，可以很快捷地对本地磁盘进行擦除数据、调整分区大小、格式化等操作。 一、verbdiskutil 命令的格式为：diskutil &lt;verb&gt; &lt;options&gt;不带任何选项的 diskutil 命令会列出该命令支持的 verb 及其对应的介绍：123456789101112131415161718192021222324252627282930313233343536373839404142➜ ~ diskutilDisk Utility ToolUtility to manage local disks and volumesUsage: diskutil [quiet] &lt;verb&gt; &lt;options&gt;, where &lt;verb&gt; is as follows: list (List the partitions of a disk) info[rmation] (Get information on a specific disk or partition) listFilesystems (List file systems available for formatting) activity (Continuous log of system-wide disk arbitration) u[n]mount (Unmount a single volume) unmountDisk (Unmount an entire disk (all volumes)) eject (Eject a disk) mount (Mount a single volume) mountDisk (Mount an entire disk (all mountable volumes)) rename[Volume] (Rename a volume) verifyVolume (Verify the file system data structures of a volume) repairVolume (Repair the file system data structures of a volume) verifyDisk (Verify the components of a partition map of a disk) repairDisk (Repair the components of a partition map of a disk) eraseDisk (Erase an existing disk, removing all volumes) eraseVolume (Erase an existing volume) reformat (Erase an existing volume with same name and type) eraseOptical (Erase optical media (CD/RW, DVD/RW, etc.)) zeroDisk (Erase a disk, writing zeros to the media) randomDisk (Erase a disk, writing random data to the media) secureErase (Securely erase a disk or freespace on a volume) partitionDisk ((re)Partition a disk, removing all volumes) resizeVolume (Resize a volume, increasing or decreasing its size) splitPartition (Split an existing partition into two or more) mergePartitions (Combine two or more existing partitions into one) appleRAID &lt;verb&gt; (Perform additional verbs related to AppleRAID) coreStorage &lt;verb&gt; (Perform additional verbs related to CoreStorage) apfs &lt;verb&gt; (Perform additional verbs related to APFS)diskutil &lt;verb&gt; with no options will provide help on that verb 上面列出的 verb 主要分为以下几类： 获取磁盘和分区信息：如 list、info、activity 等 挂（卸）载磁盘或卷：如 mount、eject、mountDisk 等 验证、修复磁盘分区或文件系统：如 verifyVolume、repairDisk 等 分区操作：如 splitPartitions、mergePartitions 等 其他：如 appleRAID、apfs 等 如不清楚某个 verb 的具体命令格式，可以直接使用 diskutil 命令加上该 verb 并且不带任何其他选项，命令行即输出该 verb 的使用介绍。如 eraseDisk 的使用介绍：12345678910➜ ~ diskutil eraseDiskUsage: diskutil eraseDisk format name [APM[Format]|MBR[Format]|GPT[Format]] MountPoint|DiskIdentifier|DeviceNodeCompletely erase an existing whole disk. All volumes on this disk will bedestroyed. Ownership of the affected disk is required.Format is the specific file system name you want to erase it as (HFS+, etc.).Example: diskutil eraseDisk JHFS+ UntitledUFS disk3 二、获取磁盘分区信息1. list可以使用 list 选项简要列出 MacOS 系统的磁盘及分区信息，包括分区类型（TYPE）、分区名（NAME）、容量大小（SIZE）和标志符（IDENTIFIER）等。如此时系统挂载了 dmg 映像文件，其信息也会显示在列表中（下表中的 disk3 ）。1234567891011121314151617181920212223242526➜ ~ diskutil list/dev/disk0 (internal, physical): #: TYPE NAME SIZE IDENTIFIER 0: GUID_partition_scheme *121.3 GB disk0 1: EFI EFI 209.7 MB disk0s1 2: Apple_APFS Container disk1 121.1 GB disk0s2/dev/disk1 (synthesized): #: TYPE NAME SIZE IDENTIFIER 0: APFS Container Scheme - +121.1 GB disk1 Physical Store disk0s2 1: APFS Volume Mac OS 78.4 GB disk1s1 2: APFS Volume Preboot 22.5 MB disk1s2 3: APFS Volume Recovery 517.8 MB disk1s3 4: APFS Volume VM 3.2 GB disk1s4/dev/disk2 (external, physical): #: TYPE NAME SIZE IDENTIFIER 0: FDisk_partition_scheme *7.8 GB disk2 1: Windows_FAT_32 UNTITLED 7.8 GB disk2s1/dev/disk3 (disk image): #: TYPE NAME SIZE IDENTIFIER 0: Apple_partition_scheme +39.1 MB disk3 1: Apple_partition_map 32.3 KB disk3s1 2: Apple_HFS Wireshark 39.1 MB disk3s2 其中的 /dev/disk0 为内置磁盘，/dev/disk2 为外置磁盘（U 盘，已在 Windows系统下格式化为 FAT32 格式），/dev/disk3 为 DMG 映像文件。而 /dev/disk1 其实就是 disk0s2 作为 APFS 文件系统容器的具体信息。 2. infoinfo 选项可以列出指定磁盘或分区的详细信息。如查看 disk2 （即 8 G 优盘）的信息：12345678910111213141516171819202122232425262728~ diskutil info disk2 Device Identifier: disk2 Device Node: /dev/disk2 Whole: Yes Part of Whole: disk2 Device / Media Name: DataTraveler 2.0 Volume Name: Not applicable (no file system) Mounted: Not applicable (no file system) File System: None Content (IOContent): FDisk_partition_scheme OS Can Be Installed: No Media Type: Generic Protocol: USB SMART Status: Not Supported Disk Size: 7.8 GB (7807696896 Bytes) (exactly 15249408 512-Byte-Units) Device Block Size: 512 Bytes Read-Only Media: No Read-Only Volume: Not applicable (no file system) Device Location: External Removable Media: Removable Media Removal: Software-Activated Virtual: No 输出的信息包括设备标志符（Device Identifier）、设备节点（Device Node）、设备名（Device / Media Name）、容量大小（Disk Size）、块大小（Block Size）等。 也可以查看某个分区的详细信息：1234567891011121314151617181920212223242526272829303132333435363738394041~ diskutil info disk1s1 Device Identifier: disk1s1 Device Node: /dev/disk1s1 Whole: No Part of Whole: disk1 Volume Name: Mac OS Mounted: Yes Mount Point: / Partition Type: 41504653-0000-11AA-AA11-00306543ECAC File System Personality: APFS Type (Bundle): apfs Name (User Visible): APFS Owners: Enabled OS Can Be Installed: Yes Booter Disk: disk1s2 Recovery Disk: disk1s3 Media Type: Generic Protocol: PCI SMART Status: Verified Volume UUID: E9D63DEC-29D7-3EE0-B9BB-3614E31EA747 Disk / Partition UUID: E9D63DEC-29D7-3EE0-B9BB-3614E31EA747 Disk Size: 121.1 GB (121123069952 Bytes) (exactly 236568496 512-Byte-Units) Device Block Size: 4096 Bytes Volume Total Space: 121.1 GB (121123069952 Bytes) (exactly 236568496 512-Byte-Units) Volume Used Space: 80.0 GB (79982071808 Bytes) (exactly 156214984 512-Byte-Units) (66.0%) Volume Free Space: 41.1 GB (41140998144 Bytes) (exactly 80353512 512-Byte-Units) (34.0%) Allocation Block Size: 4096 Bytes Read-Only Media: No Read-Only Volume: No Device Location: Internal Removable Media: Fixed Solid State: Yes Hardware AES Support: No 三、擦除磁盘或分区eraseDisk 选项用于擦除整个磁盘并重新格式化。该命令的格式为：diskutil eraseDisk &lt;format&gt; &lt;name&gt; [APM|MBR|GPT] MountPoint|DiskIdentifier|DeviceNodeformat 用于指定擦除数据后需要重新建立的文件系统类型。可以为 %noformat% 来跳过初始化文件系统的操作。其他支持的类型可以通过 listFilesystems 选项查看。123456789101112131415161718192021222324252627➜ ~ diskutil listFilesystemsFormattable file systemsThese file system personalities can be used for erasing and partitioning.When specifying a personality as a parameter to a verb, case is not considered.-------------------------------------------------------------------------------PERSONALITY USER VISIBLE NAME-------------------------------------------------------------------------------APFS APFS (or) APFSICase-sensitive APFS APFS (Case-sensitive)ExFAT ExFATFree Space Free Space (or) FREEMS-DOS MS-DOS (FAT)MS-DOS FAT12 MS-DOS (FAT12)MS-DOS FAT16 MS-DOS (FAT16)MS-DOS FAT32 MS-DOS (FAT32) (or) FAT32HFS+ Mac OS ExtendedCase-sensitive HFS+ Mac OS Extended (Case-sensitive) (or) HFSXCase-sensitive Journaled HFS+ Mac OS Extended (Case-sensitive, Journaled) (or) JHFSXJournaled HFS+ Mac OS Extended (Journaled) (or) JHFS+ 用来测试的优盘如下所示，已在 Windows 下格式化为 FAT32 格式。可以使用 diskutil eraseDisk ExFAT StarkyDisk disk2 命令将优盘数据擦除并格式化为 ExFAT 格式。123456789101112131415161718192021222324➜ ~ diskutil eraseDisk ExFAT StarkyDisk disk2Started erase on disk2Unmounting diskCreating the partition mapWaiting for partitions to activateFormatting disk2s2 as ExFAT with name StarkyDiskVolume name : StarkyDiskPartition offset : 411648 sectors (210763776 bytes)Volume size : 14835712 sectors (7595884544 bytes)Bytes per sector : 512Bytes per cluster: 32768FAT offset : 2048 sectors (1048576 bytes)# FAT sectors : 2048Number of FATs : 1Cluster offset : 4096 sectors (2097152 bytes)# Clusters : 231744Volume Serial # : 5ad7f879Bitmap start : 2Bitmap file size : 28968Upcase start : 3Upcase file size : 5836Root start : 4Mounting diskFinished erase on disk2 此时的优盘信息为：分区表变为 GPT 类型，且多了一个 EFI 分区。 也可以在擦除磁盘时指定分区表类型：12345678910111213141516171819202122232425➜ ~ sudo diskutil eraseDisk ExFAT StarkyDisk MBR disk2Password:Started erase on disk2Unmounting diskCreating the partition mapWaiting for partitions to activateFormatting disk2s1 as ExFAT with name StarkyDiskVolume name : StarkyDiskPartition offset : 2 sectors (1024 bytes)Volume size : 15249406 sectors (7807695872 bytes)Bytes per sector : 512Bytes per cluster: 32768FAT offset : 2048 sectors (1048576 bytes)# FAT sectors : 2048Number of FATs : 1Cluster offset : 4096 sectors (2097152 bytes)# Clusters : 238207Volume Serial # : 5ad80e37Bitmap start : 2Bitmap file size : 29776Upcase start : 3Upcase file size : 5836Root start : 4Mounting diskFinished erase on disk2 此时的优盘分区表变为 MBR 类型： 其他擦除命令如 eraseVolume （完全擦除整个磁盘或某个磁盘分区，创建新的文件系统）、zeroDisk （向整个磁盘或某个分区全部写入 ‘0’）使用 zeroDisk 命令擦除磁盘（该过程会花费很长的时间，我试了）后，该磁盘上的全部信息被抹除，同时也不再包含分区和文件系统信息：则再次插入此优盘会提示你『初始化』或『格式化』该磁盘。 四、创建磁盘分区可以通过 partionDisk 选项完成对磁盘的分区操作。该命令的格式为：1234diskutil partitionDisk MountPoint|DiskIdentifier|DeviceNode [numberOfPartitions] [APM|MBR|GPT] [part1Format part1Name part1Size part2Format part2Name part2Size part3Format part3Name part3Size ...] 命令选项中的 Size 用来指定分区的大小（以扇区数计量），合法的值包括带有指定后缀的浮点数。其中的后缀有 B(ytes), S(512-byte-blocks), K(ilobytes), M(egabytes), G(igabytes), T(erabytes), P(etabytes)，也可以是 % 来表示对整个磁盘的占比。最后一个分区会自动扩展到占用整个磁盘的剩余空间，如果想为最后一个分区指定固定的大小，可在其后再创建一个类型为『free space』的分区。12345678910111213141516171819➜ ~ sudo diskutil partitionDisk disk2 3 MBR MS-DOS F01 3G JHFS+ F02 3G &quot;Free Space&quot; F03 0Started partitioning on disk2Unmounting diskCreating the partition mapWaiting for partitions to activateFormatting disk2s1 as MS-DOS (FAT) with name F01512 bytes per physical sector/dev/rdisk2s1: 5847920 sectors in 730990 FAT32 clusters (4096 bytes/cluster)bps=512 spc=8 res=32 nft=2 mid=0xf8 spt=32 hds=255 hid=2 drv=0x80 bsec=5859376 bspf=5711 rdcl=2 infs=1 bkbs=6Mounting diskFormatting disk2s2 as Mac OS Extended (Journaled) with name F02Initialized /dev/rdisk2s2 as a 3 GB case-insensitive HFS Plus volume with a 8192k journalMounting diskFinished partitioning on disk2/dev/disk2 (external, physical): #: TYPE NAME SIZE IDENTIFIER 0: FDisk_partition_scheme *7.8 GB disk2 1: DOS_FAT_32 F01 3.0 GB disk2s1 2: Apple_HFS F02 3.0 GB disk2s2 上面的命令在优盘（disk2）上创建了 3 个分区，第一个（F01）格式为 FAT32，大小是 3 Gb。第二个（F02）格式为 JHFS+，大小为 3 Gb。最后一个是『自由空间』，大小为剩余的容量。所以实际上只是分了两个区，整体的分区表类型为 MBR。 五、分割/合并磁盘分区splitPartition 选项可以用来将已存在的某个分区再分割成数个更小的分区，注意原分区上的所有数据都会丢失。该选项的第一个参数为需要分割的分区的挂载点/标志符/设备节点，其余参数和使用 partitionDisk 时相同。12345678910111213141516171819202122232425➜ ~ sudo diskutil list | grep disk2/dev/disk2 (external, physical): 0: GUID_partition_scheme *7.8 GB disk2 1: EFI EFI 209.7 MB disk2s1 2: Apple_HFS starky 7.5 GB disk2s2➜ ~ sudo diskutil splitPartition disk2s2 2 MS-DOS F01 3g JHFS+ F02 3gStarted partitioning on disk2s2 starkySplittingUnmounting diskWaiting for partitions to activateFormatting disk2s2 as MS-DOS (FAT) with name F01512 bytes per physical sector/dev/rdisk2s2: 5845824 sectors in 730728 FAT32 clusters (4096 bytes/cluster)bps=512 spc=8 res=32 nft=2 mid=0xf8 spt=32 hds=255 hid=411648 drv=0x80 bsec=5857280 bspf=5709 rdcl=2 infs=1 bkbs=6Mounting diskFormatting disk2s3 as Mac OS Extended (Journaled) with name F02Initialized /dev/rdisk2s3 as a 4 GB case-insensitive HFS Plus volume with a 8192k journalMounting diskFinished partitioning on disk2s2 starky/dev/disk2 (external, physical): #: TYPE NAME SIZE IDENTIFIER 0: GUID_partition_scheme *7.8 GB disk2 1: EFI EFI 209.7 MB disk2s1 2: Microsoft Basic Data F01 3.0 GB disk2s2 3: Apple_HFS F02 4.5 GB disk2s3 上面的命令将优盘的第二个分区（disk2s2）又分割成了两个更小的分区，分别是 FAT32 格式的 F01（disk2s2），和 JHFS+ 格式的 F02（disk2s3）。虽然命令中指定了 F02 的大小是 3G，因为是最后一个分区，所以自动扩展到占用剩余的磁盘空间。最后它的实际大小是 4.5G。 mergePartitions 选项用来将多个已存在的分区合并为一个大的分区。该选项的格式为：diskutil mergePartitions [force] format name DiskIdentifier|DeviceNode DiskIdentifier|DeviceNode第一个分区参数为起始分区，第二个分区参数为结束分区。这两个分区之间的所有分区都将被合并。如果 force 选项没有被指定，且合并前的第一个分区是可调整大小的文件系统（如 JHFS+），则第一个分区上的数据会保留到合并后的分区。 1234567891011121314151617181920➜ ~ sudo diskutil list | grep disk2/dev/disk2 (external, physical): 0: GUID_partition_scheme *7.8 GB disk2 1: EFI EFI 209.7 MB disk2s1 2: Apple_HFS F01 2.9 GB disk2s2 3: Microsoft Basic Data F02 4.5 GB disk2s4➜ ~ sudo diskutil mergePartitions JHFS+ Starky disk2s2 disk2s4Merging partitions into a new partition Start partition: disk2s2 F01 Finish partition: disk2s4 F02Started partitioning on disk2Merging partitionsWaiting for partitions to activateGrowing diskFinished partitioning on disk2/dev/disk2 (external, physical): #: TYPE NAME SIZE IDENTIFIER 0: GUID_partition_scheme *7.8 GB disk2 1: EFI EFI 209.7 MB disk2s1 2: Apple_HFS F01 7.5 GB disk2s2 六、调整分区大小（无损）resizeVolume 选项可以无损调整（增加或缩减）分区大小。 将 disk2s2 分区缩减为 4g 大小，腾出的空间作为『free space』：1234567891011121314151617181920212223242526272829303132➜ ~ diskutil list | grep disk2/dev/disk2 (external, physical): 0: GUID_partition_scheme *7.8 GB disk2 1: EFI EFI 209.7 MB disk2s1 2: Apple_HFS F01 7.5 GB disk2s2➜ ~ sudo diskutil resizeVolume disk2s2 4gResizing to 4000000000 bytesStarted partitioning on disk2s2 F01Verifying the diskVerifying file systemVolume was successfully unmountedPerforming fsck_hfs -fn -x /dev/rdisk2s2Checking Journaled HFS Plus volumeChecking extents overflow fileChecking catalog fileChecking multi-linked filesChecking catalog hierarchyChecking extended attributes fileChecking volume bitmapChecking volume informationThe volume F01 appears to be OKFile system check exit code is 0Restoring the original state found as mountedResizingShrinking file systemModifying partition mapFinished partitioning on disk2s2 F01/dev/disk2 (external, physical): #: TYPE NAME SIZE IDENTIFIER 0: GUID_partition_scheme *7.8 GB disk2 1: EFI EFI 209.7 MB disk2s1 2: Apple_HFS F01 4.0 GB disk2s2 此时 disk2s2 内的文件如下： 将 disk2s2 分区扩展，并尽可能占用所有可用的自由空间。123456789101112131415161718192021222324252627➜ ~ sudo diskutil resizeVolume disk2s2 RResizing to full size (fit to fill)Started partitioning on disk2s2 F01Verifying the diskVerifying file systemVolume was successfully unmountedPerforming fsck_hfs -fn -x /dev/rdisk2s2Checking Journaled HFS Plus volumeChecking extents overflow fileChecking catalog fileChecking multi-linked filesChecking catalog hierarchyChecking extended attributes fileChecking volume bitmapChecking volume informationThe volume F01 appears to be OKFile system check exit code is 0Restoring the original state found as mountedResizingModifying partition mapGrowing file systemFinished partitioning on disk2s2 F01/dev/disk2 (external, physical): #: TYPE NAME SIZE IDENTIFIER 0: GUID_partition_scheme *7.8 GB disk2 1: EFI EFI 209.7 MB disk2s1 2: Apple_HFS F01 7.5 GB disk2s2 此时 disk2s2 内的文件如下： 参考文章man diskutil]]></content>
      <categories>
        <category>MacOS</category>
      </categories>
      <tags>
        <tag>Admin</tag>
        <tag>System</tag>
        <tag>Tools</tag>
        <tag>Hardware</tag>
        <tag>MacOS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu 16.04 搭建 NFS 文件共享服务器]]></title>
    <url>%2F2018%2F04%2F10%2Fubuntu-1604-NFS-server%2F</url>
    <content type="text"><![CDATA[NFS 即网络文件系统（Network File System），是一种分布式文件系统协议，该协议允许客户端主机可以像访问本地文件系统一样通过网络访问服务器端文件，即可以将远程服务器文件直接 mount（挂载）到本地的文件目录结构中进行访问。 一、软件安装服务器端需要安装 nfs-kernel-server 软件包：$ sudo apt-get update$ sudo apt-get install nfs-kernel-server 二、服务器配置默认情况下，NFS 服务器上定义了某个共享目录，则该目录及其子目录下的所有文件都可被访问。出于对安全的考虑，客户端任何需要超级用户（即 root 用户，UID=0 &amp; GID=0）权限的文件操作都默认映射到 UID=65534 和 GID=65534 的用户，即 Ubuntu 系统中的 nobody:nogroup。例如客户端使用 root 权限在挂载的共享目录中创建文件时，该文件的属主和属组自动变为 nobody:nogroup，而非 root:root 。 1. 在服务器端创建共享目录sudo mkdir -p /var/nfs/gernelsudo mkdir -p /var/nfs/publicsudo chown nobody:nogroup /var/nfs/gernel 2. 修改 exports 文件为了使 NFS 服务器定义的共享文件可被指定的客户端主机访问，需要在服务器端的 /etc/exports 文件中添加对应的记录。该文件的格式如下：Directory Host(Options ...) Host(Options) #comment关于 /etc/exports 文件的详细语法格式可参考 man exports 。 文件示例：123/var/nfs/gernel 192.168.56.0/24(rw,insecure,sync,no_subtree_check)/var/nfs/public *(ro,insecure,sync,no_subtree_check)/home/starky 192.168.56.1(rw,insecure,no_root_squash,sync,no_subtree_check) 第一条纪录表示 192.168.56.0/24 子网中的所有主机都可挂载 var/nfs/gernel 目录并拥有读写（rw）权限 第二条纪录表示所有主机都可挂载 /var/nfs/public 目录且拥有只读（ro）权限 第三条纪录表示客户端 IP 地址为 192.168.56.1 的主机可以挂载 /home/starky 目录并拥有读写权限，而且任何 root 权限（UID=0 , GID=0）的文件操作都不默认映射给 nobody:nogroup，而保持属主（组）仍为 root（no_root_squash） insecure 选项：允许通过任意端口的远程访问 sync 选项：强制 NFS 服务器在响应请求之前将文件的改动写入磁盘（强调客户端和服务端文件内容的一致性，但会降低文件操作的效率）。 no_subtree_check 选项：禁用 subtree_check 。subtree_check 用来设置服务器在收到请求时，检查该文件是否在指定目录结构中依旧可用（该选项会在某些情况下发生错误：重命名某文件的同时，该文件在客户端打开）。 三、客户端挂载共享目录列出 nfs 服务器上的共享目录12345$ showmount -e 192.168.56.102Exports list on 192.168.56.102:/home/starky 192.168.56.1/var/nfs/public */var/nfs/gernel 192.168.56.0/24 创建挂载点sudo mkdir -p /mnt/nfs/gernelsudo mkdir -p /mnt/nfs/publicsudo mkdir -p /mnt/nfs/starky 挂载远程目录sudo mount 192.168.56.102:/var/nfs/gernel /mnt/nfs/gernelsudo mount 192.168.56.102:/var/nfs/public /mnt/nfs/publicsudo mount 192.168.56.102:/home/starky /mnt/nfs/starky 权限测试 如截图所示： NFS 的权限设定基于 Linux 文件系统的权限管理，即客户端挂载远程共享目录后，会把它们当成本地磁盘目录一样对待，也是根据文件的属主（组）及其对应的权限设定来限制访问。gernel 目录的属主（组）为 nobody:nogroup（65534:65534），所以虽然该目录为读写权限，非 root 用户无法执行新建操作。而 root 用户由于 NFS 默认的安全机制，会自动映射到 nobody:nogroup。由于我在客户端和服务端都有一个名为 starky 的用户，且它们的 UID:GID 都为1000:1000，所以服务端的 /home/starky 目录可以直接被客户端的 starky 用户访问。且由于 no_root_squash 选项，通过 sudo 命令创建的文件其属主仍为 root（而不会再映射为 nobody）。当然这会导致一些安全问题，比如多个客户端同时都有 UID（GID）为1000的用户（不管用户名是什么），则这些用户会共享服务端 /home/starky 目录里的文件权限。 四、系统启动时自动挂载共享目录可编辑 /etc/fstab 文件令挂载共享目录的 mount 操作成为系统的固定配置（手动输入的 mount 命令属于临时挂载，重启会自动卸载），使得系统重启后可以自动挂载远程文件系统。/etc/fstab 文件的示例内容如下：1234# filesystem mountpoint fstype flags dump fsck192.168.56.102:/var/nfs/gernel /mnt/nfs/gernel nfs rw,bg,intr,hard,nodev,nosuid 0 0192.168.56.102:/var/nfs/public /mnt/nfs/public nfs4 ro,bg,intr,soft,nodev,nosuid 0 0192.168.56.102:/home/starky /mnt/nfs/starky nfs rw,bg,intr,hard,nodev,nosuid 0 0 附录：1. /etc/exports 文件中的 Host 格式/etc/exports 文件的格式为：Directory Host(Options ...) Host(Options) #comment其中的 Host 项用来指定可访问对应共享目录的主机，其格式可分为以下几种： 单个主机Host 项可以为一个或多个单独的 TCP/IP 主机名或 IP 地址 123adminadmin.starky.net192.168.56.101 IP 子网 12310.0.0.0/255.0.0.0 172.16.0.0/255.255.0.0192.168.56.0/24 TCP/IP 域通过使用通配符，可以指定某个特定域中的全部或部分主机 123*.starky.net*craft.starky.net???.starky.net NIS 组可以指定某个 NIS 组中所有主机的访问权限，使用 @group 2. /etc/exports 文件中的 Options 选项 描述 ro 只读权限 rw 读写权限（默认） rw=list 通过 list 指定具有写权限的客户端主机，其他主机则为只读权限 root_squash 将 UID 0 和 GID 0 映射到 anonuid 和 anongid（即 Ubuntu 系统中的 nobody 和 nogroup） no_root_squash 允许需要 root 权限的文件操作，有安全风险 all_squash 将所有的 UID 和 GID 映射到它们的匿名形式，主要针对不信任的主机 anonuid=xxx 指定客户端 root 权限的操作需要映射到的 UID（默认是65534） anongid=xxx 指定客户端 root 权限的操作需要映射到的 GID（默认是65534） insecure 允许通过任意端口的远程访问 async 服务器可以在写入硬盘之前响应客户端的写入请求 wdelay 通过延迟同步多个客户端对文件的更新 sec=flavor 指定共享目录的安全验证方法，包括 sys（UNIX 验证），dh (DES)，krb5i，krb5p 和 none（匿名访问） 3. NFS 挂载选项 选项 描述 rw 以读写模式挂载文件系统（rw 也需在服务端定义） ro 以只读模式挂载文件系统 bg 如挂载失败（服务器无响应），在后台继续尝试并执行其他挂载请求 hard 如果服务器无响应，重复发送请求直到服务器回复 soft 如果服务器无响应，重复发送请求，超过一定时间后返回错误，而不会一直阻塞 intr 允许用户中断阻塞的文件操作（并返回错误） nointr 不允许用户中断客户端的文件操作请求 retrans=n 在 soft 模式下，指定返回错误前重复发送请求的次数 timeo=n 设置超时后重复发送请求的时间间隔（单位 1/10 秒） rsize=n 设置读取 buffer 大小为 n bytes wsize=n 设置写入 buffer 大小为 n bytes sec=flavor 设置安全验证方法 proto=proto 设置传输协议，NFSv4 必须为 TCP 4. NFS 协议讨论传输协议最初的 NFSv2 由于性能原因使用 UDP 协议，虽然 NFS 添加了自己的包序列重组和错误检查功能，但 UDP 和 NFS 都不具备阻塞控制算法，所以在大型的互联网络环境中缺乏足够的性能。NFSv3 提供了 UDP 和 TCP 协议之间的选择。NFSv4 只能使用 TCP 协议。随着 CPU，内存等硬件设备和网络传输速度的提高，最初由于性能需求而倾向 UDP 协议的选择也变得不再必要。 StateNFSv2 和 NFSv3 是无状态的连接，服务端不会跟踪客户端对共享目录的挂载情况，而是使用 “cookie” 来记录一次成功的挂载。”cookie” 不会因为服务器重启而删除，可以用来在服务器挂掉之后保留客户端的连接信息。NFSv4 是有状态的连接，客户端和服务端都会维护文件操作纪录及文件锁的状态。所以不再需要 “cookie” 的使用。 文件锁早期版本的 NFS 协议（v2 &amp; v3）由于是无状态的连接，它们并不清楚哪些主机正在使用哪些文件。但是文件锁的实现又需要获取状态信息。所以早期协议中的文件锁是独立于 NFS 实现的。而 NFSv4 将文件锁的实现整合到了核心协议中，虽然此举增加了复杂度，但同时也解决了早期版本中的很多问题。但是为了兼容使用 V2 和 V3 协议的客户端，独立的 locked 和 statd 守护进程仍旧需要。 安全相关NFS 协议最初在设计时并不关注安全性，NFSv4 通过引入对更强大的安全服务和身份验证的支持，加强了该协议的安全性。 传统的 NFS 协议大多使用 AUTH_SYS 验证方式，基于 UNIX 的用户和组标识。在这种方式下，客户端只需要发送自己的 UID 和 GID 并与服务器上的 /etc/passwd 文件内容作对比，以决定其拥有怎样的权限。所以当多个客户端存在 UID 相同的用户时，这些用户会拥有相同的文件权限。更进一步，拥有 root 权限的用户可以通过 su 命令切换到任意 UID 登录，服务器会因此给予其对应 UID 的权限。为了防止上面的问题出现，服务器可选择使用更健壮的验证机制比如 Kerberos 结合 NFS PRCSEC_GSS。 NFS 共享目录的访问控制基于 /etc/exports 文件中定义的主机名或 IP 地址。但是客户端很容易针对其身份和 IP 地址造假，这也会导致一些安全问题。NFSv4 只使用 TCP 作为自己的传输协议，而且通常只开放 2049 端口进行数据传输。在配置防火墙时，除了放开 2049 端口的限制外，还要时刻注意数据传输的源地址和目标地址。 5. Windows 系统挂载共享目录win10 系统默认不能挂载 NFS 共享目录，需要进入控制面板 - 程序 - 程序和功能 - 启用或关闭 Windows 功能，勾选上 NFS 服务。之后就可以使用 mount 命令挂载共享目录了。只是 Windows 系统并不使用 Linux 那样的用户管理，导致挂载的共享目录只能读取而没有写入的权限。解决办法是在注册表中新建两个 DWORD 值，用作匿名用户的 UID 和 GID。默认参数下的挂载选项，UID 和 GID 都为 -2：可进入注册表编辑器（regedit），定位到 HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\ClientForNFS\CurrentVersion\Default ，新建两个名为 AnonymousUid 和 AnonymousGid 的 DWORD（32位）值，改成自己需要用到的数字（我都改成了 0 ，即对应 Linux 系统中的 root 用户。如需要改为 0 以外的数字，注意先转换成 16 位）。此时的挂载选项变为：如更改未生效，可重启电脑。 参考资料UNIX and Linux System Administration Handbook, 4th EditionHow to Mount an NFS Share Using a Windows 10 Machine]]></content>
      <categories>
        <category>Server</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Server</tag>
        <tag>Admin</tag>
        <tag>Configuration</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[netstat 命令用法详解]]></title>
    <url>%2F2018%2F03%2F29%2Fnetstat-manual%2F</url>
    <content type="text"><![CDATA[Netstat（network statistics）是在内核中访问网络连接状态及其相关信息的命令行程序，可以显示路由表、实际的网络连接和网络接口设备的状态信息，以及与 IP、TCP、UDP 和 ICMP 协议相关的统计数据，一般用于检验本机各端口的网络服务运行状况。 命令选项 显示所有连接。-a 选项会列出 tcp, udp 和 unix 协议下所有套接字的所有连接。 只列出 TCP 或 UDP 协议的连接 使用 -t 选项列出 TCP 协议的连接，可和 -a 选项配合使用 使用 -u 选项列出 UDP 协议的连接 禁用反向域名解析，加快查询速度默认情况下 netstat 会通过反向域名解析查找每个 IP 地址对应的主机名，会降低查找速度。n 选项可以禁用此行为，并且用户 ID 和端口号也优先使用数字显示。 只列出监听中的连接-l 选项可以只列出正在监听的连接（不能和 a 选项同时使用） 获取进程名、进程号以及用户 ID-p 选项可以查看进程信息（此时 netstat 应尽量运行在 root 权限之下，否则不能得到运行在 root 权限下的进程名）-pe 选项可以同时查看进程名（号）和进程所属的用户名 显示路由信息使用 -r 选项打印内核路由信息，与 route 命令输出一样。 网络接口信息-i 选项可以输出网络接口设备的统计信息，结合上 -e 选项，等于 ifconfig 命令的输出。 获取网络协议的统计信息-s 选项可以输出针对不同网络协议的统计信息，包括 Ip、Icmp、Tcp 和 Udp 等。 命令实例 打印 active 状态的连接 查看指定服务是否正常运行 参考文章netstat 的10个基本用法]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Admin</tag>
        <tag>Tools</tag>
        <tag>Networking</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu 16.04 配置 L2TP over IPSec VPN 服务器]]></title>
    <url>%2F2018%2F03%2F23%2FL2TP-VPN-Server-on-Ubuntu-1604%2F</url>
    <content type="text"><![CDATA[VPN 即 Virtual Private Network（虚拟专用网），简单来说，就是在公共网络上搭建一条虚拟的私有链路，可以通过该链路加入到远程的私有网络环境中。所以常用来帮助员工在办公室外安全地访问企业内部网。创建私有链路需要使用隧道技术，用到的协议包括点对点隧道协议（PPTP），第2层隧道协议（L2TP）等。macOS 系统已经不再支持 PPTP 类型的 VPN。 一、安装软件包$ sudo apt-get install strongswan xl2tpd ppp lsofIPSec 是组建安全的 VPN 时使用的一个加密和认证标准，而 strongSwan 是一个完全支持 IKEv1 和 IKEv2 的 IKE 后台进程。 二、修改配置文件1. 修改系统转发配置在 /etc/sysctl.conf 文件末尾添加以下内容：1234567net.ipv4.ip_forward = 1net.ipv4.conf.all.accept_redirects = 0net.ipv4.conf.all.send_redirects = 0net.ipv4.conf.default.rp_filter = 0net.ipv4.conf.default.accept_source_route = 0net.ipv4.conf.default.send_redirects = 0net.ipv4.icmp_ignore_bogus_error_responses = 1 启用配置：$ sudo sysctl -p 2. 配置 strongswan(IPSec)在 /etc/ipsec.conf 文件末尾添加如下内容：12345678910111213141516171819202122232425262728293031323334version 2 config setupconn L2TP-PSK-noNAT authby=secret #shared secret. Use rsasig for certificates. auto=add #the ipsec tunnel should be started and routes created when the ipsec daemon itself starts. keyingtries=3 #Only negotiate a conn. 3 times. ikelifetime=8h keylife=1h ike=aes256-sha1,aes128-sha1,3des-sha1 type=transport #because we use l2tp as tunnel protocol left=10.2.67.203 # VPN 服务器的 IP 地址，&apos;%any&apos; 表示任意地址 leftprotoport=17/1701 right=%any rightprotoport=17/%any dpddelay=10 # Dead Peer Dectection (RFC 3706) keepalives delay dpdtimeout=20 # length of time (in seconds) we will idle without hearing either an R_U_THERE poll from our peer, or an R_U_THERE_ACK reply. dpdaction=clear # When a DPD enabled peer is declared dead, what action should be taken. clear means the eroute and SA with both be cleared. 配置共享密钥 /etc/ipsec.secrets：1%any : PSK &quot;PASSWORD&quot; %any 针对任意服务器地址，PASSWORD 需要改为足够安全的长密码 3. 配置 xl2tpd在 /etc/xl2tpd/xl2tpd.conf 文件末尾添加如下内容：1234567891011121314151617[global]ipsec saref = yessaref refinfo = 30;debug avp = yes;debug network = yes;debug state = yes;debug tunnel = yes[lns default]ip range = 192.168.100.100 - 192.168.100.200local ip = 192.168.100.1refuse pap = yesrequire authentication = yes;ppp debug = yespppoptfile = /etc/ppp/options.xl2tpdlength bit = yes local ip 表示 VPN 虚拟网络的网关，ip range 表示客户端连接 VPN 服务器时能分配到的 IP 地址在 /etc/ppp/options.xl2tpd 文件中添加如下内容：12345678910111213require-mschap-v2ms-dns 10.2.64.1ms-dns 114.114.114.114authmtu 1200mru 1000crtsctshide-passwordmodemname l2tpdproxyarplcp-echo-interval 30lcp-echo-failure 4 修改 ms-dns 为需要 vpn 客户端使用的 dns 服务器 4. 添加用户修改 /etc/ppp/chap-secrets 文件：12starky l2tpd password1 *bob l2tpd password2 * 格式为：用户名、服务、密码、限制 ip 。 以上的配置完成以后，重启服务就可以使用客户端连接了。不过此时还不能通过该 VPN 访问互联网，需要部署 IP 转发（使用 iptables ）。 三、配置转发输入下面的指令，开启 gre 协议，并打开服务器 47 和 1723 号端口。123$ sudo iptables -A INPUT -p gre -j ACCEPT $ sudo iptables -A INPUT -p tcp --dport 1723 -j ACCEPT $ sudo iptables -A INPUT -p tcp --dport 47 -j ACCEPT 开启一个 NAT 转发$ sudo iptables -t nat -A POSTROUTING -s 192.168.100.0/24 -o wlp4s0 -j MASQUERADEwlp4s0 表示当前服务器使用的网卡设备名。可以通过 ifconfig 命令查看 通过上面的指令，iptables 做了这样一件事：将所有从服务器上传出的源地址为 192.168.100.1-255 的数据包源 ip 改成服务器的 ip 。 四、连接测试首先需要重启服务：12sudo ipsec restartsudo service xl2tpd restart Mac 电脑上在网络偏好设置里新建 VPN 连接，类型选 L2TP over IPSec。验证设置如下图：连接成功图示：在命令行下使用 Tcpdump 的抓包结果： 参考文章Ubuntu 16.04 配置L2TP VPN Server]]></content>
      <categories>
        <category>Server</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Server</tag>
        <tag>Admin</tag>
        <tag>Configuration</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简单实用的 vim 配置文件]]></title>
    <url>%2F2018%2F03%2F20%2Fvim-configuration%2F</url>
    <content type="text"><![CDATA[Vim 号称『编辑器之神』，既已成神，自然有它凌驾于众生之上的资本。而我只是拿它当个『编辑器』罢了。从来没想过鼓捣些什么神奇的插件，然后摇身一变，成了别人眼里无所不能的『IDE』。在我看来总有些招摇撞骗的感觉。可能折腾的过程才是最值得体味的吧。只是因为它的高效，随手可得，偶尔改改配置文件什么的，感觉很顺手就够了。 所以这儿贴出的配置文件，初衷也只是拿它作为一个再简单不过的编辑器，最起码的要求，就是看上去更合我胃口一点。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697&quot; 关闭对 vi 的兼容性set nocompatible&quot; 使退格键正常处理 indent,eol,start 等set backspace=2&quot; 显示行号set nu&quot; 显示标尺set ruler&quot; 突出显示当前行set cursorline&quot; 高亮显示对应的括号set showmatch&quot; 对应括号的高亮时间（单位 1/10 秒）set matchtime=5&quot; 高亮搜索时的匹配项set hlsearch&quot; 搜索时逐字符匹配set incsearch&quot; 搜索时忽略大小写set ignorecase&quot; 开启语法高亮syntax on&quot; 开启文件类型检测filetype on&quot; 允许载入对应文件类型的插件filetype plugin on&quot; 为特定文件载入对应的缩进文件filetype indent on&quot; 关闭备份功能set nobackup&quot; 文件未保存(或文件只读)时弹出确认set confirm&quot; 切换 buffer 时自动保存当前文件set autowrite&quot; 文件有外部改动时自动载入set autoread&quot; 自动切换为当前文件所在的目录set autochdir&quot; 设置鼠标可用set mouse=aset selection=exclusiveset selectmode=mouse,key&quot; 共享剪贴板set clipboard+=unnamed&quot; 隐藏工具栏和菜单栏（GVim）&quot;set guioptions-=T&quot;set guioptions-=m&quot; tab 宽度和缩进设置set tabstop=4set shiftwidth=4&quot; 不使用空格代替制表符set noexpandtab&quot; 在行和段开始处使用制表符set smarttab&quot; 使用 C 风格的缩进set cindent&quot; 自动缩进（继承上一行的缩进方式）set autoindent&quot; 为 C 程序提供自动缩进set smartindent&quot; 允许折叠set foldenable&quot; 根据语法折叠set fdm=syntax&quot; 手动折叠&quot; set fdm=manual&quot; 设定折叠层数setlocal foldlevel=1&quot; 通过空格键开关折叠nnoremap &lt;space&gt; @=((foldclosed(line(&apos;.&apos;)) &lt; 0) ? &apos;zc&apos; : &apos;zo&apos;)&lt;CR&gt;&quot; 显示状态栏set laststatus=2&quot; 设置状态栏显示的信息set statusline=\ %&lt;%.20F[%1*%M%*%n%R%H]%=\ [%&#123;&amp;ff&#125;:%&#123;&amp;encoding&#125;]\ %Y\ \ \ %l:%v\ %p%%/%L\ \ \ %&#123;strftime(\&quot;%y/%m/%d\ %H:%M\&quot;)&#125;\ \ &quot; 显示输入的命令set showcmd&quot; 增强模式中的命令行自动完成功能set wildmenu&quot; 设置命令行的高度，默认为 1set cmdheight=2&quot; 设置编码set encoding=utf-8set fileencodings=utf-8,usc-bom,shift-jis,gb18030,gbk,gb2312,cp936,utf-16,big-5,euc-jp,latin1set whichwrap=b,s,&lt;,&gt;,[,]&quot; 开启Normal或Visual模式下退格键、空格键、左右方向键，Insert或Replace模式下左右方向键的跳行功能 没有插件，甚至没有自定义组合键，还是觉得没那个必要了。倒是状态栏费了好一阵功夫。。。也许有机会，可以好好陪它玩一下，感受感受神之光芒的洗礼。这会儿，只当它是个工具。对不起咯]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Configuration</tag>
        <tag>Tools</tag>
        <tag>VIM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tcpdump 命令用法详解]]></title>
    <url>%2F2018%2F03%2F20%2FTcpdump-manual%2F</url>
    <content type="text"><![CDATA[Tcpdump 是信息安全领域常用的嗅探和网络分析工具，运行在命令行下。虽然要用好它需要对 TCP/IP 协议有足够的了解，但从另一个角度讲，多用一下同样也能促进对网络协议的掌握。 大部分 Linux 发行版都内置了 Tcpdump 工具。如果没有，也可以直接使用对应的包管理器进行安装（如：$ sudo apt-get install tcpdump 和 $ sudo yum install tcpdump） 一、命令选项 -i any：监听所有网络接口 -i eth0：监听指定的网络接口（eth0） -D：列出所有可用的网络接口 -n：不解析主机名 -nn：不解析主机名和端口名 -q：输出较少的信息 -t：更便于阅读的时间戳输出 -tttt：最便于阅读的时间戳输出 -X：以 HEX 和 ASCII 模式输出数据包的内容 -XX：与 -X 选项相同，同时还输出 ethernet 头 -v, -vv, -vvv：输出更多数据包的信息 -c：获取到指定数目的数据包后就停止 -s：定义 snaplength (size) ，-s0 表示获取全部 -S：输出绝对序列号 -e：获取 ethernet 头信息 -E：通过提供 key 来解密 IPSEC 流量 二、表达式通过表达式可以对各种不同类型的网络流量进行过滤，以获取到需要的信息。这也是 tcpdump 强大功能的一个体现。主要有 3 种类型的表达式： Type（类型）选项包括 host 、net 和 port Direction（方向）选项包括 src 和 dst 以及它们的组合 Proto（协议）包括 tcp 、udp 、ICMP 和 ah 等 三、应用实例指定网络接口：# tcpdump -i &lt;dev&gt;vboxnet0 是 virtualvox 虚拟机通过 Host-only 方式虚拟的一张网卡 原始信息输出模式：# tcpdump -ttttnnvvS更详细的输出，不解析主机名和端口名，使用绝对序列号，方便阅读的时间戳 通过IP地址过滤：# tcpdump host 10.2.64.110.2.64.1 是我的 DNS 服务器地址 HEX 输出# tcpdump -nnvXSs 0 -c1 icmp 通过源地址和目标地址进行过滤# tcpdump src 10.2.67.203 # tcpdump dst 10.2.67.203 通过子网进行过滤# tcpdump net 10.2.64.0/24 监听指定端口号# tcpdump port 515515 是本地打印机 LPD 服务的端口号 指定协议# tcpdmp icmp 端口范围# tcpdump portrange 21-23 通过包大小过滤# tcpdump less 32# tcpdump greater 64# tcpdump &lt;= 128 写入 PCAP 文件# tcpdump port 80 -w capture_file 读取 PCAP 文件# tcpdump -r capture_file 四、高级功能1. 逻辑运算符可以通过命令选项的不同组合（使用逻辑运算符）完成更复杂的任务。运算符包括以下3种： AND（and 或 &amp;） OR（or 或 ||） EXCEPT （not 或 !） # tcpdump src 10.2.64.29 and dst port 80即捕捉从指定主机（10.2.64.92）发出，且目标端口为 80 的所有网络数据 # tcpdump src net 192.168.0.0/16 and dst net 10.0.0.0/8 or 172.16.0.0/16即捕捉从指定子网（192.168.0.0/16）发送到目标子网（10.0.0.0/8 和 172.16.0.0/16）的所有网络数据 # tcpdump src 192.168.56.1 and not dst port 22即捕捉从指定主机（192.168.56.1）发出，且目标端口不为 22 的所有网络数据 2. 指定 TCP 标志位（Flags）# tcpdump &#39;tcp[13] &amp; 32!=0&#39; 所有 URGENT (URG) 包# tcpdump &#39;tcp[13] &amp; 16!=0&#39; 所有 ACKNOWLEDGE (ACK) 包# tcpdump &#39;tcp[13] &amp; 8!=0&#39; 所有 PUSH (PSH) 包# tcpdump &#39;tcp[13] &amp; 4!=0&#39; 所有 RESET (RST) 包# tcpdump &#39;tcp[13] &amp; 2!=0&#39; 所有 SYNCHRONIZE (SYN) 包# tcpdump &#39;tcp[13] &amp; 1!=0&#39; 所有 FINISH (FIN) 包# tcpdump &#39;tcp[13]=18&#39; 所有 SYNCHRONIZE/ACKNOWLEDGE (SYNACK) 包 其他指定标志位的方式如：# tcpdump &#39;tcp[tcpflags] == tcp-syn&#39;# tcpdump &#39;tcp[tcpflags] == tcp-fin&#39; 一些特殊的用法# tcpdump &#39;tcp[13] = 6&#39; RST 和 SYN 同时启用的数据包（不正常）# tcpdump &#39;tcp[32:4] = 0x47455420&#39; 获取 http GET 请求的文本# tcpdump &#39;tcp[(tcp[12]&gt;&gt;2):4] = 0x5353482D&#39; 获取任何端口的 ssh 连接（通过 banner 信息）# tcpdump &#39;ip[8] &lt; 10&#39; ttl 小于 10 的数据包（出现问题或 traceroute 命令）# tcpdump &#39;ip[6] &amp; 128 != 0&#39; 非常有可能是黑客入侵的情况 参考文章：A tcpdump Tutorial and Primer with Examples]]></content>
      <categories>
        <category>Pentest</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Tools</tag>
        <tag>Security</tag>
        <tag>Networking</tag>
        <tag>Pentest</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在 Ubuntu 16.04 上通过 SSL/TLS 搭建安全的 FTP 服务器]]></title>
    <url>%2F2018%2F03%2F19%2Fsecure-ftp-with-tls-on-ubuntu%2F</url>
    <content type="text"><![CDATA[FTP 是 File Transfer Protocol （文件传输协议）的简称，用于在 Internet 上控制文件的双向传输。作为很古老的一种文件传输协议，简单的服务器搭建和丰富的客户端支持是它的优势，但安全性却是它很大的一个软肋。（在建立连接时使用明文传输用户名和密码等重要信息） 一、安全性测试1. 安装 ftp 服务：ubuntu 16.04 可以使用包管理器直接安装 vsftpd 以建立 ftp 服务器。$ sudo apt-get install vsftpd vsftpd 的配置文件为 /etc/vsftpd.conf，默认即开启了本地用户（local_enable=YES）的登录和下载权限，可以直接使用。如需使用上传功能，可以将配置文件中 #write_enable=YES 前面的注释去掉。因为主要是测试安全性，其他配置选项暂不做改动。 2. 使用 wireshark 抓包Wireshark 是一个功能强大的网络抓包和分析工具。这里使用它来对 FTP 客户端与服务器之间的数据交换进行监控。因为 Ubuntu 服务器安装在 virtualbox 虚拟机中，联网使用的是 Host-only 模式，所以抓包时监控的是 vboxnet0 虚拟网卡。 效果如下：可以看到，FTP 的用户名和密码都是使用明文传输的，可以直接被看到。 3. 更安全的 SFTP 服务SFTP 是 Secure File Transfer Protocol （安全文件传送协议）的缩写，包含在 ssh 服务中。Ubuntu 16.04 系统中，配置好 ssh 服务后，sftp 服务即默认开启。需要注意的是，sftp 使用了加密、解密技术，所以传输效率比普通的FTP要低得多。 可以使用 sudo apt-get openssh-server 命令安装 ssh 服务，如 sftp 服务未默认开启，可以编辑 sshd 配置文件：/etc/ssh/sshd_config，添加上 Subsystem sftp /usr/lib/openssh/sftp-server。 使用 sftp 服务时的抓包截图：可以看到，截获的包内容都变成了 Encrypted packet 二、搭建安全的 FTPS 服务这里要详细说明的是另外一种解决方案，使用 SSL/TLS 对 FTP 的数据传输进行加密。关于 SFTP 与 FTPS 的之间的对比，建议参考此文章：FTPS (FTP over SSL) vs SFTP (SSH File Transfer Protocol)。 1. 创建证书FTPS 是使用安全套接层（SSL）证书的 FTP 技术，也就是使用用户 ID、密码和 SSL 证书进行身份验证。$ sudo openssl req -x509 -nodes -keyout /etc/ssl/private/vsftpd.pem -out /etc/ssl/private/vsftpd.pem -days 365 -newkey rsa:2048上面的命令用于生成证书和 key 并保存在 vsftpd.pem 文件中。运行后会提示你输入相关信息（可以随便填写，不要留空）：1234567Country Name (2 letter code) [AU]:State or Province Name (full name) [Some-State]:Locality Name (eg, city) []:hangzhouOrganization Name (eg, company) [Internet Widgits Pty Ltd]:Organizational Unit Name (eg, section) []:sectionCommon Name (e.g. server FQDN or YOUR name) []:starkyEmail Address []:starky@email.com 2. 修改配置文件如果你有开启 ufw 防火墙（默认是未开启的），需要先在防火墙配置中开放指定端口用于通讯和数据传输。12$ sudo ufw allow 990/tcp$ sudo ufw allow 4000:5000/tcp 我这里没有开启 ufw ，所以不需要以上操作。直接修改 vsftpd 的配置文件（$ sudo vim /etc/vsftpd.conf）。将文件中的对应配置做如下修改（没有就添加）：1234567891011121314151617# 开启 ssl 并指定使用的协议ssl_enable=YESssl_tlsv1=YESssl_sslv2=NOssl_sslv3=NO# 指定证书和 key 文件rsa_cert_file=/etc/ssl/private/vsftpd.pemrsa_private_key_file=/etc/ssl/private/vsftpd.pem# 安全选项allow_anon_ssl=NOforce_local_data_ssl=YESforce_local_logins_ssl=YESrequire_ssl_reuse=NOssl_ciphers=HIGH# 指定主动模式时使用的端口范围pasv_min_port=40000pasv_max_port=50000 修改完成后重启 vsftpd 服务：$ sudo systemctl restart vsftpd 三、连接验证客户端使用 filezilla 连接服务器，新建站点时使用如下配置：12345Host: 192.168.56.102Protocol: FTP – File Transfer ProtocolEncryption: Require explicit FTP over TLSLogon Type: Ask for passwordUser: username 点连接后会跳出输入密码界面和证书信息，确定之后即可成功连接而此时 wireshark 的抓包截图如下：捕捉到的请求和响应信息都是已加密过的密文。 参考文章Setting Up a Secure FTP Server using SSL/TLS on Ubuntu关于 vsftpd 配置文件的详细解释可参考：Vsftpd - Ubuntu中文]]></content>
      <categories>
        <category>Server</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Server</tag>
        <tag>Admin</tag>
        <tag>Ubuntu</tag>
        <tag>FTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[蚂蚱之死]]></title>
    <url>%2F2018%2F03%2F16%2FThe-Death-of-Grasshopper%2F</url>
    <content type="text"><![CDATA[我小时候是个极恶毒的家伙田野地头儿上走着，每遇蚂蚱蟋蟀之流无论大小，必捕而杀之还是很残忍的那种，处决然后以得胜者的气势扬长而去大有替天行道的侠者风范 以旧的社会主义论调而言，它们是害虫，杀了是为民除害从物竞天择适者生存的观念来讲强者凌驾于弱者之上，又似乎天经地义 于是终于坦然。甚至于有了上瘾的迹象直到很多年过去，到了城里很少再见到它们了竟然又开始想念 我们都是些无能为力的弱者做着些自我欺骗的勾当 小蚂蚱，希望有机会你我可以角色互换]]></content>
      <categories>
        <category>nonsense</category>
      </categories>
      <tags>
        <tag>nonsense</tag>
        <tag>胡言乱语</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 打包 压缩 解压 命令详解]]></title>
    <url>%2F2018%2F03%2F11%2Fuse-tar-to-package-and-compress-files%2F</url>
    <content type="text"><![CDATA[tar 命令是 Linux 环境下最基本的打包工具，注意打包并不等同于压缩。打包只是负责将多个文件整理后合成为一个文件包（即归档，方便传输分享），一般后缀为 .tar。而文件打包后通常都要进行压缩，以节省空间和传输时间。所以打包和压缩是紧密相关但并不相同的两个命令（过程）。用 tar 命令加上适当的选项可以统一执行这两道程序。 一、压缩命令常用的 Linux 压缩工具如下： 压缩工具 对应后缀 对应 tar 选项 gzip .gz z bzip2 .bz 或 .bz2 j compress .Z Z xz .xz J lzma .lzma a PS：lzma 等同于 xz –format=lzma 关于上面表格中的压缩命令，命令选项都大同小异。可以查看相应的帮助信息（如 gzip --help）或手册（如 man xz）。 二、使用 tar 命令打包压缩单独使用压缩命令（如 gzip 或 bzip2）的情形并不常见，多用于单个文件或对多个文件逐个进行压缩。更多的时候使用 tar 命令先打包多个文件或目录后再配合指定的选项执行压缩操作。 tar 命令选项： 第一选项（指定操作方式）： -c ：创建归档文件 -x ：解包归档文件 -t ：列出归档文件的内容列表 -r ：向归档文件中添加（替换）文件（只对未压缩的归档文件有效） -u ：更新归档文件中的内容（只对未压缩的归档文件有效） 压缩选项（指定压缩方法）：-z，-j，-J，-a，分别对应于 gzip，bzip2，xz，lzma 四种压缩命令。 通用选项： -v ：开启更详细的输出信息 -f ：指定归档文件的位置 -w ：交互模式 三、总结 tar 格式：打包：tar -cvf Archive.tar DirName解包：tar -xvf Archive.tar gz 格式：压缩：gzip FileName解压：gzip -d FileName.gz 或 gunzip FileName.gz tar.gz 或 tgz 格式：压缩：tar -czvf FileName.tar.gz DirName解压：tar -xzvf FileName.tar.gz bz 或 bz2 格式：压缩：bzip2 -z FileName解压：bzip2 -d FileName.bz 或 bunzip2 FileName.bz tar.bz 或 tar.bz2 格式：压缩：tar -cjvf FileName.tar.bz DirName解压：tar -xjvf FileName.tar.bz Z 格式：压缩：compress FileName解压：uncompress FileName.Z tar.Z 格式：压缩：tar -cZvf FileName.tar.Z DirName解压：tar -xZvf FileName.tar.Z xz 格式：压缩：xz -z FileName.xz DirName解压：xz -d FileName.xz 或 unxz FileName.xz tar.xz 格式：压缩：tar -cJvf FileName.tar.xz DirName解压：tar -xJvf FileName.tar.xz zip 格式：压缩：zip FileName.zip DirName解压：unzip FileName.zip 更详细的 tar 命令使用方法可参见 man tar]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Admin</tag>
        <tag>Tools</tag>
        <tag>Trick</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ssh-使用-RSA-密钥完成免密码登录]]></title>
    <url>%2F2018%2F03%2F11%2Fssh-login-by-RSA%2F</url>
    <content type="text"><![CDATA[大多数 Linux 服务器并不包含完善的用户界面，很多时候也并非安装在本地机器上。而是使用 SSH 远程登录的方式来完成对服务器的控制。SSH（Secure Shell）提供两种级别的验证方式。第一种是基于口令的验证，即使用自己的用户名和密码登录远程机器。第二种是基于密钥的验证，即先在本地机器上创建一对密钥（公钥和私钥），将公钥上传到远程服务器，登录时通过对比客户端与远程端的密钥来进行验证。基于密钥的验证是不需要在网络上传输口令的，相对而言更加安全。 Linux 上的 ssh 服务器可以使用 openssh ，使用软件包管理器直接安装即可：$ sudo apt-get install openssh-server 使用密钥进行远程登录还可以实现自动登录（不需要输入密码），以下为详细配置过程。 一、在本地机器上创建密钥$ ssh-keygen -t rsa -C &#39;email@domain.com&#39;-t 选项用来指定密钥类型，默认即为 rsa)；-C 选项用来提供说明文字命令执行成功后会在 ~/.ssh 目录下分别创建公钥（默认为 id_rsa.pub）和私钥（默认为 id_rsa）文件 二、将公钥上传至服务器这一步需要将本地生成的公钥文件（id_rsa.pub）内容添加到服务器上的 ~/.ssh/authorized_keys 文件中。 可使用 scp 命令完成远程复制：1234$ scp ~/.ssh/id_rsa.pub username@hostname:~/ # 将公钥文件上传至服务器用户主目录$ ssh username@hostname # 使用用户名和密码登录至服务器$ mkdir .ssh # 在远程服务器上创建 .ssh 目录$ cat id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys # 将公钥文件内容追加到authorized_keys文件末尾 上面我使用的是 virtualbox 虚拟机安装的 ubuntu 16.04 Server，利用 NAT 的端口转发将宿主机的 8022 端口映射到了虚拟机的 22 端口。-P 8022 用于指定端口号 以上步骤完成后就可以通过 ssh username@hostname 命令直接登录远程主机。 三、配置登录别名可以通过在本地机器上的 ~/.ssh/config 文件中定义别名，然后使用 ssh &lt;alias&gt; 命令即可直接登录远程服务器。该文件格式如下：12345Host alias # 自定义别名HostName hostname # 服务器地址Port port # 远程 ssh 服务的端口号，默认为22User user # 用户名IdentityFile ~/.ssh/id_rsa # 本地公钥文件位置 登录效果： 针对第二步中上传密钥的操作，还可以使用此命令：$ cat ~/.ssh/id_rsa.pub | ssh username@hostname &quot;mkdir ~/.ssh; cat &gt;&gt; ~/.ssh/authorized_keys&quot; 附：配置 github 账号时也需要用到生成密钥的操作，可以参考上面的 ssh-keygen 命令]]></content>
      <categories>
        <category>Admin</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Server</tag>
        <tag>Admin</tag>
        <tag>Tools</tag>
        <tag>Networking</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL Server 5.7 修改 root 密码]]></title>
    <url>%2F2018%2F03%2F09%2FMysql-change-root-password%2F</url>
    <content type="text"><![CDATA[通常安装 MySQL Server 时，如使用包管理器（比如 ubuntu 的 apt-get），可在安装过程中设置 MySQL 的 root 密码。装好后使用 mysql -u root -p 命令登录并管理数据库。而使用其他方式安装的 MySQL 数据库（如 wamp ）默认设置了空的 root 密码。可在需要的时候进行修改。 一、SET PASSWORD使用空密码登录 root 用户并直接重新设置密码1234$ mysql -uroot -p...mysql&gt; SET PASSWORD FOR root@localhost=PASSWORD(&apos;your password&apos;);Query OK, 0 rows affected, 1 warning (0.02 sec) 二、UPDATE mysql使用空密码登录 root 用户并更新 mysql 数据库中的 user 表12345678$ mysql -uroot -p...mysql&gt; UPDATE mysql.user SET authentication_string=PASSWORD(&apos;your password&apos;) -&gt; WHERE user=&apos;root&apos; AND host=&apos;localhost&apos;;Query OK, 0 rows affected, 1 warning (0.00 sec)Rows matched: 1 Changed: 0 Warnings: 1mysql&gt; FLUSH PRIVILEGES;Query OK, 0 rows affected (0.01 sec) 三、创建数据库并授予权限最基本的方法为：使用 root 账号登录并创建数据库，再分配其权限给某个普通用户，再将该数据库与某个网络应用绑定。CREATE DATABASE db_nameGRANT privileges ON db_name.tables TO user@domains IDENTIFIED BY &#39;user_pass&#39;ALL 指代该数据库的所有权限，‘%’ 表示允许该用户从任意主机登录（可修改为指定 IP 地址，默认是 localhost）。starky.* 表示该数据库中的所有表格 附：ubuntu 16.04 取消 MySQL Server 的默认自启动$ sudo systemctl disable mysql取消 mysql 开机自启动$ sudo systemctl start mysql 启动 mysql 服务]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Admin</tag>
        <tag>Database</tag>
        <tag>Mysql</tag>
        <tag>Security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则表达式学习笔记]]></title>
    <url>%2F2018%2F02%2F25%2Flearn-regex%2F</url>
    <content type="text"><![CDATA[正则表达式（regular expression）用来定义一种 模式，相关的 Linux 工具（如 sed、gawk ）以及 Perl 等编程语言可以通过该模式对文本内容进行匹配，再进行替换等操作。正则表达式并非只有一种实现，在 Linux 环境中，不同的应用程序往往使用不同类型的正则表达式。最常见的两种有基本正则表达式（BRE）引擎和扩展正则表达式（ERE）引擎。大部分 Linux 工具至少遵循 BRE 对规则的定义，编程语言多使用 ERE 引擎。其中 gawk 就使用了 ERE 引擎。这里只介绍一些最常见的正则表达式。 普通文本普通字符包括没有显式指定为元字符的所有可打印和不可打印字符。这包括所有大写和小写字母、数字、标点符号和一些其他符号。正则表达式在匹配文本时，不管其定义的模式（区分大小写）出现在文本的什么位置或者出现几次，只要文本中包含此模式，该文本就会传递给相应的 Linux 工具做进一步的处理。在 sed 和 gawk 等工具中，模式的定义包含在两个 ‘ / ‘ 中，下面的 sed -n &#39;/模式/p&#39;命令类似于 Linux 中的 grep ，对符合正则表达式模式的文本进行打印输出。123456789101112$ echo &quot;This is a test&quot; | sed -n &apos;/test/p&apos; This is a test$ echo &quot;This is a test&quot; | sed -n &apos;/trial/p&apos;$$ sed -n &apos;/ /p&apos; data1.txtThis is a normal line of text.This is a line with two spaces.This is a line with a TAB.$ sed -n &apos;/ /p&apos; data1.txtThis is a line with two spaces.$ gawk &apos;/\t/&#123;print $0&#125;&apos; data1.txtThis is a line with a TAB. 上面的例子中涉及到多个空格的匹配，同时非打印字符如制表符（\t）、换行符（\n）等定义在 ERE 中，所以 sed 命令不再支持，例子中使用的是 gawk 。 特殊字符特殊字符包含以下几种：.*[]^${}\+?|()，它们在正则表达式中有着特殊的含义，如 ‘ . ‘ 匹配任何单字符。而对于特殊符号自身的匹配则需要进行转义（在该字符前加上 ‘ \ ‘ ），即匹配 ‘ . ‘ 需使用 ‘ \. ‘ 。 特殊字符的描述如下表所示： 特殊字符 描述 $ 匹配输入字符串的结尾位置 ( ) 标记一个子表达式的开始和结束位置。子表达式可以获取供以后使用 * 匹配前面的子表达式零次或多次 + 匹配前面的子表达式一次或多次 . 匹配除换行符 \n 之外的任何单字符 [ 标记一个中括号表达式的开始 ? 匹配前面的子表达式零次或一次，或指明一个非贪婪限定符 ^ 匹配输入字符串的开始位置。在方括号中使用时，表示不接受该字符集合 { 标记限定符表达式的开始 管道符 指明两项之间的一个选择 123456789$ cat data2.txtThe cost is $4.003 / 2$ sed -n &apos;/\$/p&apos; data2.txtThe cost is $4.00$ sed -n &apos;/\//p&apos; data2.txt3 / 2$ sed -n &apos;///p&apos; data2.txtsed: 1: &quot;///p&quot;: invalid command code / 1. 定位符定位符用来描述字符串或单词的边界，^ 和 $ 分别指定字符串的开始与结束位置，\b 描述单词的前或后边界，\B 表示非单词边界。当 ^ 并非位于模式开头时，仍当普通字符看待。123456789101112131415161718$ echo &quot;The book store&quot; | sed -n &apos;/^book/p&apos; $$ echo &quot;books are great&quot; | sed -n &apos;/^book/p&apos; Books are great$ echo &quot;This is a good book&quot; | sed -n &apos;/book$/p&apos;This is a good book$ echo &quot;This book is good&quot; | sed -n &apos;/book$/p&apos; $$ echo &quot;This ^ is a test&quot; | sed -n &apos;/s ^/p&apos; This ^ is a test&gt;&gt;&gt; import re&gt;&gt;&gt; re.findall(r&apos;\bbook&apos;,&apos;The book store&apos;)[&apos;book&apos;]&gt;&gt;&gt; re.findall(r&apos;\bbook&apos;,&apos;Thebook store&apos;)[]&gt;&gt;&gt; re.findall(r&apos;book\b&apos;,&apos;Thebook store&apos;)[&apos;book&apos;] \b 和 \B 属于 ERE，上例中使用了 Python 的 re 模块（注意空格如何影响输出） 组合定位符1234567$ cat data4this is a test of using both anchors I said this is a testthis is a testI&apos;m sure this is a test.$ sed -n &apos;/^this is a test$/p&apos; data4 this is a test 过滤空行1234567$ cat data5This is one test line.This is another test line. $ sed &apos;/^$/d&apos; data5This is one test line. This is another test line. 2. ‘ . ‘ 符号‘ . ‘ 匹配除 \n 以外的任何单字符，包括空格。所以 /.at/ 匹配 ‘cat’ 和行中间的 ‘at’ （实际为 ‘ at’ ），却不匹配行首的 ‘at’ 。123456&gt;&gt;&gt; print(text)The cat is sleeping.This test is at line two.at ten o&apos;clock we&apos;ll go home.&gt;&gt;&gt; re.findall(&apos;.at&apos;,text)[&apos;cat&apos;, &apos; at&apos;] 3. 字符集合包裹在一对中括号内的多个字符和数字构成一个字符集合，用来限制该位置只匹配集合中出现的字符。如 /[AaEeIiOoUu]/ 可以匹配所有元音字母1234$ echo &quot;Yes&quot; | sed -n &apos;/[Yy]es/p&apos; Yes$ echo &quot;yes&quot; | sed -n &apos;/[Yy]es/p&apos; yes 字符范围用连字号可以表示一个字符的范围 模式 含义 [a-z] 匹配所有的小写字母 [A-Z] 匹配所有的大写字母 [a-zA-Z] 匹配所有的字母 [0-9] 匹配所有的数字 [0-9\.\-] 匹配所有的数字、小数点和连字符 当在一组方括号里使用 ^ 时，它表示”非”或”排除”的意思，常常用来剔除某个字符。如 [^a-z] 匹配除了小写字母以外的所有字符 此外，还有一些特殊的字符集合。 模式 含义 [[:alpha:]] 匹配所有字母 [[:digit:]] 匹配所有数字 [[:alnum:]] 匹配所有字母和数字 [[:blank:]] 匹配所有空格和 Tab 字符 [[:space:]] 匹配所有空白字符：Space, Tab, NL, FF, VT, CR [[:upper:]] 匹配所有大写字母 [[:lower:]] 匹配所有小写字母 [[:print:]] 匹配所有可打印字符 [[:punct:]] 匹配所有标点符号 [[:xdigit:]] 匹配所有16进制的数字，相当于[0-9a-fA-F] 4. ‘ * ‘ 符号‘ * ‘ 表示匹配前面的字符或子表达式零次或多次12345678$ echo &quot;ik&quot; | sed -n &apos;/ie*k/p&apos; ik$ echo &quot;iek&quot; | sed -n &apos;/ie*k/p&apos; iek$ echo &quot;ieek&quot; | sed -n &apos;/ie*k/p&apos; ieek$ echo &quot;ieeek&quot; | sed -n &apos;/ie*k/p&apos; ieeek ‘ * ‘ 号还可以应用在字符集合上12345678910$ echo &quot;bt&quot; | sed -n &apos;/b[ae]*t/p&apos; bt$ echo &quot;bat&quot; | sed -n &apos;/b[ae]*t/p&apos; bat$ echo &quot;bet&quot; | sed -n &apos;/b[ae]*t/p&apos; bet$ echo &quot;baaeeaeeat&quot; | sed -n &apos;/b[ae]*t/p&apos; baaeeaeeat$ echo &quot;baakeeet&quot; | sed -n &apos;/b[ae]*t/p&apos; $ 5. ‘ ? ‘ 和 ‘ + ‘ 符号‘ ? ‘ 表示匹配前面的字符或子表达式零次或一次123456$ echo &quot;bt&quot; | gawk &apos;/be?t/&#123;print $0&#125;&apos; bt$ echo &quot;bet&quot; | gawk &apos;/be?t/&#123;print $0&#125;&apos; bet$ echo &quot;beet&quot; | gawk &apos;/be?t/&#123;print $0&#125;&apos; $ ‘ + ‘ 表示匹配前面的字符或子表达式一次或多次123456$ echo &quot;beet&quot; | gawk &apos;/be+t/&#123;print $0&#125;&apos; beet$ echo &quot;bet&quot; | gawk &apos;/be+t/&#123;print $0&#125;&apos; bet$ echo &quot;bt&quot; | gawk &apos;/be+t/&#123;print $0&#125;&apos; $ 6. 限定符限定符用来指定正则表达式的一个给定组件必须要出现多少次才能满足匹配。有 或 + 或 ? 或 {n} 或 {n,} 或 {n,m} 共6种。前三种前面已经讲到，除 外其他5种都属于 ERE 。 模式 含义 {n} n 是一个非负整数。匹配确定的 n 次。例如，/o{2}/ 不能匹配 “Bob” 中的 ‘o’，但是能匹配 “food” 中的两个 ‘o’。 {n,} n 是一个非负整数。至少匹配n 次。例如，/o{2,}/ 不能匹配 “Bob” 中的 ‘o’，但能匹配 “foooood” 中的所有 ‘o’。/o{1,}/ 等价于 /o+/ 。/o{0,}/ 则等价于 /o*/ 。 {n,m} m 和 n 均为非负整数，其中 n &lt;= m 。最少匹配 n 次且最多匹配 m 次。例如，/o{1,3}/ 将匹配 “fooooood” 中的前三个 ‘o’ 。/o{0,1}/ 等价于 /o?/ 。 12345678$ echo &quot;bt&quot; | gawk --re-interval &apos;/be&#123;1,2&#125;t/&#123;print $0&#125;&apos; $$ echo &quot;bet&quot; | gawk --re-interval &apos;/be&#123;1,2&#125;t/&#123;print $0&#125;&apos; bet$ echo &quot;beet&quot; | gawk --re-interval &apos;/be&#123;1,2&#125;t/&#123;print $0&#125;&apos; beet$ echo &quot;beeet&quot; | gawk --re-interval &apos;/be&#123;1,2&#125;t/&#123;print $0&#125;&apos; $ /[ae]{1,2}/ 匹配 ‘a’ , ‘e’ , ‘aa’ , ‘ae’ , ‘ee’ 。 * 和 + 限定符都是贪婪的，因为它们会尽可能多的匹配文字，只有在它们的后面加上一个 ? 就可以实现非贪婪或最小匹配。如匹配 HTML 文档里的标签：12345&gt;&gt;&gt; text=&quot;&lt;h1&gt;Head Line&lt;/h1&gt;&quot;&gt;&gt;&gt; re.findall(r&apos;&lt;.*&gt;&apos;,text)[&apos;&lt;h1&gt;Head Line&lt;/h1&gt;&apos;]&gt;&gt;&gt; re.findall(r&apos;&lt;.*?&gt;&apos;,text)[&apos;&lt;h1&gt;&apos;, &apos;&lt;/h1&gt;&apos;] 7. ‘ | ‘ 符号管道（’ | ‘）符号用来定义两个或多个模式，且彼此之间是逻辑或的关系。123456$ echo &quot;The cat is asleep&quot; | gawk &apos;/cat|dog/&#123;print $0&#125;&apos; The cat is asleep$ echo &quot;The dog is asleep&quot; | gawk &apos;/cat|dog/&#123;print $0&#125;&apos; The dog is asleep$ echo &quot;He has a hat.&quot; | gawk &apos;/[ch]at|dog/&#123;print $0&#125;&apos; He has a hat. 8. 分组小括号用于将正则表达式的模式进行分组1234$ echo &quot;Sat&quot; | gawk &apos;/Sat(urday)?/&#123;print $0&#125;&apos;Sat$ echo &quot;Saturday&quot; | gawk &apos;/Sat(urday)?/&#123;print $0&#125;&apos; Saturday 上例中的 /Sat(urday)?/ 用于匹配 ‘Sat’ 或者 ‘Saturday’ ，’urday’ 加上小括号后被当成一个整体，再附上 ? 符号表示该组合出现零次或一次。 附录：运算符优先级 运算符（由高到低） 描述 反斜杠（\） 转义符 (), (?:), (?=), [] 圆括号和方括号 *, +, ?, {n}, {n,}, {n,m} 限定符 ^, $, 任何元字符、任何字符 定位点和序列（即：位置和顺序） 替换运算符（管道符） 替换，”或”操作 字符具有高于替换运算符（|）的优先级，使得 /m|food/ 匹配 ‘m’ 或 ‘food’ 。若要匹配 ‘mood’ 或 ‘food’ ，可使用括号创建子表达式：/(m|f)ood/ 。 参考资料：Linux Command Line and Shell Scripting Bible 3rd Edition正则表达式-菜鸟教程]]></content>
      <categories>
        <category>Programming</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Admin</tag>
        <tag>Tools</tag>
        <tag>Trick</tag>
        <tag>Programming</tag>
        <tag>regex</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[版本管理工具（nvm、virtualenv(wrapper)-和-rbenv-的安装与使用）]]></title>
    <url>%2F2018%2F02%2F02%2Fnvm-virtualenv-rbenv%2F</url>
    <content type="text"><![CDATA[我是个懒惰的人，对于编程着实懂得不多，能clone下来的绝对不自己写。。。但是像 nodejs 和 Python 这俩哥们，本来版本就不少，再加上众多的软件包依赖，常常clone下来了运行还报错。可想而知，配置好相互独立的运行环境（避免软件包版本冲突）是多么必要的一件事。 一、 nvmnvm 是一个跨平台的 Node 版本管理工具。Windows系统下可安装 nvm-windows，有编译好的exe安装包文件提供下载，安装好后可以直接在命令行使用。 Linux 和 Mac 可以使用网站上提供的安装脚本：使用cURL：curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.8/install.sh | bash使用wget：wget -qO- https://raw.githubusercontent.com/creationix/nvm/v0.33.8/install.sh | bash 如安装出现问题，请确保以下内容12export NVM_DIR=&quot;$HOME/.nvm&quot;[ -s &quot;$NVM_DIR/nvm.sh&quot; ] &amp;&amp; \. &quot;$NVM_DIR/nvm.sh&quot; 已添加到你的命令行配置文件（~/.bash_profile, ~/.zshrc, ~/.profile, 或 ~/.bashrc）中。具体可参考 nvm 的README。 使用技巧 nvm --help 获取该命令的帮助信息 nvm install [-s] &lt;version&gt; 下载安装指定版本的Node，[-s] 表示从源码安装如：nvm install 8.9 安装最新8.9.x稳定版本的Nodejs nvm ls-remote 查看可供下载安装的所有版本 nvm use &lt;version&gt; 使用指定版本的 Node（即切换当前运行环境为该版本的 Node） nvm run &lt;version&gt; [&lt;args&gt;] 运行指定版本的 Node 程序如：nvm run 8.9.4 app.js 用 8.9.4 版本的 nodejs 执行 app.js nvm which &lt;version&gt; 获取该版本Node可执行文件的路径 nvm ls 列出已安装的版本 nvm alias default &lt;version&gt; 设置进入任何新终端时的默认 Node 版本 nvm current 查看当前配置下的 Node 版本 PS： export NVM_NODEJS_ORG_MIRROR=https://npm.taobao.org/mirrors/node 用于将安装源改为国内镜像 二、virtualenv 和 virtualenvwrapper1.virtualenvvirtualenv 是用来创建独立的 Python 运行环境的工具。可以直接通过 Python 的 pip 命令安装，也可以使用系统的软件包管理器（如 Ubuntu 的 apt-get）。 安装：[sudo] pip install virtualenv 加上 sudo 表示全局安装基本用法：virtualenv -p PYTHON_EXE DEST_DIR -p PYTHON_EXE 指定创建虚拟环境时使用的 Python 可执行程序的路径，默认是用来安装 virtualenv 的 Python。 DEST_DIR 表示将虚拟环境安装至目标文件夹 如：virtualenv -p python3 web表示使用系统 PATH 变量指定的 Python3 程序，将虚拟环境安装至当前目录下的 web 目录。source web/bin/activate命令用于激活此虚拟环境（Windows系统此命令为：web\Scripts\activate）。待操作完成需要退出时，输入deactivate即可。 2.virtualenvwrappervirtualenvwrapper 是针对 virtualenv 的一组扩展工具。Windows 系统环境下可安装 virtualenvwrapper-win 。安装：Linux or Mac：pip install virtualenvwrapperWindows：pip install virtualenvwrapper-win 完成后将以下内容添加到命令行配置文件中123export WORKON_HOME=$HOME/.virtualenvsexport PROJECT_HOME=$HOME/Develsource /usr/local/bin/virtualenvwrapper.sh WORKON_HOME 定义了在什么位置创建虚拟环境PROJECT_HOME 定义了在什么位置创建 Python 代码项目 PS：如果安装 virtualenvwrapper 时使用的 python 并非 PATH 环境变量中定义的默认值，可以额外添加一行export VIRTUALENVWRAPPER_PYTHON = &lt;PYTHON_EXE&gt; 使用技巧 mkvirtualenv ：在 WORKON_HOME 定义的路径下创建新的运行环境语法：mkvirtualenv [-a project_path] [-i package] [-r requirements_file] [virtualenv options] ENVNAME例：mkvirtualenv -i flask -p /usr/local/bin/python3 env_flask rmvirtualenv ：删除 WORKON_HOME 里已安装的某个运行环境语法：rmvirtualenv ENVNAME workon :列出或切换虚拟运行环境 mkproject ：在 WORK_ON 目录里创建虚拟环境的同时在 PROJECT_HOME 目录下创建项目文件夹其他命令及用法可参考 virtualenvwrapper 文档 三、rbenvrbenv 是 ruby 语言的版本管理工具。MacOS 系统可直接使用 brew 命令安装：brew install rbenv Linux系统可使用 git 命令手动安装。在命令行界面依此输入以下命令：1234$ git clone https://github.com/rbenv/rbenv.git ~/.rbenv$ echo &apos;export PATH=&quot;$HOME/.rbenv/bin:$PATH&quot;&apos; &gt;&gt; ~/.bashrc$ echo &apos;eval &quot;$(rbenv init -)&quot;&apos; &gt;&gt; ~/.bashrc$ source ~/.bashrc 以上命令将 rbenv 的项目文件 clone 到本地同时更新 PATH 环境变量。之后输入 如显示版本信息和帮助内容，则安装成功。123此时的 rbenv 命令是没有 install 选项的，如需要使用 rbenv install 命令下载并编译安装其他版本的 ruby，需要再安装用来编译 Ruby 源代码的工具 [ruby-build](https://github.com/rbenv/ruby-build) 。因为是编译安装 ruby，需要先安装好编译用到的依赖库，然后将 ruby-build 项目文件 clone 到本地即可： $ sudo apt-get install autoconf bison build-essential libssl-dev libyaml-dev libreadline6 libreadline6-dev zlib1g zlib1g-dev$ git clone https://github.com/rbenv/ruby-build.git ~/.rbenv/plugins/ruby-build` 命令简介 rbenv install -l 列出所有可供安装的 ruby 版本 rbenv install &lt;version&gt; 编译安装指定版本的 ruby rbenv versions 查看已安装的所有 ruby 版本 rbenv global &lt;version&gt; 设置全局版本 rbenv local &lt;version&gt; 设置本地版本（针对特定的项目，会在当前目录下创建 .rbenv-version 文件覆盖全局版本配置） rbenv shell &lt;version&gt; 设置当前终端版本。优先级最高。 参考文章：How To Install Ruby on Rails with rbenv on Ubuntu 16.04]]></content>
      <categories>
        <category>Programming</category>
      </categories>
      <tags>
        <tag>Admin</tag>
        <tag>Tools</tag>
        <tag>Python</tag>
        <tag>Programming</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cURL-基本使用方法介绍]]></title>
    <url>%2F2018%2F01%2F11%2FcURL-Manual%2F</url>
    <content type="text"><![CDATA[cURL是一个利用URL语法在命令行下工作的文件传输工具，支持文件上传和下载，是综合传输工具。其源代码可在 Github 上阅读和获取（包括libcurl），这里只简单地介绍下常见的使用方法。 一、获取文件语法：curl -option URL不加任何选项时，默认将结果打印到标准输出（STDOUT）-o filename 选项：将获取到的内容以指定文件名（filename）保存至本地-O 选项：使用URL中的文件名将其保存至本地–progress 选项表示仅用『#』和百分比表示下载进度，若下载中断，可以添加-C - 选项断点续传–limit-rate 选项对下载文件时的速度进行限制 二、获取响应头信息-i 选项：输出时响应头和文档内容都显示-I 选项：只显示响应头信息不显示文档内容 可以看出，默认情况下 cURL 不会发送 HTTP Location headers（重定向），即遇到需要跳转的网页不自动跳转。curl www.jianshu.com会得到 『301 Moved Permanently』，而不会跳转至 https://www.jianshu.com。 可以通过添加 -L 选项进行重定向。（图中的 -s 选项表示静默模式） 三、自定义User-AgentUser-Agent 是浏览器的身份标识，远程服务器通过它可以获取客户端使用的操作系统、浏览器版本等信息。（写过爬虫的都知道……）-A 选项可以自定义 User-Agent 信息，默认是 curl/版本号访问上图中的网站时会返回浏览者的 User-Agent 信息–header 选项可以自定义其他请求头信息如curl --header &quot;Content-Type:application/json&quot; URL 关于HTTP消息头（包括请求头和响应头）的简介，可参考这篇文章https://itbilu.com/other/relate/EJ3fKUwUx.html 四、cookie信息Cookie 是访问的远程站点存储在客户端计算机上的一段信息，通常储存着用户对某个站点的设置，比如偏好的语言或地理位置，也包括个人身份识别信息。–cookie 选项可以附加上 cookie 信息-c cookie-file 可以保存服务器返回的 cookie 到文件-b cookie-file 可以使用该文件作为 cookie 信息 五、HTTP动词默认无选项的 curl 命令即使用了 GET（获取） 动词，另外还有 POST（新建），PUT（更新），DELETE（删除）等方法。通过这些动词可以很方便的访问 Restful 架构的 API。命令格式为：curl -d data -X method URL-d 选项指定要传输的数据，-X 选项指定使用的方法。只附加 -d 选项则默认使用 POST 方法，可以通过此命令完成简单的表单验证操作 附录：参考文章：Using curl to automate HTTP jobs]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Admin</tag>
        <tag>Tools</tag>
        <tag>Trick</tag>
        <tag>Networking</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nmap-网络扫描实战（2）--端口扫描]]></title>
    <url>%2F2017%2F11%2F29%2Fscan-network-using-Nmap-2%2F</url>
    <content type="text"><![CDATA[开放的端口意味着远程主机上正在运行着联网的服务，而某些难以察觉的编程错误或实现缺陷会使这些服务容易受到攻击，有时甚至成为侵入整个系统的突破口。这些网络服务往往使用 TCP 或 UDP 作为传输协议。TCP（Transmission Control Protocol）是一种连接导向的协议，相对更常用。而 UDP（User Datagram Protocol）是一种非连接导向的协议，多用于对传输速度的要求高于数据完整性的服务。而通过检测端口及服务来入侵远程系统的渗透测试方法即为端口扫描。 一、TCP 端口扫描技术1. Connect 扫描Connect 扫描对每一个端口都尝试建立完整的 TCP 连接（三步握手），如果连接创建成功，则该端口被判定为开放的。 2. Stealth 扫描Stealth 扫描也常被称作 SYN 扫描或半开放扫描。该技术向每一个被扫描的端口发送一个单独的 SYN 包，如果收到 SYN+ACK 回复，则该端口被判定为开放的。这之后不会再遵照三步握手的程序向目标主机发送 ACK 包，所以并没有开启完整的TCP连接，而目标主机的日志系统一般也不会记录这类扫描的痕迹。 3. Zombie 扫描『僵尸』扫描背后的实现原理比较负责。整个过程如下图所示：简单来说， 先找一个远程系统作为『僵尸』主机，该主机与网络中的其他主机之间不存在活跃的网络连接。 向『僵尸』主机发送一个 SYN+ACK 包并记录下该主机初始的 IPID 值。 伪装成『僵尸』主机（将报文中的源IP地址替换为『僵尸』主机的）向目标主机发送一个 SYN 数据包。 如果目标端口是开放的，则目标主机会向『僵尸』主机返回一个 SYN+ACK 包，而『僵尸』主机（觉得很懵逼。。。）则返回一个 RST 包并把自己的 IPID 值增加 1。如果目标端口是关闭的，则目标主机会向『僵尸』主机返回 RST 响应，而收到 RST 的『僵尸』主机（依然不清楚发生了什么）则不做任何动作，IPID 值也不会增加。 向『僵尸』主机发送另一个 SYN+ACK 包，从返回的 RST 包中获取最终的 IPID 值。如果该值比第 2 步时增加了 1，则目标端口是关闭的。如果最终增加了 2，则目标端口是开放的。 一点儿也不简单哈。。。 命令示例在特权用户下执行时，nmap 默认采用 SYN 扫描方式（即不开启完整的TCP连接）以节省扫描时间。同时这种扫描行为也不易被目标主机的日志系统记录到。而普通用户不具有修改原始数据包的权限，所以只能通过 connect系统调用 打开完整的 TCP 连接以完成对远程系统的扫描。所以从效率和安全的角度出发，应优先选择 SYN 扫描而非 connect 扫描。具体可参考 nmap 官方文档——端口扫描技术12345$ sudo nmap 10.2.64.1 -p 80# 特权用户 SYN 扫描$ nmap 10.2.64.1 -p 80# 普通用户 connect 扫描 也可以显式地指定采用哪种扫描方式，-sT 表示 connect 扫描，-sS 表示 SYN 扫描。-p 选项用来指定扫描的端口号或端口范围（一共有65535个端口可供扫描，默认扫描1000个常用的端口）。如：12$ sudo nmap 10.2.64.1 -p 21,22,80,443$ sudo nmap 10.2.64.1 -p 20-25 从上述命令的输出结果中可以看出，该主机的 22,80 端口是开放的（很可能运行着ssh服务和http服务），21 和 443 端口是关闭的。 二、UDP 端口扫描技术UDP 扫描相对显得更有难度，同时也更乏味和耗时。其中一种方式依赖于ICMP端口不可达响应，即假设每一个被扫描的 UDP 端口在不开放时都会回复 ICMP 端口不可达的响应，而收不到该响应时则判定端口为开放的。但有时候被扫描主机不允许生成端口不可达响应，或该响应被限制在一定频率内，也可能是被主机的防火墙隔离。此种方法就会产生不准确的结果。另一种方式是通过发送服务相关的请求来探测远程主机上对应的服务。此种方法可信度更高，但同时消耗的时间也更多。open|filtered 表示该端口可能是开放的，也可能被防火墙屏蔽掉了。]]></content>
      <categories>
        <category>Pentest</category>
      </categories>
      <tags>
        <tag>Tools</tag>
        <tag>Security</tag>
        <tag>Networking</tag>
        <tag>Pentest</tag>
        <tag>Hacking</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[grep 命令使用技巧]]></title>
    <url>%2F2017%2F11%2F23%2Fgrep-Tricks%2F</url>
    <content type="text"><![CDATA[grep（globally search a regular expression and print）是一个强大的文本搜索工具。常常出现在管道符（|）身后，对大段的文本输出进行过滤，打印出与特定模式相匹配的内容。 1. 基本用法$ grep pattern filename或 $ cat filename | grep pattern或 $ grep pattern file1 file2 …（搜索多个文件） 示例文件（numbers.txt）：123456789101 1 1 1 1 12 2 2 2 2 23 3 3 3 3 34 4 4 4 4 45 5 5 5 5 5six six sixseven seven seveneight eight eightnine nine nine10 10 10 10 命令输出： 2. -v（打印 不包含 匹配项的行）其中 -E 选项表示开启扩展正则表达式（grep -E 等同于 egrep）添加上 -v 选项后输出的是不匹配的内容 3. -o（只输出匹配项而不是默认的整行内容） 4. -c（统计包含匹配项的行数）如$ grep 1 numbers.txt输出为 2，（即第一行 1 1 1 1 1 1 1 和最后一行 10 10 10 10，计算的是行数） 5. -n（打印输出时额外显示行号） 6. -i （搜索时忽略匹配模式中的大小写）grep 默认是大小写敏感的，加 -i 选项可以在匹配时不区分大小写。 7. -e（多个匹配模式）注意格式 8. 打印匹配文本之前或之后的内容-A n ：额外打印匹配文本之后n行内容-B n ：额外打印匹配文本之前n行内容-C n ：额外打印匹配文本前后n行内容 9. -l（搜索多个文件并查找匹配文本在哪些文件中）$ grep -l pattern file1 file2 …该命令的输出为包含 pattern 的文件名同时可以使用 -r 选项对目录进行递归搜索$ grep -r pattern dir]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Admin</tag>
        <tag>Tools</tag>
        <tag>Trick</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sed 命令详解]]></title>
    <url>%2F2017%2F11%2F09%2Fsed-manual%2F</url>
    <content type="text"><![CDATA[sed 即 stream editor，一个简单而强大的文本解析转换工具，1973-1974年期间由贝尔实验室的 Lee E. McMahon 开发，能够完美的配合正则表达式使用。处理文本时，当前处理的行会先存储在临时缓冲区中，称为模式空间（pattern space），操作完成后再把缓冲区的内容送往屏幕。接着处理下一行，直到文件末尾。文件内容并没有改变，除非使用重定向存储输出。sed 主要用来自动编辑一个或多个文件，简化对文件的反复操作，编写转换程序等。 1. 使用 s 命令替换基本使用sed 默认情况下通过 STDIN 输入流读取数据，可以利用管道符（|）进行重定向。如下：12$ echo &quot;This is a test&quot; | sed &apos;s/test/big test/&apos;This is a big test s 替换命令的格式为：s/pattern/replacement/flags ，如下：1234567891011$ cat test.txtThe quick brown fox jumps over the lazy dog.The quick brown fox jumps over the lazy dog.The quick brown fox jumps over the lazy dog.The quick brown fox jumps over the lazy dog.$$ sed &apos;s/dog/cat/&apos; test.txtThe quick brown fox jumps over the lazy cat.The quick brown fox jumps over the lazy cat.The quick brown fox jumps over the lazy cat.The quick brown fox jumps over the lazy cat. 使用 s 命令进行替换时，默认只替换每行中的第一个匹配。全局替换需增加 g 选项。12345$ sed &apos;s/o/O/g&apos; test.txtThe quick brOwn fOx jumps Over the lazy dOg.The quick brOwn fOx jumps Over the lazy dOg.The quick brOwn fOx jumps Over the lazy dOg.The quick brOwn fOx jumps Over the lazy dOg. sed 默认只将处理后的内容输出，而不对原文件的内容做任何改动。如需写入文件，可使用重定向：$ sed &#39;s/dog/cat/&#39; test.txt &gt; test2.txt或通过 -i 选项直接修改文件内容：$ sed -i &#39;s/dog/cat/&#39; test.txt address如果需要将命令应用到特定的一行或多行内容，可以使用 line addressing。格式为 [address[,address]][!]command。address 可以是数字或模式，也可以通过逗号分隔两个 address 表示一个区间范围。如只将第2行中的 dog 替换为 cat：12345$ sed &apos;2s/dog/cat/&apos; test.txtThe quick brown fox jumps over the lazy dog.The quick brown fox jumps over the lazy cat.The quick brown fox jumps over the lazy dog.The quick brown fox jumps over the lazy dog. 或者$ sed &#39;1,3s/dog/cat/&#39; test.txt，替换1-3行的内容。$ sed &#39;2,$s/dog/cat/&#39; test.txt，替换第2行到最后一行的内容。 ! 表示完成匹配后是否在该行执行替换命令。加上 ! 表示不执行。如下：1234567891011121314151617$ cat lines.txtThis is line oneThis is line twoThis is line threeThis is line four$$ sed &apos;/one/,2s/line/LINE/&apos; lines.txtThis is LINE oneThis is LINE twoThis is line threeThis is line four$$ sed &apos;/one/,2!s/line/LINE/&apos; lines.txtThis is line oneThis is line twoThis is LINE threeThis is LINE four 替换选项sed 的替换命令除了可以附加 g 选项（全局替换）外，还有更多选项适用于不同的情形。 数字。表示只替换每行中的第 n 个匹配项，如：12345$ sed &apos;s/o/O/2&apos; test.txtThe quick brown fOx jumps over the lazy dog.The quick brown fOx jumps over the lazy dog.The quick brown fOx jumps over the lazy dog.The quick brown fOx jumps over the lazy dog. 或$ sed &#39;s/o/O/2g&#39; test.txt 替换每行中从第二个开始的所有匹配项（即替换每行中从第二个 o 开始直到该行行尾的所有 o 字符） p，表示打印处理前的原始内容，结合上 -n 选项（不打印输出）则可以只输出处理过的内容。 123456789$ sed &apos;s/three/3/p&apos; lines.txtThis is line oneThis is line twoThis is line 3This is line 3This is line four$$ sed -n &apos;s/three/3/p&apos; lines.txtThis is line 3 w，将处理过的内容写入文件 1234$ sed &apos;s/three/3/w line3.txt&apos; lines.txt$$ cat line3.txtThis is line 3 sed 命令选项 删除：d$ sed &#39;2,$d&#39; lines.txt 删除 lines.txt 中第2行到最后一行的内容。$ sed &#39;/two/d&#39; lines.txt 删除 lines.txt 中包含 two 的行。 追加（行下）：a 1234567$ sed &apos;/two/a\&gt; This is a line behind line 2&apos; lines.txtThis is line oneThis is line twoThis is a line behind line 2This is line threeThis is line four 插入（行上）：i 12$ sed &apos;2i\&gt; This is a line above line 2&apos; lines.txt 在第2行以上插入内容。 修改：c12$ sed &apos;/two/c\&gt; Line 2&apos; lines.txt 将包含 two 的行修改为 Line 2（整行内容替换为 Line 2）。 字符转换：y格式为：[address]y/inchars/outchars/输入文件中所有包含在 inchars 中的字符都将替换为 outchars 中对应的字符。1234567891011$ cat line_number.txtThis is line 1.This is line 2.This is line 3.This is another line 1.$$ sed &apos;y/123/456/&apos; line_number.txtThis is line 4.This is line 5.This is line 6.This is another line 4. 其他用法 打印输出sed 的 p 命令可以达到类似 grep 的效果，结合上 address 功能还可以完成更复杂的筛选打印操作。 12345678910111213$ sed -n &apos;p&apos; lines.txtThis is line oneThis is line twoThis is line threeThis is line four$$ sed -n &apos;2,3p&apos; lines.txtThis is line twoThis is line three$$sed -n &apos;/two/,/three/p&apos; lines.txtThis is line twoThis is line three 多个匹配可以通过 -e 选项实现多个匹配的替换 12345$ sed -e &apos;s/fox/kangaroo/;s/dog/cat/&apos; test.txtThe quick brown kangaroo jumps over the lazy cat.The quick brown kangaroo jumps over the lazy cat.The quick brown kangaroo jumps over the lazy cat.The quick brown kangaroo jumps over the lazy cat. 也可以这样：12345678$ sed -e &apos;&gt; s/brown/red/&gt; s/fox/kangaroo/&gt; s/dog/cat/&apos; test.txtThe quick red kangaroo jumps over the lazy cat.The quick red kangaroo jumps over the lazy cat.The quick red kangaroo jumps over the lazy cat.The quick red kangaroo jumps over the lazy cat. 从脚本文件中读取命令 12345678910$ cat script.seds/brown/red/s/fox/kangaroo/s/dog/cat$$ sed -f script.sed test.txtThe quick red kangaroo jumps over the lazy cat.The quick red kangaroo jumps over the lazy cat.The quick red kangaroo jumps over the lazy cat.The quick red kangaroo jumps over the lazy cat. 可以使用 &amp; 变量表示前面的匹配项，如： 12345$ sed &apos;s/fox/&amp;es/&apos; test.txtThe quick brown foxes jumps over the lazy dog.The quick brown foxes jumps over the lazy dog.The quick brown foxes jumps over the lazy dog.The quick brown foxes jumps over the lazy dog. 参考书籍和文章：Linux Command Line and Shell Scripting Bible, 3rd EditionSED 简明教程 by 陈皓Linux 命令大全 / SED 命令]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Admin</tag>
        <tag>Tools</tag>
        <tag>Trick</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux-系统管理（1）----获取硬件信息]]></title>
    <url>%2F2017%2F11%2F02%2FLinux-get-System-Infomation%2F</url>
    <content type="text"><![CDATA[当系统启动时，Linux 内核会自动检测硬件设备并加载相应的驱动程序。但这些硬件检测信息在启动时很快就滚动消失，所以需要在进入系统后再次显示这类信息，以发现潜在的问题。 demsgdmesg 命令可以列出系统启动时硬件检测和驱动加载的情况，以及后续由内核生成的其他信息。dmesg 命令的输出示例：从输出信息中可以找到 Linux 内核版本、内核命令行选项以及连接到此计算机的硬件设备，如串口、鼠标接口、CD驱动器、网卡和并行端口等。 tips:dmesg 命令的输出确实有点长，所以常通过管道符（|）将其导向 more 或 less 命令单页显示。或者输送给 head、tail、grep等文字处理工具。如：# dmesg | head -20 只输出前 20 行日志# dmesg | tail -20 只输出最后 20 行日志# dmesg | grep -i usb 只输出包含 “usb” 字符串的日志行（-i 选项表示忽略大小写）常用作筛选的字符串包括 usb、dma、tty、memory、eth、sda等，也可以多个关键字相组合。# dmesg | grep -E -i &quot;eth|sda&quot; 筛选包含字符串 “eth” 或 “sda” 的日志行 lspcilspci 命令可以列出系统中的 PCI 总线及其连接的设备。该命令的输出如下：输出信息中包括声音（Multimedia audio controller），USB设备（USB controller），视频输出（VGA compatible controller），有线网卡（Ethernet controller）和磁盘（SATA controller）等。如需获取更详尽的信息，还可以在该命令后增加一至多个 -v 选项（如 -vvv）。 lsusb如果只对USB设备感兴趣，可以通过 lsusb 命令来获知USB设备的情况（同样可以通过增加 -v 选项来获取更详细的输出）。以上面截图中第三行为例： Bus 002 指明设备连接到哪条总线 Device 003 表明这是连接到某条总线的第三台设备 ID 指设备 id Logitech, Inc. Unifying Receiver 表示生产商和设备名 tips：找出连接了多少 USB 设备：find /dev/bus 列出某台 USB 设备的详细信息，如：lsusb -D /dev/bus/usb/001/002以树层结构列出 USB 设备：lsusb -t其中 12M 和 480M 指 USB 类型的传输速率。 12M 意味着 USB1.0/1.1 的速率是12Mbit/s 480M 意味着 USB2.0 的速率是 480Mbit/s 5.0G 意味着 USB3.0 的速率是 5.0 Gbit/s lsblklsblk 命令用于列出所有可用块设备的信息，还能显示他们之间的依赖关系。块设备有硬盘，闪存盘，cd-ROM等等。 NAME ：块设备名。 MAJ:MIN ：主要和次要设备号。 RM ：设备是否属于可移动设备。如 sdb 的 RM 值为1，是可移动设备。 SIZE ：设备的容量大小信息。 RO ：设备是否为只读。 TYPE ：设备是磁盘还是磁盘上的一个分区。在本例中，sda 和 sdb 是磁盘，而 sr0 是只读存储（rom）。 MOUNTPOINT ：设备的挂载点。 lscpulscpu 命令可以获得 CPU 的详细信息，如CPU架构（如 i686 或 x86_64）、运算模式（32bit 或 64bit）、核心数、每颗核心的线程数、型号、主频等。 lsmod如果你新增加了硬件，却不能被系统自动识别。可能你需要手动地加载对应的内核模块。内核模块安装在 /lib/modules/ 的子目录下，该子目录的名字对应内核的版本。即 /lib/modules/4.10.0-19-generic 目录下包含了 4.10.0-19-generic 内核的驱动程序。lsmod 命令用于列出当前系统下已经载入的内核模块。获取已加载模块的信息，可以使用 modinfo 命令。另外，还可以使用 modprobe 命令加载模块，rmmod 命令移除模块。 参考书目和文章：Linux Bible，9th EditionLinux lsblk 命令详解Linux中显示系统中USB信息的lsusb命令]]></content>
      <categories>
        <category>Admin</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Admin</tag>
        <tag>System</tag>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nmap-网络扫描实战（1）--主机发现]]></title>
    <url>%2F2017%2F11%2F02%2Fscan-network-using-Nmap-1%2F</url>
    <content type="text"><![CDATA[主机发现指的是从网络中寻找活跃主机的过程。该过程的关注点不在于如何获取目标的详细信息，而是在尽量减少资源消耗的情况下，获得目标们在逻辑上的分布。 OSI 模型 OSI 模型（即 Open Systems Interconnection model 开放式系统互联通信参考模型），由国际标准化组织（ISO）提出，是一个试图使各种网络设备在世界范围内互联通信的标准框架。该模型将计算机网络体系结构划分为7层，如下图所示：本文涉及到的主机探测方法，主要利用了定义在 Layer 2，3 和 4 上的网络协议。 1. Layer 2（ARP） 优势 非常快速 高可信度 劣势 不能探测远程系统（ARP 属于不可路由协议） ARP（Address Resolution Protocol 地址解析协议）是通过解析网路层（Layer 3）地址来找寻数据链路层（Layer 2）地址的一个重要的网络传输协议，即将 Layer 3 中逻辑性的 IP 地址翻译成 Layer 2 中物理性的 MAC 地址。发起查询的主机先在本地网络中广播一条 ARP 请求，符合该查询的主机则直接返回一条包含其 MAC 地址的 ARP 回复，收到回复后的主机会更新保存在本地的 ARP 缓存并开启两者间的网络通信。该过程不使用任何形式的身份验证和授权。 命令示例# nmap -sn 10.1.87.0-255# nmap -sn 10.1.87.0/24# nmap -iL iplist.txt -sn -sn 选项同 -sP，即关闭默认的端口扫描，只执行 Ping 扫描，这在主机发现时可以节省很多时间。从表面上看，执行的 Ping 扫描属于 Layer 3 上的协议。这里 nmap 会根据提供的 IP 地址自动判定是否为本地子网，对本地子网发送 ARP 请求，对远程网络则执行 Ping 扫描。如下图（本地子网）： 输出内容包括活跃主机的 IP 地址、网络延迟、MAC 地址及对应的硬件厂商。WireShark 捕获到的流量信息： 当探测的 IP 地址不属于本地子网时，则执行 Ping 扫描（输出信息无 MAC 地址），输出如下： WireShark 捕获到的流量信息： 2. Layer 3（ICMP） 优势 可探测远程系统（可路由协议） 相对较快 劣势 比 ARP 慢 可能被防火墙拦截 Layer 3 上的 ICMP 探测是最为人熟知的扫描手段（ping 命令总用过的吧）。ICMP 代表 Internet Control Message Protocol（互联网控制消息协议），它的功能之一，就是通过向目标主机发送 ICMP echo 请求，看是否收到 echo 响应，来确定其是否处于活跃状态。如 Ping 命令的输出：返回结果中包括信号往返时间和(信息)包丢失情况的统计信息。 前面已经提到过，nmap 的 Ping 扫描可以根据 IP 地址自行在 ARP 和 ICMP 协议间切换，不需要额外的选项。 3. Layer 4（TCP） 优势 可探测远程系统 比 ICMP 更可靠 劣势 有时防火墙会导致异常结果 全局扫描会非常耗时 TCP 扫描的原理在于，一条单独的 TCP Finish(FIN) 包或者 Acknowledge(ACK) 包通常会触发远程主机的 Reset(RST) 响应，而发送至远程主机的 Synchronize(SYN) 包通常会触发 SYN+ACK 或者 RST 响应（取决于被扫描端口的开放情况）。重点在于，来自指定主机的任何响应都可以确定该主机处于存活状态。 当目标主机所有的 TCP 服务都被防火墙隔离时，UDP 扫描有时就显得极为有效。但有些 UDP 服务回复的是 ICMP 端口不可达响应，而这类响应会被高防护的防火墙阻止。另一些 UDP 服务则只对特定的请求作出响应，使得有效的 UDP 扫描需要针对不同的服务采用针对性的技术。 命令示例 UDP 扫描# nmap 10.1.87.0-255 -PU53 -sn TCP 扫描（发送 ACK 包）# nmap 10.1.87.0/24 -PA80 -sn 附：1. TCP &amp; UDP在 OSI 模型中，IP 协议位于网路层（Layer 3），它可以提供寻址、数据报路由及其他功能，将一台设备连接至另外一台设备。TCP 协议位于传输层（Layer 4），负责管理连接以及各设备间数据的稳定传输。 TCP 是一种连接导向（connection-oriented）的协议。在 TCP 传输数据之前，客户端和服务端之间需要通过一种三步握手的机制来创建连接。过程如下： 客户端通过向服务端发送一个包含 SYN（synchronize）标志的数据包来初始化连接，在 SYN 字段中包含了一个随机的初始序列号（ISN）。 接着服务端向客户端同样回复一个 SYN 包（其中有它自己的 ISN）。同时服务端发送一个 ACK（acknowledge）包来告诉客户端自己收到了前面的信息。该 ACK 报文中包含了客户端的 ISN+1 的值。 客户端发送一个 ACK 包（包含 服务端的 ISN+1）来告知服务端，自己已收到消息。此时，两者之间才开始交换数据。 当连接关闭时： 客户端发送一个包含 FIN（finish）标志的数据包。 服务端发送 ACK 包表示自己已收到。 当服务端准备好关闭时，它会发送一个 FIN 包。 客户端发送 ACK 包表示自己已收到。开启连接的过程可参考下图： TCP 是一种强调数据完整性的协议。通过上述机制，在传输过程中若有一个包丢失，TCP 会自动重新传输（直到接收者发出 ACK 包）。如果数据包到达时次序错误，TCP 会对它们进行重排，之后才交给应用程序。所以传输文件或者重要数据如 HTTP 和 FTP 都是用的 TCP 协议。 UDP 属于非连接导向（connectionless）的协议。在传输数据之前，他不需要先创建一个 UDP 连接。如果发生丢包，UDP 也不会重复发送（丢失包的重发根据情况由应用程序来完成）。所以像视频流等可以承受丢包损失的多媒体应用常通过 UDP 传输。常见的使用 UDP 的应用：DNS、DHCP、SNMP 等。 2. TCP表头格式 参考书籍及文章：Kali Linux Network Scanning Cookbook by Justin HutchensTCP 三向交握 (Three-way Handshake)]]></content>
      <categories>
        <category>Pentest</category>
      </categories>
      <tags>
        <tag>Tools</tag>
        <tag>Security</tag>
        <tag>Networking</tag>
        <tag>Pentest</tag>
        <tag>Hacking</tag>
        <tag>TCP/IP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ncat--网络工具箱里的『瑞士军刀』]]></title>
    <url>%2F2017%2F10%2F19%2FNcat-document%2F</url>
    <content type="text"><![CDATA[Ncat is a general-purpose command-line tool for reading, writing, redirecting, and encrypting data across a network. It aims to be your network Swiss Army knife, handling a wide variety of security testing and administration tasks. 以前在手机上装 busybox ，总听人讲到什么『瑞士军刀』。哥们儿小地方的娃，没见过大场面，这回总算在网上找到张图片。总的来说，Ncat 还是对得起这个称号的，小巧但功能强悍。这里只简要地介绍下有趣的功能。关于安装，Ncat 其实是 nmap 项目对传统的 Netcat（即 nc 命令）的重写，是包含在 nmap 安装包里的，具体可参考官网。不做赘述。 一、Ncat 作为浏览器命令示例：ncat -C scanme.nmap.org 80其中 -C 是格式化选项，80 指代端口号（ web 服务监听）。输出结果如下：需要注意的是，该命令是以交互的方式执行的。即输入 ncat -C scanme.nmap.org 80 和 回车 后，接着继续输入 GET / HTTP/1.0 ，再敲击两次 回车 。即可获取目标网站的 HTML 文档内容。 二、监听模式（模拟 web 服务器）命令示例：ncat -l 8080 &lt; hello.http其中 hello.http 的文件内容：1234567HTTP/1.0 200 OK&lt;html&gt; &lt;body&gt; &lt;h1&gt;Hello, world!&lt;/h1&gt; &lt;/body&gt;&lt;/html&gt; -l 即 –listen（监听）。实际效果如下：需要注意的是，访问一次后程序即自动退出。 三、执行命令（远程 shell）命令示例：ncat -l 8080 --exec &quot;/bin/echo Hello.&quot;效果如下：进一步，可以开启一个远程 shell 供其他设备连接。命令如下：ncat -l 8022 --exec &quot;/bin/bash -i&quot;效果如下： Ncat 同时还支持 sh 脚本（ –sh-exec ）和 lua 脚本（ –lua-exec ） 注：以上情形均支持局域网远程访问，访问时将 IP 地址改为对应数字。截图中为了方便，只在本地测试。 四、访问控制 只允许指定客户端连接：ncat -l --allow 10.2.67.204 只拒绝指定客户端连接：ncat -l --deny 10.2.67.204 只允许指定网段的本地 IP： ncat -l --allow 10.2.67.0/24 ncat -l --allow 10.2.67.0-255 从文件中获取允许访问的地址列表：ncat -l --allowfile trusted_hosts.txt 设置最大连接数为5：ncat -l –max-conns 5五、文件传输 #####传输单个文件 接收者监听：receiver$ ncat -l &gt; outputfilesender$ ncat --send-only receiver_ip &lt; inputfile 发送者监听：sender$ ncat -l --send-only &lt; inputfilereceiver$ ncat sender_ip &gt; outputfile #####传输目录receiver$ ncat -l | tar xzvf -sender$ tar czvf - dirname | ncat --send-only receiver_ip效果如下： #####传输磁盘镜像（压缩）receiver$ ncat -l | bzip2 -d &gt; sender-hda.imagesender$ cat /dev/hda | bzip2 | ncat --send-only receiver_ip六、聊天 #####双人聊天host1$ ncat -lhost2$ ncat host1 #####多人聊天server$ ncat -l --chatclients$ ncat server_ip效果如下：七、简易 web 服务器 Linux 用户：ncat -lk -p 8080 --sh-exec &quot;echo -e &#39;HTTP/1.1 200 OK\r\n&#39;; cat index.html&quot; Windows 用户：ncat -lk -p 8080 --sh-exec &quot;echo HTTP/1.1 200 OK&amp; echo(&amp;type index.html&quot;八、流媒体视频server$ $cat video.avi | ncat -lclient$ ncat server_ip | mplayer -vo x11 -cache 3000 -效果如下：]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Admin</tag>
        <tag>Tools</tag>
        <tag>Trick</tag>
        <tag>Networking</tag>
      </tags>
  </entry>
</search>
